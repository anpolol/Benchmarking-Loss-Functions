{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import numpy as np\n",
    "from modules.model import Net\n",
    "from sklearn.metrics import f1_score\n",
    "from modules.sampling import Sampler, SamplerContextMatrix, SamplerRandomWalk,SamplerFactorization,SamplerAPP\n",
    "from datetime import datetime\n",
    "import random\n",
    "from torch_geometric.data import GraphSAINTNodeSampler\n",
    "import pickle\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "import collections\n",
    "from torch_geometric.datasets import Planetoid,WikipediaNetwork,Actor,WebKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "df=pd.read_csv('data_analysis_realdata.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df['dataset']=='Cora') & (df['conv']=='GCN')]['test acc micro'].max(),df[(df['dataset']=='Cora') & (df['conv']=='GCN')]['test acc micro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df['dataset']=='Citeseer') & (df['conv']=='GCN')]['test acc micro'].max(),df[(df['dataset']=='Citeseer') & (df['conv']=='GCN')]['test acc micro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df['dataset']=='Cornell') & (df['conv']=='GCN')]['test acc micro'].max(),df[(df['dataset']=='Cornell') & (df['conv']=='GCN')]['test acc micro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df['dataset']=='chameleon') & (df['conv']=='GCN')]['test acc micro'].max(), df[(df['dataset']=='chameleon') & (df['conv']=='GCN')]['test acc micro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df['dataset']=='Wisconsin') & (df['conv']=='GCN') ]['test acc micro'].max(),df[(df['dataset']=='Wisconsin') & (df['conv']=='GCN') ]['test acc micro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df['dataset']=='Texas') & (df['conv']=='GCN') ]['test acc micro'].max() ,df[(df['dataset']=='Texas') & (df['conv']=='GCN') ]['test acc micro'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=list(dict(collections.Counter(df['loss'])).keys())\n",
    "\n",
    "attrs=['label assortativity','feature assortativity', 'cluster coefficient', 'average shortest path','average degree']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size' : 25}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau as Kcorr\n",
    "from scipy.stats import pearsonr as Pcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('final_data.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "losses = list(dict(collections.Counter(df['loss'])).keys())\n",
    "\n",
    "su=0\n",
    "ff=0\n",
    "for i,loss1 in enumerate(losses):\n",
    "    for loss2 in losses[i+1:]:\n",
    "       # print(loss1,loss2)\n",
    "        su+=1\n",
    "        x=df[(df['loss']==loss1) & (df['conv'] == 'GCN' )]['test acc micro']\n",
    "        y=df[(df['loss']==loss2) & (df['conv'] == 'GCN' )]['test acc micro']\n",
    "        if Pcorr(x,y)[0]<0.98:\n",
    "            ff+=1   \n",
    "print(ff,su)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON OF DENSITY OF BENCHMARK SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_excel('benchmark_space_ideal.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "df=pd.read_csv('final_data.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size' : 20}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=px.parallel_coordinates(df,dimensions=['label assortativity', 'feature assortativity', 'cluster coefficient', 'average shortest path', 'average degree'])\n",
    "fig2.update_layout(\n",
    "    font=dict(\n",
    "        size=22,  # Set the font size here\n",
    "        color = 'black'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2=px.parallel_coordinates(df_2,dimensions=['label assortativity', 'feature assortativity', 'cluster coefficient', 'average shortest path', 'average degree'])\n",
    "fig2.update_layout(\n",
    "    font=dict(\n",
    "        size=22,  # Set the font size here\n",
    "        color = 'black'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df.groupby(['group','label assortativity']).mean()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('label assortativity')\n",
    "df_analysis['newlevel'] = 'label assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs:\n",
    "    df_1 = df.groupby(['group',attr]).mean()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group'],how='left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attr in ['label assortativity']+attrs:\n",
    "    df_1 = df.groupby(['group',attr]).mean()['test acc macro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    sns.heatmap(df_1,cmap='GnBu')\n",
    "    plt.title('macro')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df.groupby(['group','loss','label assortativity']).std()['test acc micro']\n",
    "\n",
    "df_analysis = df_analysis.unstack('label assortativity')\n",
    "df_analysis['newlevel'] = 'label assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[1:]:\n",
    "    df_1 = df.groupby(['group','loss',attr]).std()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df.groupby(['group','loss','label assortativity']).mean()['test acc micro']\n",
    "\n",
    "df_analysis = df_analysis.unstack('label assortativity')\n",
    "df_analysis['newlevel'] = 'label assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[1:]:\n",
    "    df_1 = df.groupby(['group','loss',attr]).mean()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# la=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[(df['label assortativity']==0.1) ]\n",
    "\n",
    "df_analysis = df_analysis.groupby(['group','loss','feature assortativity']).mean()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('feature assortativity')\n",
    "df_analysis['newlevel'] = 'feature assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[2:]:\n",
    "    df_1 =  df[(df['label assortativity']==0.1) ].groupby(['group','loss',attr]).mean()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[(df['label assortativity']==0.1)]\n",
    "\n",
    "df_analysis = df_analysis.groupby(['group','loss','feature assortativity']).std()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('feature assortativity')\n",
    "df_analysis['newlevel'] = 'feature assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[2:]:\n",
    "    df_1 =  df[(df['label assortativity']==0.1) ].groupby(['group','loss',attr]).std()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# la=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[(df['label assortativity']==0.5)]\n",
    "df_analysis = df_analysis.groupby(['group','loss','feature assortativity']).mean()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('feature assortativity')\n",
    "df_analysis['newlevel'] = 'feature assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[2:]:\n",
    "    df_1 = df[(df['label assortativity']==0.5)].groupby(['group','loss',attr]).mean()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[(df['label assortativity']==0.5)]\n",
    "df_analysis = df_analysis.groupby(['group','loss','feature assortativity']).std()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('feature assortativity')\n",
    "df_analysis['newlevel'] = 'feature assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[2:]:\n",
    "    df_1 = df[(df['label assortativity']==0.5) ].groupby(['group','loss',attr]).std()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# la=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[(df['label assortativity']==0.9) ]\n",
    "df_analysis = df_analysis.groupby(['group','loss','feature assortativity']).mean()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('feature assortativity')\n",
    "df_analysis['newlevel'] = 'feature assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[2:]:\n",
    "    df_1 = df[(df['label assortativity']==0.9)].groupby(['group','loss',attr]).mean()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[(df['label assortativity']==0.9) ]\n",
    "df_analysis = df_analysis.groupby(['group','loss','feature assortativity']).std()['test acc micro']\n",
    "df_analysis = df_analysis.unstack('feature assortativity')\n",
    "df_analysis['newlevel'] = 'feature assortativity'\n",
    "df_analysis=df_analysis.set_index('newlevel', append=True).unstack('newlevel')\n",
    "\n",
    "for attr in attrs[2:]:\n",
    "    df_1 = df[(df['label assortativity']==0.9) ].groupby(['group','loss',attr]).std()['test acc micro']\n",
    "    df_1 = df_1.unstack(attr)\n",
    "    df_1['newlevel'] = attr\n",
    "    df_1 = df_1.set_index('newlevel', append=True).unstack('newlevel')\n",
    "    \n",
    "    df_analysis = pd.merge(df_analysis,df_1,on=['group','loss'],how='left')\n",
    "df_analysis=df_analysis.round(decimals=2)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "df=pd.read_csv('final_data.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby=df[['conv','dataset','test acc micro']].groupby(['conv','dataset'],as_index=False).max()\n",
    "df_merge = pd.merge(df_groupby,df,on=['conv','dataset','test acc micro'],how='left')\n",
    "list_of_dicts=[]\n",
    "\n",
    "for conv in ['GCN','GAT','SAGE']:\n",
    "    orders = collections.Counter(df_merge[df_merge['conv']==conv]['loss'])\n",
    "    list_of_dicts.append(orders)\n",
    "new_dict=list_of_dicts[0]+list_of_dicts[1]+list_of_dicts[2]\n",
    "\n",
    "global_rank=(sorted(new_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "rank_GCN=(sorted(list_of_dicts[0].items(), key=lambda x: x[1], reverse=True))\n",
    "rank_GAT=(sorted(list_of_dicts[1].items(), key=lambda x: x[1], reverse=True))\n",
    "rank_SAGE=(sorted(list_of_dicts[2].items(), key=lambda x: x[1], reverse=True))\n",
    "print(rank_SAGE,rank_GCN,rank_GAT,global_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(rank_GCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('final_data.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in features:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "        plt.plot( list(df[ (df['conv'] == conv)].groupby(feat).mean().index),  df[(df['conv']==conv)].groupby(feat).mean()['test acc micro'],label=conv,marker='*', linewidth = 1)\n",
    "    plt.legend()\n",
    "    plt.title(feat)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boxplots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boxplots = df[(df['loss' ]=='VERSE_Adj')|(df['loss']=='HOPE_RPR') | (df['loss']=='LapEigen') | (df['loss']=='VERSE_SR') | (df['loss' ]=='DeepWalk')| (df['loss' ]=='Force2Vec')]\n",
    "features=['label assortativity','feature assortativity','cluster coefficient','average shortest path','average degree']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistically significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA\n",
    "losses=list(dict(collections.Counter(df['loss'])).keys())\n",
    "import scipy.stats as stats\n",
    "to_test = []\n",
    "for loss in losses:\n",
    "    to_test.append(df[df['loss']==loss]['test acc micro'])\n",
    "\n",
    "fvalue, pvalue = stats.f_oneway(to_test[0],to_test[1],to_test[2],to_test[3],to_test[4],to_test[5],to_test[6],to_test[7],to_test[8],to_test[9],to_test[10],to_test[11],to_test[12])\n",
    "#fvalue, pvalue = stats.f_oneway(df[df['loss']=='HOPE_Katz']['test acc micro'],df[df['loss']=='HOPE_CN']['test acc micro'], df[df['loss']=='HOPE_RPR']['test acc micro'], df[df['loss']=='LapEigen']['test acc micro'],df[df['loss']=='LINE']['test acc micro'],df[df['loss']=='VERSE_PPR']['test acc micro'], df[df['loss']=='GraphFactorization']['test acc micro'], df[df['loss']=='HOPE_AA']['test acc micro'], df[df['loss']=='Node2Vec']['test acc micro'], df[df['loss']=='VERSE_Adj']['test acc micro'],df[df['loss']=='DeepWalk']['test acc micro'],df[df['loss']=='APP']['test acc micro'],df[df['loss']=='VERSE_SR']['test acc micro'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#внутри группы GF\n",
    "fvalue, pvalue = stats.f_oneway(to_test[0],to_test[1],to_test[2],to_test[6],to_test[7])\n",
    "print(pvalue<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#внутри группы RandomWalks\n",
    "fvalue, pvalue = stats.f_oneway(to_test[1],to_test[8])\n",
    "print(pvalue<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#внутри группы matrix sim\n",
    "fvalue, pvalue = stats.f_oneway(to_test[4],to_test[5],to_test[9],to_test[11],to_test[12])\n",
    "print(pvalue<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "losses_2=['LINE','VERSE_SR','VERSE_PPR','VERSE_Adj','APP']\n",
    "for i,loss1 in enumerate(losses_2):\n",
    "    for loss2 in losses_2[i+1:]:\n",
    "       # print(loss1,loss2)\n",
    "       # print(loss)\n",
    "        v1 = df[df['loss']==loss1]['test acc micro']\n",
    "        v2 = df[df['loss']==loss2]['test acc micro']\n",
    "\n",
    "        res = ttest_ind(v1, v2)\n",
    "\n",
    "        if (res.pvalue <= 0.05):\n",
    "            print(loss1,loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВЫБИВАЕТСЯ ТОЛЬКО VERSE ADJ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
