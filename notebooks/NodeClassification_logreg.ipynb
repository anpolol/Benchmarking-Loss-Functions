{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch_geometric.datasets import Planetoid, WikipediaNetwork, Actor, WebKB\n",
    "\n",
    "from modules.model import Net\n",
    "from modules.sampling import SamplerContextMatrix, SamplerRandomWalk, SamplerFactorization, SamplerAPP\n",
    "\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = pd.read_csv('../results/final_data.csv') #pd.read_csv('../classification_on_features.csv')\n",
    "analysis = analysis.drop(columns='Unnamed: 0') \n",
    "analysis\n",
    "\n",
    "synthetic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "42.0"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(analysis[(analysis['loss']=='HOPE_RPR') & (analysis['label assortativity']==0.1)])/3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "benchmark_data_dir = \"../data_benchmark/\"\n",
    "help_data = \"../data_help/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "if synthetic:\n",
    "    datasets_names=[]\n",
    "    l_a_trgt = random.choice([0.1,0.5,0.9])\n",
    "    f_a_trgt = random.choice([0.1,0.5,0.9])\n",
    "    cl_trgt = random.choice([0.01,0.1,0.2,0.3,0.5])\n",
    "    asp_trgt =  random.choice([2,3,4,5,6,7])\n",
    "    a_deg_trgt =  random.choice([2,5,10,15,20,25,30,35,40])\n",
    "    datasets_names = [(l_a_trgt,f_a_trgt,cl_trgt,asp_trgt,a_deg_trgt)]\n",
    "    #for l_a_trgt in [0.1,0.5,0.9]:\n",
    "    #            for f_a_trgt in [0.1,0.5,0.9]:\n",
    "    #                for cl_trgt in [0.01,0.1,0.2,0.3,0.5]:\n",
    "    #                    for asp_trgt in [2,3,4,5,6,7]:\n",
    "    #                        for a_deg_trgt in [2,5,10,15,20,25,30,35,40]:\n",
    "    #                            datasets_names.append((l_a_trgt,f_a_trgt,cl_trgt,asp_trgt,a_deg_trgt))\n",
    "    def data_load(name):\n",
    "        x = torch.tensor(np.load(f'{benchmark_data_dir}/graph_'+str(name)+'_attr.npy'),dtype=torch.float)\n",
    "        edge_list = torch.tensor(np.load(f'{benchmark_data_dir}/graph_'+str(name)+'_edgelist.npy')).t()\n",
    "        y =  torch.tensor(np.load(f'{benchmark_data_dir}/graph_'+str(name)+'_labels.npy'))\n",
    "        data=Data(x=x,edge_index=edge_list,y=y)\n",
    "        indices=list(range(len(data.x)))\n",
    "\n",
    "        train_indices = torch.tensor(indices[:int(0.7*len(indices)+1)])\n",
    "        val_indices = torch.tensor(indices[int(0.7*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        test_indices = torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        train_mask = torch.tensor([False]*len(indices))\n",
    "        test_mask = torch.tensor([False]*len(indices))\n",
    "        val_mask = torch.tensor([False]*len(indices))\n",
    "        train_mask[train_indices] =True\n",
    "        test_mask[test_indices]=True\n",
    "        val_mask[val_indices]=True\n",
    "        return data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask\n",
    "else:\n",
    "    datasets_names = ['Cornell','Texas','Wisconsin','Actor','Pubmed','squirrel']\n",
    "\n",
    "    def data_load(name):\n",
    "        if name == 'Cora' or name == 'Citeseer' or name == 'Pubmed':\n",
    "            data = Planetoid(root='/tmp/'+str(name), name=name,transform=T.NormalizeFeatures())[0]\n",
    "        elif name == 'Actor':\n",
    "            data = Actor(root='/tmp/actor',transform=T.NormalizeFeatures())[0]\n",
    "        elif name == \"Cornell\" or name==\"Texas\" or name==\"Wisconsin\":\n",
    "            data = WebKB(root='/tmp/'+str(name),name=name,transform=T.NormalizeFeatures())[0]\n",
    "        elif name == 'squirrel' or name=='chameleon':\n",
    "            data = WikipediaNetwork(root='/tmp/'+str(name), name=name,transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "        indices=list(range(len(data.x)))\n",
    "\n",
    "        train_indices = torch.tensor(indices[:int(0.7*len(indices)+1)])\n",
    "        val_indices = torch.tensor(indices[int(0.7*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        test_indices = torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        train_mask = torch.tensor([False]*len(indices))\n",
    "        test_mask = torch.tensor([False]*len(indices))\n",
    "        val_mask = torch.tensor([False]*len(indices))\n",
    "        train_mask[train_indices] =True\n",
    "        test_mask[test_indices]=True\n",
    "        val_mask[val_indices]=True\n",
    "        return data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "class Main:\n",
    "    def __init__(self,name, conv, device, loss_function, mode):\n",
    "        data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask = data_load(name)\n",
    "        self.Conv = conv\n",
    "        self.device = device\n",
    "        self.x = data.x\n",
    "        self.y = data.y.squeeze()\n",
    "        self.data=data.to(device)\n",
    "        self.loss = loss_function\n",
    "        self.mode = mode\n",
    "        self.datasetname=name\n",
    "        self.train_indices =train_indices# torch.tensor(indices[:int(0.7*len(indices)+1)])\n",
    "        self.val_indices =val_indices# torch.tensor(indices[int(0.7*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        self.test_indices = test_indices#torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        self.train_mask = train_mask#torch.tensor([False]*len(indices))\n",
    "        self.test_mask = test_mask#torch.tensor([False]*len(indices))\n",
    "        self.val_mask =val_mask# torch.tensor([False]*len(indices))\n",
    "        self.flag = self.loss[\"flag_tosave\"]\n",
    "        super(Main, self).__init__()\n",
    "    def sampling(self,Sampler, epoch, nodes, loss):\n",
    "        if (epoch == 0): \n",
    "            if self.flag:  \n",
    "                if \"alpha\" in self.loss: \n",
    "                    name_of_file = self.datasetname+\"_samples_\"+loss[\"Name\"]+\"_alpha_\"+str(loss[\"alpha\"])+\".pickle\"\n",
    "                elif \"betta\" in self.loss: \n",
    "                    name_of_file = self.datasetname+\"_samples_\"+loss[\"Name\"]+\"_betta_\"+str(loss[\"betta\"])+\".pickle\"\n",
    "                else:\n",
    "                    name_of_file = self.datasetname+\"_samples_\"+loss[\"Name\"]+\".pickle\"             \n",
    "                \n",
    "                if os.path.exists(f'{help_data}/'+str(name_of_file)):\n",
    "                    with open(f'{help_data}/'+str(name_of_file),'rb') as f:\n",
    "                        self.samples = pickle.load(f)\n",
    "                else:\n",
    "                    self.samples = Sampler.sample(nodes) \n",
    "                    with open(f'{help_data}/'+str(name_of_file),'wb') as f:\n",
    "                        pickle.dump(self.samples,f)\n",
    "            else:\n",
    "                self.samples = Sampler.sample(nodes)\n",
    " \n",
    "    def train(self, model,data,optimizer,Sampler,train_loader,dropout,epoch,loss):\n",
    "        model.train()   \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "       # print('train loader',len(train_loader))\n",
    "        \n",
    "        if model.mode == 'unsupervised':\n",
    "            if model.conv=='GCN':\n",
    "                arr = torch.nonzero(self.train_mask == True)\n",
    "                indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "                #print('before',data.x)\n",
    "                out = model.inference(data.to(self.device),dp=dropout)\n",
    "                #print('after',out, sum(sum(out)))\n",
    "                samples = self.sampling(Sampler,epoch, indices_of_train_data,loss)\n",
    "                loss = model.loss(out[self.train_mask], self.samples)\n",
    "                #print('loss',loss)\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    adjs = [adj.to(self.device) for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id.to(self.device)].to(self.device), adjs)\n",
    "                    self.sampling(Sampler,epoch,n_id[:batch_size],loss)                 \n",
    "                    loss = model.loss(out, self.samples)#pos_batch.to(device), neg_batch.to(device))\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)\n",
    "        elif model.mode== 'supervised':\n",
    "            if model.conv=='GCN':\n",
    "                out = model.inference(data.to(self.device),dp=dropout)\n",
    "                y=self.y.to(self.device)\n",
    "                loss = model.loss_sup(out[self.train_mask],y[self.train_mask])\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    adjs = [adj.to(self.device) for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id].to(self.device), adjs)\n",
    "                    y = self.y.to(self.device)\n",
    "                    loss = model.loss_sup(out,y[n_id[:batch_size]])\n",
    "                    total_loss += loss\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)       \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, model, data,hidden_layer_for_classifier):\n",
    "        model.eval()\n",
    "        out = model.inference(data.to(self.device))\n",
    "\n",
    "        y_true = self.y.cpu().detach().numpy()\n",
    "        self.y=self.y.cpu()\n",
    "        if model.mode == 'supervised':\n",
    "            y_true = self.y.unsqueeze(-1)\n",
    "            y_pred = out.cpu().argmax(dim=-1, keepdim=True)\n",
    "\n",
    "            accs_micro = []\n",
    "            accs_macro = []\n",
    "            for mask in [self.train_mask,self.test_mask,self.val_mask]:\n",
    "                accs_micro += [accuracy_score(self.y.detach()[mask].cpu().numpy(),y_pred[mask])]\n",
    "                accs_macro += [accuracy_score(self.y.detach()[mask].cpu().numpy(),y_pred[mask])]\n",
    "\n",
    "            return out,accs_micro,accs_macro\n",
    "\n",
    "        elif model.mode == 'unsupervised':\n",
    "               # clf = LogisticRegression(max_iter = 3000,C=c).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "\n",
    "                clf = MLPClassifier(random_state=1, max_iter=300,hidden_layer_sizes=(hidden_layer_for_classifier)).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "                accs_micro = []\n",
    "                accs_macro = []\n",
    "                for mask in [self.train_mask,self.test_mask,self.val_mask]:\n",
    "                    accs_micro += [accuracy_score(self.y.detach()[mask].cpu().numpy(),clf.predict(out.cpu().detach()[mask].numpy()))]\n",
    "                    accs_macro += [accuracy_score(self.y.detach()[mask].cpu().numpy(),clf.predict(out.cpu().detach()[mask].numpy()))]\n",
    "                return out, accs_micro,accs_macro\n",
    "\n",
    "    def run(self,params):\n",
    "\n",
    "        hidden_layer=params['hidden_layer']\n",
    "        out_layer=params['out_layer']\n",
    "        dropout=params['dropout']\n",
    "        size=params['size of network, number of convs']\n",
    "        learning_rate=params['lr']\n",
    "        hidden_layer_for_classifier=params['hidden_layer_for_classifier']\n",
    "\n",
    "        #hidden_layer=64,out_layer=128,dropout=0.0,size=1,learning_rate=0.001,c=100\n",
    "        classifier = \"logistic regression\"\n",
    "        train_loader = NeighborSampler(self.data.edge_index, node_idx=self.train_mask, batch_size = int(sum(self.train_mask)), sizes=[-1]*size)\n",
    "\n",
    "        Sampler = self.loss[\"Sampler\"]\n",
    "        LossSampler = Sampler(self.datasetname, self.data, device=device, mask=self.train_mask, loss_info=self.loss, help_dir=help_data)\n",
    "        model = Net(dataset = self.data,mode=self.mode,conv=self.Conv,loss_function=self.loss,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = (size),dropout = dropout)\n",
    "        model.to(self.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)\n",
    "                #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "        scheduler=lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "        losses=[]\n",
    "        train_accs_mi=[]\n",
    "        test_accs_mi=[]\n",
    "        val_accs=[]\n",
    "        name_of_plot='conv: '+model.conv+', mode: '+model.mode+', loss from '+self.loss[\"Name\"]\n",
    "        train_accs_ma = []\n",
    "        test_accs_ma = []\n",
    "        print(name_of_plot)\n",
    "        log = 'Loss: {:.4f}, Epoch: {:03d}, Train acc micro: {:.4f}, Test acc micro: {:.4f},Train acc macro: {:.4f}, Test acc macro: {:.4f}'\n",
    "\n",
    "        for epoch in range(100):\n",
    "                    print(epoch)\n",
    "                    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,self.loss)\n",
    "                    losses.append(loss.detach().cpu())\n",
    "                    out, [train_acc_mi, test_acc_mi,val_acc_mi],[train_acc_ma, test_acc_ma,val_acc_ma] = self.test(model,self.data,hidden_layer_for_classifier)\n",
    "                    train_accs_mi.append(train_acc_mi)\n",
    "                    test_accs_mi.append(test_acc_mi)\n",
    "                    train_accs_ma.append(train_acc_ma)\n",
    "                    test_accs_ma.append(test_acc_ma)\n",
    "                    print(log.format(loss, epoch, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma))\n",
    "        #np.save('../data_help/embedings_'+str(self.datasetname)+str(self.loss['name'])+'.npy', out.cpu().numpy())\n",
    "                    \n",
    "                     #scheduler.step()\n",
    "        print(log.format(loss, epoch, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma))\n",
    "        plt.plot(losses)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        plt.plot(test_accs_mi)\n",
    "        plt.title(name_of_plot+' test f1 micro')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "                  \n",
    "        plt.plot(test_accs_ma)\n",
    "        plt.title(name_of_plot+' test f1 macro')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        return train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MainOptuna(Main):\n",
    "    def objective(self,trial):\n",
    "        # Integer parameter\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [32,64,128])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5,step = 0.1)\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [1,2,3])\n",
    "        Conv = self.Conv\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-3,1e-2)\n",
    "\n",
    "        #c =trial.suggest_categorical(\"c\",  [0.001, 0.01, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,10,20,30,100])\n",
    "        hidden_layer_for_classifier = trial.suggest_categorical(\"hidden_layer_for_classifier\", [32,64,128,256])\n",
    "        # варьируем параметры\n",
    "        loss_to_train={}\n",
    "        for name in self.loss:\n",
    "\n",
    "            if type(self.loss[name]) == list :\n",
    "                if len(self.loss[name]) == 3:\n",
    "                    var = trial.suggest_int(name,self.loss[name][0],self.loss[name][1],step=self.loss[name][2])\n",
    "                    loss_to_train[name] = var\n",
    "                elif len(self.loss[name]) == 2:\n",
    "                    var_2 = trial.suggest_float(name,self.loss[name][0],self.loss[name][1])\n",
    "                    loss_to_train[name] = var_2\n",
    "                else:\n",
    "                    var_3 = trial.suggest_categorical(name, self.loss[name])\n",
    "                    loss_to_train[name] = var_3\n",
    "            else:\n",
    "                loss_to_train[name] = self.loss[name]\n",
    "        if name =='q' and type(self.loss[name]) == list:\n",
    "            var_5 = trial.suggest_categorical('p', self.loss['p'])\n",
    "            var_4 = trial.suggest_categorical('q', self.loss[name])\n",
    "            if var_4 > 1:\n",
    "                var_4=1\n",
    "            if var_5 < var_4:\n",
    "                var_5=var_4\n",
    "            loss_to_train['q'] = var_4\n",
    "            loss_to_train['p'] = var_5\n",
    "\n",
    "        Sampler =loss_to_train[\"Sampler\"]\n",
    "        model = Net(dataset = self.data,mode=self.mode,conv=Conv,loss_function=loss_to_train,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = size,dropout = dropout)\n",
    "        train_loader = NeighborSampler(self.data.edge_index, batch_size = int(sum(self.train_mask)),node_idx=self.train_mask, sizes=[-1]*size)\n",
    "\n",
    "        LossSampler = Sampler(self.datasetname,self.data,device=self.device,mask=self.train_mask,loss_info=loss_to_train, help_dir=help_data)\n",
    "        model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)\n",
    "\n",
    "        for epoch in range(50):\n",
    "            loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,loss_to_train)\n",
    "        _, [train_acc_mi, test_acc_mi,val_acc_mi], [train_acc_ma, test_acc_ma,val_acc_ma] = self.test(model=model, data=self.data, hidden_layer_for_classifier=hidden_layer_for_classifier)\n",
    "        trial.report(np.sqrt(val_acc_mi*val_acc_ma), epoch)\n",
    "        return np.sqrt(val_acc_mi*val_acc_ma)\n",
    "\n",
    "    \n",
    "    def run(self,number_of_trials):\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss,\"+str(self.Conv)+\" conv\")\n",
    "        study.optimize(self.objective,n_trials = number_of_trials)\n",
    "        trial = study.best_trial\n",
    "        return trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#loss functions\n",
    "\n",
    "VERSE_PPR =  {\"Name\": \"VERSE_PPR\",\"C\": \"PPR\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]}\n",
    "VERSE_Adj =  {\"Name\": \"VERSE_Adj\",\"C\": \"Adj\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n",
    "\n",
    "VERSE_SR =  {\"Name\": \"VERSE_SimRank\",\"C\": \"SR\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"Sampler\":SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk_length\":[5, 10, 15, 20],\"walks_per_node\":[5, 10, 15, 20],\"num_negative_samples\":[1,6, 11, 16, 21],\"context_size\" : [5, 10, 15, 20],\"p\":1,\"q\":1,\"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\" : SamplerRandomWalk } #Проблемы с памятью после того, как увеличила количество тренировочных данных\n",
    "Node2Vec = {\"Name\": \"Node2Vec\",\"walk_length\":[5, 10, 15, 20],\"walks_per_node\":[5, 10, 15, 20],\"num_negative_samples\":[1,6, 11, 16, 21],\"context_size\" : [5, 10, 15, 20],\"p\": [0.25, 0.50, 1, 2, 4] ,\"q\":[0.25, 0.50, 1, 2, 4], \"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\": SamplerRandomWalk}#то же самое \n",
    "APP ={\"Name\": \"APP\",\"C\": \"PPR\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerAPP}\n",
    "HOPE_Katz = {\"Name\": \"HOPE_Katz\",\"C\":\"Katz\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"betta\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} #проверить\n",
    "\n",
    "HOPE_RPR = {\"Name\": \"HOPE_RPR\",\"C\":\"RPR\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} #проверить\n",
    "HOPE_CN = {\"Name\": \"HOPE_CommonNeighbors\",\"C\":\"CN\",\"loss var\": \"Factorization\",\"flag_tosave\":False,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} \n",
    "HOPE_AA = {\"Name\": \"HOPE_AdamicAdar\",\"C\":\"AA\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} \n",
    "\n",
    "LapEigen = {\"Name\": \"LaplacianEigenMaps\", \"C\":\"Adj\",\"loss var\": \"Laplacian EigenMaps\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]}\n",
    "LINE = {\"Name\": \"LINE\",\"C\": \"Adj\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n",
    "GraphFactorization = {\"Name\": \"Graph Factorization\",\"C\":\"Adj\",\"loss var\": \"Factorization\",\"flag_tosave\":False,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} \n",
    "\n",
    "Force2Vec = {\"Name\": \"Force2Vec\",\"C\": \"Adj\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Force2Vec\",\"flag_tosave\":False,\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "analysis = pd.DataFrame(columns=['loss','conv','dataset','train acc micro','test acc micro','train acc macro','test acc macro'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "       loss  conv    dataset  train acc micro  test acc micro  \\\n0        no    no  Wisconsin         0.982955        0.900000   \n1        no    no      Texas         0.992248        0.750000   \n2        no    no      Texas         0.868217        0.694444   \n3        no    no  Wisconsin         0.880682        0.880000   \n4  HOPE_RPR  SAGE  Wisconsin         0.971591        0.920000   \n5  HOPE_RPR  SAGE      Texas         0.891473        0.722222   \n6  HOPE_RPR  SAGE      Texas         0.968992        0.722222   \n7  HOPE_RPR  SAGE  Wisconsin         0.988636        0.900000   \n\n   train acc macro  test acc macro     clf  \n0         0.982955        0.900000     MLP  \n1         0.992248        0.750000     MLP  \n2         0.868217        0.694444  logreg  \n3         0.880682        0.880000  logreg  \n4         0.971591        0.920000  logreg  \n5         0.891473        0.722222  logreg  \n6         0.968992        0.722222     MLP  \n7         0.988636        0.900000     MLP  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>conv</th>\n      <th>dataset</th>\n      <th>train acc micro</th>\n      <th>test acc micro</th>\n      <th>train acc macro</th>\n      <th>test acc macro</th>\n      <th>clf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>no</td>\n      <td>no</td>\n      <td>Wisconsin</td>\n      <td>0.982955</td>\n      <td>0.900000</td>\n      <td>0.982955</td>\n      <td>0.900000</td>\n      <td>MLP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>no</td>\n      <td>no</td>\n      <td>Texas</td>\n      <td>0.992248</td>\n      <td>0.750000</td>\n      <td>0.992248</td>\n      <td>0.750000</td>\n      <td>MLP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>no</td>\n      <td>no</td>\n      <td>Texas</td>\n      <td>0.868217</td>\n      <td>0.694444</td>\n      <td>0.868217</td>\n      <td>0.694444</td>\n      <td>logreg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>no</td>\n      <td>no</td>\n      <td>Wisconsin</td>\n      <td>0.880682</td>\n      <td>0.880000</td>\n      <td>0.880682</td>\n      <td>0.880000</td>\n      <td>logreg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOPE_RPR</td>\n      <td>SAGE</td>\n      <td>Wisconsin</td>\n      <td>0.971591</td>\n      <td>0.920000</td>\n      <td>0.971591</td>\n      <td>0.920000</td>\n      <td>logreg</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HOPE_RPR</td>\n      <td>SAGE</td>\n      <td>Texas</td>\n      <td>0.891473</td>\n      <td>0.722222</td>\n      <td>0.891473</td>\n      <td>0.722222</td>\n      <td>logreg</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>HOPE_RPR</td>\n      <td>SAGE</td>\n      <td>Texas</td>\n      <td>0.968992</td>\n      <td>0.722222</td>\n      <td>0.968992</td>\n      <td>0.722222</td>\n      <td>MLP</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HOPE_RPR</td>\n      <td>SAGE</td>\n      <td>Wisconsin</td>\n      <td>0.988636</td>\n      <td>0.900000</td>\n      <td>0.988636</td>\n      <td>0.900000</td>\n      <td>MLP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-16 16:39:25,862]\u001B[0m A new study created in memory with name: HOPE_RPR loss,SAGE conv\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:26,791]\u001B[0m Trial 0 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005644814149460171, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.3155151033570005}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:28,366]\u001B[0m Trial 1 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008100369621738716, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.07040946219481936}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:29,344]\u001B[0m Trial 2 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0078091937845522754, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.32825511525536244}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:30,402]\u001B[0m Trial 3 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007687775771845637, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.7921166732045489}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:31,928]\u001B[0m Trial 4 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009089982214813677, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.9291870100067023}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:33,324]\u001B[0m Trial 5 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007163779647517923, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.14927670809858928}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:34,246]\u001B[0m Trial 6 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005630468203077521, 'hidden_layer_for_classifier': 32, 'alpha': 0.6, 'lmbda': 0.4655897409960984}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:35,815]\u001B[0m Trial 7 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005991249160361014, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.21298347457321576}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:36,914]\u001B[0m Trial 8 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006111741415275862, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.42599518496835176}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:38,376]\u001B[0m Trial 9 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007399474455795945, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.902510096939578}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:39,476]\u001B[0m Trial 10 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005138893085221158, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.649988397111716}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:40,301]\u001B[0m Trial 11 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005082836555340128, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.6438172227373774}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:41,040]\u001B[0m Trial 12 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005050758855142186, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.6424166627825914}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:42,735]\u001B[0m Trial 13 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006652448555521099, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.6414461515604457}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:44,501]\u001B[0m Trial 14 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006548220042266198, 'hidden_layer_for_classifier': 32, 'alpha': 0.5, 'lmbda': 0.31528054236792075}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:45,371]\u001B[0m Trial 15 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009636035924429838, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.5545720553189215}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:46,210]\u001B[0m Trial 16 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005565814937474587, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.791646469362603}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:48,415]\u001B[0m Trial 17 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006757259136070552, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.3439896024517025}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:49,297]\u001B[0m Trial 18 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009947809389680753, 'hidden_layer_for_classifier': 32, 'alpha': 0.7, 'lmbda': 0.0011463563278459876}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:50,408]\u001B[0m Trial 19 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008525203826197671, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.7892726729178063}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:51,495]\u001B[0m Trial 20 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005643828973155652, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.991427466321936}. Best is trial 0 with value: 0.8333333333333334.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:52,331]\u001B[0m Trial 21 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009992521033113693, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.5049323447660716}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:53,255]\u001B[0m Trial 22 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009896250475403046, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.5381511373166727}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:54,177]\u001B[0m Trial 23 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008860706175409514, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2130562714781304}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:55,118]\u001B[0m Trial 24 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00613810569984391, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.804718670607963}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:56,028]\u001B[0m Trial 25 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0055286705665956, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.3967861970943048}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:56,874]\u001B[0m Trial 26 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008868670400366678, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.21366834106297586}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:57,677]\u001B[0m Trial 27 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009111906134995214, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.22422370489669277}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:58,607]\u001B[0m Trial 28 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009429459938421135, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.2623046103588915}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:39:59,641]\u001B[0m Trial 29 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008261898677692392, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.08499424270936576}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:00,481]\u001B[0m Trial 30 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00859716903653052, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.7156879105176736}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:01,283]\u001B[0m Trial 31 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009249685846433691, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.21564122201116875}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:02,168]\u001B[0m Trial 32 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009624765731742759, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11806022985100001}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:03,236]\u001B[0m Trial 33 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008942069191140413, 'hidden_layer_for_classifier': 32, 'alpha': 0.9, 'lmbda': 0.2809854276885515}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:04,249]\u001B[0m Trial 34 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00790816080493892, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.3536525167633363}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:05,154]\u001B[0m Trial 35 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00959730922778532, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.14373947323299952}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:06,145]\u001B[0m Trial 36 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00795920757397781, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.379058987008214}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:07,254]\u001B[0m Trial 37 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008348679280995041, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.15600391694633112}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:08,059]\u001B[0m Trial 38 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009510850125264073, 'hidden_layer_for_classifier': 128, 'alpha': 0.6, 'lmbda': 0.027232537583523314}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:09,102]\u001B[0m Trial 39 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007575368854482136, 'hidden_layer_for_classifier': 128, 'alpha': 0.4, 'lmbda': 0.4720973498689996}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:10,073]\u001B[0m Trial 40 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008771249051313441, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.1639554134821134}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:10,919]\u001B[0m Trial 41 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009781951473103208, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.29826197565644824}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:11,663]\u001B[0m Trial 42 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007177467308561737, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.44176968133209865}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:12,888]\u001B[0m Trial 43 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009330937908627431, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10657452282692616}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:14,114]\u001B[0m Trial 44 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0097044876382287, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.29567414141396575}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:40:15,175]\u001B[0m Trial 45 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007869946616354775, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.36870741942200574}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:16,109]\u001B[0m Trial 46 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008955359367573733, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.5184502611853875}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:17,311]\u001B[0m Trial 47 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007383783885084609, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.42465384086867886}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:18,207]\u001B[0m Trial 48 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007017077002307484, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.3391024361714581}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:19,311]\u001B[0m Trial 49 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008736305949290556, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.5813033223504065}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:20,589]\u001B[0m Trial 50 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009153832571116976, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.2457809212423031}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:21,425]\u001B[0m Trial 51 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008076601074263936, 'hidden_layer_for_classifier': 128, 'alpha': 0.6, 'lmbda': 0.5083005830910261}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:22,259]\u001B[0m Trial 52 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0092232462890462, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.24928288578880117}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:23,165]\u001B[0m Trial 53 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009064537583327103, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.17162802273575234}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:23,967]\u001B[0m Trial 54 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009457180688046556, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.18027167114047812}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:24,870]\u001B[0m Trial 55 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008319391031433265, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.13207888056673342}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:25,688]\u001B[0m Trial 56 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008359303091427867, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.03611960594103081}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:26,577]\u001B[0m Trial 57 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009967180202937218, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.124022743419979}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:27,418]\u001B[0m Trial 58 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008549180081854053, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.06248358680858959}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:28,501]\u001B[0m Trial 59 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00818840092053342, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.19311475906534037}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:29,341]\u001B[0m Trial 60 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007729072557955083, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.1315040421532941}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:30,119]\u001B[0m Trial 61 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009050190857954929, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.20914722616260728}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:30,939]\u001B[0m Trial 62 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008765191910691745, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.08731657650664809}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:31,754]\u001B[0m Trial 63 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009075910098737597, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.23941688562840968}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:32,521]\u001B[0m Trial 64 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008457758258603051, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.3274461434890602}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:33,305]\u001B[0m Trial 65 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009562357577958681, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.15123526398399315}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:34,084]\u001B[0m Trial 66 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009737446226752376, 'hidden_layer_for_classifier': 32, 'alpha': 0.4, 'lmbda': 0.17644669130061102}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:34,969]\u001B[0m Trial 67 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009592531534505599, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.5868421137834816}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:35,784]\u001B[0m Trial 68 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009318888487323668, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.03928086229303657}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:36,682]\u001B[0m Trial 69 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00981004040955368, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.15573714055279397}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:37,582]\u001B[0m Trial 70 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00935615132522373, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.05178852216578754}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:38,387]\u001B[0m Trial 71 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00954613990004781, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.018771382986322836}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:39,200]\u001B[0m Trial 72 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009317159366928795, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.08226670847204692}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:40,087]\u001B[0m Trial 73 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009517160650051756, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10268443742170869}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:40,917]\u001B[0m Trial 74 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009980228703309365, 'hidden_layer_for_classifier': 32, 'alpha': 0.6, 'lmbda': 0.014650476279714341}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:41,687]\u001B[0m Trial 75 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008902461746011846, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.15609997072123447}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:42,545]\u001B[0m Trial 76 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008651741002570067, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.2671935029387136}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:43,382]\u001B[0m Trial 77 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007999864852310795, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.12711255444503464}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:44,356]\u001B[0m Trial 78 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008935903747924101, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.197874994293071}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:45,316]\u001B[0m Trial 79 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009840716603232175, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0017652109875897493}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:46,071]\u001B[0m Trial 80 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008860469550840515, 'hidden_layer_for_classifier': 32, 'alpha': 0.8, 'lmbda': 0.1485705783873426}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:46,829]\u001B[0m Trial 81 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009620600931497195, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.049927598113551075}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:47,647]\u001B[0m Trial 82 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009189559661696526, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.06613121266302233}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:48,520]\u001B[0m Trial 83 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009481559700322764, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.07607697458539205}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:49,519]\u001B[0m Trial 84 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009143639513525295, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.0376139101567364}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:50,516]\u001B[0m Trial 85 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008437479364266372, 'hidden_layer_for_classifier': 128, 'alpha': 0.4, 'lmbda': 0.47254282143972637}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:51,808]\u001B[0m Trial 86 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008260394292690895, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.10020400463060174}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:52,910]\u001B[0m Trial 87 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007528549587766799, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.09404674412170497}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:53,772]\u001B[0m Trial 88 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007464705486874121, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.10708653876530477}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:54,813]\u001B[0m Trial 89 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007630985593222217, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.68758245759515}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:55,574]\u001B[0m Trial 90 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009375765618657926, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.4081022522723997}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:56,350]\u001B[0m Trial 91 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009033396757111959, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1415796965423978}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:57,206]\u001B[0m Trial 92 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009286300316998251, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.06231873470763967}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:58,092]\u001B[0m Trial 93 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00970180511487793, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.17802990620220857}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:58,901]\u001B[0m Trial 94 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008847659288107792, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.2259528626108358}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:40:59,716]\u001B[0m Trial 95 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008664523699920315, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.16729069211362746}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:00,487]\u001B[0m Trial 96 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009170596292159263, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.12517376954267778}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:01,277]\u001B[0m Trial 97 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009170675244765666, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.013604408331754823}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:02,118]\u001B[0m Trial 98 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008983164744784226, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.03065232073871478}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:02,909]\u001B[0m Trial 99 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006555186496640249, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.014461687942404355}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:03,638]\u001B[0m Trial 100 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006567002449137907, 'hidden_layer_for_classifier': 64, 'alpha': 0.6, 'lmbda': 0.08618759993460444}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:04,479]\u001B[0m Trial 101 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0061318723304392775, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.10805135948639279}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:05,347]\u001B[0m Trial 102 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006302770591254704, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.06656184476008031}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:06,199]\u001B[0m Trial 103 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009401388692963522, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.05091301271359073}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:06,985]\u001B[0m Trial 104 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007011827961831481, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.09459684343875015}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:07,797]\u001B[0m Trial 105 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007773579498515302, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.19451991668635582}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:08,634]\u001B[0m Trial 106 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007752016516559098, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.19762378022693539}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:09,473]\u001B[0m Trial 107 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008163210038488494, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.30194402825488537}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:10,454]\u001B[0m Trial 108 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008327511258682661, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.14916973412548712}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:11,290]\u001B[0m Trial 109 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009590544806733983, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.009697094373437257}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:12,117]\u001B[0m Trial 110 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007894788874875575, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.578607564637652}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:13,017]\u001B[0m Trial 111 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008091351114963497, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.13307755263657617}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:13,846]\u001B[0m Trial 112 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007294612727793295, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10481365482151346}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:14,601]\u001B[0m Trial 113 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008243919902360774, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.16574136204457232}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:15,357]\u001B[0m Trial 114 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009252263230540602, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.028622614111850436}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:16,171]\u001B[0m Trial 115 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009251734709702775, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.036487521178586016}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:16,986]\u001B[0m Trial 116 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009903309192066384, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.3663008629346367}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:17,908]\u001B[0m Trial 117 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009902203878717998, 'hidden_layer_for_classifier': 32, 'alpha': 0.7, 'lmbda': 0.3554850498266673}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:18,695]\u001B[0m Trial 118 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005752863941885575, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.00019675385337303286}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:19,384]\u001B[0m Trial 119 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006804073920368985, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.4490181203105892}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:20,201]\u001B[0m Trial 120 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006235434593000825, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.06625315958782538}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:21,033]\u001B[0m Trial 121 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006279238814400572, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.06579379697535165}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:21,916]\u001B[0m Trial 122 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005158274703267754, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.13478731061736401}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:22,786]\u001B[0m Trial 123 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005821433842536645, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.22506420196924026}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:23,602]\u001B[0m Trial 124 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009083056900963768, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.23169945236957923}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:24,420]\u001B[0m Trial 125 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006427474673022856, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.049976881682075}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:25,248]\u001B[0m Trial 126 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009190866388082076, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.08572091450877628}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:26,067]\u001B[0m Trial 127 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009454744007046307, 'hidden_layer_for_classifier': 32, 'alpha': 0.5, 'lmbda': 0.11896763651890382}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:26,889]\u001B[0m Trial 128 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005971072585500238, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.056551508370370096}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:27,665]\u001B[0m Trial 129 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00600276129891393, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.02159925023985744}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:28,417]\u001B[0m Trial 130 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00787449009543631, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.022832399136781714}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:29,234]\u001B[0m Trial 131 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009574288243940444, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.012945689453957052}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:30,071]\u001B[0m Trial 132 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008894386341538992, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.5476677598988824}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:30,852]\u001B[0m Trial 133 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009687776450918322, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.49314811022785815}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:31,776]\u001B[0m Trial 134 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007529520334728914, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.09152944749718284}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:32,585]\u001B[0m Trial 135 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007091523146279092, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10858985799036772}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:33,462]\u001B[0m Trial 136 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006769148386239454, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.12451069351196231}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:34,302]\u001B[0m Trial 137 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009371655091049477, 'hidden_layer_for_classifier': 32, 'alpha': 0.6, 'lmbda': 0.07642261775406417}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:35,236]\u001B[0m Trial 138 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006837037828549533, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.05068506199435131}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:36,026]\u001B[0m Trial 139 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006373754647523792, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.20762438383808535}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:36,858]\u001B[0m Trial 140 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006425909689574291, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.27088498650390413}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:37,682]\u001B[0m Trial 141 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009199045020312711, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18360873607112033}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:38,525]\u001B[0m Trial 142 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009170121555155593, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18887983101622546}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:39,347]\u001B[0m Trial 143 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007667650573964725, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.14371503923428536}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:40,127]\u001B[0m Trial 144 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00938837555299745, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.04020873678455377}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:40,955]\u001B[0m Trial 145 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009307816286375342, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.04186515374052227}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:41,857]\u001B[0m Trial 146 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007335552350028486, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0746379174727279}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:42,557]\u001B[0m Trial 147 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0074258903360416365, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.8961176112477671}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:43,352]\u001B[0m Trial 148 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007221265215509083, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.10219452568260023}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:44,113]\u001B[0m Trial 149 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007740998321337926, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.3959599843989557}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:44,956]\u001B[0m Trial 150 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005458504923714473, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.05739359120043526}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:45,735]\u001B[0m Trial 151 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00878852245914355, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10947360642146275}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:46,495]\u001B[0m Trial 152 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008969534825949702, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0778168381361253}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:47,323]\u001B[0m Trial 153 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007985281925322682, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.1207693287799329}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:48,161]\u001B[0m Trial 154 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00973836609254298, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1642776610066164}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:49,000]\u001B[0m Trial 155 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00660954728043271, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.09219564041398032}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:49,916]\u001B[0m Trial 156 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00527061656750023, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.22428918502348932}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:50,737]\u001B[0m Trial 157 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006245262662419464, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.14666100307538427}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:51,478]\u001B[0m Trial 158 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006933121234629545, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.1295095613222147}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:52,404]\u001B[0m Trial 159 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005985241408680706, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.016510577645472382}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:53,223]\u001B[0m Trial 160 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005757403319374742, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.2059621704466413}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:54,003]\u001B[0m Trial 161 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005915368525951771, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.05076247009394344}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:54,840]\u001B[0m Trial 162 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005170810853887786, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.03351959675575866}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:55,660]\u001B[0m Trial 163 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006342436724580102, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.06482114073844436}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:56,554]\u001B[0m Trial 164 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005352210760984006, 'hidden_layer_for_classifier': 128, 'alpha': 0.4, 'lmbda': 0.13390999545378438}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:57,382]\u001B[0m Trial 165 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006287497579910681, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.001295035512610558}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:58,359]\u001B[0m Trial 166 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006523620540463964, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.24519814361589196}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:59,070]\u001B[0m Trial 167 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005781835088119866, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.06390391144882608}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:41:59,840]\u001B[0m Trial 168 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006521904138801562, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.026856487867826448}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:00,697]\u001B[0m Trial 169 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00613663923573715, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.02176548126937753}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:01,535]\u001B[0m Trial 170 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006012571793055757, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.0011107691955160037}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:02,514]\u001B[0m Trial 171 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005808302571449371, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.04718817478948864}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:03,296]\u001B[0m Trial 172 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006058871956652648, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.028810265658767497}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:04,076]\u001B[0m Trial 173 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009510836482363848, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1714794893265818}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:04,924]\u001B[0m Trial 174 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00848145878296906, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.087291329160744}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:05,749]\u001B[0m Trial 175 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009136917086822778, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10212604913670469}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:06,631]\u001B[0m Trial 176 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007073826640371909, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.1597561889277616}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:07,391]\u001B[0m Trial 177 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00765765016121498, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1831582415434306}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:08,171]\u001B[0m Trial 178 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007844393535421426, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.05787905199233161}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:09,012]\u001B[0m Trial 179 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006698746193386143, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.11545972983510772}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:09,728]\u001B[0m Trial 180 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0066758220055771296, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.2116445229545632}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:10,543]\u001B[0m Trial 181 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00559665392875026, 'hidden_layer_for_classifier': 64, 'alpha': 0.6, 'lmbda': 0.19301963559341184}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:11,320]\u001B[0m Trial 182 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00587718578586182, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.17571227747559498}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:12,168]\u001B[0m Trial 183 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0077447056490985355, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.2156513376034873}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:13,013]\u001B[0m Trial 184 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006161247086044975, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.0773523273185994}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:13,848]\u001B[0m Trial 185 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007289292004014957, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.12138216178348941}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:14,659]\u001B[0m Trial 186 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007134689633059354, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1425514595677727}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:15,439]\u001B[0m Trial 187 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006437127152638451, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.3114887389278203}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:16,282]\u001B[0m Trial 188 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006397656749533555, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.36081455432087284}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:17,046]\u001B[0m Trial 189 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006426426619271142, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.28796837835551914}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:18,001]\u001B[0m Trial 190 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005003932770483817, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.13082236272698192}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:18,817]\u001B[0m Trial 191 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006886475325792744, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1083676971626358}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:19,625]\u001B[0m Trial 192 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009000430919317714, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.0819015131812083}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:20,569]\u001B[0m Trial 193 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009238950857310588, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.2634514621164899}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:21,414]\u001B[0m Trial 194 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007589185163863294, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1871189726009007}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:22,217]\u001B[0m Trial 195 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009426589023568754, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.039449676215415064}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:22,999]\u001B[0m Trial 196 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0075213345436142215, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.14917433948880868}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:23,851]\u001B[0m Trial 197 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007982558481660632, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.2298375225334134}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:24,740]\u001B[0m Trial 198 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007390003247072774, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.1499568761145964}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:25,570]\u001B[0m Trial 199 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00935853684016549, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.06670126865904753}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:26,441]\u001B[0m Trial 200 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009851341737743451, 'hidden_layer_for_classifier': 128, 'alpha': 0.4, 'lmbda': 0.14014270352007147}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:27,205]\u001B[0m Trial 201 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005937499947772696, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.02695589757450035}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:28,006]\u001B[0m Trial 202 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009597450064783302, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11052706920381546}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:28,908]\u001B[0m Trial 203 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005687119868327713, 'hidden_layer_for_classifier': 128, 'alpha': 0.5, 'lmbda': 0.04069502474831477}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:30,033]\u001B[0m Trial 204 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009783727860314867, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.018418525067238803}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:30,960]\u001B[0m Trial 205 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009526706028244862, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.06255248521913281}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:31,872]\u001B[0m Trial 206 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006340167446745835, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.09405654215289125}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:32,799]\u001B[0m Trial 207 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009210098797786967, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.08634082878559984}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:33,596]\u001B[0m Trial 208 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006066715422300289, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.0276593193047458}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:34,699]\u001B[0m Trial 209 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00616832970143764, 'hidden_layer_for_classifier': 128, 'alpha': 0.7, 'lmbda': 0.16361714434066144}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:35,545]\u001B[0m Trial 210 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006102606325077285, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.08026005233633923}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:36,369]\u001B[0m Trial 211 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005985541617028674, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.19843452194343303}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:37,210]\u001B[0m Trial 212 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006076109870372316, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18004204219884126}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:38,055]\u001B[0m Trial 213 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009076258612763401, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.162379723106886}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:38,928]\u001B[0m Trial 214 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007692772938835231, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.12073807244163973}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:39,840]\u001B[0m Trial 215 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007922020649499716, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.15562648559387884}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:40,659]\u001B[0m Trial 216 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006574997823614663, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.011902945663886253}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:41,538]\u001B[0m Trial 217 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008725020006913343, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.3798762240168716}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:42,421]\u001B[0m Trial 218 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008102600160636365, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.04218534964265084}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:43,294]\u001B[0m Trial 219 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008575466716574187, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.0006841580998844798}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:44,176]\u001B[0m Trial 220 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006749988337978057, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.17698451757443417}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:45,062]\u001B[0m Trial 221 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006713956780064178, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18430620995997699}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:45,951]\u001B[0m Trial 222 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0063625000334740665, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.04665597484268101}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:46,825]\u001B[0m Trial 223 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00945829580681697, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.3247167334395778}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:47,687]\u001B[0m Trial 224 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0062043918945655615, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.34887467665861766}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:48,561]\u001B[0m Trial 225 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007237649504956768, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.021000397835939412}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:49,414]\u001B[0m Trial 226 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009276753415794136, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0276528515701763}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:50,279]\u001B[0m Trial 227 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009293914494161832, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0697981397862831}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:51,347]\u001B[0m Trial 228 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007671321139781836, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.1473720371807544}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:52,148]\u001B[0m Trial 229 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00822572594861703, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.09475469054197716}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:52,993]\u001B[0m Trial 230 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0078096227448185215, 'hidden_layer_for_classifier': 32, 'alpha': 0.6, 'lmbda': 0.09616237983813625}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:53,871]\u001B[0m Trial 231 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007575716099442792, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.19922272828675772}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:54,790]\u001B[0m Trial 232 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0076205113728126505, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.17208802219163977}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:55,665]\u001B[0m Trial 233 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007508886592844589, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.35725455327719724}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:56,521]\u001B[0m Trial 234 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00843437567146538, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.30809075542846714}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:57,465]\u001B[0m Trial 235 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007354240990920172, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.14251300587494795}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:58,326]\u001B[0m Trial 236 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007203261639547202, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11899256717753096}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:42:59,323]\u001B[0m Trial 237 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008342205250369675, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1409026117358105}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:00,344]\u001B[0m Trial 238 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00784807039294138, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10481529459621203}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:01,350]\u001B[0m Trial 239 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008483105549843073, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.12800424809737682}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:02,225]\u001B[0m Trial 240 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00777374368835785, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.4324068052122634}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:03,098]\u001B[0m Trial 241 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006443648714525737, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.43033126117311693}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:04,086]\u001B[0m Trial 242 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007434759210632727, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.15889323915826503}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:04,946]\u001B[0m Trial 243 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00911581729587673, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.056464256576376506}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:05,980]\u001B[0m Trial 244 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0064645097581373405, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1581454718515081}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:06,857]\u001B[0m Trial 245 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008976558804712322, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.08919154737596838}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:07,748]\u001B[0m Trial 246 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005510584318625602, 'hidden_layer_for_classifier': 32, 'alpha': 0.8, 'lmbda': 0.05594843057678602}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:08,600]\u001B[0m Trial 247 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006974208217260913, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11052600496081541}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:09,471]\u001B[0m Trial 248 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006276337958406373, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18780205354050597}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:10,421]\u001B[0m Trial 249 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009763925645674526, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.3370942522468381}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:11,409]\u001B[0m Trial 250 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009994206083885676, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.17249554157695549}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:12,273]\u001B[0m Trial 251 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009097990107417776, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.23932110974268037}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:13,216]\u001B[0m Trial 252 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009862165420234142, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.2146518318071739}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:14,145]\u001B[0m Trial 253 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007650716736966911, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.13756444726026726}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:15,003]\u001B[0m Trial 254 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0074216541352641364, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.38373254052265676}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:15,932]\u001B[0m Trial 255 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008383364423901292, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.1524997211117046}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:16,846]\u001B[0m Trial 256 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00809574448971861, 'hidden_layer_for_classifier': 128, 'alpha': 0.5, 'lmbda': 0.12778906599597473}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:17,687]\u001B[0m Trial 257 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009635156245985516, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.07837328820570244}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:18,566]\u001B[0m Trial 258 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008884728463460851, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.04515374677873664}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:19,472]\u001B[0m Trial 259 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00973074501077431, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.08456065985782614}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:20,530]\u001B[0m Trial 260 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009188565881094025, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.08922019362811985}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:21,349]\u001B[0m Trial 261 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00824554766188704, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.07047397791597061}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:22,240]\u001B[0m Trial 262 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0062943533390869486, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.06220147677540677}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:23,117]\u001B[0m Trial 263 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006475537021274535, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.0024834623284047206}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:23,968]\u001B[0m Trial 264 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009076364373288775, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.007946981065237392}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:24,899]\u001B[0m Trial 265 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009195787472344567, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.11695382857433276}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:25,811]\u001B[0m Trial 266 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009316749883628232, 'hidden_layer_for_classifier': 128, 'alpha': 0.6, 'lmbda': 0.10125908542512901}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:26,698]\u001B[0m Trial 267 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00942552092627804, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.042403925118296514}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:27,579]\u001B[0m Trial 268 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009387879966517883, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.033217382151555515}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:28,460]\u001B[0m Trial 269 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00958493346530233, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1880958572700806}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:29,377]\u001B[0m Trial 270 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0063439049173958425, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18113209475607678}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:30,251]\u001B[0m Trial 271 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009011208773929587, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.025455187678906133}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:31,120]\u001B[0m Trial 272 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005868790143211604, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.02494485601598334}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:32,176]\u001B[0m Trial 273 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008564883937633959, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.054734007499145136}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:33,042]\u001B[0m Trial 274 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0066119249210987545, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.0860217099338079}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:33,929]\u001B[0m Trial 275 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0060736969261087565, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.06925522975781498}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:34,806]\u001B[0m Trial 276 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00953451683089705, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.020977706075992024}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:35,574]\u001B[0m Trial 277 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007897992174645627, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.001603439982133456}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:36,437]\u001B[0m Trial 278 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007347848607582016, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10740994345594061}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:37,243]\u001B[0m Trial 279 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0059819911526785285, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.023000916782773165}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:38,186]\u001B[0m Trial 280 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009150535173210126, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.04188079227607617}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:39,044]\u001B[0m Trial 281 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007090992755132225, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.12106570557940427}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:40,053]\u001B[0m Trial 282 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0067315043246011065, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.16519249374180933}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:40,947]\u001B[0m Trial 283 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0075850839927356865, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.186122757196511}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:41,856]\u001B[0m Trial 284 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006129686858426211, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.19802213388713102}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:42,876]\u001B[0m Trial 285 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006909361997558408, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14289442122136495}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:43,738]\u001B[0m Trial 286 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008854686079738352, 'hidden_layer_for_classifier': 32, 'alpha': 0.8, 'lmbda': 0.18834959028261555}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:44,615]\u001B[0m Trial 287 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007550578309600017, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.15701576881707202}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:45,544]\u001B[0m Trial 288 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007448512195485711, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.12816848691509558}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:46,521]\u001B[0m Trial 289 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007812108889634083, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10527185091518698}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:47,383]\u001B[0m Trial 290 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008956986444896762, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.12514598365369956}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:48,280]\u001B[0m Trial 291 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00899268749589727, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.13144296165295707}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:49,794]\u001B[0m Trial 292 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009636170059704942, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21181921406198165}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:51,195]\u001B[0m Trial 293 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006819778011490592, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1742735625265855}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:52,693]\u001B[0m Trial 294 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008352752355060476, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.442939243740501}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:53,690]\u001B[0m Trial 295 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009302137597607235, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.16755458459324366}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:54,547]\u001B[0m Trial 296 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005161636930605297, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.04299081380634144}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:55,546]\u001B[0m Trial 297 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007320496675073697, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.0960087501832152}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:56,552]\u001B[0m Trial 298 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006342998869666365, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.15294259679808586}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:57,476]\u001B[0m Trial 299 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006554355909799403, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2608352300165505}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:58,347]\u001B[0m Trial 300 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00641319900237893, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2764789820782941}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:43:59,340]\u001B[0m Trial 301 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007439513820254425, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4704291483746521}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:00,353]\u001B[0m Trial 302 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007342611676941358, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14162980201251912}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:01,371]\u001B[0m Trial 303 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0086634766129745, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.15706025257023076}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:02,204]\u001B[0m Trial 304 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00830464948425828, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.10615892687378295}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:03,191]\u001B[0m Trial 305 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007726739773625112, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.41633686742928977}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:04,173]\u001B[0m Trial 306 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007735796868556494, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.42206607990291156}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:05,282]\u001B[0m Trial 307 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007424271869846663, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.40552263512676673}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:06,194]\u001B[0m Trial 308 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008738388306150964, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.14285533367891762}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:07,207]\u001B[0m Trial 309 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008183110726711676, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.5296080630463833}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:08,115]\u001B[0m Trial 310 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005655279126670548, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.07640065160835625}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:09,000]\u001B[0m Trial 311 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006201143883689575, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.210167307661632}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:09,997]\u001B[0m Trial 312 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00541729997288548, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.5058791493182191}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:11,016]\u001B[0m Trial 313 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007979578737696606, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.4774377299157724}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:11,938]\u001B[0m Trial 314 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009821195886877092, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.3790786633621493}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:12,780]\u001B[0m Trial 315 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005278825641246858, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.354082019904292}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:13,673]\u001B[0m Trial 316 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007534552097600774, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.3179416510786116}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:14,655]\u001B[0m Trial 317 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009491150030653877, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.018317760605601374}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:15,599]\u001B[0m Trial 318 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009071158673336976, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.10111939116541183}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:16,463]\u001B[0m Trial 319 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00884972381855691, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.08650538077455637}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:17,388]\u001B[0m Trial 320 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006493946903243349, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.7393846601569268}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:18,385]\u001B[0m Trial 321 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0064731769810559, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.37035536684670506}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:19,317]\u001B[0m Trial 322 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00924033986123515, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.3047263248449564}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:20,282]\u001B[0m Trial 323 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009238371161979841, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.32987343451089157}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:21,106]\u001B[0m Trial 324 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006609898443597262, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.0007154597451702362}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:21,996]\u001B[0m Trial 325 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006398260538168772, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.062218595197635965}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:22,806]\u001B[0m Trial 326 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009381635930192228, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.0337248904481153}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:23,841]\u001B[0m Trial 327 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00927347246486628, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.042141873758244484}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:24,741]\u001B[0m Trial 328 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009150423888683536, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.11945796100888217}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:26,017]\u001B[0m Trial 329 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009395672640928785, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.001536380206152807}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:27,157]\u001B[0m Trial 330 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009158624013505283, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.9589018065632986}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:28,110]\u001B[0m Trial 331 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007256333043087665, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.05510984560409679}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:29,119]\u001B[0m Trial 332 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007519022527874399, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.07784275198731026}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:30,083]\u001B[0m Trial 333 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00943584106234727, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.05100176698490535}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:31,081]\u001B[0m Trial 334 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009469532139205459, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1630374747105111}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:32,038]\u001B[0m Trial 335 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005884082175981155, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.5606684547733458}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:32,949]\u001B[0m Trial 336 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005973889446523741, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.06649303079675782}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:33,775]\u001B[0m Trial 337 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0065096881676603895, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.04218399428401323}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:34,561]\u001B[0m Trial 338 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008980272950787844, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11933633931325598}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:35,389]\u001B[0m Trial 339 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009908454992920692, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.01756465952049512}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:36,266]\u001B[0m Trial 340 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008112435542773886, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.016171453278280002}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:37,254]\u001B[0m Trial 341 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009716378787943318, 'hidden_layer_for_classifier': 128, 'alpha': 0.6, 'lmbda': 0.026625470554176155}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:38,138]\u001B[0m Trial 342 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007180621309471792, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.8451168831848612}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:38,948]\u001B[0m Trial 343 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006822864212314184, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.08645414082937963}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:39,693]\u001B[0m Trial 344 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006640303563845217, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.08526588716364832}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:40,564]\u001B[0m Trial 345 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009232503309537923, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.044283504263199436}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:41,486]\u001B[0m Trial 346 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006245787947494713, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.061873755094081176}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:42,356]\u001B[0m Trial 347 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006342033738505742, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.0007036851764145521}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:43,239]\u001B[0m Trial 348 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006619515872056423, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.04304138436700581}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:44,095]\u001B[0m Trial 349 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008454888441260246, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.13241586842119976}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:45,136]\u001B[0m Trial 350 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.006190527215498322, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.07317135176901612}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:46,023]\u001B[0m Trial 351 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006660285247123762, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.06480146964585518}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:46,961]\u001B[0m Trial 352 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006501934667085862, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.10189453551925837}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:47,980]\u001B[0m Trial 353 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009338217471240117, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.11228928488028897}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:48,873]\u001B[0m Trial 354 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0065525173374283594, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.02563777019276825}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:49,733]\u001B[0m Trial 355 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007809563000744669, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.14530443593512862}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:50,604]\u001B[0m Trial 356 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007825006615806825, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10390821160346767}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:51,485]\u001B[0m Trial 357 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0058060593504244504, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.056770070386854415}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:52,287]\u001B[0m Trial 358 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009473357825356568, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.02430204390830129}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:53,235]\u001B[0m Trial 359 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009574777038079312, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.23133106670601447}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:54,120]\u001B[0m Trial 360 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006083624833996639, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.08390592806590669}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:55,013]\u001B[0m Trial 361 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006285168150814424, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.21183512461134268}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:55,976]\u001B[0m Trial 362 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006042411079116399, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.18604705748131273}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:56,936]\u001B[0m Trial 363 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008709850020767917, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.49233616662318147}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:57,815]\u001B[0m Trial 364 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0071254046762321025, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.24511859031428865}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:58,791]\u001B[0m Trial 365 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006381830737720298, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24690655545101775}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:44:59,804]\u001B[0m Trial 366 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008025141940378027, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.09074834496756724}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:00,838]\u001B[0m Trial 367 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008213179888211174, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6069484234962047}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:01,841]\u001B[0m Trial 368 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009385172140019098, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6940365050270361}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:02,728]\u001B[0m Trial 369 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009011896758095545, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11945509669033937}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:03,600]\u001B[0m Trial 370 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007712729461023319, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.12987367244198714}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:04,598]\u001B[0m Trial 371 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008924487552949719, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.09612787819839355}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:05,614]\u001B[0m Trial 372 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008950367863635702, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.09820449741293691}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:06,515]\u001B[0m Trial 373 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009082978311807894, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11111392151416838}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:07,228]\u001B[0m Trial 374 finished with value: 0.7222222222222222 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009146949254452466, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.11981793190098092}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:08,105]\u001B[0m Trial 375 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00654224021882997, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.08208467737274477}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:09,121]\u001B[0m Trial 376 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009148479332585753, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.070045750406278}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:09,979]\u001B[0m Trial 377 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009339280540328435, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.07263342196432923}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:10,803]\u001B[0m Trial 378 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007924385954519813, 'hidden_layer_for_classifier': 32, 'alpha': 0.6, 'lmbda': 0.4539783307324933}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:11,729]\u001B[0m Trial 379 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009660364528086222, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.0477567309974856}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:12,544]\u001B[0m Trial 380 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009896474087502658, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.0464748734274555}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:13,431]\u001B[0m Trial 381 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0070241681163512116, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.14536296397723322}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:14,362]\u001B[0m Trial 382 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00690780548112957, 'hidden_layer_for_classifier': 32, 'alpha': 0.5, 'lmbda': 0.25862272523310237}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:15,214]\u001B[0m Trial 383 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007260354878190405, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.2753396896010389}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:16,153]\u001B[0m Trial 384 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0054560264304690026, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.15101727272737758}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:17,080]\u001B[0m Trial 385 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007473961282806618, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.5106304608030491}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:18,081]\u001B[0m Trial 386 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008771013332965327, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.5185923987242839}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:19,136]\u001B[0m Trial 387 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007332233844205643, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.13887432632227212}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:20,086]\u001B[0m Trial 388 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0076383131939445365, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.5403910849589648}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:20,976]\u001B[0m Trial 389 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009237094034086853, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.005043684890513871}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:21,984]\u001B[0m Trial 390 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007583510994741671, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.46458814124163456}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:23,059]\u001B[0m Trial 391 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007614048346511268, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14242951727828612}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:24,118]\u001B[0m Trial 392 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007355059530643744, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4742622120897715}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:24,910]\u001B[0m Trial 393 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00677739527034466, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.3454887881575978}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:25,715]\u001B[0m Trial 394 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009959877725759951, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.036528288831373004}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:26,595]\u001B[0m Trial 395 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009990532211271923, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.15767870356451338}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:27,472]\u001B[0m Trial 396 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009279024415225, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.3037128753890133}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:28,573]\u001B[0m Trial 397 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.006412435524131571, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.4038673050499565}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:29,492]\u001B[0m Trial 398 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0074079258785087745, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.023628055928153834}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:30,356]\u001B[0m Trial 399 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0098688144241583, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.3367175388002644}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:31,215]\u001B[0m Trial 400 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006562997947056319, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.2719909989671216}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:32,059]\u001B[0m Trial 401 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00946285441922205, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.4861053411594036}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:32,977]\u001B[0m Trial 402 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009224236398517755, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.3223649040997896}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:33,841]\u001B[0m Trial 403 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008911836024942252, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.3037973252789186}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:34,761]\u001B[0m Trial 404 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009284181710128545, 'hidden_layer_for_classifier': 128, 'alpha': 0.4, 'lmbda': 0.17284452726134403}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:35,787]\u001B[0m Trial 405 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0053209021461303645, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.29943266057019}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:36,698]\u001B[0m Trial 406 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009470380543346058, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.13690303219095426}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:37,539]\u001B[0m Trial 407 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005825691479297012, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.023246517146509424}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:38,486]\u001B[0m Trial 408 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009058348323712292, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.12434621051878178}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:39,462]\u001B[0m Trial 409 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007690255576012232, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.18961308798486556}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:40,517]\u001B[0m Trial 410 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005074078167565467, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4328390674506332}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:41,506]\u001B[0m Trial 411 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007495209606474648, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.49837946056014826}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:42,538]\u001B[0m Trial 412 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007576180659942394, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4830141608152639}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:43,436]\u001B[0m Trial 413 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006172899897109246, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.22420107961540925}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:44,464]\u001B[0m Trial 414 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005453664415842387, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.39617763510746973}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:45,471]\u001B[0m Trial 415 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005397824189983153, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.42273939345793876}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:46,513]\u001B[0m Trial 416 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005095898908097076, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3864653650327529}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:47,534]\u001B[0m Trial 417 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007728045527229008, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4375131683666779}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:48,606]\u001B[0m Trial 418 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007397088957192121, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.5097874796069372}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:49,620]\u001B[0m Trial 419 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007283398300939352, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.47684753973403}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:50,714]\u001B[0m Trial 420 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005708750287690721, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.29453459937531984}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:51,600]\u001B[0m Trial 421 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0051700805846191895, 'hidden_layer_for_classifier': 32, 'alpha': 0.9, 'lmbda': 0.2756258607346686}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:52,545]\u001B[0m Trial 422 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008670745761288644, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.2641804916298815}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:53,488]\u001B[0m Trial 423 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008814244944593265, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.240915331483234}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:54,437]\u001B[0m Trial 424 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005026501728403203, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.29655794322030316}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:55,149]\u001B[0m Trial 425 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0074849887057162265, 'hidden_layer_for_classifier': 32, 'alpha': 0.6, 'lmbda': 0.28364395020822586}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:56,026]\u001B[0m Trial 426 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008826342672647543, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.32369290584895166}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:56,918]\u001B[0m Trial 427 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009521009050524588, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.04844197251564948}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:57,714]\u001B[0m Trial 428 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008635937087371974, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.05011102567808758}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:58,642]\u001B[0m Trial 429 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008738559080537549, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.31652937586753044}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:45:59,426]\u001B[0m Trial 430 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00943368220163393, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.06530896651084672}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:00,206]\u001B[0m Trial 431 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005242646590036966, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.35713920531511684}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:01,097]\u001B[0m Trial 432 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009362402408511217, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.34036835115202957}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:01,881]\u001B[0m Trial 433 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006179240886820549, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.1001380746647537}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:02,803]\u001B[0m Trial 434 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00803307030476897, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6309757544680931}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:03,616]\u001B[0m Trial 435 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009695795159718648, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.061149855382108556}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:04,406]\u001B[0m Trial 436 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007510147375433539, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.27679342627145015}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:05,194]\u001B[0m Trial 437 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009791288738686269, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.5296506933176961}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:06,157]\u001B[0m Trial 438 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009789663882493279, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.5688716261549446}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:07,021]\u001B[0m Trial 439 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005538682762850003, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.2660578338577759}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:07,729]\u001B[0m Trial 440 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005376106392233456, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.2490612228814408}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:08,513]\u001B[0m Trial 441 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009227249844240122, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.03847202110498484}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:09,341]\u001B[0m Trial 442 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009186892159926397, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.370911929963527}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:10,341]\u001B[0m Trial 443 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00516253875219666, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.2521219812833444}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:11,138]\u001B[0m Trial 444 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005577156513649972, 'hidden_layer_for_classifier': 64, 'alpha': 0.6, 'lmbda': 0.4491676836921406}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:11,922]\u001B[0m Trial 445 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009584835566165803, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.3230351431967745}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:12,727]\u001B[0m Trial 446 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00526629679934007, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.27412747854872294}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:13,526]\u001B[0m Trial 447 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006285570826774564, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2904192152632106}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:14,316]\u001B[0m Trial 448 finished with value: 0.6111111111111112 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009914183066238548, 'hidden_layer_for_classifier': 64, 'alpha': 0.9, 'lmbda': 0.2918956557528864}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:15,104]\u001B[0m Trial 449 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009438741384284844, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.056332705673074905}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:15,991]\u001B[0m Trial 450 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009358970507103983, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.059392667422927176}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:16,929]\u001B[0m Trial 451 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00892833567790418, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6568910923712713}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:17,864]\u001B[0m Trial 452 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00817748466899968, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1898486642577852}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:18,694]\u001B[0m Trial 453 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006370994557699598, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.17679994157800466}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:19,622]\u001B[0m Trial 454 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009280473942705762, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.03148148331232516}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:20,394]\u001B[0m Trial 455 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008017764392376465, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.10279160970405066}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:21,183]\u001B[0m Trial 456 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006223612345667592, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.07358184850080413}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:22,160]\u001B[0m Trial 457 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007888401650330635, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.09378125536094509}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:22,969]\u001B[0m Trial 458 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006265299298943939, 'hidden_layer_for_classifier': 64, 'alpha': 0.3, 'lmbda': 0.06974149815342343}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:23,663]\u001B[0m Trial 459 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005926917681578296, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.016841245529403047}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:24,431]\u001B[0m Trial 460 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008381336959325096, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.10020785047455434}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:25,286]\u001B[0m Trial 461 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008423122064497876, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0882753763805563}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:26,119]\u001B[0m Trial 462 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008513077587554593, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.6204639955936476}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:26,908]\u001B[0m Trial 463 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008235926549397664, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.0012391530818007604}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:27,684]\u001B[0m Trial 464 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008158796949913442, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.6118954588680099}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:28,516]\u001B[0m Trial 465 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008271962425887609, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.08916823553795288}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:29,565]\u001B[0m Trial 466 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008416298712886778, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.08545470449212839}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:30,392]\u001B[0m Trial 467 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009119588749145426, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1177962265919227}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:31,333]\u001B[0m Trial 468 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009056423762828154, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10053844231418578}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:32,262]\u001B[0m Trial 469 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008015461695587162, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.778419448476471}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:33,239]\u001B[0m Trial 470 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008099054410424895, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.5880227511446423}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:34,252]\u001B[0m Trial 471 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0085593179027018, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.09794301513262402}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:35,050]\u001B[0m Trial 472 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006704259808415862, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.16908751737468491}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:35,821]\u001B[0m Trial 473 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008912037109399999, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1131043624955739}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:36,615]\u001B[0m Trial 474 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008986554829447132, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.09172092434372593}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:37,415]\u001B[0m Trial 475 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007817690256540458, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1210772521942605}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:38,253]\u001B[0m Trial 476 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005982287819141316, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.057667841284255505}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:39,155]\u001B[0m Trial 477 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007948166028003361, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.06772129613489669}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:39,905]\u001B[0m Trial 478 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00806737397010985, 'hidden_layer_for_classifier': 64, 'alpha': 0.5, 'lmbda': 0.043447407497387874}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:40,643]\u001B[0m Trial 479 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00824345936409957, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.0680950554996857}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:41,384]\u001B[0m Trial 480 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008314097938920609, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.05107114693380867}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:42,137]\u001B[0m Trial 481 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007926648775801392, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.029290501048908804}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:42,895]\u001B[0m Trial 482 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005789737899287486, 'hidden_layer_for_classifier': 64, 'alpha': 0.6, 'lmbda': 0.076790598596607}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:43,680]\u001B[0m Trial 483 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007816514586470395, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.12913381560464746}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:44,460]\u001B[0m Trial 484 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007891886306774317, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.7492832315291678}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:45,208]\u001B[0m Trial 485 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005926247534515045, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.040893723324820844}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:46,158]\u001B[0m Trial 486 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008960314045654557, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.11083647579007863}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:46,878]\u001B[0m Trial 487 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005647012671128069, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.07760265790407217}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:47,827]\u001B[0m Trial 488 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00863191268696205, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.02403512043004983}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:48,806]\u001B[0m Trial 489 finished with value: 0.6666666666666666 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009553373095278123, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.4855477685232771}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:49,754]\u001B[0m Trial 490 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007702170458311724, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10861614404287132}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:50,500]\u001B[0m Trial 491 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009092148478959838, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.06579117836079917}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:51,252]\u001B[0m Trial 492 finished with value: 0.7777777777777778 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006055227288341289, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.6630673044954225}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:52,242]\u001B[0m Trial 493 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006464016090121914, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.23659824559726428}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:53,190]\u001B[0m Trial 494 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007619821474236094, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.08058154805985038}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:54,127]\u001B[0m Trial 495 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008888067181982038, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.0925209224598239}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:55,000]\u001B[0m Trial 496 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006159223380265177, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.10269267510469957}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:55,867]\u001B[0m Trial 497 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006106645084826988, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.07045784828709548}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:56,717]\u001B[0m Trial 498 finished with value: 0.8333333333333334 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0071186172522737625, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.05709214376360184}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:46:57,656]\u001B[0m Trial 499 finished with value: 0.8888888888888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007317024569051204, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.44575109407785873}. Best is trial 21 with value: 0.8888888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: SAGE, mode: unsupervised, loss from HOPE_RPR\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 55.3740, Epoch: 000, Train acc micro: 0.6124, Test acc micro: 0.5278,Train acc macro: 0.6124, Test acc macro: 0.5278\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 63.9525, Epoch: 001, Train acc micro: 0.6124, Test acc micro: 0.5278,Train acc macro: 0.6124, Test acc macro: 0.5278\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.7617, Epoch: 002, Train acc micro: 0.5969, Test acc micro: 0.5556,Train acc macro: 0.5969, Test acc macro: 0.5556\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.0141, Epoch: 003, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 59.4185, Epoch: 004, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 56.2342, Epoch: 005, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.1191, Epoch: 006, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.7761, Epoch: 007, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.9836, Epoch: 008, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.8261, Epoch: 009, Train acc micro: 0.5426, Test acc micro: 0.5278,Train acc macro: 0.5426, Test acc macro: 0.5278\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 54.0687, Epoch: 010, Train acc micro: 0.6279, Test acc micro: 0.5278,Train acc macro: 0.6279, Test acc macro: 0.5278\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.3829, Epoch: 011, Train acc micro: 0.6279, Test acc micro: 0.5556,Train acc macro: 0.6279, Test acc macro: 0.5556\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.9204, Epoch: 012, Train acc micro: 0.6202, Test acc micro: 0.5278,Train acc macro: 0.6202, Test acc macro: 0.5278\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.8018, Epoch: 013, Train acc micro: 0.6202, Test acc micro: 0.5278,Train acc macro: 0.6202, Test acc macro: 0.5278\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.8427, Epoch: 014, Train acc micro: 0.6202, Test acc micro: 0.5278,Train acc macro: 0.6202, Test acc macro: 0.5278\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.9727, Epoch: 015, Train acc micro: 0.6279, Test acc micro: 0.5556,Train acc macro: 0.6279, Test acc macro: 0.5556\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.0267, Epoch: 016, Train acc micro: 0.6357, Test acc micro: 0.5556,Train acc macro: 0.6357, Test acc macro: 0.5556\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.8836, Epoch: 017, Train acc micro: 0.6434, Test acc micro: 0.5556,Train acc macro: 0.6434, Test acc macro: 0.5556\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.6901, Epoch: 018, Train acc micro: 0.6589, Test acc micro: 0.5556,Train acc macro: 0.6589, Test acc macro: 0.5556\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.5752, Epoch: 019, Train acc micro: 0.6589, Test acc micro: 0.6111,Train acc macro: 0.6589, Test acc macro: 0.6111\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.5196, Epoch: 020, Train acc micro: 0.6589, Test acc micro: 0.6389,Train acc macro: 0.6589, Test acc macro: 0.6389\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.4795, Epoch: 021, Train acc micro: 0.6589, Test acc micro: 0.6389,Train acc macro: 0.6589, Test acc macro: 0.6389\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.4450, Epoch: 022, Train acc micro: 0.6589, Test acc micro: 0.6389,Train acc macro: 0.6589, Test acc macro: 0.6389\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.4216, Epoch: 023, Train acc micro: 0.6744, Test acc micro: 0.6389,Train acc macro: 0.6744, Test acc macro: 0.6389\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.4000, Epoch: 024, Train acc micro: 0.6822, Test acc micro: 0.6389,Train acc macro: 0.6822, Test acc macro: 0.6389\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.3539, Epoch: 025, Train acc micro: 0.6822, Test acc micro: 0.6389,Train acc macro: 0.6822, Test acc macro: 0.6389\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.2744, Epoch: 026, Train acc micro: 0.6899, Test acc micro: 0.6389,Train acc macro: 0.6899, Test acc macro: 0.6389\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.1834, Epoch: 027, Train acc micro: 0.6899, Test acc micro: 0.6667,Train acc macro: 0.6899, Test acc macro: 0.6667\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.1033, Epoch: 028, Train acc micro: 0.6899, Test acc micro: 0.6667,Train acc macro: 0.6899, Test acc macro: 0.6667\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.0359, Epoch: 029, Train acc micro: 0.6977, Test acc micro: 0.6667,Train acc macro: 0.6977, Test acc macro: 0.6667\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.9708, Epoch: 030, Train acc micro: 0.7132, Test acc micro: 0.6667,Train acc macro: 0.7132, Test acc macro: 0.6667\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.8979, Epoch: 031, Train acc micro: 0.7132, Test acc micro: 0.6667,Train acc macro: 0.7132, Test acc macro: 0.6667\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.8119, Epoch: 032, Train acc micro: 0.7132, Test acc micro: 0.6667,Train acc macro: 0.7132, Test acc macro: 0.6667\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.7115, Epoch: 033, Train acc micro: 0.7132, Test acc micro: 0.6667,Train acc macro: 0.7132, Test acc macro: 0.6667\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.5976, Epoch: 034, Train acc micro: 0.7132, Test acc micro: 0.6667,Train acc macro: 0.7132, Test acc macro: 0.6667\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.4712, Epoch: 035, Train acc micro: 0.7132, Test acc micro: 0.6667,Train acc macro: 0.7132, Test acc macro: 0.6667\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.3326, Epoch: 036, Train acc micro: 0.7209, Test acc micro: 0.6667,Train acc macro: 0.7209, Test acc macro: 0.6667\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.1824, Epoch: 037, Train acc micro: 0.7364, Test acc micro: 0.6667,Train acc macro: 0.7364, Test acc macro: 0.6667\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.0224, Epoch: 038, Train acc micro: 0.7674, Test acc micro: 0.6667,Train acc macro: 0.7674, Test acc macro: 0.6667\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.8552, Epoch: 039, Train acc micro: 0.7752, Test acc micro: 0.6667,Train acc macro: 0.7752, Test acc macro: 0.6667\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.6831, Epoch: 040, Train acc micro: 0.7752, Test acc micro: 0.6944,Train acc macro: 0.7752, Test acc macro: 0.6944\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.5077, Epoch: 041, Train acc micro: 0.7829, Test acc micro: 0.6944,Train acc macro: 0.7829, Test acc macro: 0.6944\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.3301, Epoch: 042, Train acc micro: 0.7907, Test acc micro: 0.6944,Train acc macro: 0.7907, Test acc macro: 0.6944\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.1513, Epoch: 043, Train acc micro: 0.7907, Test acc micro: 0.6944,Train acc macro: 0.7907, Test acc macro: 0.6944\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.9724, Epoch: 044, Train acc micro: 0.7984, Test acc micro: 0.6944,Train acc macro: 0.7984, Test acc macro: 0.6944\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.7938, Epoch: 045, Train acc micro: 0.8140, Test acc micro: 0.6944,Train acc macro: 0.8140, Test acc macro: 0.6944\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.6153, Epoch: 046, Train acc micro: 0.8217, Test acc micro: 0.6944,Train acc macro: 0.8217, Test acc macro: 0.6944\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.4361, Epoch: 047, Train acc micro: 0.8295, Test acc micro: 0.6944,Train acc macro: 0.8295, Test acc macro: 0.6944\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.2542, Epoch: 048, Train acc micro: 0.8450, Test acc micro: 0.7222,Train acc macro: 0.8450, Test acc macro: 0.7222\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.0674, Epoch: 049, Train acc micro: 0.8527, Test acc micro: 0.7500,Train acc macro: 0.8527, Test acc macro: 0.7500\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 48.8740, Epoch: 050, Train acc micro: 0.8605, Test acc micro: 0.7500,Train acc macro: 0.8605, Test acc macro: 0.7500\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 48.6733, Epoch: 051, Train acc micro: 0.8682, Test acc micro: 0.7500,Train acc macro: 0.8682, Test acc macro: 0.7500\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 48.4654, Epoch: 052, Train acc micro: 0.8837, Test acc micro: 0.7500,Train acc macro: 0.8837, Test acc macro: 0.7500\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 48.2508, Epoch: 053, Train acc micro: 0.8915, Test acc micro: 0.7778,Train acc macro: 0.8915, Test acc macro: 0.7778\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 48.0297, Epoch: 054, Train acc micro: 0.8992, Test acc micro: 0.7778,Train acc macro: 0.8992, Test acc macro: 0.7778\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 47.8025, Epoch: 055, Train acc micro: 0.9070, Test acc micro: 0.7778,Train acc macro: 0.9070, Test acc macro: 0.7778\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 47.5693, Epoch: 056, Train acc micro: 0.9070, Test acc micro: 0.7778,Train acc macro: 0.9070, Test acc macro: 0.7778\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 47.3311, Epoch: 057, Train acc micro: 0.9070, Test acc micro: 0.7778,Train acc macro: 0.9070, Test acc macro: 0.7778\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 47.0889, Epoch: 058, Train acc micro: 0.9070, Test acc micro: 0.7778,Train acc macro: 0.9070, Test acc macro: 0.7778\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 46.8441, Epoch: 059, Train acc micro: 0.9225, Test acc micro: 0.7778,Train acc macro: 0.9225, Test acc macro: 0.7778\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 46.5977, Epoch: 060, Train acc micro: 0.9225, Test acc micro: 0.7778,Train acc macro: 0.9225, Test acc macro: 0.7778\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 46.3509, Epoch: 061, Train acc micro: 0.9225, Test acc micro: 0.7778,Train acc macro: 0.9225, Test acc macro: 0.7778\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 46.1042, Epoch: 062, Train acc micro: 0.9225, Test acc micro: 0.7778,Train acc macro: 0.9225, Test acc macro: 0.7778\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 45.8584, Epoch: 063, Train acc micro: 0.9225, Test acc micro: 0.7778,Train acc macro: 0.9225, Test acc macro: 0.7778\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 45.6142, Epoch: 064, Train acc micro: 0.9225, Test acc micro: 0.7778,Train acc macro: 0.9225, Test acc macro: 0.7778\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 45.3721, Epoch: 065, Train acc micro: 0.9302, Test acc micro: 0.7778,Train acc macro: 0.9302, Test acc macro: 0.7778\n",
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 45.1320, Epoch: 066, Train acc micro: 0.9302, Test acc micro: 0.7500,Train acc macro: 0.9302, Test acc macro: 0.7500\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.8935, Epoch: 067, Train acc micro: 0.9302, Test acc micro: 0.7500,Train acc macro: 0.9302, Test acc macro: 0.7500\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.6560, Epoch: 068, Train acc micro: 0.9302, Test acc micro: 0.7500,Train acc macro: 0.9302, Test acc macro: 0.7500\n",
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.4193, Epoch: 069, Train acc micro: 0.9380, Test acc micro: 0.7500,Train acc macro: 0.9380, Test acc macro: 0.7500\n",
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.1837, Epoch: 070, Train acc micro: 0.9380, Test acc micro: 0.7500,Train acc macro: 0.9380, Test acc macro: 0.7500\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.9494, Epoch: 071, Train acc micro: 0.9612, Test acc micro: 0.7500,Train acc macro: 0.9612, Test acc macro: 0.7500\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.7170, Epoch: 072, Train acc micro: 0.9612, Test acc micro: 0.7222,Train acc macro: 0.9612, Test acc macro: 0.7222\n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.4868, Epoch: 073, Train acc micro: 0.9612, Test acc micro: 0.7222,Train acc macro: 0.9612, Test acc macro: 0.7222\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.2594, Epoch: 074, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.0353, Epoch: 075, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 42.8148, Epoch: 076, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 42.5982, Epoch: 077, Train acc micro: 0.9690, Test acc micro: 0.7222,Train acc macro: 0.9690, Test acc macro: 0.7222\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 42.3852, Epoch: 078, Train acc micro: 0.9690, Test acc micro: 0.7222,Train acc macro: 0.9690, Test acc macro: 0.7222\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 42.1754, Epoch: 079, Train acc micro: 0.9690, Test acc micro: 0.7222,Train acc macro: 0.9690, Test acc macro: 0.7222\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.9683, Epoch: 080, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.7635, Epoch: 081, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.5606, Epoch: 082, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.3592, Epoch: 083, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.1592, Epoch: 084, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.9606, Epoch: 085, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.7634, Epoch: 086, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.5677, Epoch: 087, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.3738, Epoch: 088, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.1815, Epoch: 089, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.9910, Epoch: 090, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.8023, Epoch: 091, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.6151, Epoch: 092, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.4292, Epoch: 093, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.2446, Epoch: 094, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.0609, Epoch: 095, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 38.8779, Epoch: 096, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 38.6955, Epoch: 097, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 38.5138, Epoch: 098, Train acc micro: 0.9690, Test acc micro: 0.7500,Train acc macro: 0.9690, Test acc macro: 0.7500\n",
      "99\n",
      "Loss: 38.3327, Epoch: 099, Train acc micro: 0.9690, Test acc micro: 0.7222,Train acc macro: 0.9690, Test acc macro: 0.7222\n",
      "Loss: 38.3327, Epoch: 099, Train acc micro: 0.9690, Test acc micro: 0.7222,Train acc macro: 0.9690, Test acc macro: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-16 16:47:21,240]\u001B[0m A new study created in memory with name: HOPE_RPR loss,SAGE conv\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss  conv    dataset  train acc micro  test acc micro  \\\n",
      "0        no    no  Wisconsin         0.982955        0.900000   \n",
      "1        no    no      Texas         0.992248        0.750000   \n",
      "2        no    no      Texas         0.868217        0.694444   \n",
      "3        no    no  Wisconsin         0.880682        0.880000   \n",
      "4  HOPE_RPR  SAGE  Wisconsin         0.971591        0.920000   \n",
      "5  HOPE_RPR  SAGE      Texas         0.891473        0.722222   \n",
      "6  HOPE_RPR  SAGE      Texas         0.968992        0.722222   \n",
      "\n",
      "   train acc macro  test acc macro     clf  \n",
      "0         0.982955        0.900000     MLP  \n",
      "1         0.992248        0.750000     MLP  \n",
      "2         0.868217        0.694444  logreg  \n",
      "3         0.880682        0.880000  logreg  \n",
      "4         0.971591        0.920000  logreg  \n",
      "5         0.891473        0.722222  logreg  \n",
      "6         0.968992        0.722222     MLP  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:22,182]\u001B[0m Trial 0 finished with value: 0.4 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007623423511209641, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.5483663618759705}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:23,168]\u001B[0m Trial 1 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00941141893001075, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.7097242818492321}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:24,061]\u001B[0m Trial 2 finished with value: 0.28 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005582969770797997, 'hidden_layer_for_classifier': 32, 'alpha': 0.4, 'lmbda': 0.30493394561731346}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:25,193]\u001B[0m Trial 3 finished with value: 0.28 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005848434585062039, 'hidden_layer_for_classifier': 64, 'alpha': 0.7, 'lmbda': 0.11839141354903537}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:26,315]\u001B[0m Trial 4 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0068775745008694805, 'hidden_layer_for_classifier': 64, 'alpha': 0.6, 'lmbda': 0.06942382377467893}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:27,366]\u001B[0m Trial 5 finished with value: 0.32 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00932901380957297, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.37764404485973535}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:28,383]\u001B[0m Trial 6 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005331939118319635, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.5857884243547137}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:29,412]\u001B[0m Trial 7 finished with value: 0.32 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007240779586782082, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.5045312045058982}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:47:30,376]\u001B[0m Trial 8 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008542818045306242, 'hidden_layer_for_classifier': 128, 'alpha': 0.7, 'lmbda': 0.07202265644313655}. Best is trial 0 with value: 0.4.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:31,236]\u001B[0m Trial 9 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008589885047204435, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.9669581690986688}. Best is trial 9 with value: 0.56.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:32,054]\u001B[0m Trial 10 finished with value: 0.44 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008303130785966657, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.9903088992551938}. Best is trial 9 with value: 0.56.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:32,917]\u001B[0m Trial 11 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008120423528168082, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.9831762692251078}. Best is trial 9 with value: 0.56.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:33,718]\u001B[0m Trial 12 finished with value: 0.44 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00852804302730712, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.971803154980153}. Best is trial 9 with value: 0.56.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:34,671]\u001B[0m Trial 13 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008902790339794804, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.7960713963154952}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:35,626]\u001B[0m Trial 14 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009939199847247447, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.7957093274991813}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:36,523]\u001B[0m Trial 15 finished with value: 0.48 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009083179257099956, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.8504081772138983}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:37,478]\u001B[0m Trial 16 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006620914153939677, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.7608880841599023}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:38,458]\u001B[0m Trial 17 finished with value: 0.44 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009954169105522187, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.6907615294581678}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:39,382]\u001B[0m Trial 18 finished with value: 0.44 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009982364013439797, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.8358594826958802}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:40,314]\u001B[0m Trial 19 finished with value: 0.52 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00784177372497938, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.9064138506343455}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:41,281]\u001B[0m Trial 20 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008889825100350595, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.6299734662727691}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:42,233]\u001B[0m Trial 21 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009475725862086021, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.8394589186264102}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:43,178]\u001B[0m Trial 22 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00960062860293907, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.7853538419513146}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:44,148]\u001B[0m Trial 23 finished with value: 0.48 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009800233308890256, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.7509043201108772}. Best is trial 13 with value: 0.6.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:45,156]\u001B[0m Trial 24 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009373489449855619, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.39827477521056526}. Best is trial 24 with value: 0.64.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:46,137]\u001B[0m Trial 25 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008869242467330922, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.34701104092893253}. Best is trial 24 with value: 0.64.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:47,128]\u001B[0m Trial 26 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009455301738192635, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.3216906982132973}. Best is trial 26 with value: 0.68.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:48,100]\u001B[0m Trial 27 finished with value: 0.6 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009062176216952456, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.3801534046075867}. Best is trial 26 with value: 0.68.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:49,154]\u001B[0m Trial 28 finished with value: 0.6 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008117140900754587, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.21219262186067187}. Best is trial 26 with value: 0.68.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:50,153]\u001B[0m Trial 29 finished with value: 0.32 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00749645247255339, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.40585273218621937}. Best is trial 26 with value: 0.68.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:51,053]\u001B[0m Trial 30 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009228339643681976, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2774034453326766}. Best is trial 26 with value: 0.68.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:52,002]\u001B[0m Trial 31 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009297143600063413, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2485629891401059}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:52,986]\u001B[0m Trial 32 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009519818152618386, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.18735542333875493}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:53,925]\u001B[0m Trial 33 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009656749433643589, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1804888550004894}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:54,723]\u001B[0m Trial 34 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009640019971902516, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1859094803525195}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:55,807]\u001B[0m Trial 35 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009666897957540214, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16343203160136074}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:56,783]\u001B[0m Trial 36 finished with value: 0.36 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006358597066912224, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.27175750118402175}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:57,608]\u001B[0m Trial 37 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009314768435026662, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.002056097694008663}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:47:58,475]\u001B[0m Trial 38 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00867145875017485, 'hidden_layer_for_classifier': 32, 'alpha': 0.4, 'lmbda': 0.46275935158487846}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:47:59,392]\u001B[0m Trial 39 finished with value: 0.48 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009534065693911303, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.22769655905563888}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:00,280]\u001B[0m Trial 40 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009172932586533013, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1259066181425127}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:01,250]\u001B[0m Trial 41 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00937615443308381, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.3337573619702407}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:02,157]\u001B[0m Trial 42 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009703775900072271, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.42436199841500233}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:03,182]\u001B[0m Trial 43 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005935773655936164, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25430175124081306}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:04,442]\u001B[0m Trial 44 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005149709733603924, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.07698505860023633}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:05,590]\u001B[0m Trial 45 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00589449332176553, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2447271909395244}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:06,456]\u001B[0m Trial 46 finished with value: 0.48 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007168659756155598, 'hidden_layer_for_classifier': 32, 'alpha': 0.4, 'lmbda': 0.1418811911746837}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:07,529]\u001B[0m Trial 47 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005860272495650708, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.31365978187160737}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:08,547]\u001B[0m Trial 48 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005860142622165769, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.013215146552634588}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:09,704]\u001B[0m Trial 49 finished with value: 0.32 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005704383694627952, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.016282379004014635}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:10,754]\u001B[0m Trial 50 finished with value: 0.28 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006157216963956288, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.31808316913629975}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:11,761]\u001B[0m Trial 51 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005439372234294306, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.08721610816858695}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:12,787]\u001B[0m Trial 52 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005499253973394623, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.09324014030782161}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:13,785]\u001B[0m Trial 53 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00606520407424926, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.050101571414876506}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:14,740]\u001B[0m Trial 54 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0060948785031456855, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.1000762081452164}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:15,750]\u001B[0m Trial 55 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005438533990502113, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.04843068148452623}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:16,763]\u001B[0m Trial 56 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006809985015705231, 'hidden_layer_for_classifier': 128, 'alpha': 0.6, 'lmbda': 0.2619419061389836}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:17,810]\u001B[0m Trial 57 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005057526665556402, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.13930329660919755}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:18,841]\u001B[0m Trial 58 finished with value: 0.4 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005076038287806813, 'hidden_layer_for_classifier': 128, 'alpha': 0.7, 'lmbda': 0.5298863223825895}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:19,776]\u001B[0m Trial 59 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0064758375340603445, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.16394993557365373}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:20,786]\u001B[0m Trial 60 finished with value: 0.64 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0056957564390841655, 'hidden_layer_for_classifier': 128, 'alpha': 0.5, 'lmbda': 0.04117368326297169}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:21,804]\u001B[0m Trial 61 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00529952355536749, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.11474167539023655}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:22,742]\u001B[0m Trial 62 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005231958773515742, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.21136052877132833}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:23,766]\u001B[0m Trial 63 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006122769904036572, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.1333334785682923}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:24,816]\u001B[0m Trial 64 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0052877024812667895, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.175085959782117}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:25,800]\u001B[0m Trial 65 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005262226610695274, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.2959048112010227}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:26,693]\u001B[0m Trial 66 finished with value: 0.64 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0052535462604102225, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2953886040438637}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:27,660]\u001B[0m Trial 67 finished with value: 0.32 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005710186908133107, 'hidden_layer_for_classifier': 128, 'alpha': 0.9, 'lmbda': 0.2093633303432877}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:28,721]\u001B[0m Trial 68 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005501285399693124, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3645139685686911}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:29,909]\u001B[0m Trial 69 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005596448227454472, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3737405600441598}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:31,007]\u001B[0m Trial 70 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006003740095489042, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4426779449492689}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:32,063]\u001B[0m Trial 71 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006332063988237317, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.45117217452293507}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:33,108]\u001B[0m Trial 72 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0058365204271493805, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3483693527655807}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:34,191]\u001B[0m Trial 73 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005577758270843292, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24931351929811826}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:35,134]\u001B[0m Trial 74 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005596689346777752, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.3632327132179696}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:36,298]\u001B[0m Trial 75 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005784907886770649, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.24326036874643428}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:37,271]\u001B[0m Trial 76 finished with value: 0.52 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006280756014054211, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.4920817602141669}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:38,403]\u001B[0m Trial 77 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005948771595111447, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.33518510379719196}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:39,325]\u001B[0m Trial 78 finished with value: 0.48 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005405156592447745, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.3461047997335559}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:40,399]\u001B[0m Trial 79 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00765074740373335, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.2636698246425111}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:41,469]\u001B[0m Trial 80 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005953684451923803, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2959236399927291}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:42,549]\u001B[0m Trial 81 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0059513022421502585, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3146235588740307}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:43,676]\u001B[0m Trial 82 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0062147881868001185, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3973061377509787}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:44,844]\u001B[0m Trial 83 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006799208555708214, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.40193701319816766}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:45,917]\u001B[0m Trial 84 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006833319039748721, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.396990976895617}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:46,893]\u001B[0m Trial 85 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006540103052733749, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.30021461218358664}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:48,029]\u001B[0m Trial 86 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006240586818338496, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22885181919572276}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:49,130]\u001B[0m Trial 87 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007014022014843311, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3347810922449033}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:50,329]\u001B[0m Trial 88 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006742275961876711, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.4816508000248103}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:51,384]\u001B[0m Trial 89 finished with value: 0.4 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0072100760739995775, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.37171493307404213}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:52,253]\u001B[0m Trial 90 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007043709655730263, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.4261322265100971}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:53,313]\u001B[0m Trial 91 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006992607716162634, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2839557144085914}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:54,435]\u001B[0m Trial 92 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007969541170484495, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3405396939753741}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:55,563]\u001B[0m Trial 93 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005797697730317335, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19260663182771495}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:56,613]\u001B[0m Trial 94 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008309384332916976, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3537537569495743}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:57,698]\u001B[0m Trial 95 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0062344591931120024, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3152905989655296}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:58,566]\u001B[0m Trial 96 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00832903099666573, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.25588371286198175}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:48:59,655]\u001B[0m Trial 97 finished with value: 0.32 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009836767931455206, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.5691660198983447}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:00,688]\u001B[0m Trial 98 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006405639566181195, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.2377871752514037}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:01,636]\u001B[0m Trial 99 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0066759103417520175, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.4101532347747955}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:02,694]\u001B[0m Trial 100 finished with value: 0.44 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007379556134922626, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.33140005803766176}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:03,767]\u001B[0m Trial 101 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00875556853675522, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21720338641609616}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:04,875]\u001B[0m Trial 102 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005981989841886637, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2822504809687383}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:05,994]\u001B[0m Trial 103 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0055469090080988576, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2738217098785366}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:07,062]\u001B[0m Trial 104 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005514204746672001, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19288671353324027}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:08,135]\u001B[0m Trial 105 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005633784987531596, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2769333454952248}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:09,256]\u001B[0m Trial 106 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.0054828119097300515, 'hidden_layer_for_classifier': 32, 'alpha': 0.2, 'lmbda': 0.27719756553719826}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:10,229]\u001B[0m Trial 107 finished with value: 0.4 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006032024901307566, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.3875743627987088}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:11,280]\u001B[0m Trial 108 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005816884822712701, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.304839359833444}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:49:12,146]\u001B[0m Trial 109 finished with value: 0.32 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0051835867664534446, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.35964137137550456}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:13,231]\u001B[0m Trial 110 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008399244497503096, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.33832904768102157}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:14,306]\u001B[0m Trial 111 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006488171944130224, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2287559292459536}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:15,391]\u001B[0m Trial 112 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005859224427677815, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25185430803907427}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:16,503]\u001B[0m Trial 113 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006593093017356616, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19830019500688634}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:17,577]\u001B[0m Trial 114 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006188529520099181, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1983806850230164}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:18,651]\u001B[0m Trial 115 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005399362050559072, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14295757236769968}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:19,777]\u001B[0m Trial 116 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005690197695663918, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.15662504834809376}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:20,841]\u001B[0m Trial 117 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008928860421605166, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22796960874567554}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:21,911]\u001B[0m Trial 118 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0057574968444416025, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4156981277583299}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:22,868]\u001B[0m Trial 119 finished with value: 0.4 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005975175793535479, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.2914718446548433}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:23,971]\u001B[0m Trial 120 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00871006183689444, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.38085804179188476}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:25,043]\u001B[0m Trial 121 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006579500511361279, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4656044609842309}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:26,154]\u001B[0m Trial 122 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006141375198655218, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.26601413166565696}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:27,259]\u001B[0m Trial 123 finished with value: 0.72 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005920534668188695, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.31855235375033497}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:28,355]\u001B[0m Trial 124 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006403316965511928, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.30411314628764147}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:29,403]\u001B[0m Trial 125 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0059908315407690045, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24957912987181977}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:30,511]\u001B[0m Trial 126 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007724453393342638, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1748973480565745}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:31,556]\u001B[0m Trial 127 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007436791676220419, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6691347796421145}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:32,434]\u001B[0m Trial 128 finished with value: 0.4 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005347511748117924, 'hidden_layer_for_classifier': 32, 'alpha': 0.4, 'lmbda': 0.12118248093118236}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:49:33,269]\u001B[0m Trial 129 finished with value: 0.32 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005552517797681763, 'hidden_layer_for_classifier': 64, 'alpha': 0.8, 'lmbda': 0.21451482828842536}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:49:34,461]\u001B[0m Trial 130 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.0055279663281503745, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10947504938051605}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:35,570]\u001B[0m Trial 131 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0053751440880836195, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1423717513087066}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:36,628]\u001B[0m Trial 132 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005679095777155453, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3283967614260376}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:37,726]\u001B[0m Trial 133 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006081734487092302, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3572983674869068}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:38,809]\u001B[0m Trial 134 finished with value: 0.48 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005955996368701061, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.28167326423725425}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:39,903]\u001B[0m Trial 135 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006985404405098477, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.41015790592575496}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:40,946]\u001B[0m Trial 136 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005631949938966606, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.43278187961284015}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:42,047]\u001B[0m Trial 137 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005870532025383182, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.31651227949814836}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:43,015]\u001B[0m Trial 138 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006301137659686079, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.4465547276265019}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:44,093]\u001B[0m Trial 139 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005080641709157801, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2684345732368644}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:45,156]\u001B[0m Trial 140 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005140703063313328, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.1542533896703372}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:46,238]\u001B[0m Trial 141 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006674752471113397, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20095563534724517}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:47,301]\u001B[0m Trial 142 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006214275718486287, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3393153325524032}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:48,427]\u001B[0m Trial 143 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006273804704046437, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2649167471838094}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:49,558]\u001B[0m Trial 144 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009236833532155958, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.23636484561764515}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:50,617]\u001B[0m Trial 145 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005029899518253206, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3864786086328832}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:51,692]\u001B[0m Trial 146 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005793412918144326, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.29334652490764707}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:52,807]\u001B[0m Trial 147 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00806968935164983, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.17771828671847917}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:53,909]\u001B[0m Trial 148 finished with value: 0.72 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007311601777310605, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.21998246072446626}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:54,836]\u001B[0m Trial 149 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0060665748852276645, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.267359695164245}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:49:55,966]\u001B[0m Trial 150 finished with value: 0.28 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006393963366547139, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.5242871987353914}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:57,032]\u001B[0m Trial 151 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0055822010052383525, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.31182145848548476}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:58,100]\u001B[0m Trial 152 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005779609269859579, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.329723058011175}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:49:59,206]\u001B[0m Trial 153 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0053935031686329965, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3688491971244509}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:00,091]\u001B[0m Trial 154 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005311816773062656, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1461082916485272}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:01,155]\u001B[0m Trial 155 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005135128069812019, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2485175363511975}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:02,277]\u001B[0m Trial 156 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0052045837648139, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.24189733715511694}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:03,421]\u001B[0m Trial 157 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009071997597844784, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.34999469936942745}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:04,541]\u001B[0m Trial 158 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009532341527559962, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.42587975630360775}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:05,719]\u001B[0m Trial 159 finished with value: 0.48 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007095152629077024, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.28647823002086265}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:06,838]\u001B[0m Trial 160 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006159949524409028, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.2627197028878831}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:07,925]\u001B[0m Trial 161 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008823008381996667, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1922213265081773}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:08,987]\u001B[0m Trial 162 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005012587549932294, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20301856309239819}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:10,093]\u001B[0m Trial 163 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00974079938740066, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22555214634941098}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:11,141]\u001B[0m Trial 164 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005917418504661078, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.30491271708996537}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:12,062]\u001B[0m Trial 165 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005761480254703128, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.18804080919600386}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:13,198]\u001B[0m Trial 166 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008603913223334928, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.28050183655459654}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:14,120]\u001B[0m Trial 167 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006025560219916294, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.24245786977188724}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:15,165]\u001B[0m Trial 168 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0068167403623165, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.41040917531642074}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:16,288]\u001B[0m Trial 169 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006138100172035091, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2612924725859601}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:17,286]\u001B[0m Trial 170 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005462023720259828, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.37606858918628544}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:18,390]\u001B[0m Trial 171 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006116162137774576, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.32804918700632674}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:19,365]\u001B[0m Trial 172 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00567014501567305, 'hidden_layer_for_classifier': 128, 'alpha': 0.8, 'lmbda': 0.33596610465731674}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:20,438]\u001B[0m Trial 173 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0093840611471639, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.31034640466278357}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:21,565]\u001B[0m Trial 174 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006888437695704272, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21958233258122226}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:22,642]\u001B[0m Trial 175 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006520338758504958, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.23387804512343235}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:23,740]\u001B[0m Trial 176 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008435577773124711, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19962654811952368}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:24,757]\u001B[0m Trial 177 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008130394408637474, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.2545055210611645}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:25,864]\u001B[0m Trial 178 finished with value: 0.56 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008319705303160256, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.16978732143164232}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:26,908]\u001B[0m Trial 179 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009294803188604159, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2802084651723257}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:28,023]\u001B[0m Trial 180 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005121600230142385, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2573540251244681}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:29,090]\u001B[0m Trial 181 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005151297995895126, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3552916295939271}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:30,177]\u001B[0m Trial 182 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009077953040419024, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3521377347644116}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:31,251]\u001B[0m Trial 183 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006637009746840177, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.2035521138219092}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:32,309]\u001B[0m Trial 184 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006384549717174236, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.18198131197693013}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:33,293]\u001B[0m Trial 185 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009891410544284648, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2667650147062739}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:34,433]\u001B[0m Trial 186 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005380864958816582, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14774854177179492}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:35,404]\u001B[0m Trial 187 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009783862553256905, 'hidden_layer_for_classifier': 32, 'alpha': 0.7, 'lmbda': 0.302599489227035}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:36,375]\u001B[0m Trial 188 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008977171724126156, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2243633111424299}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:37,416]\u001B[0m Trial 189 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006143116729768726, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.29152000327057775}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:38,531]\u001B[0m Trial 190 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006223425458255962, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24630720727274455}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:39,603]\u001B[0m Trial 191 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005714478873243638, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2742576238779755}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:40,668]\u001B[0m Trial 192 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006010231816768163, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.32019191893639243}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:41,787]\u001B[0m Trial 193 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005275351398216653, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.32040596253829867}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:42,880]\u001B[0m Trial 194 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005295721518641097, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3347046336330063}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:43,934]\u001B[0m Trial 195 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009443082812916118, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2285420813125269}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:45,025]\u001B[0m Trial 196 finished with value: 0.24 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009628152646705166, 'hidden_layer_for_classifier': 128, 'alpha': 0.3, 'lmbda': 0.24723399692414114}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:45,961]\u001B[0m Trial 197 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007975612430332537, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2191743814519784}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:47,031]\u001B[0m Trial 198 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008495150132112933, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.27802021529981563}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:48,012]\u001B[0m Trial 199 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005458628781203366, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2963491864271117}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:49,116]\u001B[0m Trial 200 finished with value: 0.44 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005257906270639142, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.34923763550954856}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:50,203]\u001B[0m Trial 201 finished with value: 0.68 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0070914012436842306, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2532291311403747}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:51,183]\u001B[0m Trial 202 finished with value: 0.64 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005088320041108277, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.36824193758836327}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:52,301]\u001B[0m Trial 203 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007556165457521517, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.07216752690652611}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:53,373]\u001B[0m Trial 204 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006287532738760089, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2005586483304756}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:54,448]\u001B[0m Trial 205 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005181262639439844, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1745050797840835}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:55,580]\u001B[0m Trial 206 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005529856761768178, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19206930165461022}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:56,663]\u001B[0m Trial 207 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009189089327880113, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.38964435019274607}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:57,734]\u001B[0m Trial 208 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005862839551268235, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.31579346497050986}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:58,849]\u001B[0m Trial 209 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0056309576032669804, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.33277606839728263}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:50:59,954]\u001B[0m Trial 210 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005346434346848195, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16638941769392554}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:01,002]\u001B[0m Trial 211 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006083571715649924, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4301909581634738}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:02,080]\u001B[0m Trial 212 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006098822411688392, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.44634656175954646}. Best is trial 31 with value: 0.8.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:03,173]\u001B[0m Trial 213 finished with value: 0.84 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005808308411466081, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.18816541192487096}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:04,295]\u001B[0m Trial 214 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0051053371267194055, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21678861977084266}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:05,425]\u001B[0m Trial 215 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005156299650387419, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.27318872568770003}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:06,551]\u001B[0m Trial 216 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005847033332622347, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.29586237563752416}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:07,601]\u001B[0m Trial 217 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0050027910445860305, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.20675912199237392}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:08,711]\u001B[0m Trial 218 finished with value: 0.4 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005035217941479693, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.8927354581655516}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:09,792]\u001B[0m Trial 219 finished with value: 0.4 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005190119498443448, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.21421842486274928}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:10,870]\u001B[0m Trial 220 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005132279986270822, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.18205172686463164}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:11,989]\u001B[0m Trial 221 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008637059521115986, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24122314305524012}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:13,077]\u001B[0m Trial 222 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008488202238694124, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1313574467487715}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:14,153]\u001B[0m Trial 223 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007954511706990196, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.12615015084663345}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:15,278]\u001B[0m Trial 224 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008099320254246227, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.12467989050597575}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:16,410]\u001B[0m Trial 225 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0077619513838444645, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.10579883156364969}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:17,349]\u001B[0m Trial 226 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005760356632438974, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.15544649027452878}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:51:18,368]\u001B[0m Trial 227 finished with value: 0.36 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005944294349153519, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16795131686120635}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:19,495]\u001B[0m Trial 228 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00852176217917316, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3239432043724475}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:20,581]\u001B[0m Trial 229 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008228450405384282, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.17149414931802567}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:21,651]\u001B[0m Trial 230 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008156186933598375, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.17944684333260963}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:22,781]\u001B[0m Trial 231 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008400087005485501, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3961358788439387}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:23,875]\u001B[0m Trial 232 finished with value: 0.64 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00856221083745588, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3230088775231697}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:24,946]\u001B[0m Trial 233 finished with value: 0.48 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008527157669094508, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.2735034726832225}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:26,060]\u001B[0m Trial 234 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008348193468216459, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2646257706441336}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:27,131]\u001B[0m Trial 235 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00547896632233034, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3693574915066863}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:28,216]\u001B[0m Trial 236 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008227547102623592, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.35361149377499174}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:29,386]\u001B[0m Trial 237 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005652141950845347, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.46668499098565686}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:30,346]\u001B[0m Trial 238 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008429896470640486, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.1903515691841825}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:31,435]\u001B[0m Trial 239 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00847009423576171, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14765087606051672}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:32,575]\u001B[0m Trial 240 finished with value: 0.76 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008685309602108176, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1606143420710641}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:33,688]\u001B[0m Trial 241 finished with value: 0.72 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00873724758046752, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16501789169261594}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:34,768]\u001B[0m Trial 242 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005269118579722812, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.35040390037735736}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:35,846]\u001B[0m Trial 243 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005255504393590107, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2974820907447593}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:36,822]\u001B[0m Trial 244 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006843872237808379, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.23172021175605056}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:37,720]\u001B[0m Trial 245 finished with value: 0.6 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0051766125991128805, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.25091592269466134}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:38,825]\u001B[0m Trial 246 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008262223181028996, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25844955659562097}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:39,821]\u001B[0m Trial 247 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005751679303533383, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2140157415768705}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:40,924]\u001B[0m Trial 248 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005832076117559383, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3816586420205326}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:42,014]\u001B[0m Trial 249 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006216803437730208, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.3369352979580673}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:43,014]\u001B[0m Trial 250 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008589997849132723, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2325113221633903}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:44,174]\u001B[0m Trial 251 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009718418911679233, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2272891359769448}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:45,255]\u001B[0m Trial 252 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008927231149372213, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.27973316340161397}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:46,371]\u001B[0m Trial 253 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0051320301477549585, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2978435635722914}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:47,464]\u001B[0m Trial 254 finished with value: 0.28 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005328251843088374, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.37099087674073106}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:48,529]\u001B[0m Trial 255 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005607446242819164, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.3061402095290687}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:49,610]\u001B[0m Trial 256 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006982055090269903, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21549949146185465}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:50,707]\u001B[0m Trial 257 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0050216543904380165, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.18338627530359763}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:51,790]\u001B[0m Trial 258 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0070183112668938995, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2078852769717795}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:52,879]\u001B[0m Trial 259 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005021359455526136, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.20013151815807184}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:54,001]\u001B[0m Trial 260 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005102232084637719, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1352986163330568}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:55,261]\u001B[0m Trial 261 finished with value: 0.36 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007891534168339813, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10455964383971511}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:56,185]\u001B[0m Trial 262 finished with value: 0.64 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005408339272472776, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.08689076177050747}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:57,280]\u001B[0m Trial 263 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008770892155395685, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.28017326434661916}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:58,354]\u001B[0m Trial 264 finished with value: 0.36 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00843679536850474, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.31493053163665474}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:51:59,489]\u001B[0m Trial 265 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00794883923476162, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.17665977690184387}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:00,610]\u001B[0m Trial 266 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005224643961919309, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.1256403115256009}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:01,682]\u001B[0m Trial 267 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0052188732625595815, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2497892813767555}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:02,732]\u001B[0m Trial 268 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009311204877867733, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.33482657334193144}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:03,623]\u001B[0m Trial 269 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008244130634012104, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.17752358594444514}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:04,550]\u001B[0m Trial 270 finished with value: 0.52 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008249799596354614, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20347945330616957}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:05,513]\u001B[0m Trial 271 finished with value: 0.56 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005039686912575149, 'hidden_layer_for_classifier': 64, 'alpha': 0.2, 'lmbda': 0.3889822730799928}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:06,547]\u001B[0m Trial 272 finished with value: 0.48 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0060376120149764735, 'hidden_layer_for_classifier': 128, 'alpha': 0.5, 'lmbda': 0.1490017816667331}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:07,508]\u001B[0m Trial 273 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005123681472643351, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.41535967716559186}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:08,558]\u001B[0m Trial 274 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009157852502271416, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.5996991668425908}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:09,682]\u001B[0m Trial 275 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005509414286164716, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19096523982525498}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:10,834]\u001B[0m Trial 276 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008052639668415152, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25363225955851093}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:11,912]\u001B[0m Trial 277 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005425146811317582, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.12264836406214588}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:13,012]\u001B[0m Trial 278 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0073026016576396464, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.21044617203867427}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:14,105]\u001B[0m Trial 279 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005551484297952438, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.31997876492148697}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:15,057]\u001B[0m Trial 280 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006474512285976117, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2895429011381466}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:16,351]\u001B[0m Trial 281 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005891187544245156, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.4130217174369907}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:17,450]\u001B[0m Trial 282 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005202902081134061, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.23747872142866203}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:18,534]\u001B[0m Trial 283 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009574221520746901, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1960961522199995}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:19,605]\u001B[0m Trial 284 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009204067349176611, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3522479884143431}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:20,595]\u001B[0m Trial 285 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005007095451435032, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19121495858207727}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:21,682]\u001B[0m Trial 286 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008358960765502424, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3213447571298517}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:22,823]\u001B[0m Trial 287 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005732758285680554, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2667190664886704}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:23,881]\u001B[0m Trial 288 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005284358478197587, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.30593315912209074}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:24,826]\u001B[0m Trial 289 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006766437340139066, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22860804790224126}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:25,898]\u001B[0m Trial 290 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005491540753711715, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.33588808936151887}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:26,955]\u001B[0m Trial 291 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008524190210097262, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.28003065763596535}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:27,926]\u001B[0m Trial 292 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006134072496156945, 'hidden_layer_for_classifier': 128, 'alpha': 0.2, 'lmbda': 0.5096204505846821}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:28,823]\u001B[0m Trial 293 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005375096645146011, 'hidden_layer_for_classifier': 32, 'alpha': 0.9, 'lmbda': 0.1366800415349358}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:29,899]\u001B[0m Trial 294 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00564328541782084, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.39212871077385336}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:30,845]\u001B[0m Trial 295 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008855095315958576, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19496426444960224}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:31,771]\u001B[0m Trial 296 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008146259940944159, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.22966287715112316}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:32,886]\u001B[0m Trial 297 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005990566175462136, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.15565849328683382}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:34,017]\u001B[0m Trial 298 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005910363281872083, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.29320050877534776}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:35,150]\u001B[0m Trial 299 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005822161657618716, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.15563348637192137}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:36,294]\u001B[0m Trial 300 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008448044571183236, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24589418640446778}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:37,458]\u001B[0m Trial 301 finished with value: 0.56 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005924811983229099, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.29837107790631545}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:38,657]\u001B[0m Trial 302 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0051196537705092806, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1697770015045833}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:39,766]\u001B[0m Trial 303 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005624356257816938, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1643161455042974}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:40,920]\u001B[0m Trial 304 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005959806495515159, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.2869354691163135}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:42,160]\u001B[0m Trial 305 finished with value: 0.28 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006026443893827577, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.30494182747841264}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:43,309]\u001B[0m Trial 306 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0066550496679811545, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.233347403812518}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:44,473]\u001B[0m Trial 307 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00512397728428352, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2629026437024494}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:45,654]\u001B[0m Trial 308 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005507964317520223, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.34450768330779163}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:46,718]\u001B[0m Trial 309 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005350588386189068, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.26428136405745606}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:47,881]\u001B[0m Trial 310 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00631715973548092, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20891422774002041}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:49,036]\u001B[0m Trial 311 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005075160068422944, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.18632253221853393}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:50,186]\u001B[0m Trial 312 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006270810422399521, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.26187743507070327}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:51,287]\u001B[0m Trial 313 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005743665487303643, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2702328401767038}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:52,457]\u001B[0m Trial 314 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005213990422388234, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25246365204646254}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:53,626]\u001B[0m Trial 315 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007411343520237383, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.26853710902789807}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:54,726]\u001B[0m Trial 316 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008645430998805003, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24052266050660873}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:55,860]\u001B[0m Trial 317 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005881838316919311, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2865745547791817}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:57,012]\u001B[0m Trial 318 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005126112100314594, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21440709337743916}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:58,151]\u001B[0m Trial 319 finished with value: 0.68 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007628973957571522, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2881366542858792}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:52:59,061]\u001B[0m Trial 320 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008559854058824796, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.2718074502035999}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:00,759]\u001B[0m Trial 321 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005207858758710739, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.31033958379861704}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:02,207]\u001B[0m Trial 322 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005251472630093222, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3300460661924995}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:03,864]\u001B[0m Trial 323 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005011001878990446, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.3129783257797988}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:05,587]\u001B[0m Trial 324 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009467982744355518, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2551032238486692}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:06,957]\u001B[0m Trial 325 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00575633403831959, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2872067596786082}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:08,184]\u001B[0m Trial 326 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008012867033070931, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.10635486583948939}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:09,031]\u001B[0m Trial 327 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005294945553397846, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.185189686953577}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:10,280]\u001B[0m Trial 328 finished with value: 0.36 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005148497503986669, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2696957280369289}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:11,365]\u001B[0m Trial 329 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005082391086138219, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.3074155249685017}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:12,501]\u001B[0m Trial 330 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007184272627783504, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.7280657553435592}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:13,633]\u001B[0m Trial 331 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005198600545462666, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2102717334185219}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:14,803]\u001B[0m Trial 332 finished with value: 0.68 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005691021149665765, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.27554004384883246}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:16,337]\u001B[0m Trial 333 finished with value: 0.36 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006168253474454383, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.2254704264069856}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:17,741]\u001B[0m Trial 334 finished with value: 0.52 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005001875862213882, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.3199215665447179}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:19,058]\u001B[0m Trial 335 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005916551226117962, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.30542190618026954}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:20,359]\u001B[0m Trial 336 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005418337983760631, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.1301916677655648}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:21,507]\u001B[0m Trial 337 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005794741050466604, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3675382226246444}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:22,745]\u001B[0m Trial 338 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00532976640099067, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.23575679634320507}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:23,903]\u001B[0m Trial 339 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005213498924434998, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20025644415657395}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:25,008]\u001B[0m Trial 340 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0094344639939901, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2568793911536237}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:26,126]\u001B[0m Trial 341 finished with value: 0.44 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00511185229682336, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.25038496369785185}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:27,269]\u001B[0m Trial 342 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005110485508821151, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.23665499913875115}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:28,202]\u001B[0m Trial 343 finished with value: 0.56 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00528769375515211, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.2896042863057068}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:29,303]\u001B[0m Trial 344 finished with value: 0.84 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005004856077135731, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2666555950528324}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:30,444]\u001B[0m Trial 345 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0050077910078270725, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25698955205319995}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:31,553]\u001B[0m Trial 346 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007808915677546839, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2741048494766778}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:32,666]\u001B[0m Trial 347 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005182684599287116, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.256615628923752}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:33,780]\u001B[0m Trial 348 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009405875104506559, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.29241948047933314}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:34,884]\u001B[0m Trial 349 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0051194926190495475, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22198070530730582}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:35,859]\u001B[0m Trial 350 finished with value: 0.64 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005086438157947166, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.22994814636742672}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:36,979]\u001B[0m Trial 351 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005181258761330783, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22010501393822715}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:38,219]\u001B[0m Trial 352 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005004475645960373, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2431119907818248}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:39,326]\u001B[0m Trial 353 finished with value: 0.48 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005147601817270144, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.27331820681768887}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:40,350]\u001B[0m Trial 354 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005338528208166917, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20211367859825052}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:41,435]\u001B[0m Trial 355 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005069693043232844, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.17380958597383928}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:42,580]\u001B[0m Trial 356 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0052645676348647575, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2164739039170106}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:43,743]\u001B[0m Trial 357 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005563835071487472, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.301664842628526}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:44,896]\u001B[0m Trial 358 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0050007243792479636, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2465074647791338}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:46,042]\u001B[0m Trial 359 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007530875241602997, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2695480684407571}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:47,147]\u001B[0m Trial 360 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0052548282306279495, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.32486015898189324}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:48,255]\u001B[0m Trial 361 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005164942479638734, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.23903860167338567}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:49,396]\u001B[0m Trial 362 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005454521620671766, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1828783205731314}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:50,517]\u001B[0m Trial 363 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0057302524245372135, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.2099554552658297}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:51,760]\u001B[0m Trial 364 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005084405020965863, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22336235868798548}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:53,168]\u001B[0m Trial 365 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005197806323761603, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.26412333813387}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:54,795]\u001B[0m Trial 366 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005299901224725619, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.28822603884601866}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:56,144]\u001B[0m Trial 367 finished with value: 0.44 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005379124601505155, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.5535860475714292}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:57,293]\u001B[0m Trial 368 finished with value: 0.52 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005818554744135827, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.30908007639941376}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:58,390]\u001B[0m Trial 369 finished with value: 0.48 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009511230884497287, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.2867815662526412}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:53:59,640]\u001B[0m Trial 370 finished with value: 0.56 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009952586911241491, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.9554966066422479}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:00,868]\u001B[0m Trial 371 finished with value: 0.44 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005565123090824278, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.2674930821402238}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:01,885]\u001B[0m Trial 372 finished with value: 0.6 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005094174636381779, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.1984761335331753}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:02,987]\u001B[0m Trial 373 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009305766794624809, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2514532935592054}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:04,296]\u001B[0m Trial 374 finished with value: 0.36 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.0058644069737802005, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.321355393053533}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:05,415]\u001B[0m Trial 375 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005190756456153279, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16036683674766072}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:06,554]\u001B[0m Trial 376 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0051033322344893745, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1839438360076902}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:07,701]\u001B[0m Trial 377 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006057365373311331, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.28869005526668523}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:08,824]\u001B[0m Trial 378 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005653051637669673, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.33826120892880546}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:10,036]\u001B[0m Trial 379 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005264520185420649, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.24105729569384102}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:11,168]\u001B[0m Trial 380 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00543939588026793, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21513651843941173}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:12,279]\u001B[0m Trial 381 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0053996359395851136, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.15727014692409186}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:13,457]\u001B[0m Trial 382 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009640251383393418, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2573119355638313}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:14,512]\u001B[0m Trial 383 finished with value: 0.44 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005452587675591524, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.31728662055130513}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:15,636]\u001B[0m Trial 384 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005298835415833118, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21604782624210572}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:16,750]\u001B[0m Trial 385 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005982078754653037, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.28014701819065707}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:17,873]\u001B[0m Trial 386 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005553916358275553, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.1775921781858514}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:18,953]\u001B[0m Trial 387 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005476367347279739, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3535957715561767}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:20,106]\u001B[0m Trial 388 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005370979401121532, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20088453382802246}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:21,228]\u001B[0m Trial 389 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005695473097611413, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.225963847623663}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:22,302]\u001B[0m Trial 390 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005850578782165348, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6561880789209615}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:23,252]\u001B[0m Trial 391 finished with value: 0.44 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005797552288944839, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.36548010508783224}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:24,376]\u001B[0m Trial 392 finished with value: 0.44 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005927646749506694, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.5887787970225669}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:25,451]\u001B[0m Trial 393 finished with value: 0.44 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005228520982351196, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.2980863329514678}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:26,524]\u001B[0m Trial 394 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008359017279250548, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.35367206460819056}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:27,653]\u001B[0m Trial 395 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005473435365146509, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6370246359216527}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:28,626]\u001B[0m Trial 396 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00561272037981778, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6598599707198486}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:29,475]\u001B[0m Trial 397 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005853437561453603, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.4833577362280631}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:30,765]\u001B[0m Trial 398 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005088102949447083, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.24127815250671034}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:31,878]\u001B[0m Trial 399 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005028456336613988, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.19717058857869113}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:32,939]\u001B[0m Trial 400 finished with value: 0.64 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006066900843262605, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.8557602488460587}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:34,128]\u001B[0m Trial 401 finished with value: 0.28 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005724018545761393, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.7146666838210841}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:35,255]\u001B[0m Trial 402 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005547402118936072, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3415635246863123}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:36,372]\u001B[0m Trial 403 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009004265013959746, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.14142502340010996}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:37,510]\u001B[0m Trial 404 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005324897928474497, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.173920835241267}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:38,686]\u001B[0m Trial 405 finished with value: 0.28 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008461549975924028, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.33015201856029597}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:39,811]\u001B[0m Trial 406 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008665820396534296, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22957947080905478}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:40,908]\u001B[0m Trial 407 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005447958500302514, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.300626132906533}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:41,948]\u001B[0m Trial 408 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054717800439158856, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.26073476694610415}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:42,900]\u001B[0m Trial 409 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005925961990402947, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.2473180803303563}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:43,994]\u001B[0m Trial 410 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005662409131416065, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21147372423544017}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:45,118]\u001B[0m Trial 411 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005245349377304967, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.19461404923627018}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:46,203]\u001B[0m Trial 412 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005408775269464263, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.35471557705167134}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:47,291]\u001B[0m Trial 413 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005783871869937627, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22301948188302254}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:48,480]\u001B[0m Trial 414 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005135744401376756, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2711624040253682}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:49,585]\u001B[0m Trial 415 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005179226032748876, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.6816873333125036}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:50,666]\u001B[0m Trial 416 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00500415839422383, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3368387318917152}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:51,644]\u001B[0m Trial 417 finished with value: 0.52 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005554849792590739, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.219597025519567}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "\u001B[32m[I 2022-11-16 16:54:52,614]\u001B[0m Trial 418 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008771214371698017, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.16553976120601188}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:53,706]\u001B[0m Trial 419 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006198445696978345, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.38212716349625747}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:54,837]\u001B[0m Trial 420 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005341633551434436, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.5311634369711501}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:55,837]\u001B[0m Trial 421 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005185605916160715, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.8354155963729643}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:56,844]\u001B[0m Trial 422 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005323465980863224, 'hidden_layer_for_classifier': 64, 'alpha': 0.4, 'lmbda': 0.3046048168064307}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:57,994]\u001B[0m Trial 423 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005995258163421388, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2362678668742606}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:54:59,132]\u001B[0m Trial 424 finished with value: 0.6 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00818961324851329, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.8092199680601349}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:00,322]\u001B[0m Trial 425 finished with value: 0.32 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.006072295255807574, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2659001721348995}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:01,492]\u001B[0m Trial 426 finished with value: 0.72 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0059610925782240766, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.18698886488514166}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:02,631]\u001B[0m Trial 427 finished with value: 0.28 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009393254271747491, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.24299297860844832}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:03,765]\u001B[0m Trial 428 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005878089470052794, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20663500702188384}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:04,852]\u001B[0m Trial 429 finished with value: 0.6 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007724732329063226, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.145220162270227}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:05,912]\u001B[0m Trial 430 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008607760441569048, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.3626006180433624}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:07,050]\u001B[0m Trial 431 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00577305039727676, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22514957210510583}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:08,157]\u001B[0m Trial 432 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005578922724246928, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.7788315664241365}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:09,298]\u001B[0m Trial 433 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0053923155549302215, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.18359885104110002}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:10,273]\u001B[0m Trial 434 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006110142334927614, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2818286785350222}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:11,374]\u001B[0m Trial 435 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0050001792117143765, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.3181614144390972}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:12,546]\u001B[0m Trial 436 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005732164656871354, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.057181547735221716}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:13,628]\u001B[0m Trial 437 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005680773688354637, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.07484956327617645}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:14,702]\u001B[0m Trial 438 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005766451769974537, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.05357130885351841}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:15,866]\u001B[0m Trial 439 finished with value: 0.68 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0058567400127086605, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16740569709780037}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:16,972]\u001B[0m Trial 440 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005478942080018031, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2435232919655369}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:18,088]\u001B[0m Trial 441 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008370572341931155, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2535089934071977}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:18,948]\u001B[0m Trial 442 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008498680200873613, 'hidden_layer_for_classifier': 32, 'alpha': 0.3, 'lmbda': 0.21466923842552796}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:20,202]\u001B[0m Trial 443 finished with value: 0.36 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.0058337394006771895, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.09750841903695107}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:21,343]\u001B[0m Trial 444 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005975476211413309, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.262428679870519}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:22,444]\u001B[0m Trial 445 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0052409717789387465, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.27941979519415083}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:23,418]\u001B[0m Trial 446 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008299200518450936, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3012459416381134}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:24,520]\u001B[0m Trial 447 finished with value: 0.44 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005727197418821043, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.03722797125089494}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:25,766]\u001B[0m Trial 448 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006024890504996705, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.19183540180925596}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:26,871]\u001B[0m Trial 449 finished with value: 0.36 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009254868422905427, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.2018337060996686}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:27,984]\u001B[0m Trial 450 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005911451266833131, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.34033153422401047}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:29,079]\u001B[0m Trial 451 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005639079329385073, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3348505885672449}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:30,154]\u001B[0m Trial 452 finished with value: 0.76 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005581090052588044, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22299859616291992}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:31,297]\u001B[0m Trial 453 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005512066434729212, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2476859187564563}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:32,490]\u001B[0m Trial 454 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005162029600861962, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2862655999061313}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:33,584]\u001B[0m Trial 455 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0059866532361004775, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.0021034846975603316}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:34,605]\u001B[0m Trial 456 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006133697355207078, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.6301022022552937}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:35,779]\u001B[0m Trial 457 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006039683674108347, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.026709317167680487}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:36,777]\u001B[0m Trial 458 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005108990814304291, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3112303831532798}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:37,885]\u001B[0m Trial 459 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005127904567050087, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.3566704232335978}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:39,015]\u001B[0m Trial 460 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005770588648374416, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.13440075898667736}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:40,129]\u001B[0m Trial 461 finished with value: 0.64 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009110000465582515, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.22608883689768566}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:41,224]\u001B[0m Trial 462 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009473240338982593, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.22820346969791994}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:42,408]\u001B[0m Trial 463 finished with value: 0.64 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0052798192277940855, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.20341587241648668}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:43,584]\u001B[0m Trial 464 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005944731178244391, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.022598811922149895}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:44,631]\u001B[0m Trial 465 finished with value: 0.8 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005377457401237975, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.16261858227368192}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:45,628]\u001B[0m Trial 466 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005853796584339064, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.15841532486978255}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:46,709]\u001B[0m Trial 467 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006153376558799423, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.056937497852997225}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:47,939]\u001B[0m Trial 468 finished with value: 0.36 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008531791737461204, 'hidden_layer_for_classifier': 256, 'alpha': 0.7, 'lmbda': 0.27877198706911127}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:49,044]\u001B[0m Trial 469 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005719079755792172, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.17757192525081852}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:50,178]\u001B[0m Trial 470 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005656792946658375, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2632772608236883}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:51,314]\u001B[0m Trial 471 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005068316160589035, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2540164897726385}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:52,302]\u001B[0m Trial 472 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007259544848286764, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.29740149745009337}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:53,379]\u001B[0m Trial 473 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0058130330609993995, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2441310442106441}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:54,396]\u001B[0m Trial 474 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005003977137825635, 'hidden_layer_for_classifier': 256, 'alpha': 0.3, 'lmbda': 0.3198091283146214}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:55,582]\u001B[0m Trial 475 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005878420366560042, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2715036960650671}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:56,703]\u001B[0m Trial 476 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005984667192918248, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2414041981431644}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:57,831]\u001B[0m Trial 477 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0056280445609006935, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.11180683501478512}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:55:58,971]\u001B[0m Trial 478 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005951350456047465, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.28822894083936984}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:00,098]\u001B[0m Trial 479 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0054926445993583465, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.3203247394002187}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:01,169]\u001B[0m Trial 480 finished with value: 0.32 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005797239426925148, 'hidden_layer_for_classifier': 256, 'alpha': 0.9, 'lmbda': 0.23697012940717876}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:02,129]\u001B[0m Trial 481 finished with value: 0.68 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006035766716400257, 'hidden_layer_for_classifier': 128, 'alpha': 0.1, 'lmbda': 0.01023944669451203}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:03,241]\u001B[0m Trial 482 finished with value: 0.76 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0062251714625536185, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.26661549284718455}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:04,329]\u001B[0m Trial 483 finished with value: 0.76 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005090390464105078, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.3793517639145188}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:05,498]\u001B[0m Trial 484 finished with value: 0.76 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005701458568673471, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.20991778954031132}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:06,606]\u001B[0m Trial 485 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008925111529693407, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.34606198812301053}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:07,743]\u001B[0m Trial 486 finished with value: 0.8 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005625995877800306, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2700877562318219}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:09,126]\u001B[0m Trial 487 finished with value: 0.28 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005540161869240064, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.4045441697296556}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:10,225]\u001B[0m Trial 488 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0057111566219698396, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.12701428369870146}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:11,227]\u001B[0m Trial 489 finished with value: 0.56 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009519950838733245, 'hidden_layer_for_classifier': 256, 'alpha': 0.4, 'lmbda': 0.07996900662529123}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:12,421]\u001B[0m Trial 490 finished with value: 0.8 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005991838638570693, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2735363989859721}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:13,522]\u001B[0m Trial 491 finished with value: 0.52 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005907184076903077, 'hidden_layer_for_classifier': 32, 'alpha': 0.1, 'lmbda': 0.18934553236247978}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:14,807]\u001B[0m Trial 492 finished with value: 0.72 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006148402971951361, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.2306711925849938}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:16,032]\u001B[0m Trial 493 finished with value: 0.32 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006362217398765584, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.21058394331109917}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:17,059]\u001B[0m Trial 494 finished with value: 0.48 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005074230282392352, 'hidden_layer_for_classifier': 256, 'alpha': 0.8, 'lmbda': 0.25397798488253476}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:18,088]\u001B[0m Trial 495 finished with value: 0.64 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005773513574573882, 'hidden_layer_for_classifier': 256, 'alpha': 0.1, 'lmbda': 0.25379267092441377}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:19,298]\u001B[0m Trial 496 finished with value: 0.72 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006133130606692366, 'hidden_layer_for_classifier': 256, 'alpha': 0.2, 'lmbda': 0.012763910867259518}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:20,331]\u001B[0m Trial 497 finished with value: 0.6 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005834426750832304, 'hidden_layer_for_classifier': 64, 'alpha': 0.1, 'lmbda': 0.2870512316074203}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:21,490]\u001B[0m Trial 498 finished with value: 0.64 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005954501829917988, 'hidden_layer_for_classifier': 256, 'alpha': 0.6, 'lmbda': 0.009284254726877864}. Best is trial 213 with value: 0.84.\u001B[0m\n",
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "\u001B[32m[I 2022-11-16 16:56:22,718]\u001B[0m Trial 499 finished with value: 0.48 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00589686733829911, 'hidden_layer_for_classifier': 256, 'alpha': 0.5, 'lmbda': 0.36801988551549325}. Best is trial 213 with value: 0.84.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: SAGE, mode: unsupervised, loss from HOPE_RPR\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 77.7837, Epoch: 000, Train acc micro: 0.5341, Test acc micro: 0.5600,Train acc macro: 0.5341, Test acc macro: 0.5600\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.3220, Epoch: 001, Train acc micro: 0.4886, Test acc micro: 0.5200,Train acc macro: 0.4886, Test acc macro: 0.5200\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 77.5051, Epoch: 002, Train acc micro: 0.5284, Test acc micro: 0.5600,Train acc macro: 0.5284, Test acc macro: 0.5600\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 73.7830, Epoch: 003, Train acc micro: 0.6136, Test acc micro: 0.7000,Train acc macro: 0.6136, Test acc macro: 0.7000\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.5053, Epoch: 004, Train acc micro: 0.6080, Test acc micro: 0.7000,Train acc macro: 0.6080, Test acc macro: 0.7000\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.5628, Epoch: 005, Train acc micro: 0.6193, Test acc micro: 0.7200,Train acc macro: 0.6193, Test acc macro: 0.7200\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 73.1289, Epoch: 006, Train acc micro: 0.6364, Test acc micro: 0.7200,Train acc macro: 0.6364, Test acc macro: 0.7200\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 73.2499, Epoch: 007, Train acc micro: 0.6534, Test acc micro: 0.7600,Train acc macro: 0.6534, Test acc macro: 0.7600\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.7176, Epoch: 008, Train acc micro: 0.6875, Test acc micro: 0.8000,Train acc macro: 0.6875, Test acc macro: 0.8000\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.2934, Epoch: 009, Train acc micro: 0.6875, Test acc micro: 0.7800,Train acc macro: 0.6875, Test acc macro: 0.7800\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.1366, Epoch: 010, Train acc micro: 0.6818, Test acc micro: 0.7800,Train acc macro: 0.6818, Test acc macro: 0.7800\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.1044, Epoch: 011, Train acc micro: 0.6932, Test acc micro: 0.7600,Train acc macro: 0.6932, Test acc macro: 0.7600\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.1266, Epoch: 012, Train acc micro: 0.6989, Test acc micro: 0.8000,Train acc macro: 0.6989, Test acc macro: 0.8000\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.1601, Epoch: 013, Train acc micro: 0.7045, Test acc micro: 0.8000,Train acc macro: 0.7045, Test acc macro: 0.8000\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.1382, Epoch: 014, Train acc micro: 0.6989, Test acc micro: 0.8000,Train acc macro: 0.6989, Test acc macro: 0.8000\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.0441, Epoch: 015, Train acc micro: 0.7045, Test acc micro: 0.8000,Train acc macro: 0.7045, Test acc macro: 0.8000\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.9265, Epoch: 016, Train acc micro: 0.7045, Test acc micro: 0.8000,Train acc macro: 0.7045, Test acc macro: 0.8000\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.8244, Epoch: 017, Train acc micro: 0.7330, Test acc micro: 0.8000,Train acc macro: 0.7330, Test acc macro: 0.8000\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.7410, Epoch: 018, Train acc micro: 0.7557, Test acc micro: 0.8200,Train acc macro: 0.7557, Test acc macro: 0.8200\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.6657, Epoch: 019, Train acc micro: 0.7614, Test acc micro: 0.8400,Train acc macro: 0.7614, Test acc macro: 0.8400\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.5906, Epoch: 020, Train acc micro: 0.7670, Test acc micro: 0.8400,Train acc macro: 0.7670, Test acc macro: 0.8400\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.5112, Epoch: 021, Train acc micro: 0.7784, Test acc micro: 0.8400,Train acc macro: 0.7784, Test acc macro: 0.8400\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.4234, Epoch: 022, Train acc micro: 0.7898, Test acc micro: 0.8600,Train acc macro: 0.7898, Test acc macro: 0.8600\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.3240, Epoch: 023, Train acc micro: 0.7898, Test acc micro: 0.8600,Train acc macro: 0.7898, Test acc macro: 0.8600\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.2148, Epoch: 024, Train acc micro: 0.8011, Test acc micro: 0.8600,Train acc macro: 0.8011, Test acc macro: 0.8600\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 71.1010, Epoch: 025, Train acc micro: 0.7955, Test acc micro: 0.8600,Train acc macro: 0.7955, Test acc macro: 0.8600\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.9876, Epoch: 026, Train acc micro: 0.8068, Test acc micro: 0.8600,Train acc macro: 0.8068, Test acc macro: 0.8600\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.8764, Epoch: 027, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.7671, Epoch: 028, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.6589, Epoch: 029, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.5513, Epoch: 030, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.4438, Epoch: 031, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.3350, Epoch: 032, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.2229, Epoch: 033, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.1058, Epoch: 034, Train acc micro: 0.8239, Test acc micro: 0.8600,Train acc macro: 0.8239, Test acc macro: 0.8600\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.9819, Epoch: 035, Train acc micro: 0.8295, Test acc micro: 0.8600,Train acc macro: 0.8295, Test acc macro: 0.8600\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.8503, Epoch: 036, Train acc micro: 0.8295, Test acc micro: 0.8600,Train acc macro: 0.8295, Test acc macro: 0.8600\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.7101, Epoch: 037, Train acc micro: 0.8295, Test acc micro: 0.8600,Train acc macro: 0.8295, Test acc macro: 0.8600\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.5608, Epoch: 038, Train acc micro: 0.8466, Test acc micro: 0.8800,Train acc macro: 0.8466, Test acc macro: 0.8800\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.4022, Epoch: 039, Train acc micro: 0.8523, Test acc micro: 0.8800,Train acc macro: 0.8523, Test acc macro: 0.8800\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.2342, Epoch: 040, Train acc micro: 0.8523, Test acc micro: 0.8600,Train acc macro: 0.8523, Test acc macro: 0.8600\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.0570, Epoch: 041, Train acc micro: 0.8580, Test acc micro: 0.8600,Train acc macro: 0.8580, Test acc macro: 0.8600\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 68.8708, Epoch: 042, Train acc micro: 0.8580, Test acc micro: 0.8600,Train acc macro: 0.8580, Test acc macro: 0.8600\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 68.6762, Epoch: 043, Train acc micro: 0.8580, Test acc micro: 0.8600,Train acc macro: 0.8580, Test acc macro: 0.8600\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 68.4735, Epoch: 044, Train acc micro: 0.8693, Test acc micro: 0.8600,Train acc macro: 0.8693, Test acc macro: 0.8600\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 68.2628, Epoch: 045, Train acc micro: 0.8693, Test acc micro: 0.8600,Train acc macro: 0.8693, Test acc macro: 0.8600\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 68.0437, Epoch: 046, Train acc micro: 0.8693, Test acc micro: 0.8600,Train acc macro: 0.8693, Test acc macro: 0.8600\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 67.8155, Epoch: 047, Train acc micro: 0.8807, Test acc micro: 0.8600,Train acc macro: 0.8807, Test acc macro: 0.8600\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 67.5774, Epoch: 048, Train acc micro: 0.8750, Test acc micro: 0.8600,Train acc macro: 0.8750, Test acc macro: 0.8600\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 67.3286, Epoch: 049, Train acc micro: 0.8977, Test acc micro: 0.8600,Train acc macro: 0.8977, Test acc macro: 0.8600\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 67.0690, Epoch: 050, Train acc micro: 0.9091, Test acc micro: 0.8600,Train acc macro: 0.9091, Test acc macro: 0.8600\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 66.7993, Epoch: 051, Train acc micro: 0.9148, Test acc micro: 0.8600,Train acc macro: 0.9148, Test acc macro: 0.8600\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 66.5204, Epoch: 052, Train acc micro: 0.9261, Test acc micro: 0.8600,Train acc macro: 0.9261, Test acc macro: 0.8600\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 66.2337, Epoch: 053, Train acc micro: 0.9432, Test acc micro: 0.9000,Train acc macro: 0.9432, Test acc macro: 0.9000\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 65.9400, Epoch: 054, Train acc micro: 0.9432, Test acc micro: 0.9000,Train acc macro: 0.9432, Test acc macro: 0.9000\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 65.6400, Epoch: 055, Train acc micro: 0.9489, Test acc micro: 0.9000,Train acc macro: 0.9489, Test acc macro: 0.9000\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 65.3341, Epoch: 056, Train acc micro: 0.9489, Test acc micro: 0.9000,Train acc macro: 0.9489, Test acc macro: 0.9000\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 65.0227, Epoch: 057, Train acc micro: 0.9602, Test acc micro: 0.9200,Train acc macro: 0.9602, Test acc macro: 0.9200\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 64.7060, Epoch: 058, Train acc micro: 0.9659, Test acc micro: 0.9200,Train acc macro: 0.9659, Test acc macro: 0.9200\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 64.3836, Epoch: 059, Train acc micro: 0.9716, Test acc micro: 0.9000,Train acc macro: 0.9716, Test acc macro: 0.9000\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 64.0551, Epoch: 060, Train acc micro: 0.9716, Test acc micro: 0.9000,Train acc macro: 0.9716, Test acc macro: 0.9000\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 63.7205, Epoch: 061, Train acc micro: 0.9716, Test acc micro: 0.9000,Train acc macro: 0.9716, Test acc macro: 0.9000\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 63.3802, Epoch: 062, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 63.0352, Epoch: 063, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 62.6868, Epoch: 064, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 62.3359, Epoch: 065, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 61.9836, Epoch: 066, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 61.6303, Epoch: 067, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 61.2763, Epoch: 068, Train acc micro: 0.9773, Test acc micro: 0.9000,Train acc macro: 0.9773, Test acc macro: 0.9000\n",
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 60.9219, Epoch: 069, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 60.5667, Epoch: 070, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 60.2106, Epoch: 071, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 59.8530, Epoch: 072, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 59.4932, Epoch: 073, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 59.1308, Epoch: 074, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 58.7650, Epoch: 075, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 58.3954, Epoch: 076, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 58.0218, Epoch: 077, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 57.6439, Epoch: 078, Train acc micro: 0.9830, Test acc micro: 0.9000,Train acc macro: 0.9830, Test acc macro: 0.9000\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 57.2620, Epoch: 079, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 56.8762, Epoch: 080, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 56.4872, Epoch: 081, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 56.0956, Epoch: 082, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 55.7027, Epoch: 083, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 55.3095, Epoch: 084, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 54.9169, Epoch: 085, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 54.5261, Epoch: 086, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 54.1379, Epoch: 087, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.7527, Epoch: 088, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 53.3712, Epoch: 089, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.9935, Epoch: 090, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.6196, Epoch: 091, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52.2496, Epoch: 092, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.8832, Epoch: 093, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.5204, Epoch: 094, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 51.1611, Epoch: 095, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.8048, Epoch: 096, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.4517, Epoch: 097, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.1013, Epoch: 098, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "99\n",
      "Loss: 49.7537, Epoch: 099, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n",
      "Loss: 49.7537, Epoch: 099, Train acc micro: 0.9886, Test acc micro: 0.9000,Train acc macro: 0.9886, Test acc macro: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss  conv    dataset  train acc micro  test acc micro  \\\n",
      "0        no    no  Wisconsin         0.982955        0.900000   \n",
      "1        no    no      Texas         0.992248        0.750000   \n",
      "2        no    no      Texas         0.868217        0.694444   \n",
      "3        no    no  Wisconsin         0.880682        0.880000   \n",
      "4  HOPE_RPR  SAGE  Wisconsin         0.971591        0.920000   \n",
      "5  HOPE_RPR  SAGE      Texas         0.891473        0.722222   \n",
      "6  HOPE_RPR  SAGE      Texas         0.968992        0.722222   \n",
      "7  HOPE_RPR  SAGE  Wisconsin         0.988636        0.900000   \n",
      "\n",
      "   train acc macro  test acc macro     clf  \n",
      "0         0.982955        0.900000     MLP  \n",
      "1         0.992248        0.750000     MLP  \n",
      "2         0.868217        0.694444  logreg  \n",
      "3         0.880682        0.880000  logreg  \n",
      "4         0.971591        0.920000  logreg  \n",
      "5         0.891473        0.722222  logreg  \n",
      "6         0.968992        0.722222     MLP  \n",
      "7         0.988636        0.900000     MLP  \n"
     ]
    }
   ],
   "source": [
    "loss = HOPE_RPR\n",
    "loss_name = 'HOPE_RPR'\n",
    "analysis=pd.read_csv('../results/experiments_with_MLP_accuracy.csv')\n",
    "analysis=analysis.drop(columns=['Unnamed: 0'])\n",
    "clf='MLP'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for name in datasets_names[1:3]:\n",
    "    for conv in ['SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name) & (analysis['clf'] == clf)] ) == 0:\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values = MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma, 'MLP'],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/experiments_with_MLP_accuracy.csv')\n",
    "                print(analysis)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "4    0.070352\nName: test acc micro, dtype: float64"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = pd.read_csv('../results/final_data.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "analysis = analysis[(analysis['loss'] == 'features') & (analysis['label assortativity']==0.1) & (analysis['cluster coefficient']==0.2) & (analysis['feature assortativity']==0.1) & (analysis['average shortest path']==3) & (analysis['average degree']==5)]\n",
    "analysis['test acc micro']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "           loss  conv       dataset  train acc micro  test acc micro  \\\n0      features    no   0.10.10.225         0.318117        0.090452   \n1      features    no  0.10.10.2220         0.783167        0.045226   \n2      features    no  0.10.10.2240         0.492154        0.040201   \n3      features    no   0.10.10.232         0.957204        0.060302   \n4      features    no   0.10.10.235         0.733238        0.070352   \n...         ...   ...           ...              ...             ...   \n7821  Force2Vec   GAT  0.90.90.5320         0.833096        0.276382   \n7822  Force2Vec  SAGE  0.90.90.5320         0.644793        0.115578   \n7823  Force2Vec   GCN   0.90.90.545         0.413695        0.281407   \n7824  Force2Vec   GAT   0.90.90.545         0.633381        0.291457   \n7825  Force2Vec  SAGE   0.90.90.545         0.437946        0.231156   \n\n      train acc macro  test acc macro  label assortativity  \\\n0            0.315114        0.085427                  0.1   \n1            0.783860        0.042904                  0.1   \n2            0.492240        0.039874                  0.1   \n3            0.957408        0.067781                  0.1   \n4            0.733541        0.069418                  0.1   \n...               ...             ...                  ...   \n7821         0.840901        0.274703                  0.9   \n7822         0.645156        0.099258                  0.9   \n7823         0.413026        0.277476                  0.9   \n7824         0.633967        0.271363                  0.9   \n7825         0.431685        0.192414                  0.9   \n\n      feature assortativity  cluster coefficient  average shortest path  \\\n0                       0.1                  0.2                    2.0   \n1                       0.1                  0.2                    2.0   \n2                       0.1                  0.2                    2.0   \n3                       0.1                  0.2                    3.0   \n4                       0.1                  0.2                    3.0   \n...                     ...                  ...                    ...   \n7821                    0.9                  0.5                    3.0   \n7822                    0.9                  0.5                    3.0   \n7823                    0.9                  0.5                    4.0   \n7824                    0.9                  0.5                    4.0   \n7825                    0.9                  0.5                    4.0   \n\n      average degree group  \n0                5.0    no  \n1               20.0    no  \n2               40.0    no  \n3                2.0    no  \n4                5.0    no  \n...              ...   ...  \n7821            20.0   5.0  \n7822            20.0   5.0  \n7823             5.0   5.0  \n7824             5.0   5.0  \n7825             5.0   5.0  \n\n[7826 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>conv</th>\n      <th>dataset</th>\n      <th>train acc micro</th>\n      <th>test acc micro</th>\n      <th>train acc macro</th>\n      <th>test acc macro</th>\n      <th>label assortativity</th>\n      <th>feature assortativity</th>\n      <th>cluster coefficient</th>\n      <th>average shortest path</th>\n      <th>average degree</th>\n      <th>group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>features</td>\n      <td>no</td>\n      <td>0.10.10.225</td>\n      <td>0.318117</td>\n      <td>0.090452</td>\n      <td>0.315114</td>\n      <td>0.085427</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>features</td>\n      <td>no</td>\n      <td>0.10.10.2220</td>\n      <td>0.783167</td>\n      <td>0.045226</td>\n      <td>0.783860</td>\n      <td>0.042904</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>20.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>features</td>\n      <td>no</td>\n      <td>0.10.10.2240</td>\n      <td>0.492154</td>\n      <td>0.040201</td>\n      <td>0.492240</td>\n      <td>0.039874</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>40.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>features</td>\n      <td>no</td>\n      <td>0.10.10.232</td>\n      <td>0.957204</td>\n      <td>0.060302</td>\n      <td>0.957408</td>\n      <td>0.067781</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>features</td>\n      <td>no</td>\n      <td>0.10.10.235</td>\n      <td>0.733238</td>\n      <td>0.070352</td>\n      <td>0.733541</td>\n      <td>0.069418</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.2</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7821</th>\n      <td>Force2Vec</td>\n      <td>GAT</td>\n      <td>0.90.90.5320</td>\n      <td>0.833096</td>\n      <td>0.276382</td>\n      <td>0.840901</td>\n      <td>0.274703</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>0.5</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>7822</th>\n      <td>Force2Vec</td>\n      <td>SAGE</td>\n      <td>0.90.90.5320</td>\n      <td>0.644793</td>\n      <td>0.115578</td>\n      <td>0.645156</td>\n      <td>0.099258</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>0.5</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>7823</th>\n      <td>Force2Vec</td>\n      <td>GCN</td>\n      <td>0.90.90.545</td>\n      <td>0.413695</td>\n      <td>0.281407</td>\n      <td>0.413026</td>\n      <td>0.277476</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>0.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>7824</th>\n      <td>Force2Vec</td>\n      <td>GAT</td>\n      <td>0.90.90.545</td>\n      <td>0.633381</td>\n      <td>0.291457</td>\n      <td>0.633967</td>\n      <td>0.271363</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>0.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>7825</th>\n      <td>Force2Vec</td>\n      <td>SAGE</td>\n      <td>0.90.90.545</td>\n      <td>0.437946</td>\n      <td>0.231156</td>\n      <td>0.431685</td>\n      <td>0.192414</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>0.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7826 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-14 14:58:17,953]\u001B[0m A new study created in memory with name: LINE loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:24,805]\u001B[0m Trial 0 finished with value: 0.2380619024282447 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0054822792212987645, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 7, 'num_negative_samples': 11, 'lmbda': 0.40547634715723746}. Best is trial 0 with value: 0.2380619024282447.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:31,415]\u001B[0m Trial 1 finished with value: 0.25371731211689774 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.0057534293104274945, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 11, 'lmbda': 0.05032029497001922}. Best is trial 1 with value: 0.25371731211689774.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:32,266]\u001B[0m Trial 2 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009122750168447893, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.2088427451152648}. Best is trial 1 with value: 0.25371731211689774.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:33,241]\u001B[0m Trial 3 finished with value: 0.15100707750500572 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005566873154482499, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.9990938690873092}. Best is trial 1 with value: 0.25371731211689774.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:35,882]\u001B[0m Trial 4 finished with value: 0.1860567901095383 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005241518632893815, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.7793301026076783}. Best is trial 1 with value: 0.25371731211689774.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:36,812]\u001B[0m Trial 5 finished with value: 0.2394978881971497 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008110785432678342, 'reg_lambda': 0.3, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.3907524482467001}. Best is trial 1 with value: 0.25371731211689774.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:37,979]\u001B[0m Trial 6 finished with value: 0.254807324013771 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007499930754919603, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 16, 'lmbda': 0.13798777226787673}. Best is trial 6 with value: 0.254807324013771.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:38,761]\u001B[0m Trial 7 finished with value: 0.1929723812387374 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008979465250736708, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.6717011656045708}. Best is trial 6 with value: 0.254807324013771.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:41,148]\u001B[0m Trial 8 finished with value: 0.24576906973258095 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008725689048794338, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 5, 'num_negative_samples': 11, 'lmbda': 0.06709501275128393}. Best is trial 6 with value: 0.254807324013771.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:42,120]\u001B[0m Trial 9 finished with value: 0.23970362196709122 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008555235058132825, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.34481251316212913}. Best is trial 6 with value: 0.254807324013771.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:43,005]\u001B[0m Trial 10 finished with value: 0.22932404724142094 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007075866468454365, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.5952297133666893}. Best is trial 6 with value: 0.254807324013771.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:49,424]\u001B[0m Trial 11 finished with value: 0.25951411571958366 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006877643888855062, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 7.950467196904398e-05}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:58:53,928]\u001B[0m Trial 12 finished with value: 0.1801582084085542 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00657604432773699, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.2094880540015462}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:05,353]\u001B[0m Trial 13 finished with value: 0.1527778201613457 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007567528379453516, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.1715648367967625}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:08,656]\u001B[0m Trial 14 finished with value: 0.21635205370805938 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006473104614084087, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.004951670295309241}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:10,215]\u001B[0m Trial 15 finished with value: 0.25442122303408327 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007460635563331386, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.27437177213703107}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:14,612]\u001B[0m Trial 16 finished with value: 0.17892722030510885 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006407361711288838, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.09696803703282472}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:15,835]\u001B[0m Trial 17 finished with value: 0.1675028160400037 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009775322501743917, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.5150007407647804}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:17,489]\u001B[0m Trial 18 finished with value: 0.18590890830852755 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007945938000846475, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.13879105690699814}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:19,930]\u001B[0m Trial 19 finished with value: 0.125971633549051 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.0069597585098031475, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 6, 'lmbda': 0.0020705608462588455}. Best is trial 11 with value: 0.25951411571958366.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:23,101]\u001B[0m Trial 20 finished with value: 0.2814964919868042 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006031567907259227, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.473951827658479}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:26,395]\u001B[0m Trial 21 finished with value: 0.2105092456093784 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006110944057825649, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.33195702648195136}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:29,660]\u001B[0m Trial 22 finished with value: 0.19178967295690613 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007068365385572886, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.845180599698441}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:32,812]\u001B[0m Trial 23 finished with value: 0.16459827639617794 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0074297422803861245, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.4984500147630426}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:36,143]\u001B[0m Trial 24 finished with value: 0.22914094160000265 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005875591572348064, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.26001778220449623}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:37,883]\u001B[0m Trial 25 finished with value: 0.211681726462342 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006823827319227119, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.12248235033463553}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:38,691]\u001B[0m Trial 26 finished with value: 0.22777276185004408 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006157919714889893, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.47480002201679217}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:40,841]\u001B[0m Trial 27 finished with value: 0.16802038805898323 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007921703136971069, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 3, 'num_negative_samples': 16, 'lmbda': 0.6797545168657979}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:45,188]\u001B[0m Trial 28 finished with value: 0.17006994193209202 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008253772113657009, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 16, 'lmbda': 0.28473931769692684}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:46,884]\u001B[0m Trial 29 finished with value: 0.125971633549051 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005423783403140476, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.42689519880810267}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:48,178]\u001B[0m Trial 30 finished with value: 0.2106411986951694 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005051023118588121, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.5715886803102792}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:49,578]\u001B[0m Trial 31 finished with value: 0.2515506529197497 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00748047330206103, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.25983065426099516}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:50,923]\u001B[0m Trial 32 finished with value: 0.19342597244374066 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007307095057253443, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.16479878353687172}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:52,288]\u001B[0m Trial 33 finished with value: 0.16253298958892817 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0076840480633013014, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 11, 'lmbda': 0.05073530541209764}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 14:59:53,606]\u001B[0m Trial 34 finished with value: 0.1391506018081835 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006674226866673388, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.219931431143978}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:03,609]\u001B[0m Trial 35 finished with value: 0.1978606075992686 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006049986808942114, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.3965077030607786}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:04,514]\u001B[0m Trial 36 finished with value: 0.10569963951264663 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007248995570444376, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 1, 'num_negative_samples': 21, 'lmbda': 0.32148614666591585}. Best is trial 20 with value: 0.2814964919868042.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:05,782]\u001B[0m Trial 37 finished with value: 0.2848596242361112 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005660953450372066, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.1978176480355443}. Best is trial 37 with value: 0.2848596242361112.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:10,875]\u001B[0m Trial 38 finished with value: 0.2459580371468916 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005737433060174796, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.9981286271127319}. Best is trial 37 with value: 0.2848596242361112.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:11,909]\u001B[0m Trial 39 finished with value: 0.23788482345072648 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005573388286566603, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.05353407470174841}. Best is trial 37 with value: 0.2848596242361112.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:12,687]\u001B[0m Trial 40 finished with value: 0.18870000355792088 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005271608124914674, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 1, 'num_negative_samples': 11, 'lmbda': 0.09975921814402089}. Best is trial 37 with value: 0.2848596242361112.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:13,961]\u001B[0m Trial 41 finished with value: 0.29333372955483283 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006320988442618514, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.19248222977000262}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:15,206]\u001B[0m Trial 42 finished with value: 0.2524560450613177 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006291276618417855, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.18842916953197775}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:16,457]\u001B[0m Trial 43 finished with value: 0.20085238919202045 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00573980623840309, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.08764791549042328}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:17,745]\u001B[0m Trial 44 finished with value: 0.21522297761267753 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006602951043049213, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.0002903032933145311}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:24,140]\u001B[0m Trial 45 finished with value: 0.17713475552034988 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.0059472873233238025, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.21716658975007752}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:25,343]\u001B[0m Trial 46 finished with value: 0.23643003122248565 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006793844346408873, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 16, 'lmbda': 0.14718382680914954}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:28,403]\u001B[0m Trial 47 finished with value: 0.2827301578079488 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006318359666537051, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3604719128215853}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:31,659]\u001B[0m Trial 48 finished with value: 0.24990714042432946 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005528409686712371, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.36988857682163867}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:34,872]\u001B[0m Trial 49 finished with value: 0.18604475571442805 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006445077507913574, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.4384891185494524}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:38,095]\u001B[0m Trial 50 finished with value: 0.21816363325865626 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006197556922628698, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5585543137321344}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:41,393]\u001B[0m Trial 51 finished with value: 0.21464258873141948 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00635293437315032, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3018289935643405}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:00:51,765]\u001B[0m Trial 52 finished with value: 0.2610957457314123 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006902577277067027, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.24167058065292202}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:01:01,949]\u001B[0m Trial 53 finished with value: 0.28072592195545903 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006858472888053774, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3466568653136902}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:01:12,078]\u001B[0m Trial 54 finished with value: 0.21495161774820412 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007081908261868409, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3672155277216711}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:01:22,187]\u001B[0m Trial 55 finished with value: 0.1968649111100845 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006681551637542114, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.23849202235285588}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:01:32,448]\u001B[0m Trial 56 finished with value: 0.2745432413267278 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005919525427887187, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4543049468296523}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:01:47,140]\u001B[0m Trial 57 finished with value: 0.2615326681358902 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005890243591171866, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4586058454225789}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:01:57,009]\u001B[0m Trial 58 finished with value: 0.2318244251638815 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005687309543284077, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.6340760335081609}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:02:02,808]\u001B[0m Trial 59 finished with value: 0.22559476003306253 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005293226697922204, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.507948271326268}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:02:03,573]\u001B[0m Trial 60 finished with value: 0.16932261651165859 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005972268698956082, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.41346245663629394}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:02:18,468]\u001B[0m Trial 61 finished with value: 0.26868765751020357 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005904804962672285, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4599905936254494}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:02:33,284]\u001B[0m Trial 62 finished with value: 0.2253480927763382 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006276519649741377, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.537602539414762}. Best is trial 41 with value: 0.29333372955483283.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:02:48,006]\u001B[0m Trial 63 finished with value: 0.30072385678123564 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006127661523307316, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4678160207180978}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:02:51,173]\u001B[0m Trial 64 finished with value: 0.2506593560784439 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0061450949325076165, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.3731047648140236}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:10,133]\u001B[0m Trial 65 finished with value: 0.2489755565375919 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00656460071568981, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3247427685710592}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:13,352]\u001B[0m Trial 66 finished with value: 0.24873516931747178 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00544589982090027, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.6011490885786054}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:24,001]\u001B[0m Trial 67 finished with value: 0.2921909064122281 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009875431649884721, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.48981371583278027}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:27,039]\u001B[0m Trial 68 finished with value: 0.21714632732912495 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009842610253479453, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 11, 'lmbda': 0.5337314761187325}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:29,038]\u001B[0m Trial 69 finished with value: 0.2673292187695637 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00929325175676375, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 1, 'num_negative_samples': 21, 'lmbda': 0.49114870311090286}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:39,608]\u001B[0m Trial 70 finished with value: 0.2804077426692805 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005009190921142668, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3476624090294854}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:49,613]\u001B[0m Trial 71 finished with value: 0.1368898888770955 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009322477406206424, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.34724576320200234}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:03:59,906]\u001B[0m Trial 72 finished with value: 0.18426533094479533 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005006772985201931, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.40995383597849416}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:10,148]\u001B[0m Trial 73 finished with value: 0.19019110573118936 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00861055112830344, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.31639093474994445}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:20,663]\u001B[0m Trial 74 finished with value: 0.2308661890720338 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0051354431607961975, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.19140892933614528}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:22,408]\u001B[0m Trial 75 finished with value: 0.2087605144201182 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0064960704657399775, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.2807085347247046}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:23,208]\u001B[0m Trial 76 finished with value: 0.21915393138205472 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00564143266265706, 'reg_lambda': 10, 'n_estimators': 5, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.38432188707828485}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:26,369]\u001B[0m Trial 77 finished with value: 0.2776672674531531 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005312457504086333, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3526611304982067}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:27,429]\u001B[0m Trial 78 finished with value: 0.17607489165971374 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006066396609020746, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.6940468278333327}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:33,897]\u001B[0m Trial 79 finished with value: 0.23887886106633346 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008252896110658863, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.47830235161158663}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:36,283]\u001B[0m Trial 80 finished with value: 0.2508473036488516 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005791471226709074, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.43952544183913744}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:39,475]\u001B[0m Trial 81 finished with value: 0.15325137662443947 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005338248744274282, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.4035883601854667}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:42,940]\u001B[0m Trial 82 finished with value: 0.2712014981320764 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0051086370341907475, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.35131447504102276}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:46,255]\u001B[0m Trial 83 finished with value: 0.20862119074726979 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005188337256012525, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.28445234597693436}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:49,491]\u001B[0m Trial 84 finished with value: 0.14224300380618482 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005380059956943504, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.30899717526446874}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:52,824]\u001B[0m Trial 85 finished with value: 0.2116070781082864 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005631719368843346, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 11, 'lmbda': 0.5212552723079558}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:04:59,115]\u001B[0m Trial 86 finished with value: 0.2686561001549747 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0099942476569851, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.24243175577055312}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:00,231]\u001B[0m Trial 87 finished with value: 0.18839330595028167 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005519924643934591, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.34559849302398926}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:05,121]\u001B[0m Trial 88 finished with value: 0.17426166366614323 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006244452621607981, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.4323828942955105}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:11,262]\u001B[0m Trial 89 finished with value: 0.19997061187593315 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006738585201446522, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.578882036457161}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:15,684]\u001B[0m Trial 90 finished with value: 0.2538097645880624 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005783216177371581, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.25670514219902896}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:26,294]\u001B[0m Trial 91 finished with value: 0.2275614434088424 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005974591346483633, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.45206714971180545}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:36,581]\u001B[0m Trial 92 finished with value: 0.21858172482561664 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006371400157901852, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.47478352581568417}. Best is trial 63 with value: 0.30072385678123564.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:46,820]\u001B[0m Trial 93 finished with value: 0.30916412932243076 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008979238790775704, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5506937194534334}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:57,041]\u001B[0m Trial 94 finished with value: 0.20739175690725983 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009026712497707213, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.6009026467286177}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:05:57,857]\u001B[0m Trial 95 finished with value: 0.22766759955067709 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008786790123204179, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.6240163993292847}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:00,977]\u001B[0m Trial 96 finished with value: 0.27371906004235175 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005233321213118855, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5512577273591268}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:02,949]\u001B[0m Trial 97 finished with value: 0.2238082132327929 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009355838406696173, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3822902601273957}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:10,016]\u001B[0m Trial 98 finished with value: 0.2532793637353231 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007713982594408684, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.16935065971543098}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:12,333]\u001B[0m Trial 99 finished with value: 0.20836842324233434 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00955237114462343, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 16, 'lmbda': 0.11549205547588469}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:13,489]\u001B[0m Trial 100 finished with value: 0.15516079353348228 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00703710294717759, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.5069656420534782}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:23,949]\u001B[0m Trial 101 finished with value: 0.17870803030227445 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006070832080239961, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.40998533597828113}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:34,174]\u001B[0m Trial 102 finished with value: 0.2541704101633339 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005462612433252474, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.46295173884031987}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:44,246]\u001B[0m Trial 103 finished with value: 0.2589205284903695 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0096645181787517, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4241983053193586}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:06:55,585]\u001B[0m Trial 104 finished with value: 0.1892338495339822 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005856265585652338, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4906371469963373}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:06,684]\u001B[0m Trial 105 finished with value: 0.18518401833708134 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0061384241187957414, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5363770346001224}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:16,020]\u001B[0m Trial 106 finished with value: 0.2033190268148617 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00634043487853502, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.19717761499684985}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:22,272]\u001B[0m Trial 107 finished with value: 0.21640405760952147 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006499892854796436, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 11, 'lmbda': 0.025810408069037005}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:29,195]\u001B[0m Trial 108 finished with value: 0.22369607744646547 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007209796020613329, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3600161608567275}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:32,371]\u001B[0m Trial 109 finished with value: 0.24685880042550903 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00559070548651078, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 21, 'lmbda': 0.33121349550910156}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:33,666]\u001B[0m Trial 110 finished with value: 0.2033237333430127 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006186973067231358, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.3968388770704932}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:36,718]\u001B[0m Trial 111 finished with value: 0.22957391991292198 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005296086651235044, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5651226505919358}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:40,038]\u001B[0m Trial 112 finished with value: 0.2367203971622767 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005172317701368765, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5503262857553152}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:43,385]\u001B[0m Trial 113 finished with value: 0.21287177864798018 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005044159734800026, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.6453230295874777}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:46,687]\u001B[0m Trial 114 finished with value: 0.27196883143617095 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006032687176249853, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5237054316253387}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:07:50,069]\u001B[0m Trial 115 finished with value: 0.2563270569405651 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005228305485608382, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.490357916112251}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:00,574]\u001B[0m Trial 116 finished with value: 0.2377557177776498 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005396422593727359, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.3005396828338646}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:01,352]\u001B[0m Trial 117 finished with value: 0.18631945668646616 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005827129293878829, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.5885859572557374}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:04,644]\u001B[0m Trial 118 finished with value: 0.2175734594566842 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005700897240318199, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.44195772241432324}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:06,487]\u001B[0m Trial 119 finished with value: 0.26967299601351846 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008398051677185695, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.7221734283850316}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:16,722]\u001B[0m Trial 120 finished with value: 0.2498366358428785 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008864722245733835, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.15481080154269583}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:19,821]\u001B[0m Trial 121 finished with value: 0.1627522123694169 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006237623885269766, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5202961824619221}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:23,165]\u001B[0m Trial 122 finished with value: 0.2102183968711557 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006068270472359149, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.4721634246349479}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:26,469]\u001B[0m Trial 123 finished with value: 0.24139112137561275 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005997312694753694, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5414726076948376}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:29,779]\u001B[0m Trial 124 finished with value: 0.26418036592008637 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005909261698927488, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.51783641129653}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:33,146]\u001B[0m Trial 125 finished with value: 0.25447708477157804 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00796211145414304, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.5535039241526543}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:39,650]\u001B[0m Trial 126 finished with value: 0.24215870359476044 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005546236665249644, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.21811761223759593}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:42,035]\u001B[0m Trial 127 finished with value: 0.19880504458830678 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006436616033361814, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 16, 'lmbda': 0.6156379488209142}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:43,278]\u001B[0m Trial 128 finished with value: 0.22688179485628482 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0066160649238928655, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.4241739432435378}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:08:57,434]\u001B[0m Trial 129 finished with value: 0.26928134022131495 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005725141944491608, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5721334030465054}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:00,642]\u001B[0m Trial 130 finished with value: 0.23347450573368006 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005091330069378301, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 11, 'lmbda': 0.4930591361378096}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:03,988]\u001B[0m Trial 131 finished with value: 0.2519793314537992 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005001625691874825, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.346653853271883}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:07,448]\u001B[0m Trial 132 finished with value: 0.2103626248075746 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005250099830118295, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.369814224537801}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:10,807]\u001B[0m Trial 133 finished with value: 0.26351650051908343 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00514141612274822, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.9490609232041813}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:14,167]\u001B[0m Trial 134 finished with value: 0.27653004425396516 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005456256564282899, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3035046320624981}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:25,074]\u001B[0m Trial 135 finished with value: 0.26831840682640556 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005489261560077157, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.3002916268102981}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:26,882]\u001B[0m Trial 136 finished with value: 0.22968053924028534 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0053448766253265155, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.45233668227685797}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:33,238]\u001B[0m Trial 137 finished with value: 0.26782472623389336 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009193587278645884, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.2792593826684855}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:35,138]\u001B[0m Trial 138 finished with value: 0.23073720321358399 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0059798013742686324, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.25837452028231467}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:38,269]\u001B[0m Trial 139 finished with value: 0.15689027911122194 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0056365123072851814, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 21, 'lmbda': 0.3767681637892593}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:39,095]\u001B[0m Trial 140 finished with value: 0.1394809532663605 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.00632047042916452, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 5, 'num_negative_samples': 16, 'lmbda': 0.3288745291829541}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:42,213]\u001B[0m Trial 141 finished with value: 0.26292527468069626 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005394783394406035, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3578072987160953}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:45,636]\u001B[0m Trial 142 finished with value: 0.17124057062187237 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00582678345403181, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3884852899626332}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:48,896]\u001B[0m Trial 143 finished with value: 0.24192475266848865 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005133666701485221, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3378604550856032}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:09:52,109]\u001B[0m Trial 144 finished with value: 0.22830918097295871 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006138035186874153, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5062576661590322}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:01,541]\u001B[0m Trial 145 finished with value: 0.277129994031197 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005278771716105402, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.3135419594076081}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:13,571]\u001B[0m Trial 146 finished with value: 0.2611472944674432 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005529154632893589, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.31169273560156063}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:23,072]\u001B[0m Trial 147 finished with value: 0.2477915136752497 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009546119020759632, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.22537494853446116}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:32,230]\u001B[0m Trial 148 finished with value: 0.23927850589168587 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005284605904105926, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.17899493866261673}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:34,002]\u001B[0m Trial 149 finished with value: 0.21406206714844428 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007619030190196377, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5256953429667861}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:44,414]\u001B[0m Trial 150 finished with value: 0.19401056736844666 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00565064109064986, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.13330392406097455}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:50,716]\u001B[0m Trial 151 finished with value: 0.26901450076346367 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005455127331998514, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.40802151274738147}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:10:53,896]\u001B[0m Trial 152 finished with value: 0.18334809498601887 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005195237605969001, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.29080663011018276}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:04,596]\u001B[0m Trial 153 finished with value: 0.21142117284454057 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005100404912448738, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.2671004138236508}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:07,638]\u001B[0m Trial 154 finished with value: 0.20476604498249218 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005242236023337029, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.31943646045731305}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:17,528]\u001B[0m Trial 155 finished with value: 0.29079621077580425 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006041751641404641, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.3568841943865816}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:27,148]\u001B[0m Trial 156 finished with value: 0.18860932443345882 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006046665937105664, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.360956351841889}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:36,782]\u001B[0m Trial 157 finished with value: 0.26511408565464356 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006233118357552016, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.47380909758941814}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:46,967]\u001B[0m Trial 158 finished with value: 0.20066508433545216 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005914838137299754, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.3875136202574351}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:48,647]\u001B[0m Trial 159 finished with value: 0.2406079640522229 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009990383594781474, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.07899347177783944}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:11:50,936]\u001B[0m Trial 160 finished with value: 0.18956950673572892 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005823027579637212, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.44543650708502586}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:00,062]\u001B[0m Trial 161 finished with value: 0.2488011228079756 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005338978178447352, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.3597744127201548}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:06,365]\u001B[0m Trial 162 finished with value: 0.24728064701690203 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006138761931852133, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.3463409942331703}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:09,479]\u001B[0m Trial 163 finished with value: 0.23813234539532876 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006022701399091121, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3294817686501822}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:20,009]\u001B[0m Trial 164 finished with value: 0.2812579965193178 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006397253486931973, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4185309925515243}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:30,432]\u001B[0m Trial 165 finished with value: 0.24827229876654283 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006338697806632854, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.42475364728655207}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:36,180]\u001B[0m Trial 166 finished with value: 0.1957328111642681 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0062500624184551575, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4980745859694834}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:46,570]\u001B[0m Trial 167 finished with value: 0.24605123145530672 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0063947141660917455, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.40356532285268026}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:12:56,992]\u001B[0m Trial 168 finished with value: 0.23120273477923098 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006866557546610255, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.48201894290985553}. Best is trial 93 with value: 0.30916412932243076.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:06,918]\u001B[0m Trial 169 finished with value: 0.3197106376494038 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006444100843004348, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.4614214455135669}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:16,753]\u001B[0m Trial 170 finished with value: 0.23059183711881615 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006497320567830353, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.43214196851358727}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:26,598]\u001B[0m Trial 171 finished with value: 0.1827445648102079 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006590029912343188, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.45914848642026396}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:36,252]\u001B[0m Trial 172 finished with value: 0.24253081773552224 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006690268296142671, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.5565823727312151}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:46,283]\u001B[0m Trial 173 finished with value: 0.239361174865312 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007362789042763563, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.46925527189004324}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:55,996]\u001B[0m Trial 174 finished with value: 0.18421003711344766 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00617879091820449, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5050533291501437}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:56,866]\u001B[0m Trial 175 finished with value: 0.21775763929104525 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006457330559958908, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.5300164829563583}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:13:58,131]\u001B[0m Trial 176 finished with value: 0.24912545446720627 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005930442101467659, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.38382274794489124}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:08,641]\u001B[0m Trial 177 finished with value: 0.23865423557071883 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0063005061075354475, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4456935807051496}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:12,906]\u001B[0m Trial 178 finished with value: 0.24747155673532623 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006117142521423438, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.30974188690338456}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:27,517]\u001B[0m Trial 179 finished with value: 0.24201850893068133 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005747158871015255, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.4180375457620354}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:36,682]\u001B[0m Trial 180 finished with value: 0.22534164848383018 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006790802265147415, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.2378848038283496}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:39,836]\u001B[0m Trial 181 finished with value: 0.2660066979612127 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005081680612170358, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3711991205421804}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:43,144]\u001B[0m Trial 182 finished with value: 0.21750300328663044 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005401992702305455, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.33488613392150324}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:46,479]\u001B[0m Trial 183 finished with value: 0.17031980448840345 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005176565917334157, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3510439511181178}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:49,717]\u001B[0m Trial 184 finished with value: 0.2643036523744026 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006040506192646096, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.40322253471785413}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:52,936]\u001B[0m Trial 185 finished with value: 0.25825517953094623 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005026440454601416, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.295431263976578}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:14:59,408]\u001B[0m Trial 186 finished with value: 0.2290959573736684 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008526578720548295, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4803839501317496}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:01,227]\u001B[0m Trial 187 finished with value: 0.2294968533642669 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005264255709356236, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.20605730079417314}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:04,385]\u001B[0m Trial 188 finished with value: 0.14909076306837707 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006234000675914317, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.31888388677729435}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:07,057]\u001B[0m Trial 189 finished with value: 0.12300403043731241 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005562001001603448, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.5144636313340807}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:19,027]\u001B[0m Trial 190 finished with value: 0.21931255948809283 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00653409071844306, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.39229094154398564}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:20,832]\u001B[0m Trial 191 finished with value: 0.2141926453610515 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006415999116892473, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.7765693253680434}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:22,519]\u001B[0m Trial 192 finished with value: 0.22936781067997944 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008240498031317527, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.773543780452826}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:24,269]\u001B[0m Trial 193 finished with value: 0.27895991150562616 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008396502780633846, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.46233233816693226}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:26,012]\u001B[0m Trial 194 finished with value: 0.26821900132285414 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008890996739966859, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4603123365053943}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:27,669]\u001B[0m Trial 195 finished with value: 0.2799673533959474 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008013980856764052, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4303575111328707}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:29,293]\u001B[0m Trial 196 finished with value: 0.2515887968800029 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00791213895342211, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.43985626468015476}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:31,013]\u001B[0m Trial 197 finished with value: 0.2455378722753056 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0077811986259295985, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4869656103684092}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:33,097]\u001B[0m Trial 198 finished with value: 0.27804413956086704 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008099752322095128, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.45882858979084457}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:35,185]\u001B[0m Trial 199 finished with value: 0.21693876327843997 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008115076445590789, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.42850921668452635}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:37,259]\u001B[0m Trial 200 finished with value: 0.25864426619375236 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00852827607263831, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4614756863000393}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:39,318]\u001B[0m Trial 201 finished with value: 0.26801417536091054 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0083905389755483, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4527964193339498}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:41,393]\u001B[0m Trial 202 finished with value: 0.19054476457595812 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00817943961032867, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4968229644309877}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:43,580]\u001B[0m Trial 203 finished with value: 0.297683047095237 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00837701337631881, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.47351352583225365}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:45,721]\u001B[0m Trial 204 finished with value: 0.258992040180537 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008710281628281913, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.476392096468032}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:47,834]\u001B[0m Trial 205 finished with value: 0.26890469742085105 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008063077899768333, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.41783447483426744}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:49,964]\u001B[0m Trial 206 finished with value: 0.22881409775381265 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00786335637005022, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.43579927868815627}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:52,104]\u001B[0m Trial 207 finished with value: 0.20032295531658192 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008344209359339449, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4657058335822706}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:54,193]\u001B[0m Trial 208 finished with value: 0.1893101338795406 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00912063316376419, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4402089672105335}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:56,264]\u001B[0m Trial 209 finished with value: 0.21857760390559255 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008601406112821782, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4866483796569696}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:58,025]\u001B[0m Trial 210 finished with value: 0.20670387327786136 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007994863553759045, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3753859808620553}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:15:59,729]\u001B[0m Trial 211 finished with value: 0.2351542675311912 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007540504837764456, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.5264551302927015}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:00,918]\u001B[0m Trial 212 finished with value: 0.18226737273830756 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008406970064468314, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 11, 'lmbda': 0.5403532575638067}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:10,052]\u001B[0m Trial 213 finished with value: 0.2611198736590034 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008094414069470392, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5023784809220757}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:15,320]\u001B[0m Trial 214 finished with value: 0.19072297129936516 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00946508856578866, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.5763950675604602}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:16,154]\u001B[0m Trial 215 finished with value: 0.18377128442106327 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006102014104386462, 'reg_lambda': 20, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4581953876758224}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:27,008]\u001B[0m Trial 216 finished with value: 0.2573780956605225 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0063454251173473385, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5165801355987211}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:33,273]\u001B[0m Trial 217 finished with value: 0.318159342664126 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005953295548719283, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.40992640030637995}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:39,678]\u001B[0m Trial 218 finished with value: 0.25552932922707344 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009765797427256931, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.39400696378022676}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:41,068]\u001B[0m Trial 219 finished with value: 0.29484661621619423 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008742932021370903, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4205191523714637}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:41,906]\u001B[0m Trial 220 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008695302712461607, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.4013271223486047}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:43,242]\u001B[0m Trial 221 finished with value: 0.2855198074849472 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00844105390558272, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.42073468931508545}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:44,560]\u001B[0m Trial 222 finished with value: 0.24436111091509755 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008299696576741837, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.41844331724704986}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:45,863]\u001B[0m Trial 223 finished with value: 0.25369158498037553 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008495371054539423, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4216992948838485}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:47,177]\u001B[0m Trial 224 finished with value: 0.21679890190942455 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008790398905647458, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4490209726674329}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:48,462]\u001B[0m Trial 225 finished with value: 0.23334121003532973 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008481498609573878, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.36636478321046145}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:49,736]\u001B[0m Trial 226 finished with value: 0.20984422693509708 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008971636108346615, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4337738480437683}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:51,129]\u001B[0m Trial 227 finished with value: 0.21663989374733728 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005925902172927786, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.346824903935955}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:52,433]\u001B[0m Trial 228 finished with value: 0.1956698458845381 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008653552733289811, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.40600732169171166}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:53,758]\u001B[0m Trial 229 finished with value: 0.2548511870375316 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008226721878486266, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.47048996975334917}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:16:55,064]\u001B[0m Trial 230 finished with value: 0.2569171264639204 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00617929990918695, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.38296560287682296}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:01,438]\u001B[0m Trial 231 finished with value: 0.2109552947988415 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008417950830132843, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4513057923204805}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:05,838]\u001B[0m Trial 232 finished with value: 0.2389314129765586 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008317223671253357, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.18150300158504987}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:16,250]\u001B[0m Trial 233 finished with value: 0.2126825319517743 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005815105279204248, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.32825422054641595}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:22,547]\u001B[0m Trial 234 finished with value: 0.2304637430695649 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008166759300553437, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.41975887670399736}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:32,865]\u001B[0m Trial 235 finished with value: 0.2180482866305934 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006008297156860884, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4717914892308642}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:43,489]\u001B[0m Trial 236 finished with value: 0.25344926670457774 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005367681852926401, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.43941867917429356}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:45,301]\u001B[0m Trial 237 finished with value: 0.24543348463753561 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006281400043352298, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3645739320109161}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:17:51,484]\u001B[0m Trial 238 finished with value: 0.26554838548746873 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008586881359217868, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.153862385123156}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:01,890]\u001B[0m Trial 239 finished with value: 0.22224049356109385 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00723980417301924, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4858200178117729}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:04,055]\u001B[0m Trial 240 finished with value: 0.2257245024311231 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007797542048243812, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.39723158219232635}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:07,097]\u001B[0m Trial 241 finished with value: 0.29359319296855557 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005988084551706359, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5482256054185038}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:10,396]\u001B[0m Trial 242 finished with value: 0.2263902283601424 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007018078951827958, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.4545046124767186}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:12,914]\u001B[0m Trial 243 finished with value: 0.2067576309322535 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005870312609023559, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 6, 'lmbda': 0.33552610971046426}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:16,213]\u001B[0m Trial 244 finished with value: 0.1782618534271659 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006092890382831588, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5664602378358974}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:19,486]\u001B[0m Trial 245 finished with value: 0.20459787255481998 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005953198708778665, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5936650506174703}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:30,438]\u001B[0m Trial 246 finished with value: 0.21971095565874843 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008789952902229507, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5482892751921556}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:41,693]\u001B[0m Trial 247 finished with value: 0.2689102652326857 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005721624521750644, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4942940373801788}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:47,901]\u001B[0m Trial 248 finished with value: 0.15592118592966672 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005452707286319044, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.42506082965175834}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:48,893]\u001B[0m Trial 249 finished with value: 0.26833540702497943 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006199650294792269, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 11, 'lmbda': 0.35288864825629457}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:18:54,154]\u001B[0m Trial 250 finished with value: 0.22042342815324847 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007136198407794532, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4690906047135954}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:07,203]\u001B[0m Trial 251 finished with value: 0.24621661032897774 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006423086235986878, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3805600676660655}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:08,159]\u001B[0m Trial 252 finished with value: 0.17981219499596676 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00601325031062999, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.44342475635161505}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:11,203]\u001B[0m Trial 253 finished with value: 0.2343702986490373 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006122509197263215, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.3164606677532847}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:12,664]\u001B[0m Trial 254 finished with value: 0.2576678180393694 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005264473901864181, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.404360083479838}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:21,780]\u001B[0m Trial 255 finished with value: 0.31037128986007606 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00911511846405995, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5048663575637735}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:29,932]\u001B[0m Trial 256 finished with value: 0.23071985242687792 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009053653584296655, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5080700813120217}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:41,935]\u001B[0m Trial 257 finished with value: 0.2541103894308268 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008434513989863713, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.481497819956772}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:43,655]\u001B[0m Trial 258 finished with value: 0.2604250818342884 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008924736326126378, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.46320951825341383}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:53,204]\u001B[0m Trial 259 finished with value: 0.2599832738922347 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00931508744712523, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.43143339519729745}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:54,988]\u001B[0m Trial 260 finished with value: 0.24056643853786322 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008032404853641472, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.19895268158673496}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:19:59,478]\u001B[0m Trial 261 finished with value: 0.19832542020411978 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005622016064991434, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.4495493210992694}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:10,551]\u001B[0m Trial 262 finished with value: 0.20905850355664368 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005931293071469162, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.1122127205471898}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:11,771]\u001B[0m Trial 263 finished with value: 0.19687384921312773 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008793541747787422, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.2792527834806306}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:22,136]\u001B[0m Trial 264 finished with value: 0.19923715906955752 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00921494825801069, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4911417010398441}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:34,173]\u001B[0m Trial 265 finished with value: 0.24468413255468396 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006218990367557585, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.341147371494759}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:36,016]\u001B[0m Trial 266 finished with value: 0.20792759399669897 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009016110927571984, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.41156234848398543}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:42,367]\u001B[0m Trial 267 finished with value: 0.2593643022272751 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006334739112556784, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.29946861194331337}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:52,351]\u001B[0m Trial 268 finished with value: 0.21998632107937796 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009172917072982657, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.3765595844763123}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:20:54,088]\u001B[0m Trial 269 finished with value: 0.25242724138872563 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008267429102704902, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4613022343145926}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:00,266]\u001B[0m Trial 270 finished with value: 0.30036666046509597 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00862429761681737, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.43341335450204777}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:06,643]\u001B[0m Trial 271 finished with value: 0.23607314616284925 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008466381618141523, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.4282287819939612}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:13,950]\u001B[0m Trial 272 finished with value: 0.23564869641746228 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008630683107748857, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.3921617315633753}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:17,249]\u001B[0m Trial 273 finished with value: 0.2677820713449711 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006614767960143783, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.5125418507222708}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:18,607]\u001B[0m Trial 274 finished with value: 0.23416330601196655 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00856210948886584, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.37185206916276287}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:24,942]\u001B[0m Trial 275 finished with value: 0.2662342940494927 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008697735578032014, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 11, 'lmbda': 0.4135345160791571}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:31,099]\u001B[0m Trial 276 finished with value: 0.25209515035207364 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008352299518243953, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4836353691305544}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:32,097]\u001B[0m Trial 277 finished with value: 0.15191792805809534 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008857264695953514, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.3524779414386458}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:32,977]\u001B[0m Trial 278 finished with value: 0.21909312460032698 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008613006609449234, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.43869679608348344}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:42,291]\u001B[0m Trial 279 finished with value: 0.1989881812980266 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008513167592564496, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5355904602206409}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:45,359]\u001B[0m Trial 280 finished with value: 0.20011682331471348 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006320491006324725, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.32645068549639394}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:47,303]\u001B[0m Trial 281 finished with value: 0.2680855590574213 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009813714621836389, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.47193540635796605}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:21:53,625]\u001B[0m Trial 282 finished with value: 0.17108333619069832 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005502531523493451, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.2465326171281152}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:04,027]\u001B[0m Trial 283 finished with value: 0.24174305368115695 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006431947080936934, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.3918792306519514}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:05,129]\u001B[0m Trial 284 finished with value: 0.3082110227239772 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0076770767502850066, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.22491006676173964}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:06,913]\u001B[0m Trial 285 finished with value: 0.29976680913693543 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007791594601513594, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.21776531543190877}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:07,999]\u001B[0m Trial 286 finished with value: 0.22623750060471 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007768500127111468, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.21698577017950874}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:09,101]\u001B[0m Trial 287 finished with value: 0.2235396100581668 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007458168408524755, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.1682072081394085}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:10,111]\u001B[0m Trial 288 finished with value: 0.15673560368940517 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007603139245824961, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.2298747018837016}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:11,265]\u001B[0m Trial 289 finished with value: 0.2480191252978014 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007875540793043848, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.4981412803568547}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:12,358]\u001B[0m Trial 290 finished with value: 0.24593104205521346 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0075935254939916855, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.20117346505006886}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:13,658]\u001B[0m Trial 291 finished with value: 0.23595366040396284 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007864370783677459, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.22386502994107343}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:15,417]\u001B[0m Trial 292 finished with value: 0.26007421342999015 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0077277749033591815, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.19280493972269816}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:17,355]\u001B[0m Trial 293 finished with value: 0.19824812948110584 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007675429539300217, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.1414221505001904}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:18,495]\u001B[0m Trial 294 finished with value: 0.2490109239976539 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007957526165190713, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.44680501747814205}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:20,350]\u001B[0m Trial 295 finished with value: 0.18437761133521433 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008149782681829152, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4302574323163909}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:21,854]\u001B[0m Trial 296 finished with value: 0.20386018012932786 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006139958450639555, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.16760009913621773}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:23,730]\u001B[0m Trial 297 finished with value: 0.2090841715648256 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009456125870795824, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.46457774769919313}. Best is trial 169 with value: 0.3197106376494038.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:25,929]\u001B[0m Trial 298 finished with value: 0.3378436370161152 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008351939842518547, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.8654547865340552}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:28,115]\u001B[0m Trial 299 finished with value: 0.27268395033321535 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008277724072783727, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.24084827921180016}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:30,328]\u001B[0m Trial 300 finished with value: 0.32169561723313356 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00839142937107144, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.20700568220307258}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:32,640]\u001B[0m Trial 301 finished with value: 0.25312334655544627 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008374581259969791, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.17424052770203782}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:34,855]\u001B[0m Trial 302 finished with value: 0.21116743187505865 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00843406996167845, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.8009381062824134}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:37,131]\u001B[0m Trial 303 finished with value: 0.24073521393121577 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00854457932334427, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.940576064612296}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:39,385]\u001B[0m Trial 304 finished with value: 0.2479188152853593 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008338566995647998, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.208384147655571}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:40,348]\u001B[0m Trial 305 finished with value: 0.1426114587577523 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008781248873190777, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 6, 'lmbda': 0.7446081660770654}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:41,647]\u001B[0m Trial 306 finished with value: 0.21752512666344248 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0082378809692661, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.2015269846471837}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:49,786]\u001B[0m Trial 307 finished with value: 0.23461990239414854 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006551672776811228, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.6697683316770312}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:51,482]\u001B[0m Trial 308 finished with value: 0.17327495843154112 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007365998271754273, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.8875879830246965}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:52,948]\u001B[0m Trial 309 finished with value: 0.27227999815617904 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008461640671276898, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.261336853485946}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:53,825]\u001B[0m Trial 310 finished with value: 0.26028281902073064 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006059420012327691, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.837227819180957}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:55,581]\u001B[0m Trial 311 finished with value: 0.22220532507762622 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008687858599126063, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.22340854812624872}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:57,388]\u001B[0m Trial 312 finished with value: 0.2202030011197115 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006260661240088984, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.18468793590700153}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:22:58,817]\u001B[0m Trial 313 finished with value: 0.20010249004888755 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006757306747745488, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.15248982080982376}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:00,634]\u001B[0m Trial 314 finished with value: 0.21833223102748256 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006494031432805111, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4125735398554359}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:11,320]\u001B[0m Trial 315 finished with value: 0.2679793815621305 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009081057759183806, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.1882458956448294}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:12,787]\u001B[0m Trial 316 finished with value: 0.2769856452165148 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008561827461025564, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4178548481185385}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:17,107]\u001B[0m Trial 317 finished with value: 0.2105238266726057 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008949044352680301, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.506864304121341}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:27,114]\u001B[0m Trial 318 finished with value: 0.22037505139976485 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006940735789333752, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.21865483111445677}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:28,873]\u001B[0m Trial 319 finished with value: 0.24720444698677774 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0058699129131675595, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4461169829021755}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:35,075]\u001B[0m Trial 320 finished with value: 0.1708121130708611 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007494503109175983, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.2556558145037654}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:37,332]\u001B[0m Trial 321 finished with value: 0.18880482974865304 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006377421575839203, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.480180124471102}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:47,506]\u001B[0m Trial 322 finished with value: 0.2719533674376128 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00622020947901445, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.05724286624100905}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:54,080]\u001B[0m Trial 323 finished with value: 0.19905908956168317 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0060135543974446344, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.6159882921062394}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:23:55,940]\u001B[0m Trial 324 finished with value: 0.26523291196900695 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009630868328933968, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.429088284818062}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:05,344]\u001B[0m Trial 325 finished with value: 0.22411144948645814 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008379746402412343, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.40399089760520535}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:06,680]\u001B[0m Trial 326 finished with value: 0.25369396292048907 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006151032905570719, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.027242642179346938}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:08,310]\u001B[0m Trial 327 finished with value: 0.125971633549051 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008489101973333928, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 1, 'num_negative_samples': 6, 'lmbda': 0.7142464845841865}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:22,247]\u001B[0m Trial 328 finished with value: 0.21707896963888929 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008664211723541206, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.47756005027795106}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:23,123]\u001B[0m Trial 329 finished with value: 0.2593456361354706 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008851658038281269, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4403100936947447}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:27,404]\u001B[0m Trial 330 finished with value: 0.23295443767500099 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008190736588178033, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.3905339399258547}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:29,450]\u001B[0m Trial 331 finished with value: 0.24670034016016673 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008308103182926763, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.5260298775232045}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:35,783]\u001B[0m Trial 332 finished with value: 0.19025684334048557 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008008839292247872, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.4923343561559593}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:37,579]\u001B[0m Trial 333 finished with value: 0.23618444931638402 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0076884371602252855, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4584051823095477}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:50,680]\u001B[0m Trial 334 finished with value: 0.24042958478812185 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00989947887474925, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.8865872494220479}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:24:52,017]\u001B[0m Trial 335 finished with value: 0.20225959463840526 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005923211106038431, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.2052101897352565}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:01,920]\u001B[0m Trial 336 finished with value: 0.288664133682869 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0062912571273339045, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.9639480631510301}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:11,908]\u001B[0m Trial 337 finished with value: 0.22954829370466556 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0062865638963567625, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.9154286359754077}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:22,052]\u001B[0m Trial 338 finished with value: 0.21094228443136392 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006393132243476129, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.9623542339580994}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:29,273]\u001B[0m Trial 339 finished with value: 0.27915209327889473 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006142978838266563, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.2348436246091701}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:39,129]\u001B[0m Trial 340 finished with value: 0.2073693471765724 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006293901920276294, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.9709943763115487}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:43,532]\u001B[0m Trial 341 finished with value: 0.20535844871524864 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0065139237539160325, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.9133363756317535}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:25:54,490]\u001B[0m Trial 342 finished with value: 0.2172398924775622 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006100696598511021, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.8040712143361955}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:00,843]\u001B[0m Trial 343 finished with value: 0.23901808728185323 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005758302203033932, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.9787633447866424}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:11,778]\u001B[0m Trial 344 finished with value: 0.30647169152945664 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0062309577547014165, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.18032650608378517}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:26,452]\u001B[0m Trial 345 finished with value: 0.2491981234816257 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006355289766608741, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.16699552514330507}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:36,485]\u001B[0m Trial 346 finished with value: 0.19892645252225363 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006240604696788729, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.1449360646889115}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:42,776]\u001B[0m Trial 347 finished with value: 0.28309401657792455 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006659357484068508, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.6612770526271954}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:49,134]\u001B[0m Trial 348 finished with value: 0.1524282250764813 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006656663589613576, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.746705950179438}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:26:55,688]\u001B[0m Trial 349 finished with value: 0.24138720825803855 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00646955994079222, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.6467930526461019}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:02,407]\u001B[0m Trial 350 finished with value: 0.23805098962579854 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006615368099952247, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.8345627323905763}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:08,860]\u001B[0m Trial 351 finished with value: 0.2501047101328299 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00670237704364525, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.1935730544628535}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:16,228]\u001B[0m Trial 352 finished with value: 0.19979571076500482 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006825877102880118, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.8925589512672405}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:22,694]\u001B[0m Trial 353 finished with value: 0.19581506508626062 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006384052646292755, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.8574303299202793}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:29,314]\u001B[0m Trial 354 finished with value: 0.22891529152184933 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006203234867201391, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.1865861713528887}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:32,532]\u001B[0m Trial 355 finished with value: 0.23019106085529648 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006021739717803644, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5676426550260734}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:35,097]\u001B[0m Trial 356 finished with value: 0.12938242505157224 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006497308819447309, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 16, 'lmbda': 0.1283459109066698}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:42,340]\u001B[0m Trial 357 finished with value: 0.25612436670233363 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00631516500620918, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.6732662037402982}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:46,713]\u001B[0m Trial 358 finished with value: 0.2678457039639322 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006113257959198029, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 6, 'lmbda': 0.16119443417915472}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:50,506]\u001B[0m Trial 359 finished with value: 0.253661598933734 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006562461356511129, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.5354730058474462}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:27:53,913]\u001B[0m Trial 360 finished with value: 0.19849705881574597 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00938487027905566, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.860365621358292}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:00,551]\u001B[0m Trial 361 finished with value: 0.25074906258506235 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006445783989532664, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.9984904637172338}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:14,909]\u001B[0m Trial 362 finished with value: 0.21346023553520652 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006220923517941692, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.932952992219839}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:15,772]\u001B[0m Trial 363 finished with value: 0.1900023031562395 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006052625255556622, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.21659969128612963}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:18,830]\u001B[0m Trial 364 finished with value: 0.18400000315883905 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008745137991145945, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.23728172492195426}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:28,999]\u001B[0m Trial 365 finished with value: 0.1901877392929883 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009184000733523646, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.604115032340504}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:35,437]\u001B[0m Trial 366 finished with value: 0.20494342076482877 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008924486157046302, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.09873475439259727}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:46,598]\u001B[0m Trial 367 finished with value: 0.242686205119143 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005828191915985506, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 16, 'lmbda': 0.634631424604429}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:28:59,389]\u001B[0m Trial 368 finished with value: 0.25790531501919756 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006340081050928719, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5115982079887756}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:18,971]\u001B[0m Trial 369 finished with value: 0.2092856091575964 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006182732147247786, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.17770819524863907}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:30,651]\u001B[0m Trial 370 finished with value: 0.21765167251238685 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005946955958628428, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.5472469882931473}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:40,491]\u001B[0m Trial 371 finished with value: 0.22201039651565166 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008622003831288957, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.21098609809824956}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:41,790]\u001B[0m Trial 372 finished with value: 0.29420016579846514 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007157422789998634, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.48131006145102045}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:44,317]\u001B[0m Trial 373 finished with value: 0.20507511842201673 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007366106435943608, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.5065484187069708}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:47,785]\u001B[0m Trial 374 finished with value: 0.24464334208869648 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009674153437703703, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.48357806432530465}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:49,300]\u001B[0m Trial 375 finished with value: 0.2281747342135775 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006011613661220845, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.49433399327374705}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:50,426]\u001B[0m Trial 376 finished with value: 0.1993210509529404 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006265596358213101, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.4640482345045023}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:51,495]\u001B[0m Trial 377 finished with value: 0.24953168920852495 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007188826436242724, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.44898452856621746}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:52,536]\u001B[0m Trial 378 finished with value: 0.1824923859215079 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006109805570480821, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 6, 'lmbda': 0.47904221767688215}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:53,559]\u001B[0m Trial 379 finished with value: 0.20574776444381757 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00727615124772096, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.4204721471386705}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:55,133]\u001B[0m Trial 380 finished with value: 0.23512117225035004 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009239353440262226, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.5219333644802904}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:56,563]\u001B[0m Trial 381 finished with value: 0.12542984783824446 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00635084874080313, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 16, 'lmbda': 0.5855489452291789}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:58,514]\u001B[0m Trial 382 finished with value: 0.23772954734532342 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008505648238532166, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 3, 'num_negative_samples': 1, 'lmbda': 0.18851836396908098}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:29:59,516]\u001B[0m Trial 383 finished with value: 0.2222770309930347 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007566901791972788, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.6964270549547439}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:00,470]\u001B[0m Trial 384 finished with value: 0.1957476279057947 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008746042949677228, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 11, 'lmbda': 0.8090992561913641}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:01,741]\u001B[0m Trial 385 finished with value: 0.2817809455111059 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007071926858263896, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.4671840739943081}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:02,958]\u001B[0m Trial 386 finished with value: 0.23517865875988472 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00702972216838615, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.5005011794551844}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:04,173]\u001B[0m Trial 387 finished with value: 0.2622927529041923 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007512525586159665, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.4799653764634485}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:05,425]\u001B[0m Trial 388 finished with value: 0.23037360705622595 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007174244926093837, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.4593873973032157}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:06,690]\u001B[0m Trial 389 finished with value: 0.26621844726330673 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006938632112844748, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.5133391301822812}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:07,954]\u001B[0m Trial 390 finished with value: 0.286768381560791 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008843653583425622, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.49215529743170955}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:09,188]\u001B[0m Trial 391 finished with value: 0.23937707176853687 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008981736924466844, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.49901383155729284}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:10,761]\u001B[0m Trial 392 finished with value: 0.23053472635885833 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007103048861238675, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.5616820428778299}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:11,989]\u001B[0m Trial 393 finished with value: 0.21468522608366167 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00908607689098933, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.5357759846890949}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:13,251]\u001B[0m Trial 394 finished with value: 0.3144214202198819 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008878987203573009, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.20523683145133326}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:14,522]\u001B[0m Trial 395 finished with value: 0.17869888557512548 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008925768223530655, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.20636053177505245}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:15,770]\u001B[0m Trial 396 finished with value: 0.2171707476631072 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00879412336758245, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.23475576243672108}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:17,095]\u001B[0m Trial 397 finished with value: 0.23404307253322054 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008877690644304676, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.26465934936023705}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:18,337]\u001B[0m Trial 398 finished with value: 0.2157613577433579 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008815133147642776, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.16880050511187228}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:19,585]\u001B[0m Trial 399 finished with value: 0.19549161945156834 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008712440596592042, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.19561218375910006}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:20,764]\u001B[0m Trial 400 finished with value: 0.2179183339485337 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00905056084505561, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.2461231290052594}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:22,111]\u001B[0m Trial 401 finished with value: 0.25420482244257575 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008965548757729518, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.2189634014836888}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:23,260]\u001B[0m Trial 402 finished with value: 0.2468165667570447 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008863193897642604, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.14726120869567116}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:24,859]\u001B[0m Trial 403 finished with value: 0.24129409693465512 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008644870666223077, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.1801703321896433}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:26,217]\u001B[0m Trial 404 finished with value: 0.19960590670923017 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008721858430937961, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.2134348049244809}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:27,421]\u001B[0m Trial 405 finished with value: 0.249781650678894 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008620050787411319, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.19206359742547705}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:28,895]\u001B[0m Trial 406 finished with value: 0.24939526542421103 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009022580182109307, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 6, 'lmbda': 0.5208035558065104}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:30,863]\u001B[0m Trial 407 finished with value: 0.2992736187287888 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00885126084334245, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.1634618481012679}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:32,832]\u001B[0m Trial 408 finished with value: 0.2805259438889836 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008867339908560225, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.15993014789084165}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:34,808]\u001B[0m Trial 409 finished with value: 0.29069834370203834 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008785359550559821, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.12404194699760526}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:36,694]\u001B[0m Trial 410 finished with value: 0.22497021419783278 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008772723854137658, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.08246278975379054}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:38,560]\u001B[0m Trial 411 finished with value: 0.2057564082694328 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008808966227216199, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.10243153219903807}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:40,436]\u001B[0m Trial 412 finished with value: 0.2171454605093049 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008932224327561297, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.12927230954842178}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:42,359]\u001B[0m Trial 413 finished with value: 0.20639562140735573 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008598988438972896, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.13071384015323073}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:44,295]\u001B[0m Trial 414 finished with value: 0.1949392696103137 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009004824283155804, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.18006849096144345}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:46,418]\u001B[0m Trial 415 finished with value: 0.2333045147778751 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009119079287881833, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.1338134768025056}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:48,415]\u001B[0m Trial 416 finished with value: 0.23868087873331975 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008732688597968394, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.1695568377031814}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:50,414]\u001B[0m Trial 417 finished with value: 0.2578830809709157 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008890640001993085, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.16039703636633074}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:52,438]\u001B[0m Trial 418 finished with value: 0.26773407675424676 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008532434084948188, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.2135012510621063}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:54,428]\u001B[0m Trial 419 finished with value: 0.257762416296524 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008789546214776062, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.115348267067176}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:56,433]\u001B[0m Trial 420 finished with value: 0.22879137918112313 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00868352628523787, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.1512442042776682}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:30:58,417]\u001B[0m Trial 421 finished with value: 0.2364924568998822 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008407508746344402, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.22817318436336537}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:00,333]\u001B[0m Trial 422 finished with value: 0.24097852060210184 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008868785562482346, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.18532930000932443}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:05,927]\u001B[0m Trial 423 finished with value: 0.26200365232102124 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008566799216020533, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.19809776252767416}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:06,950]\u001B[0m Trial 424 finished with value: 0.1462197491548222 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009018194891835585, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 21, 'lmbda': 0.1491650547345497}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:07,898]\u001B[0m Trial 425 finished with value: 0.21957528657427738 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005710003360414207, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.25107257105438757}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:09,778]\u001B[0m Trial 426 finished with value: 0.19943920188013062 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008278606092770636, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.43990888626279806}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:12,124]\u001B[0m Trial 427 finished with value: 0.2413024159322963 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00867082466564118, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.4938223456312567}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:13,254]\u001B[0m Trial 428 finished with value: 0.2043297302155099 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007782348184590496, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 11, 'lmbda': 0.10889550510825807}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:15,253]\u001B[0m Trial 429 finished with value: 0.15664765664251662 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009121393230837499, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.19776174138350056}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:17,482]\u001B[0m Trial 430 finished with value: 0.24011046030049601 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008434732399876178, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.16653256649086762}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:19,384]\u001B[0m Trial 431 finished with value: 0.21815516815257296 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008941894139499449, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.4817357231094186}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:20,582]\u001B[0m Trial 432 finished with value: 0.18426288273227995 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008835062878913445, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.22846254878713143}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:22,594]\u001B[0m Trial 433 finished with value: 0.1905669197834475 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005868660238516547, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.44499275137426264}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:24,786]\u001B[0m Trial 434 finished with value: 0.24556490283495205 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008730768140664133, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.13837578040955434}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:26,736]\u001B[0m Trial 435 finished with value: 0.2486789790997878 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009539976436035252, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.17837730552205303}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:28,644]\u001B[0m Trial 436 finished with value: 0.24934756123101212 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008353916554762138, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.5490551590576359}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:31,264]\u001B[0m Trial 437 finished with value: 0.20828195487279982 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008589305985615437, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.47420439466383973}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:33,119]\u001B[0m Trial 438 finished with value: 0.2562493322119476 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008527997941974775, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5115875881572749}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:34,066]\u001B[0m Trial 439 finished with value: 0.25789474676793656 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008138293641289665, 'reg_lambda': 0.8, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 21, 'lmbda': 0.45825641847058857}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:35,849]\u001B[0m Trial 440 finished with value: 0.21003853979155146 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0059780299963419735, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.2096509282285999}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:37,064]\u001B[0m Trial 441 finished with value: 0.25939100933879916 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008875754883579846, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 1, 'lmbda': 0.2435207794900727}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:38,077]\u001B[0m Trial 442 finished with value: 0.18953890648148747 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009232703787002798, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 1, 'num_negative_samples': 6, 'lmbda': 0.9100003786891168}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:39,880]\u001B[0m Trial 443 finished with value: 0.251287631719915 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007702356607144749, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.9815140132398398}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:41,260]\u001B[0m Trial 444 finished with value: 0.22877741439902965 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008673251947581817, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 21, 'lmbda': 0.2734544419552676}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:43,172]\u001B[0m Trial 445 finished with value: 0.2502765351382008 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009009041130243922, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.09126483614977615}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:45,382]\u001B[0m Trial 446 finished with value: 0.24507384857208805 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00848078406432853, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.49032359790297936}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:46,678]\u001B[0m Trial 447 finished with value: 0.27688118914916615 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009946813183335932, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'num_negative_samples': 1, 'lmbda': 0.5303604455723041}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:57,400]\u001B[0m Trial 448 finished with value: 0.23087411535912195 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0076307553422599655, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4332225448042324}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:31:58,677]\u001B[0m Trial 449 finished with value: 0.2522010075960898 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008789537315490465, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 5, 'num_negative_samples': 21, 'lmbda': 0.40650783213817737}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:32:10,855]\u001B[0m Trial 450 finished with value: 0.29173499882576137 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006055337493634964, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.47171031077207587}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:32:22,862]\u001B[0m Trial 451 finished with value: 0.23005888705533203 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006031688971875843, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.45670935902575477}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:32:34,858]\u001B[0m Trial 452 finished with value: 0.2783832617063983 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0060905064591706085, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.49273654469876427}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:32:47,150]\u001B[0m Trial 453 finished with value: 0.19639293309900302 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005930339782858323, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.44832027498045807}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:32:59,402]\u001B[0m Trial 454 finished with value: 0.22611095605276335 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0061894385874032825, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.07208352236233032}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:33:14,357]\u001B[0m Trial 455 finished with value: 0.19070060985332457 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005859749375581959, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5041418999501037}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:33:26,245]\u001B[0m Trial 456 finished with value: 0.3202258838714131 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006113526560375677, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4738499755408719}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:33:38,371]\u001B[0m Trial 457 finished with value: 0.2467777096011782 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006121570070637804, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.479983064922712}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:33:50,559]\u001B[0m Trial 458 finished with value: 0.2375580486457566 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0059868944579866, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.516671269287171}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:34:02,557]\u001B[0m Trial 459 finished with value: 0.289659215220456 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0060745599791102774, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.47183923343487666}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:34:14,745]\u001B[0m Trial 460 finished with value: 0.26681100406113667 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006050549372338815, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4694603237358772}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:34:27,049]\u001B[0m Trial 461 finished with value: 0.2588376662305999 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006137817016452799, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.9540091617530492}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:34:39,379]\u001B[0m Trial 462 finished with value: 0.2534796309313962 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0059620763317233295, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.463130262962426}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:34:51,572]\u001B[0m Trial 463 finished with value: 0.20614478850485846 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006061821913711704, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4738939445184435}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:35:03,574]\u001B[0m Trial 464 finished with value: 0.255769014342607 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006170377988021035, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.45871208739179015}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:35:15,833]\u001B[0m Trial 465 finished with value: 0.18690934621432895 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005803564556242756, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4391769835793477}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:35:28,085]\u001B[0m Trial 466 finished with value: 0.18562702229812109 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006071574748604471, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.48199332026031794}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:35:39,979]\u001B[0m Trial 467 finished with value: 0.3163537667831715 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009738521654872127, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.11572939620857187}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:35:51,643]\u001B[0m Trial 468 finished with value: 0.2386293827956985 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009874267068420468, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.12173462681932913}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:36:03,451]\u001B[0m Trial 469 finished with value: 0.2811928455493807 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009759719230179707, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.05514455004751198}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:36:15,298]\u001B[0m Trial 470 finished with value: 0.2544154008828517 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00992743011093704, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.09501363304498142}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:36:27,256]\u001B[0m Trial 471 finished with value: 0.24910042927069076 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009826604314245856, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.13285805660454936}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:36:34,623]\u001B[0m Trial 472 finished with value: 0.15967867007509487 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009411753584002125, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.12317176102277755}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:36:46,654]\u001B[0m Trial 473 finished with value: 0.2407500494569575 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009734958769348002, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.14651100870910477}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:36:58,459]\u001B[0m Trial 474 finished with value: 0.23702846455795315 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009703633820929272, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.1189244171267062}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:37:10,512]\u001B[0m Trial 475 finished with value: 0.22883927740045973 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005923735540463875, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5018474880024699}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:37:20,179]\u001B[0m Trial 476 finished with value: 0.25208242432633876 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007838118457791596, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.16162495075885566}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:37:26,109]\u001B[0m Trial 477 finished with value: 0.25109346425283696 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009632694793588869, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.447900505954324}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:37:38,563]\u001B[0m Trial 478 finished with value: 0.21975943897302894 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006225187651770108, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.10258206031937991}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:37:48,984]\u001B[0m Trial 479 finished with value: 0.24544001480158217 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009547719163808106, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.465432844096362}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:37:49,944]\u001B[0m Trial 480 finished with value: 0.2679022154519647 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0059461268742433265, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.03498608208140805}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:38:04,396]\u001B[0m Trial 481 finished with value: 0.20565816777241552 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0061341432354777865, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5352887747785986}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:38:14,221]\u001B[0m Trial 482 finished with value: 0.21937222626732358 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005988840364797924, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.43151252567674964}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:38:29,892]\u001B[0m Trial 483 finished with value: 0.27804168418761926 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005802444542703639, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.48276971392182166}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:38:32,314]\u001B[0m Trial 484 finished with value: 0.21838948750791154 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009968197592479437, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 1, 'num_negative_samples': 1, 'lmbda': 0.5111395155913656}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:38:41,899]\u001B[0m Trial 485 finished with value: 0.2093905197347963 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009864438276557076, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5804794928359266}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:38:58,561]\u001B[0m Trial 486 finished with value: 0.17539989440955361 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007413934753973968, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.19927370173785677}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:39:07,981]\u001B[0m Trial 487 finished with value: 0.24325891239708514 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009123428410264528, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.1487492251622521}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:39:20,957]\u001B[0m Trial 488 finished with value: 0.1985377783124648 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006211105699877559, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.18019442944913283}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:39:35,748]\u001B[0m Trial 489 finished with value: 0.2487480112061985 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006068760095120723, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.4736886285993007}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:39:46,347]\u001B[0m Trial 490 finished with value: 0.20839687696339293 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009344185279726065, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.42490505480385}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:39:57,496]\u001B[0m Trial 491 finished with value: 0.215520309097732 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00894326340948476, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.49725795472334006}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:40:05,412]\u001B[0m Trial 492 finished with value: 0.26980956765319275 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005917249961567379, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.4434392670580389}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:40:16,594]\u001B[0m Trial 493 finished with value: 0.22949960354477933 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008178451459452667, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.22751997054290754}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:40:17,551]\u001B[0m Trial 494 finished with value: 0.202499597885955 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007901383130035314, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.07010827655302929}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:40:29,905]\u001B[0m Trial 495 finished with value: 0.2409228566239053 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006186617449535719, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5569967844689662}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:40:39,718]\u001B[0m Trial 496 finished with value: 0.245741617709357 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006014436435126246, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 11, 'lmbda': 0.4578069531329163}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:40:53,938]\u001B[0m Trial 497 finished with value: 0.29724003878391364 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005856398059916771, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5172974233534422}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:41:07,810]\u001B[0m Trial 498 finished with value: 0.2315282825533844 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009053630387045554, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 6, 'lmbda': 0.5217655197193832}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:41:27,900]\u001B[0m Trial 499 finished with value: 0.24816362865090963 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005786555004219277, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'num_negative_samples': 1, 'lmbda': 0.5432969017864815}. Best is trial 298 with value: 0.3378436370161152.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: GCN, mode: unsupervised, loss from LINE\n",
      "0\n",
      "Loss: 351.6750, Epoch: 000, Train acc micro: 0.9030, Test acc micro: 0.2714,Train acc macro: 0.9030, Test acc macro: 0.2651\n",
      "1\n",
      "Loss: 184.9060, Epoch: 001, Train acc micro: 0.4964, Test acc micro: 0.1558,Train acc macro: 0.4921, Test acc macro: 0.1483\n",
      "2\n",
      "Loss: 109.0102, Epoch: 002, Train acc micro: 0.9843, Test acc micro: 0.2161,Train acc macro: 0.9843, Test acc macro: 0.2102\n",
      "3\n",
      "Loss: 66.5590, Epoch: 003, Train acc micro: 0.9929, Test acc micro: 0.2362,Train acc macro: 0.9929, Test acc macro: 0.2338\n",
      "4\n",
      "Loss: 42.5508, Epoch: 004, Train acc micro: 0.9971, Test acc micro: 0.2312,Train acc macro: 0.9971, Test acc macro: 0.2222\n",
      "5\n",
      "Loss: 29.1602, Epoch: 005, Train acc micro: 0.9986, Test acc micro: 0.2111,Train acc macro: 0.9986, Test acc macro: 0.2085\n",
      "6\n",
      "Loss: 20.5121, Epoch: 006, Train acc micro: 0.9829, Test acc micro: 0.1859,Train acc macro: 0.9829, Test acc macro: 0.1761\n",
      "7\n",
      "Loss: 15.4362, Epoch: 007, Train acc micro: 0.9486, Test acc micro: 0.2161,Train acc macro: 0.9485, Test acc macro: 0.2144\n",
      "8\n",
      "Loss: 11.0946, Epoch: 008, Train acc micro: 0.9786, Test acc micro: 0.2513,Train acc macro: 0.9786, Test acc macro: 0.2462\n",
      "9\n",
      "Loss: 8.4546, Epoch: 009, Train acc micro: 0.9886, Test acc micro: 0.2261,Train acc macro: 0.9886, Test acc macro: 0.2174\n",
      "10\n",
      "Loss: 6.8105, Epoch: 010, Train acc micro: 0.9743, Test acc micro: 0.2362,Train acc macro: 0.9744, Test acc macro: 0.2220\n",
      "11\n",
      "Loss: 5.9542, Epoch: 011, Train acc micro: 0.9615, Test acc micro: 0.1910,Train acc macro: 0.9616, Test acc macro: 0.1897\n",
      "12\n",
      "Loss: 5.1874, Epoch: 012, Train acc micro: 0.9087, Test acc micro: 0.2513,Train acc macro: 0.9094, Test acc macro: 0.2456\n",
      "13\n",
      "Loss: 4.7291, Epoch: 013, Train acc micro: 0.9829, Test acc micro: 0.2312,Train acc macro: 0.9829, Test acc macro: 0.2322\n",
      "14\n",
      "Loss: 4.3599, Epoch: 014, Train acc micro: 0.9700, Test acc micro: 0.2312,Train acc macro: 0.9703, Test acc macro: 0.2282\n",
      "15\n",
      "Loss: 3.8224, Epoch: 015, Train acc micro: 0.9729, Test acc micro: 0.1960,Train acc macro: 0.9732, Test acc macro: 0.1934\n",
      "16\n",
      "Loss: 3.6198, Epoch: 016, Train acc micro: 0.9786, Test acc micro: 0.2613,Train acc macro: 0.9788, Test acc macro: 0.2559\n",
      "17\n",
      "Loss: 3.5038, Epoch: 017, Train acc micro: 0.9658, Test acc micro: 0.2261,Train acc macro: 0.9661, Test acc macro: 0.2152\n",
      "18\n",
      "Loss: 3.2328, Epoch: 018, Train acc micro: 0.9643, Test acc micro: 0.2362,Train acc macro: 0.9649, Test acc macro: 0.2320\n",
      "19\n",
      "Loss: 3.0403, Epoch: 019, Train acc micro: 0.9315, Test acc micro: 0.2211,Train acc macro: 0.9332, Test acc macro: 0.2148\n",
      "20\n",
      "Loss: 2.9534, Epoch: 020, Train acc micro: 0.9486, Test acc micro: 0.1960,Train acc macro: 0.9501, Test acc macro: 0.1903\n",
      "21\n",
      "Loss: 2.7417, Epoch: 021, Train acc micro: 0.9444, Test acc micro: 0.2312,Train acc macro: 0.9456, Test acc macro: 0.2285\n",
      "22\n",
      "Loss: 2.7611, Epoch: 022, Train acc micro: 0.9629, Test acc micro: 0.2060,Train acc macro: 0.9637, Test acc macro: 0.2028\n",
      "23\n",
      "Loss: 2.7831, Epoch: 023, Train acc micro: 0.9544, Test acc micro: 0.2060,Train acc macro: 0.9556, Test acc macro: 0.2024\n",
      "24\n",
      "Loss: 2.6553, Epoch: 024, Train acc micro: 0.9429, Test acc micro: 0.2462,Train acc macro: 0.9439, Test acc macro: 0.2418\n",
      "25\n",
      "Loss: 2.5513, Epoch: 025, Train acc micro: 0.9158, Test acc micro: 0.2312,Train acc macro: 0.9186, Test acc macro: 0.2285\n",
      "26\n",
      "Loss: 2.4862, Epoch: 026, Train acc micro: 0.9472, Test acc micro: 0.2161,Train acc macro: 0.9490, Test acc macro: 0.2103\n",
      "27\n",
      "Loss: 2.5051, Epoch: 027, Train acc micro: 0.8017, Test acc micro: 0.2211,Train acc macro: 0.8040, Test acc macro: 0.2188\n",
      "28\n",
      "Loss: 2.4443, Epoch: 028, Train acc micro: 0.9315, Test acc micro: 0.1859,Train acc macro: 0.9333, Test acc macro: 0.1842\n",
      "29\n",
      "Loss: 2.3998, Epoch: 029, Train acc micro: 0.9272, Test acc micro: 0.2261,Train acc macro: 0.9303, Test acc macro: 0.2245\n",
      "30\n",
      "Loss: 2.3384, Epoch: 030, Train acc micro: 0.9230, Test acc micro: 0.2513,Train acc macro: 0.9260, Test acc macro: 0.2495\n",
      "31\n",
      "Loss: 2.3184, Epoch: 031, Train acc micro: 0.9158, Test acc micro: 0.2563,Train acc macro: 0.9189, Test acc macro: 0.2563\n",
      "32\n",
      "Loss: 2.3110, Epoch: 032, Train acc micro: 0.9301, Test acc micro: 0.2312,Train acc macro: 0.9331, Test acc macro: 0.2288\n",
      "33\n",
      "Loss: 2.2918, Epoch: 033, Train acc micro: 0.9215, Test acc micro: 0.2312,Train acc macro: 0.9251, Test acc macro: 0.2304\n",
      "34\n",
      "Loss: 2.2481, Epoch: 034, Train acc micro: 0.8474, Test acc micro: 0.2362,Train acc macro: 0.8505, Test acc macro: 0.2379\n",
      "35\n",
      "Loss: 2.2457, Epoch: 035, Train acc micro: 0.9215, Test acc micro: 0.1910,Train acc macro: 0.9250, Test acc macro: 0.1851\n",
      "36\n",
      "Loss: 2.2455, Epoch: 036, Train acc micro: 0.7832, Test acc micro: 0.1910,Train acc macro: 0.7921, Test acc macro: 0.1820\n",
      "37\n",
      "Loss: 2.2449, Epoch: 037, Train acc micro: 0.9116, Test acc micro: 0.1910,Train acc macro: 0.9152, Test acc macro: 0.1862\n",
      "38\n",
      "Loss: 2.2208, Epoch: 038, Train acc micro: 0.8959, Test acc micro: 0.2211,Train acc macro: 0.8992, Test acc macro: 0.2201\n",
      "39\n",
      "Loss: 2.1975, Epoch: 039, Train acc micro: 0.9016, Test acc micro: 0.2312,Train acc macro: 0.9061, Test acc macro: 0.2252\n",
      "40\n",
      "Loss: 2.1944, Epoch: 040, Train acc micro: 0.9016, Test acc micro: 0.2211,Train acc macro: 0.9066, Test acc macro: 0.2119\n",
      "41\n",
      "Loss: 2.1850, Epoch: 041, Train acc micro: 0.9030, Test acc micro: 0.2111,Train acc macro: 0.9075, Test acc macro: 0.2113\n",
      "42\n",
      "Loss: 2.1630, Epoch: 042, Train acc micro: 0.8916, Test acc micro: 0.2211,Train acc macro: 0.8961, Test acc macro: 0.2207\n",
      "43\n",
      "Loss: 2.1545, Epoch: 043, Train acc micro: 0.8787, Test acc micro: 0.2261,Train acc macro: 0.8857, Test acc macro: 0.2255\n",
      "44\n",
      "Loss: 2.1475, Epoch: 044, Train acc micro: 0.8930, Test acc micro: 0.2161,Train acc macro: 0.8976, Test acc macro: 0.2165\n",
      "45\n",
      "Loss: 2.1521, Epoch: 045, Train acc micro: 0.8902, Test acc micro: 0.2010,Train acc macro: 0.8949, Test acc macro: 0.1963\n",
      "46\n",
      "Loss: 2.1412, Epoch: 046, Train acc micro: 0.8688, Test acc micro: 0.2211,Train acc macro: 0.8773, Test acc macro: 0.2148\n",
      "47\n",
      "Loss: 2.1278, Epoch: 047, Train acc micro: 0.8887, Test acc micro: 0.2261,Train acc macro: 0.8934, Test acc macro: 0.2253\n",
      "48\n",
      "Loss: 2.1314, Epoch: 048, Train acc micro: 0.8659, Test acc micro: 0.2663,Train acc macro: 0.8743, Test acc macro: 0.2690\n",
      "49\n",
      "Loss: 2.1339, Epoch: 049, Train acc micro: 0.8902, Test acc micro: 0.2362,Train acc macro: 0.8968, Test acc macro: 0.2353\n",
      "50\n",
      "Loss: 2.1184, Epoch: 050, Train acc micro: 0.8602, Test acc micro: 0.2362,Train acc macro: 0.8681, Test acc macro: 0.2360\n",
      "51\n",
      "Loss: 2.1206, Epoch: 051, Train acc micro: 0.8816, Test acc micro: 0.2010,Train acc macro: 0.8893, Test acc macro: 0.1972\n",
      "52\n",
      "Loss: 2.1094, Epoch: 052, Train acc micro: 0.8602, Test acc micro: 0.1910,Train acc macro: 0.8700, Test acc macro: 0.1920\n",
      "53\n",
      "Loss: 2.1216, Epoch: 053, Train acc micro: 0.8502, Test acc micro: 0.2663,Train acc macro: 0.8613, Test acc macro: 0.2573\n",
      "54\n",
      "Loss: 2.1084, Epoch: 054, Train acc micro: 0.8759, Test acc micro: 0.2462,Train acc macro: 0.8845, Test acc macro: 0.2445\n",
      "55\n",
      "Loss: 2.1099, Epoch: 055, Train acc micro: 0.8502, Test acc micro: 0.2563,Train acc macro: 0.8558, Test acc macro: 0.2563\n",
      "56\n",
      "Loss: 2.1100, Epoch: 056, Train acc micro: 0.8474, Test acc micro: 0.2412,Train acc macro: 0.8585, Test acc macro: 0.2361\n",
      "57\n",
      "Loss: 2.1081, Epoch: 057, Train acc micro: 0.8374, Test acc micro: 0.2111,Train acc macro: 0.8489, Test acc macro: 0.2067\n",
      "58\n",
      "Loss: 2.1037, Epoch: 058, Train acc micro: 0.8559, Test acc micro: 0.2211,Train acc macro: 0.8666, Test acc macro: 0.2191\n",
      "59\n",
      "Loss: 2.1023, Epoch: 059, Train acc micro: 0.8117, Test acc micro: 0.2211,Train acc macro: 0.8235, Test acc macro: 0.2209\n",
      "60\n",
      "Loss: 2.1030, Epoch: 060, Train acc micro: 0.8388, Test acc micro: 0.2060,Train acc macro: 0.8504, Test acc macro: 0.2000\n",
      "61\n",
      "Loss: 2.0894, Epoch: 061, Train acc micro: 0.8516, Test acc micro: 0.2563,Train acc macro: 0.8622, Test acc macro: 0.2548\n",
      "62\n",
      "Loss: 2.0979, Epoch: 062, Train acc micro: 0.8702, Test acc micro: 0.2663,Train acc macro: 0.8795, Test acc macro: 0.2630\n",
      "63\n",
      "Loss: 2.0933, Epoch: 063, Train acc micro: 0.8787, Test acc micro: 0.2111,Train acc macro: 0.8843, Test acc macro: 0.2088\n",
      "64\n",
      "Loss: 2.0979, Epoch: 064, Train acc micro: 0.8645, Test acc micro: 0.2111,Train acc macro: 0.8700, Test acc macro: 0.2111\n",
      "65\n",
      "Loss: 2.0849, Epoch: 065, Train acc micro: 0.8830, Test acc micro: 0.2663,Train acc macro: 0.8893, Test acc macro: 0.2588\n",
      "66\n",
      "Loss: 2.0870, Epoch: 066, Train acc micro: 0.8745, Test acc micro: 0.1759,Train acc macro: 0.8806, Test acc macro: 0.1739\n",
      "67\n",
      "Loss: 2.0985, Epoch: 067, Train acc micro: 0.6833, Test acc micro: 0.2161,Train acc macro: 0.6902, Test acc macro: 0.2045\n",
      "68\n",
      "Loss: 2.0827, Epoch: 068, Train acc micro: 0.8516, Test acc micro: 0.1658,Train acc macro: 0.8617, Test acc macro: 0.1647\n",
      "69\n",
      "Loss: 2.0906, Epoch: 069, Train acc micro: 0.8573, Test acc micro: 0.2764,Train acc macro: 0.8676, Test acc macro: 0.2753\n",
      "70\n",
      "Loss: 2.0790, Epoch: 070, Train acc micro: 0.8602, Test acc micro: 0.2161,Train acc macro: 0.8705, Test acc macro: 0.2187\n",
      "71\n",
      "Loss: 2.0829, Epoch: 071, Train acc micro: 0.8203, Test acc micro: 0.2312,Train acc macro: 0.8306, Test acc macro: 0.2287\n",
      "72\n",
      "Loss: 2.0829, Epoch: 072, Train acc micro: 0.8688, Test acc micro: 0.2462,Train acc macro: 0.8773, Test acc macro: 0.2440\n",
      "73\n",
      "Loss: 2.0760, Epoch: 073, Train acc micro: 0.8402, Test acc micro: 0.2161,Train acc macro: 0.8520, Test acc macro: 0.2098\n",
      "74\n",
      "Loss: 2.0757, Epoch: 074, Train acc micro: 0.8559, Test acc micro: 0.2412,Train acc macro: 0.8660, Test acc macro: 0.2379\n",
      "75\n",
      "Loss: 2.0790, Epoch: 075, Train acc micro: 0.8573, Test acc micro: 0.2915,Train acc macro: 0.8680, Test acc macro: 0.2882\n",
      "76\n",
      "Loss: 2.0817, Epoch: 076, Train acc micro: 0.8787, Test acc micro: 0.2312,Train acc macro: 0.8870, Test acc macro: 0.2307\n",
      "77\n",
      "Loss: 2.0773, Epoch: 077, Train acc micro: 0.8730, Test acc micro: 0.2161,Train acc macro: 0.8822, Test acc macro: 0.2067\n",
      "78\n",
      "Loss: 2.0772, Epoch: 078, Train acc micro: 0.8688, Test acc micro: 0.2211,Train acc macro: 0.8787, Test acc macro: 0.2188\n",
      "79\n",
      "Loss: 2.0718, Epoch: 079, Train acc micro: 0.8673, Test acc micro: 0.2010,Train acc macro: 0.8768, Test acc macro: 0.1969\n",
      "80\n",
      "Loss: 2.0756, Epoch: 080, Train acc micro: 0.8516, Test acc micro: 0.2412,Train acc macro: 0.8619, Test acc macro: 0.2392\n",
      "81\n",
      "Loss: 2.0743, Epoch: 081, Train acc micro: 0.8745, Test acc micro: 0.2764,Train acc macro: 0.8819, Test acc macro: 0.2719\n",
      "82\n",
      "Loss: 2.0737, Epoch: 082, Train acc micro: 0.8802, Test acc micro: 0.1910,Train acc macro: 0.8876, Test acc macro: 0.1893\n",
      "83\n",
      "Loss: 2.0761, Epoch: 083, Train acc micro: 0.8602, Test acc micro: 0.2312,Train acc macro: 0.8698, Test acc macro: 0.2300\n",
      "84\n",
      "Loss: 2.0714, Epoch: 084, Train acc micro: 0.8588, Test acc micro: 0.2563,Train acc macro: 0.8652, Test acc macro: 0.2553\n",
      "85\n",
      "Loss: 2.0683, Epoch: 085, Train acc micro: 0.8716, Test acc micro: 0.2161,Train acc macro: 0.8801, Test acc macro: 0.2136\n",
      "86\n",
      "Loss: 2.0635, Epoch: 086, Train acc micro: 0.8688, Test acc micro: 0.2362,Train acc macro: 0.8755, Test acc macro: 0.2275\n",
      "87\n",
      "Loss: 2.0687, Epoch: 087, Train acc micro: 0.8688, Test acc micro: 0.2462,Train acc macro: 0.8759, Test acc macro: 0.2451\n",
      "88\n",
      "Loss: 2.0680, Epoch: 088, Train acc micro: 0.8588, Test acc micro: 0.2312,Train acc macro: 0.8695, Test acc macro: 0.2281\n",
      "89\n",
      "Loss: 2.0643, Epoch: 089, Train acc micro: 0.8559, Test acc micro: 0.2362,Train acc macro: 0.8673, Test acc macro: 0.2306\n",
      "90\n",
      "Loss: 2.0639, Epoch: 090, Train acc micro: 0.8716, Test acc micro: 0.2111,Train acc macro: 0.8790, Test acc macro: 0.2116\n",
      "91\n",
      "Loss: 2.0615, Epoch: 091, Train acc micro: 0.8631, Test acc micro: 0.2261,Train acc macro: 0.8729, Test acc macro: 0.2259\n",
      "92\n",
      "Loss: 2.0642, Epoch: 092, Train acc micro: 0.8673, Test acc micro: 0.2010,Train acc macro: 0.8742, Test acc macro: 0.1979\n",
      "93\n",
      "Loss: 2.0626, Epoch: 093, Train acc micro: 0.8516, Test acc micro: 0.2211,Train acc macro: 0.8625, Test acc macro: 0.2188\n",
      "94\n",
      "Loss: 2.0615, Epoch: 094, Train acc micro: 0.8573, Test acc micro: 0.2060,Train acc macro: 0.8679, Test acc macro: 0.2051\n",
      "95\n",
      "Loss: 2.0594, Epoch: 095, Train acc micro: 0.8573, Test acc micro: 0.2362,Train acc macro: 0.8682, Test acc macro: 0.2292\n",
      "96\n",
      "Loss: 2.0620, Epoch: 096, Train acc micro: 0.8359, Test acc micro: 0.1960,Train acc macro: 0.8481, Test acc macro: 0.1953\n",
      "97\n",
      "Loss: 2.0590, Epoch: 097, Train acc micro: 0.8631, Test acc micro: 0.2362,Train acc macro: 0.8728, Test acc macro: 0.2294\n",
      "98\n",
      "Loss: 2.0545, Epoch: 098, Train acc micro: 0.8702, Test acc micro: 0.2010,Train acc macro: 0.8771, Test acc macro: 0.1980\n",
      "99\n",
      "Loss: 2.0581, Epoch: 099, Train acc micro: 0.8573, Test acc micro: 0.1910,Train acc macro: 0.8678, Test acc macro: 0.1878\n",
      "Loss: 2.0581, Epoch: 099, Train acc micro: 0.8573, Test acc micro: 0.1910,Train acc macro: 0.8678, Test acc macro: 0.1878\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = LINE\n",
    "loss_name = 'LINE'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "conv = 'GCN'\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "datasets_names=[(0.9, 0.5, 0.01, 2, 5)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.5, 0.1, 0.2, 4, 2)]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-14 15:49:10,700]\u001B[0m A new study created in memory with name: LaplacianEigenMaps loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:13,920]\u001B[0m Trial 0 finished with value: 0.19385240410878216 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007777127193822188, 'reg_lambda': 0.4, 'n_estimators': 5, 'max_depth': 1, 'lmbda': 0.9607922690701756}. Best is trial 0 with value: 0.19385240410878216.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:15,871]\u001B[0m Trial 1 finished with value: 0.2446456517625932 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00791783965440426, 'reg_lambda': 100, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.9980112113131758}. Best is trial 1 with value: 0.2446456517625932.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:17,949]\u001B[0m Trial 2 finished with value: 0.1779936685158942 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009702693430087696, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 5, 'lmbda': 0.49441619585951413}. Best is trial 1 with value: 0.2446456517625932.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:21,562]\u001B[0m Trial 3 finished with value: 0.2805804152183738 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00687837386642723, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.9911258720680396}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:24,005]\u001B[0m Trial 4 finished with value: 0.26284774803592925 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009435295873673524, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4927152319181284}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:28,253]\u001B[0m Trial 5 finished with value: 0.19820842172943404 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006863789332140283, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.1344552326951297}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:31,899]\u001B[0m Trial 6 finished with value: 0.2185055620820891 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009941949456671335, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.017897387437316947}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:33,598]\u001B[0m Trial 7 finished with value: 0.2262449789623539 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005263333076207144, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 1, 'lmbda': 0.9999140280401617}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:36,013]\u001B[0m Trial 8 finished with value: 0.1751686785189234 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008055555961430129, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.595356692513682}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:37,790]\u001B[0m Trial 9 finished with value: 0.18557012223330036 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006633560001682802, 'reg_lambda': 0.3, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.38295953969032437}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:41,854]\u001B[0m Trial 10 finished with value: 0.14058504843743466 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005059169943198749, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.7479184417993833}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:43,579]\u001B[0m Trial 11 finished with value: 0.16988843461725717 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008906733082634191, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.333687773919492}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:45,167]\u001B[0m Trial 12 finished with value: 0.25137390116883296 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0066245618111083595, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.7622797622653376}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:47,062]\u001B[0m Trial 13 finished with value: 0.23922233095641277 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008917522373611883, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.6908638121557091}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:49,538]\u001B[0m Trial 14 finished with value: 0.23381840691230202 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0058858134498885545, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.303580227256096}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:51,109]\u001B[0m Trial 15 finished with value: 0.16236500586133878 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008687300488926544, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.8388592653891933}. Best is trial 3 with value: 0.2805804152183738.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:49:59,072]\u001B[0m Trial 16 finished with value: 0.28846630556809155 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007065683424855691, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5040019594202033}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:03,171]\u001B[0m Trial 17 finished with value: 0.20353073945908493 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007126230966871992, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.6195232866958726}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:11,317]\u001B[0m Trial 18 finished with value: 0.19238234713514743 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00604478339353616, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.856528995284546}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:25,111]\u001B[0m Trial 19 finished with value: 0.22698197842757675 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007364621661788166, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.20744645005587486}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:30,447]\u001B[0m Trial 20 finished with value: 0.22247427985006538 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006158899925287486, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.4181448841397326}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:32,815]\u001B[0m Trial 21 finished with value: 0.2071552284071625 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008327396982164878, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5205912133843883}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:34,690]\u001B[0m Trial 22 finished with value: 0.21764977218743342 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009363514835840865, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5042445805418524}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:36,812]\u001B[0m Trial 23 finished with value: 0.19696961150872339 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007468211627436864, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.24707424988576243}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:44,799]\u001B[0m Trial 24 finished with value: 0.24700837647485108 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00708739963162578, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6075898146533104}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:46,446]\u001B[0m Trial 25 finished with value: 0.15695909900070248 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006365864538972662, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.8974736365165497}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:48,611]\u001B[0m Trial 26 finished with value: 0.18843923597268802 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005752974561779711, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.40937813695612546}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:55,649]\u001B[0m Trial 27 finished with value: 0.21021597157581043 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008396376507918904, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6799362343580592}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:50:58,434]\u001B[0m Trial 28 finished with value: 0.16127271588489137 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007557079137923634, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.060812128309042424}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:00,407]\u001B[0m Trial 29 finished with value: 0.17263313066210031 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007767437076300367, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.8981097094410564}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:05,708]\u001B[0m Trial 30 finished with value: 0.20572212193859496 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009261207513903458, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.561548205199716}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:07,521]\u001B[0m Trial 31 finished with value: 0.21618304678644054 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006650386104875722, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.7705005971467824}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:09,196]\u001B[0m Trial 32 finished with value: 0.10784727278570945 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0064928652134953494, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.7921909448574997}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:10,827]\u001B[0m Trial 33 finished with value: 0.15398332619154284 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006855734852340551, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.9250930658926871}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:12,421]\u001B[0m Trial 34 finished with value: 0.1778256160087917 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0070628382706819865, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.6869429904005002}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:14,046]\u001B[0m Trial 35 finished with value: 0.24175148074785072 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006286933933099793, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.48161658153648984}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:16,315]\u001B[0m Trial 36 finished with value: 0.11880693093523913 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005509340439326008, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.9484216021451288}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:17,854]\u001B[0m Trial 37 finished with value: 0.17879621136706686 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008030972352076195, 'reg_lambda': 0.4, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8201206002770355}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:19,799]\u001B[0m Trial 38 finished with value: 0.22517072810632702 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006742499557919336, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.4697861524223669}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:22,311]\u001B[0m Trial 39 finished with value: 0.23813852420378503 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009976352147243217, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.991947700107872}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:24,071]\u001B[0m Trial 40 finished with value: 0.20015144354802444 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007759407125114349, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.7283119291909033}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:31,979]\u001B[0m Trial 41 finished with value: 0.2376984522965651 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00720969261686818, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6200856298620573}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:39,910]\u001B[0m Trial 42 finished with value: 0.25883730799708643 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006982008582437113, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5656118955585033}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:48,032]\u001B[0m Trial 43 finished with value: 0.18125407983752348 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006927079972693779, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5546944508032855}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:55,944]\u001B[0m Trial 44 finished with value: 0.2275828794950316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0072635705053609384, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3741656092150534}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:51:57,872]\u001B[0m Trial 45 finished with value: 0.16654488304247853 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006508375853487475, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.44178330972125573}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:52:09,386]\u001B[0m Trial 46 finished with value: 0.2715853002281948 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006943784010039425, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5425641484469215}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:52:24,937]\u001B[0m Trial 47 finished with value: 0.20919447276210348 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007489507554284021, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.30668558669791024}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:52:36,266]\u001B[0m Trial 48 finished with value: 0.23246443039680587 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007641448311579176, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.553726591081636}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:52:48,304]\u001B[0m Trial 49 finished with value: 0.18089950551744946 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006892926214581219, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.6608598916933136}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:03,300]\u001B[0m Trial 50 finished with value: 0.22939861316870186 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009653448604300174, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.35800341616945264}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:06,957]\u001B[0m Trial 51 finished with value: 0.19751685559989657 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00667804376953371, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.5306434315199778}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:09,049]\u001B[0m Trial 52 finished with value: 0.19542669559935685 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005924412801136661, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4411605040090087}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:18,563]\u001B[0m Trial 53 finished with value: 0.19631149924121552 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.0062286304751340005, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.6438453764260295}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:20,491]\u001B[0m Trial 54 finished with value: 0.19219020218386973 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007054450203941021, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7263727796052253}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:23,610]\u001B[0m Trial 55 finished with value: 0.2104735961797597 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007334888393286736, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.575028987228876}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:27,671]\u001B[0m Trial 56 finished with value: 0.20874497804072908 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006422994325354071, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.5042465419518597}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:29,778]\u001B[0m Trial 57 finished with value: 0.23028586438934956 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007002755950541603, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8666576111637703}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:31,580]\u001B[0m Trial 58 finished with value: 0.19016824492770198 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006743087294803864, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.5988878038761407}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:38,455]\u001B[0m Trial 59 finished with value: 0.17705094574748534 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008222879583667362, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4465695235397593}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:40,427]\u001B[0m Trial 60 finished with value: 0.18242713892661133 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007879319617320267, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.23624570821937813}. Best is trial 16 with value: 0.28846630556809155.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:48,290]\u001B[0m Trial 61 finished with value: 0.2942181376141767 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007111449289634101, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6120332677317729}. Best is trial 61 with value: 0.2942181376141767.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:53:56,248]\u001B[0m Trial 62 finished with value: 0.30457963339693 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0073381724502590215, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5312917267762531}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:04,180]\u001B[0m Trial 63 finished with value: 0.17186845139208207 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007336559687377798, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5160762862615443}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:12,045]\u001B[0m Trial 64 finished with value: 0.24266468739318847 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007658217385927839, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4746976970997842}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:19,952]\u001B[0m Trial 65 finished with value: 0.27270463713948356 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007155265328211273, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6333314950876286}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:28,006]\u001B[0m Trial 66 finished with value: 0.23428940438946885 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0072035609219807135, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.41847572071240047}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:36,097]\u001B[0m Trial 67 finished with value: 0.1941493276801192 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00750631037987185, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6373143030145556}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:44,009]\u001B[0m Trial 68 finished with value: 0.23952333617296787 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006832970499377449, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.7083666487737448}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:51,850]\u001B[0m Trial 69 finished with value: 0.185200674559866 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007410947452085852, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.12930857694162745}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:54:59,940]\u001B[0m Trial 70 finished with value: 0.23605205816234567 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008776532692724943, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5920628291836426}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:07,813]\u001B[0m Trial 71 finished with value: 0.20474349250898252 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007128543569018368, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5425378074513453}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:15,659]\u001B[0m Trial 72 finished with value: 0.23849932021830594 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006971491343335239, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.584645028232387}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:23,505]\u001B[0m Trial 73 finished with value: 0.2972817687377347 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0065371419299406945, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.49587619428716356}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:31,302]\u001B[0m Trial 74 finished with value: 0.23409439886322556 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006584102783377005, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.39887354686936866}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:36,417]\u001B[0m Trial 75 finished with value: 0.25427725090468256 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006358404730008773, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.48669800702536303}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:44,994]\u001B[0m Trial 76 finished with value: 0.24252370258955375 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006783673923034701, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.5281629531469652}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:52,929]\u001B[0m Trial 77 finished with value: 0.1926533491420586 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007160937230690603, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6212145324841184}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:54,479]\u001B[0m Trial 78 finished with value: 0.28780821811150176 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006085692936652904, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.3470770400668748}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:56,073]\u001B[0m Trial 79 finished with value: 0.1979254641202219 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006090716311380752, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.30599572902452654}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:57,652]\u001B[0m Trial 80 finished with value: 0.2260926590189998 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005654970471534547, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.27950166373411567}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:55:59,329]\u001B[0m Trial 81 finished with value: 0.15764807315841836 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0065108570748815195, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4601973577304526}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:00,955]\u001B[0m Trial 82 finished with value: 0.23996880086774497 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006629830326989913, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.18093090284720054}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:09,028]\u001B[0m Trial 83 finished with value: 0.19100719503815516 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0052093323497618155, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3632894684816741}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:10,538]\u001B[0m Trial 84 finished with value: 0.18012408135694868 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0059850231256959345, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 1, 'lmbda': 0.48967073999550514}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:21,677]\u001B[0m Trial 85 finished with value: 0.23340871798120486 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006174030451043475, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.3320554384140237}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:23,869]\u001B[0m Trial 86 finished with value: 0.22862722863794022 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009146845400747502, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.6652832047793649}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:31,751]\u001B[0m Trial 87 finished with value: 0.2010156898779767 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007594084940898562, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.426151508378815}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:36,718]\u001B[0m Trial 88 finished with value: 0.23929687915714798 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00973600049427056, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5301085576075953}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:42,159]\u001B[0m Trial 89 finished with value: 0.23488188935531046 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0072379854558332945, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.5752825560926336}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:44,675]\u001B[0m Trial 90 finished with value: 0.14928488487182565 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006874681324691223, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.5007391828127727}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:56:52,634]\u001B[0m Trial 91 finished with value: 0.25621642239653303 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006984950042363431, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5480091046973777}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:00,586]\u001B[0m Trial 92 finished with value: 0.24925878862918968 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007339907824266733, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5726488602179158}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:08,738]\u001B[0m Trial 93 finished with value: 0.24298944598032307 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005771625729316507, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6398524364920061}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:16,696]\u001B[0m Trial 94 finished with value: 0.25954888050326747 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007067847178553905, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6162427276269911}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:20,690]\u001B[0m Trial 95 finished with value: 0.21070925098476895 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006318556011549747, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.46427842991603585}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:28,944]\u001B[0m Trial 96 finished with value: 0.20734487697216897 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007426607978148787, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.39347168271876376}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:31,039]\u001B[0m Trial 97 finished with value: 0.25584919367067505 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.006723457396460408, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7920459724983289}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:33,131]\u001B[0m Trial 98 finished with value: 0.21330974623635715 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007132702629003241, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5109621233528522}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:36,230]\u001B[0m Trial 99 finished with value: 0.2232094183664819 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007278564917952358, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.6070440965061441}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:43,536]\u001B[0m Trial 100 finished with value: 0.21712448870747691 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007833479574418855, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6646726515548358}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:51,512]\u001B[0m Trial 101 finished with value: 0.2961836089029543 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007001627219741782, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5612593769393494}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:57:59,605]\u001B[0m Trial 102 finished with value: 0.20057952005607654 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007090177651807159, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6237319142879707}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:07,531]\u001B[0m Trial 103 finished with value: 0.24011502605497712 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00680776916217348, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.537638945125469}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:15,722]\u001B[0m Trial 104 finished with value: 0.23901882796770893 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006550692822528476, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6982490873437563}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:17,436]\u001B[0m Trial 105 finished with value: 0.1953049026712412 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006910759322798323, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.03918182542434134}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:32,418]\u001B[0m Trial 106 finished with value: 0.25089042806512823 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007059071628120641, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.596336389073971}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:40,296]\u001B[0m Trial 107 finished with value: 0.2356321826342017 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006710181135185617, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5566640128610639}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:47,317]\u001B[0m Trial 108 finished with value: 0.2292532687715207 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008511104358160876, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.43234695955856417}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:49,602]\u001B[0m Trial 109 finished with value: 0.2812138053814263 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0064204926484083165, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.45817081186086805}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:51,815]\u001B[0m Trial 110 finished with value: 0.17004711432486772 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00802307269842965, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.456306336383237}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:54,008]\u001B[0m Trial 111 finished with value: 0.2017299911397034 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006270284506111885, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.48557227806981995}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:56,267]\u001B[0m Trial 112 finished with value: 0.2228953420397635 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00649000963938855, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5192395151247577}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:58:58,453]\u001B[0m Trial 113 finished with value: 0.22864908709524087 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006917507128454384, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5562163711352837}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:00,652]\u001B[0m Trial 114 finished with value: 0.20907669090796818 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0070024772492788675, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.33848347514209887}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:03,431]\u001B[0m Trial 115 finished with value: 0.20356331776931263 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0064532970935229465, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.5029620165622303}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:05,234]\u001B[0m Trial 116 finished with value: 0.18527211764255724 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0076775721434211, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 5, 'lmbda': 0.9569134158876191}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:12,137]\u001B[0m Trial 117 finished with value: 0.2099104511799427 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006640290000143372, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.7513234155965476}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:27,505]\u001B[0m Trial 118 finished with value: 0.22956995757199328 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007197022879758855, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5841473758779234}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:29,816]\u001B[0m Trial 119 finished with value: 0.23744793945708745 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006124644714761702, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.40403564681675913}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:36,953]\u001B[0m Trial 120 finished with value: 0.2607573948094328 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007389687479822086, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.27883810776219736}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:44,214]\u001B[0m Trial 121 finished with value: 0.22998076885143978 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007495717450857079, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2584047720695264}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:51,447]\u001B[0m Trial 122 finished with value: 0.19299562644774362 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00728286252542975, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3420286299705367}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 15:59:58,636]\u001B[0m Trial 123 finished with value: 0.18322593804458542 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007385474651830139, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.21920325934564838}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:05,948]\u001B[0m Trial 124 finished with value: 0.2387367340717138 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006793594027100019, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.27160615180793984}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:13,133]\u001B[0m Trial 125 finished with value: 0.19326689409232084 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007111915791378281, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.29301845581103514}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:21,406]\u001B[0m Trial 126 finished with value: 0.23653833366095545 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006405221686460371, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4745093551655414}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:22,810]\u001B[0m Trial 127 finished with value: 0.22957533878285055 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007215552066195694, 'reg_lambda': 10, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5303244399359743}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:26,869]\u001B[0m Trial 128 finished with value: 0.18320545871281002 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0068651829210132735, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.17388720791401568}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:30,121]\u001B[0m Trial 129 finished with value: 0.22133836028669715 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007562056576128825, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9041622290731003}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:33,212]\u001B[0m Trial 130 finished with value: 0.2321297736384427 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00660534921974906, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.6136148364039316}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:41,484]\u001B[0m Trial 131 finished with value: 0.25104680007794145 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007046320345618834, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5665231364010694}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:49,463]\u001B[0m Trial 132 finished with value: 0.2711663582346715 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006952508951925275, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6525939167538038}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:00:57,375]\u001B[0m Trial 133 finished with value: 0.20539448359993662 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006988636031079386, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6245810007015458}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:05,522]\u001B[0m Trial 134 finished with value: 0.2422043949015959 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007414123318180046, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6497850618256494}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:13,545]\u001B[0m Trial 135 finished with value: 0.22720149015616833 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007273923564910221, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5955345878649633}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:20,577]\u001B[0m Trial 136 finished with value: 0.19640532796775811 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007133005280565136, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6699748381071777}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:25,422]\u001B[0m Trial 137 finished with value: 0.10915218832556547 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006777620264569721, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5112954184022439}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:33,402]\u001B[0m Trial 138 finished with value: 0.22211685386549462 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005862601925276864, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.71823015427893}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:35,384]\u001B[0m Trial 139 finished with value: 0.2082208621085516 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006960068867204242, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.685894292092511}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:37,148]\u001B[0m Trial 140 finished with value: 0.1750340842148484 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006039001227020573, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 5, 'lmbda': 0.9885083378899895}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:45,141]\u001B[0m Trial 141 finished with value: 0.21178420616183857 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0068764923329865365, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5504470807048855}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:01:53,085]\u001B[0m Trial 142 finished with value: 0.20537239237266575 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007183466024415319, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4917794663505242}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:01,080]\u001B[0m Trial 143 finished with value: 0.16513794703662688 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007056798130566994, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5802011456059555}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:09,245]\u001B[0m Trial 144 finished with value: 0.20556715331922024 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007330972769262732, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6359548929162633}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:16,795]\u001B[0m Trial 145 finished with value: 0.20472684124176505 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.0069716652046775025, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5359039745319055}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:20,449]\u001B[0m Trial 146 finished with value: 0.1899494882351834 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00671087150246433, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.8487369622629499}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:28,738]\u001B[0m Trial 147 finished with value: 0.21922963395401018 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006844924386160902, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.44609186809992646}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:31,841]\u001B[0m Trial 148 finished with value: 0.18704925162161978 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007183059416156903, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.6012650702300628}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:39,871]\u001B[0m Trial 149 finished with value: 0.21321112674051818 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00748217977991293, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5656212613212238}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:47,952]\u001B[0m Trial 150 finished with value: 0.268242550980061 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007062252880796368, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5176511344182121}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:02:55,837]\u001B[0m Trial 151 finished with value: 0.21914521707443915 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00706161246428139, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5178799964217294}. Best is trial 62 with value: 0.30457963339693.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:03,934]\u001B[0m Trial 152 finished with value: 0.32132833314563125 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0069260696184162435, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4736353837825161}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:11,978]\u001B[0m Trial 153 finished with value: 0.2493118661802608 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007285611005655029, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.47103425779582075}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:20,016]\u001B[0m Trial 154 finished with value: 0.1979596572600503 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006892300553419405, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3795403277725}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:27,987]\u001B[0m Trial 155 finished with value: 0.18942000218577948 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006638818936893932, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.456705661557257}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:36,026]\u001B[0m Trial 156 finished with value: 0.24817577685224684 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009457195375986785, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.48837331887711555}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:37,905]\u001B[0m Trial 157 finished with value: 0.229148297863166 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006763658351920903, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5360330038473798}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:41,182]\u001B[0m Trial 158 finished with value: 0.12074151066097447 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007127505113283978, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.4292144396028301}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:42,939]\u001B[0m Trial 159 finished with value: 0.20023224794403674 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006193940277934095, 'reg_lambda': 20, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.503902953626436}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:46,966]\u001B[0m Trial 160 finished with value: 0.16299766321453663 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006941670503546235, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4109172441808615}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:03:55,247]\u001B[0m Trial 161 finished with value: 0.22932796556345605 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005557734668322651, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5525459630966506}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:03,204]\u001B[0m Trial 162 finished with value: 0.23144441344849204 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007028883486766016, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5799226090058155}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:11,144]\u001B[0m Trial 163 finished with value: 0.2385829950002404 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007242159859804504, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5233847772778435}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:19,025]\u001B[0m Trial 164 finished with value: 0.23853311114556391 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007344556912981341, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.10391994016347633}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:26,987]\u001B[0m Trial 165 finished with value: 0.180687350698284 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00654697165891534, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4753173732520608}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:29,132]\u001B[0m Trial 166 finished with value: 0.18024237850897007 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007098908755597189, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.6111310640014893}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:39,708]\u001B[0m Trial 167 finished with value: 0.27025587073507257 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008965612982217073, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5472967890705345}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:50,701]\u001B[0m Trial 168 finished with value: 0.23734779662702488 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009822817765261373, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.4989227004887145}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:04:56,250]\u001B[0m Trial 169 finished with value: 0.21641807135541016 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009477182869635687, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.8146329206919628}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:06,536]\u001B[0m Trial 170 finished with value: 0.26143541229347833 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009087583477451486, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5454275639006643}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:16,362]\u001B[0m Trial 171 finished with value: 0.15863004779515155 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009399822431767166, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5362211318075997}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:26,981]\u001B[0m Trial 172 finished with value: 0.16133032116583826 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009124462710486435, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5140574642553264}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:36,524]\u001B[0m Trial 173 finished with value: 0.17988823266746704 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009057751189283227, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.547057527520376}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:46,456]\u001B[0m Trial 174 finished with value: 0.19447004069349838 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009595127644940709, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5674556032901169}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:50,499]\u001B[0m Trial 175 finished with value: 0.125971633549051 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.008808194225036049, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.45675484458158877}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:52,222]\u001B[0m Trial 176 finished with value: 0.17300996840481095 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00895845625742645, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.6463292502948478}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:05:54,557]\u001B[0m Trial 177 finished with value: 0.16229745171474377 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006812265280946385, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.5919748150881712}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:05,776]\u001B[0m Trial 178 finished with value: 0.18290287768749264 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008693252028066614, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.4836224649217328}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:12,908]\u001B[0m Trial 179 finished with value: 0.2887247283239203 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009322998283164389, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.23424481971043243}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:16,954]\u001B[0m Trial 180 finished with value: 0.2372616006914735 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009336002861062644, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.16473319520405588}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:24,433]\u001B[0m Trial 181 finished with value: 0.3106718565590439 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009289628225394664, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3227800149313848}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:31,697]\u001B[0m Trial 182 finished with value: 0.22726566516350571 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009571530846051897, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.22371152126693594}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:38,958]\u001B[0m Trial 183 finished with value: 0.21881733043363338 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009208274286223167, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.32229881139726324}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:46,311]\u001B[0m Trial 184 finished with value: 0.21783571467826943 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009368026424734546, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.24379562408094313}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:06:53,613]\u001B[0m Trial 185 finished with value: 0.2137230969915647 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009079093780067523, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3053420542118088}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:01,025]\u001B[0m Trial 186 finished with value: 0.2297862254394493 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00891202882911079, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.28306588421709544}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:03,592]\u001B[0m Trial 187 finished with value: 0.24207088288244996 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009249145829310912, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.3602754800716365}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:11,019]\u001B[0m Trial 188 finished with value: 0.2631093317060205 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009304035433492664, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.31989244656236493}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:18,416]\u001B[0m Trial 189 finished with value: 0.24598397806231861 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009491838021396382, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.19327336520994437}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:25,773]\u001B[0m Trial 190 finished with value: 0.2424148284437109 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009319146417204485, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3162340879656376}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:33,030]\u001B[0m Trial 191 finished with value: 0.16971710391393077 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009197539059710602, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2639038914198726}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:40,292]\u001B[0m Trial 192 finished with value: 0.18167345302025376 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009243428267831187, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.34997531352040007}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:47,489]\u001B[0m Trial 193 finished with value: 0.21029123176976317 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009066550480065874, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.28284687619968935}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:07:54,798]\u001B[0m Trial 194 finished with value: 0.21048859569204378 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009548683141082433, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.25053425913885813}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:02,132]\u001B[0m Trial 195 finished with value: 0.2174947285118558 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009326655599935129, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2953324821160642}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:03,675]\u001B[0m Trial 196 finished with value: 0.19951632335481767 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006928147237762853, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5208756248134311}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:05,431]\u001B[0m Trial 197 finished with value: 0.20088775842345927 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009766061560494905, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.33522211205324054}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:13,514]\u001B[0m Trial 198 finished with value: 0.24642644760983134 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0072133167347935056, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5044782444129771}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:20,375]\u001B[0m Trial 199 finished with value: 0.2838480173784854 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009415728399007776, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3797929081575666}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:24,409]\u001B[0m Trial 200 finished with value: 0.20400163398038426 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009644391147660093, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4225134994918224}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:31,363]\u001B[0m Trial 201 finished with value: 0.2344377483569463 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009346967472203729, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3722492518950694}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:38,239]\u001B[0m Trial 202 finished with value: 0.25582235596367664 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009143707788703489, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3172296947240144}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:08:53,278]\u001B[0m Trial 203 finished with value: 0.2181169689876925 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008976729922987953, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5468465379675489}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:00,263]\u001B[0m Trial 204 finished with value: 0.23217205417679984 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009466045734232072, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3495091439832531}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:08,328]\u001B[0m Trial 205 finished with value: 0.2800505004963977 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009423151713197794, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3866476993815751}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:16,246]\u001B[0m Trial 206 finished with value: 0.19066303815691288 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009410564569479914, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.39491579955289735}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:23,136]\u001B[0m Trial 207 finished with value: 0.22449604286844246 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00927730637580344, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.37648600584661135}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:25,345]\u001B[0m Trial 208 finished with value: 0.17991136887685075 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009448491819520689, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4350381789003055}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:33,360]\u001B[0m Trial 209 finished with value: 0.2296841725038339 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009268166621450618, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3990694254064737}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:41,449]\u001B[0m Trial 210 finished with value: 0.13748159314980493 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009652622006754121, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4864031666096068}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:09:50,985]\u001B[0m Trial 211 finished with value: 0.18830942504410011 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006339568400459673, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3313884681463197}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:01,236]\u001B[0m Trial 212 finished with value: 0.2967998237591055 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007023419098092594, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5198388773738987}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:13,228]\u001B[0m Trial 213 finished with value: 0.20474506952382024 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0069437451812942586, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5232981177649768}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:21,250]\u001B[0m Trial 214 finished with value: 0.16992597576608065 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007037390290023229, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5044219208552148}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:35,113]\u001B[0m Trial 215 finished with value: 0.1761122431332149 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00711927731266668, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.46805021941150804}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:43,188]\u001B[0m Trial 216 finished with value: 0.22971802041076544 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006993097057502708, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5316716692469388}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:48,588]\u001B[0m Trial 217 finished with value: 0.27896666635270967 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0068473650073149804, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.5647959068249493}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:50,320]\u001B[0m Trial 218 finished with value: 0.1853642273717611 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006818375284721002, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 5, 'lmbda': 0.5728243165168888}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:55,801]\u001B[0m Trial 219 finished with value: 0.19715902662358376 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00689238582741876, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.4524965183117272}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:10:57,981]\u001B[0m Trial 220 finished with value: 0.14237244881983896 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009878163881258853, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.554731257202096}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:03,495]\u001B[0m Trial 221 finished with value: 0.22181744930227537 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00673571020506375, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.534069648475526}. Best is trial 152 with value: 0.32132833314563125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:18,059]\u001B[0m Trial 222 finished with value: 0.3320459730405158 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007140406035270896, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.49178855152223716}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:23,432]\u001B[0m Trial 223 finished with value: 0.1456708489025729 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007164968075886492, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.4964219804696801}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:31,685]\u001B[0m Trial 224 finished with value: 0.19882813517584827 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007015754631562095, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4711257276312261}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:39,716]\u001B[0m Trial 225 finished with value: 0.12398985784524817 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007107587852424125, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5140911687730042}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:47,638]\u001B[0m Trial 226 finished with value: 0.18428222372892877 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006827357233735656, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8808126423295235}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:51,643]\u001B[0m Trial 227 finished with value: 0.17931055562061826 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006974443575060599, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.49166753937589885}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:11:59,979]\u001B[0m Trial 228 finished with value: 0.24525504752578856 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009531330419571138, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9317941491238588}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:12:15,234]\u001B[0m Trial 229 finished with value: 0.17947011954507583 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007268609449504168, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.36525000104723165}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:12:17,425]\u001B[0m Trial 230 finished with value: 0.21256497703965593 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007067724275731107, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.568735537296839}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:12:27,401]\u001B[0m Trial 231 finished with value: 0.16345722290025522 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009390153520280822, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5475139159313612}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:12:38,516]\u001B[0m Trial 232 finished with value: 0.26988503727189567 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006655897692426427, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5204831431518708}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:12:53,448]\u001B[0m Trial 233 finished with value: 0.16468804570937065 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006688599805720733, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5118896253516869}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:13:08,201]\u001B[0m Trial 234 finished with value: 0.25870412700614304 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00672139773646932, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.48475530390899746}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:13:19,245]\u001B[0m Trial 235 finished with value: 0.2367882928855289 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00646155769046718, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5157410466777559}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:13:27,430]\u001B[0m Trial 236 finished with value: 0.23515085533523003 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006913785736767727, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.44172440882753505}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:13:35,417]\u001B[0m Trial 237 finished with value: 0.2045787100419997 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006651828777829784, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.537401935920481}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:13:50,337]\u001B[0m Trial 238 finished with value: 0.25247273844938334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006553609169173806, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.4713581540477844}. Best is trial 222 with value: 0.3320459730405158.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:13:57,294]\u001B[0m Trial 239 finished with value: 0.3740162595531689 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006826273402641834, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5869655506196354}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:04,427]\u001B[0m Trial 240 finished with value: 0.22817640673613676 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0068204390338923995, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.588276951955272}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:11,375]\u001B[0m Trial 241 finished with value: 0.19962217506039265 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006900954511800973, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6093737085598765}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:18,477]\u001B[0m Trial 242 finished with value: 0.22141478211870577 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007032710866103197, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.554980628841349}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:25,455]\u001B[0m Trial 243 finished with value: 0.19818504442931958 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007180225841259419, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6336966880554582}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:32,544]\u001B[0m Trial 244 finished with value: 0.23468454089558244 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006775136681059115, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5866394849305021}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:34,208]\u001B[0m Trial 245 finished with value: 0.12811826722443326 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006616746662237811, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 1, 'lmbda': 0.528009779373486}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:41,139]\u001B[0m Trial 246 finished with value: 0.21412117781265538 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006950561042730528, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3869146975768155}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:43,452]\u001B[0m Trial 247 finished with value: 0.3241730344864549 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008471178551182297, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5765016834524311}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:45,657]\u001B[0m Trial 248 finished with value: 0.2270683282662128 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008296078930045898, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.569858833990869}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:14:53,593]\u001B[0m Trial 249 finished with value: 0.20098000753379597 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007146783693579594, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5978045879555561}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:01,623]\u001B[0m Trial 250 finished with value: 0.24878796627006988 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00846966043066306, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5738057718308163}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:09,991]\u001B[0m Trial 251 finished with value: 0.21501960749904034 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00702122748550348, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.14751588761928103}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:13,972]\u001B[0m Trial 252 finished with value: 0.1369257965328868 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008612730411488443, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.6188846207298331}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:22,229]\u001B[0m Trial 253 finished with value: 0.24752192291540462 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006871766461789049, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.49811340486311195}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:27,631]\u001B[0m Trial 254 finished with value: 0.1689427698335767 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00671743891185895, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.34638099466734656}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:30,049]\u001B[0m Trial 255 finished with value: 0.21229515013120473 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006249443833541439, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5512589878921066}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:38,143]\u001B[0m Trial 256 finished with value: 0.16803992442452484 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0064271508305167886, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5619144505282019}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:46,003]\u001B[0m Trial 257 finished with value: 0.20015353583810788 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008140019684474286, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5995888613498809}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:15:59,708]\u001B[0m Trial 258 finished with value: 0.164362268618459 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005820418756000847, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5235895517022444}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:07,651]\u001B[0m Trial 259 finished with value: 0.15580772926688943 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00722814288582762, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5370084273258278}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:09,301]\u001B[0m Trial 260 finished with value: 0.17845385183229343 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006831339816754252, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.6517896936593639}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:17,208]\u001B[0m Trial 261 finished with value: 0.2569124573869028 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007084705957199051, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.415830165989713}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:19,213]\u001B[0m Trial 262 finished with value: 0.14826385373257278 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006947996676722239, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3224892235806638}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:34,432]\u001B[0m Trial 263 finished with value: 0.2430222809946221 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008830383647940306, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5045489845497064}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:42,430]\u001B[0m Trial 264 finished with value: 0.17712869493443906 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006582634253338031, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5868424908034708}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:47,726]\u001B[0m Trial 265 finished with value: 0.12467572563251124 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006013527926045417, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.3751080695186874}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:51,768]\u001B[0m Trial 266 finished with value: 0.19240875519347372 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009202011569060404, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.5642495551009064}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:16:59,123]\u001B[0m Trial 267 finished with value: 0.10315712259166568 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007311490978116908, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.48758566115776164}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:01,491]\u001B[0m Trial 268 finished with value: 0.16908470678960258 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007009671359137371, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5292823830866271}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:08,393]\u001B[0m Trial 269 finished with value: 0.17939373109260892 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007143129456110494, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6204392581706977}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:22,087]\u001B[0m Trial 270 finished with value: 0.23011798721783167 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006783244749400203, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.0831503767397625}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:30,000]\u001B[0m Trial 271 finished with value: 0.17902977094535225 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006887879558560419, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4638659292787141}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:37,194]\u001B[0m Trial 272 finished with value: 0.2426243886748288 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007076815302749612, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.7874728724385833}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:38,896]\u001B[0m Trial 273 finished with value: 0.2541227295040414 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009397756712634082, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.3480012110359123}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:41,811]\u001B[0m Trial 274 finished with value: 0.1331797360909803 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006962868593394476, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.546149345089051}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:46,727]\u001B[0m Trial 275 finished with value: 0.2690556733950752 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006669102580022929, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5062018344888174}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:49,701]\u001B[0m Trial 276 finished with value: 0.1986717076667132 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006692991433211791, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.5127263216741921}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:54,396]\u001B[0m Trial 277 finished with value: 0.1664670483774153 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00646669226418111, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.00236886944036091}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:17:59,124]\u001B[0m Trial 278 finished with value: 0.30392584744624923 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006590445727206426, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5102911672704414}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:03,803]\u001B[0m Trial 279 finished with value: 0.22545463752250325 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006624536017369968, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4782880622181566}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:06,511]\u001B[0m Trial 280 finished with value: 0.1645776988019999 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006523547225426541, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.4470046600499165}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:10,086]\u001B[0m Trial 281 finished with value: 0.18508187200658868 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006362151565679803, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.501383772658935}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:14,930]\u001B[0m Trial 282 finished with value: 0.17423161451582297 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006671727945325648, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9760641145180415}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:22,410]\u001B[0m Trial 283 finished with value: 0.258269126885674 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006538592649925209, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.524415723097551}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:26,547]\u001B[0m Trial 284 finished with value: 0.17399018089792273 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00677203262203646, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5738205296018385}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:31,354]\u001B[0m Trial 285 finished with value: 0.2313161533478659 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006820905113384604, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4827066461801246}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:36,020]\u001B[0m Trial 286 finished with value: 0.22544821581104138 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005664143386915221, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5555470211197662}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:40,781]\u001B[0m Trial 287 finished with value: 0.25333166712108784 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006595517972648721, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5406522130194451}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:43,181]\u001B[0m Trial 288 finished with value: 0.1577868463994667 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007410233961662588, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.506113815287509}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:47,884]\u001B[0m Trial 289 finished with value: 0.18087576615110346 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00669130016241416, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5827009726836365}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:49,445]\u001B[0m Trial 290 finished with value: 0.12850075866698685 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006880522846083635, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.45786249624271447}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:51,600]\u001B[0m Trial 291 finished with value: 0.2341481114398171 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007230555639949136, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.20923843474006104}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:18:58,613]\u001B[0m Trial 292 finished with value: 0.20125598357503396 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006428488168657648, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6736243618000441}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:13,023]\u001B[0m Trial 293 finished with value: 0.21979433847768795 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006125166599353262, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.4152200626777215}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:16,975]\u001B[0m Trial 294 finished with value: 0.23074388349248046 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006768077256680948, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.6002512785640761}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:25,128]\u001B[0m Trial 295 finished with value: 0.23863971505216927 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00794988613838877, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.494999709221077}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:30,066]\u001B[0m Trial 296 finished with value: 0.20615754267290923 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00953599155148368, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.6332908827741887}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:35,048]\u001B[0m Trial 297 finished with value: 0.21933222033945826 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006297044325392847, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5271257571519157}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:37,204]\u001B[0m Trial 298 finished with value: 0.2573730931758584 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006884545568215371, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5549172149537155}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:45,070]\u001B[0m Trial 299 finished with value: 0.18646207741064227 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006974098884985947, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4341597624256609}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:48,129]\u001B[0m Trial 300 finished with value: 0.23790009736913373 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007157573776404405, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.387476647309178}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:50,020]\u001B[0m Trial 301 finished with value: 0.1883224627211262 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00969947622537427, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.47341886812351636}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:19:58,024]\u001B[0m Trial 302 finished with value: 0.16667507764814038 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006633870221936515, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.7401432009479405}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:05,959]\u001B[0m Trial 303 finished with value: 0.27858362151245175 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0067567793579052906, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5168508092543401}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:12,891]\u001B[0m Trial 304 finished with value: 0.29600925312778215 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00503657349460403, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5377407391609677}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:20,880]\u001B[0m Trial 305 finished with value: 0.23605110689298034 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005015904670546131, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5781156121463128}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:28,879]\u001B[0m Trial 306 finished with value: 0.26824408142220985 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00775338503091869, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5424697996206567}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:35,838]\u001B[0m Trial 307 finished with value: 0.1496431878186425 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005362178744338869, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5616307246418858}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:43,998]\u001B[0m Trial 308 finished with value: 0.1550199866169709 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005458700907242983, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6137360095174251}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:20:52,037]\u001B[0m Trial 309 finished with value: 0.23201249292617873 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005126224728164655, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.534232061885259}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:00,006]\u001B[0m Trial 310 finished with value: 0.250090295680244 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0070417023537241415, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6032402755039113}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:01,939]\u001B[0m Trial 311 finished with value: 0.17737170873824004 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007316079353361194, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5651725619017127}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:09,993]\u001B[0m Trial 312 finished with value: 0.2732713909367347 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006903635520908443, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3665987360751376}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:17,921]\u001B[0m Trial 313 finished with value: 0.24167583082966157 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00528213903105864, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3657984552148972}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:25,901]\u001B[0m Trial 314 finished with value: 0.17132025524714506 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0069187797400910404, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3985496362754263}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:33,793]\u001B[0m Trial 315 finished with value: 0.2107906828240903 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00683390795593122, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.35952329796418314}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:41,699]\u001B[0m Trial 316 finished with value: 0.19445447936105517 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006972971710519773, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3446613830739626}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:49,654]\u001B[0m Trial 317 finished with value: 0.2879816938308896 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007193365715441653, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8365668630320864}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:51,811]\u001B[0m Trial 318 finished with value: 0.20116194367501206 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007463722569544283, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.38811160894375657}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:21:59,718]\u001B[0m Trial 319 finished with value: 0.13630221778695828 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007215199973914952, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8441329336857106}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:03,658]\u001B[0m Trial 320 finished with value: 0.18230499399583197 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007121063306950897, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.7627229707682306}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:05,460]\u001B[0m Trial 321 finished with value: 0.1680373904457671 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0073117260069293505, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.48913493797722163}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:10,839]\u001B[0m Trial 322 finished with value: 0.22150001065643243 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0075797985164310685, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.9082503065658614}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:19,004]\u001B[0m Trial 323 finished with value: 0.2208227636034918 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007148279069439072, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.30235145159223875}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:27,182]\u001B[0m Trial 324 finished with value: 0.2227531253955582 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007069377197544035, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8218385616626577}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:29,330]\u001B[0m Trial 325 finished with value: 0.23460314853950098 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00723017477612837, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4162091154531354}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:37,210]\u001B[0m Trial 326 finished with value: 0.21304229782458248 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0067777628602866844, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9552450955741094}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:45,281]\u001B[0m Trial 327 finished with value: 0.18241572083310978 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007382461223464413, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5162650892173957}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:22:52,432]\u001B[0m Trial 328 finished with value: 0.26211683970078853 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007045638112573108, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8814733388171676}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:00,458]\u001B[0m Trial 329 finished with value: 0.21792860206923811 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006876520514655702, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4892758601201174}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:08,295]\u001B[0m Trial 330 finished with value: 0.20778877672639415 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006953311722534744, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4573934118043908}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:10,537]\u001B[0m Trial 331 finished with value: 0.18007896802006493 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0071721416999118584, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.51210144862281}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:14,640]\u001B[0m Trial 332 finished with value: 0.19021288586638035 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0067631902416658675, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.7086916587953607}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:16,466]\u001B[0m Trial 333 finished with value: 0.21981882480696438 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007005652138235908, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.36841630264587505}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:21,812]\u001B[0m Trial 334 finished with value: 0.2132641162376046 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007254378418760762, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.23490537294634634}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:24,922]\u001B[0m Trial 335 finished with value: 0.1949821466648614 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00687417966498803, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.5384290866699811}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:33,374]\u001B[0m Trial 336 finished with value: 0.22538243360854535 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007101838120276991, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9170778472682048}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:41,281]\u001B[0m Trial 337 finished with value: 0.24092858207849724 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006827189871764985, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9356188497186313}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:43,422]\u001B[0m Trial 338 finished with value: 0.2169274156139451 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006982273145034105, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5783829034976068}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:51,141]\u001B[0m Trial 339 finished with value: 0.20612057269493816 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007368271531721658, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9877474063541405}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:23:59,167]\u001B[0m Trial 340 finished with value: 0.23951183582832286 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00646484048407185, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.43652101088177}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:07,160]\u001B[0m Trial 341 finished with value: 0.2800328063078918 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005887107836112097, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4621600429048527}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:15,070]\u001B[0m Trial 342 finished with value: 0.18732495400737245 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0057644445924689095, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4513078338767142}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:23,011]\u001B[0m Trial 343 finished with value: 0.17902686891281167 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005883357772770263, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.40531561279657347}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:31,006]\u001B[0m Trial 344 finished with value: 0.14938208031200909 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0059412741988230326, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4713075571754327}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:33,153]\u001B[0m Trial 345 finished with value: 0.1833994343047006 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0056595923083037234, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.47262952410071146}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:34,725]\u001B[0m Trial 346 finished with value: 0.15310981644226485 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006177542455040684, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.3314255837894049}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:42,652]\u001B[0m Trial 347 finished with value: 0.2807024233374676 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005403270499864315, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4281254709493253}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:50,688]\u001B[0m Trial 348 finished with value: 0.24669673828366626 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0054204596896354025, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.421752267854895}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:24:57,816]\u001B[0m Trial 349 finished with value: 0.2500889394138654 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006342432074345622, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4405947151860527}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:05,900]\u001B[0m Trial 350 finished with value: 0.19268411305097746 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005156033147552253, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.44165772758084404}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:13,838]\u001B[0m Trial 351 finished with value: 0.24909380991291522 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0053512681140576905, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.37993091268315027}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:17,829]\u001B[0m Trial 352 finished with value: 0.28768264968372503 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00604112466470471, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.40074897449638547}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:19,841]\u001B[0m Trial 353 finished with value: 0.2155442047737378 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006112742730693078, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.4102673380568497}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:23,848]\u001B[0m Trial 354 finished with value: 0.1458821757289159 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005980159374600646, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4602874041971873}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:28,206]\u001B[0m Trial 355 finished with value: 0.2652965639226475 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005229687072299758, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4266211992583471}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:32,659]\u001B[0m Trial 356 finished with value: 0.19184501439515764 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006230601465148246, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4015796117743038}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:36,617]\u001B[0m Trial 357 finished with value: 0.22203276948378067 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005521035849165673, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.47765369318083045}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:40,827]\u001B[0m Trial 358 finished with value: 0.30068891175506957 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005052771044687013, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4243500057246878}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:42,622]\u001B[0m Trial 359 finished with value: 0.19136734697387886 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005072295122085347, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.435234246488781}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:44,391]\u001B[0m Trial 360 finished with value: 0.1818912984297062 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005079930835671416, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.39279439817024875}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:48,406]\u001B[0m Trial 361 finished with value: 0.1972881771096615 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005175055148015151, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4148244495052508}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:52,864]\u001B[0m Trial 362 finished with value: 0.1716232660642066 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005011626942059001, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.44977478596916876}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:25:57,205]\u001B[0m Trial 363 finished with value: 0.2333810430330601 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005564825120132905, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4223933077289618}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:01,652]\u001B[0m Trial 364 finished with value: 0.21815465383863117 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005258718025997448, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.39776340331047877}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:05,850]\u001B[0m Trial 365 finished with value: 0.1983127977524748 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006096061519127178, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.384293023051066}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:08,039]\u001B[0m Trial 366 finished with value: 0.23049533448663165 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00602078969107352, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.4608168738118639}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:11,956]\u001B[0m Trial 367 finished with value: 0.2809681517876712 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005918770537567084, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.1947631794798813}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:16,369]\u001B[0m Trial 368 finished with value: 0.18638228067853652 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005835377570492415, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.15460673628327706}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:20,717]\u001B[0m Trial 369 finished with value: 0.2352587938495439 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005921760884738466, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.4299857659615206}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:24,927]\u001B[0m Trial 370 finished with value: 0.2290899507044874 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0056939680057442365, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.1742221800733298}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:29,060]\u001B[0m Trial 371 finished with value: 0.20662365383771822 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0058335716742216335, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.491538212700505}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:30,937]\u001B[0m Trial 372 finished with value: 0.21930751888296146 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006032913494695037, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.14243773145640162}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:34,881]\u001B[0m Trial 373 finished with value: 0.2138936612872631 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006201819259020501, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.2008825141481294}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:39,025]\u001B[0m Trial 374 finished with value: 0.1875480358048725 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005588895261838569, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.18678841437872423}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:40,786]\u001B[0m Trial 375 finished with value: 0.25012158091397013 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005112074927804569, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.22583579891965433}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:48,807]\u001B[0m Trial 376 finished with value: 0.19602384535841189 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005248690402722116, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.45966201334724277}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:26:56,784]\u001B[0m Trial 377 finished with value: 0.19168800394202726 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0057657543517898036, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2011890026990504}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:04,835]\u001B[0m Trial 378 finished with value: 0.18719884669703105 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005935037272324705, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.24887341331856574}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:11,917]\u001B[0m Trial 379 finished with value: 0.21995692342565593 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0099756615701461, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.12169661436544098}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:14,283]\u001B[0m Trial 380 finished with value: 0.31043434237464523 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009480201781596958, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8773837275513361}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:16,039]\u001B[0m Trial 381 finished with value: 0.22116411668189792 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009468469621367303, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.8135576185538314}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:18,222]\u001B[0m Trial 382 finished with value: 0.23856482748548016 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00959281696850047, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8662177069636409}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:20,389]\u001B[0m Trial 383 finished with value: 0.19525364411687368 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009386237119433148, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9784582877066309}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:22,623]\u001B[0m Trial 384 finished with value: 0.23735316584663224 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005002866117570533, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3768097517115059}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:24,505]\u001B[0m Trial 385 finished with value: 0.20852097130771552 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009407840953572347, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7968250929976707}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:26,931]\u001B[0m Trial 386 finished with value: 0.2217218046587388 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00925590126698443, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9358868767191353}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:28,685]\u001B[0m Trial 387 finished with value: 0.15442083535754933 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00956525744661686, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.9536796152625442}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:30,926]\u001B[0m Trial 388 finished with value: 0.20521157038014734 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005322794661132259, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.34693397437559254}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:32,466]\u001B[0m Trial 389 finished with value: 0.2996723386774355 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009322344025744103, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.40194075237883314}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:34,013]\u001B[0m Trial 390 finished with value: 0.24474092822300442 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009252525468173208, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4084638564084971}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:35,567]\u001B[0m Trial 391 finished with value: 0.22596082577294538 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006364791906681928, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4954348439156343}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:37,282]\u001B[0m Trial 392 finished with value: 0.287290665408765 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00541905142986065, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8727091559332582}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:38,836]\u001B[0m Trial 393 finished with value: 0.277916077494061 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009699968174550216, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8671021630444613}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:43,058]\u001B[0m Trial 394 finished with value: 0.20752155737590994 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005401394469476473, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.845485651918678}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:44,720]\u001B[0m Trial 395 finished with value: 0.2292763473602376 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005473661597412881, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4266335740080409}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:46,332]\u001B[0m Trial 396 finished with value: 0.2293661416718089 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009356450672257315, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.898028890086023}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:47,895]\u001B[0m Trial 397 finished with value: 0.21010860972797202 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009138179608593902, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8701963359336058}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:49,446]\u001B[0m Trial 398 finished with value: 0.2141233953127425 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005234746864788159, 'reg_lambda': 0.8, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8868560826231108}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:51,057]\u001B[0m Trial 399 finished with value: 0.2553481441947625 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006307983412401824, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8313959386363762}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:52,611]\u001B[0m Trial 400 finished with value: 0.21432731365251076 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00930135970684523, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5056072865784951}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:54,120]\u001B[0m Trial 401 finished with value: 0.12175191748701415 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007498156336688666, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 1, 'lmbda': 0.8582496341901897}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:55,683]\u001B[0m Trial 402 finished with value: 0.23892088430026215 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00837837952520089, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.9028018434789851}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:57,319]\u001B[0m Trial 403 finished with value: 0.18619054971211818 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005128511704632648, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8812382893549329}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:27:58,895]\u001B[0m Trial 404 finished with value: 0.19906580905087318 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005004517596288316, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4740806649977096}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:00,386]\u001B[0m Trial 405 finished with value: 0.1921315893788336 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008708675219766251, 'reg_lambda': 20, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.2629328083473935}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:01,943]\u001B[0m Trial 406 finished with value: 0.2489679694938428 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006124289289335048, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4150602880153272}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:06,011]\u001B[0m Trial 407 finished with value: 0.242898830469574 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009469864000969065, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.445490704177471}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:13,296]\u001B[0m Trial 408 finished with value: 0.24757614248604665 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005610935809622304, 'reg_lambda': 0.3, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4890659467032129}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:20,319]\u001B[0m Trial 409 finished with value: 0.24881456321663908 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005178683835469646, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.21797274846036976}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:22,138]\u001B[0m Trial 410 finished with value: 0.11278074682917255 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.0065000531696279285, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5249904421378374}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:30,231]\u001B[0m Trial 411 finished with value: 0.2195166627130423 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005504533482861778, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.35993493444478336}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:37,300]\u001B[0m Trial 412 finished with value: 0.2577851199260216 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005364153579571668, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3968532347366771}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:44,260]\u001B[0m Trial 413 finished with value: 0.19272371141059647 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009045682211007705, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.16570924746710997}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:28:52,278]\u001B[0m Trial 414 finished with value: 0.2843380588130584 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00916824254712883, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.444971071657417}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:00,211]\u001B[0m Trial 415 finished with value: 0.2643509210091491 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009219242861455274, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4793615801961563}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:05,008]\u001B[0m Trial 416 finished with value: 0.26038249377060846 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009154857769891089, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5056728440525764}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:12,789]\u001B[0m Trial 417 finished with value: 0.2512187909288614 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008176237652966063, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.540659302036551}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:14,298]\u001B[0m Trial 418 finished with value: 0.21925795481697202 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009325831376720424, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8554371047761937}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:22,410]\u001B[0m Trial 419 finished with value: 0.22763188137050006 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009418427675056403, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.46016717366141435}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:29,381]\u001B[0m Trial 420 finished with value: 0.23730513161370126 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009283953903759417, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4940950141312115}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:32,695]\u001B[0m Trial 421 finished with value: 0.24701514835427305 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009539861589518757, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.298708786442236}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:41,058]\u001B[0m Trial 422 finished with value: 0.2693383807321245 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0071604969987011415, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5165371789498923}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:48,984]\u001B[0m Trial 423 finished with value: 0.17935792820298302 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00983426596154072, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.44635663722117863}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:56,867]\u001B[0m Trial 424 finished with value: 0.24110363326313766 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008544792932023027, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5306054336070333}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:29:58,349]\u001B[0m Trial 425 finished with value: 0.14793124016680945 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009488370773572825, 'reg_lambda': 0.3, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.9176608618528843}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:06,372]\u001B[0m Trial 426 finished with value: 0.1974395042928919 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0073254174582402425, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5543222199902791}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:13,227]\u001B[0m Trial 427 finished with value: 0.22007826722512186 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009002865789852217, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3291495496950782}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:18,243]\u001B[0m Trial 428 finished with value: 0.22766507855574603 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007240422893231755, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3752293652994462}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:26,233]\u001B[0m Trial 429 finished with value: 0.23311256101599506 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009172356106052479, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.18173249183824755}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:34,341]\u001B[0m Trial 430 finished with value: 0.2565542275710689 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009625719289388435, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.04284470460157336}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:41,521]\u001B[0m Trial 431 finished with value: 0.17885099940363763 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00637013769179029, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.48272139304253414}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:43,201]\u001B[0m Trial 432 finished with value: 0.1898565265619192 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009331965871481518, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.4433985722287403}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:50,087]\u001B[0m Trial 433 finished with value: 0.21832972635407735 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0065633505756638715, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.892237902524656}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:30:58,243]\u001B[0m Trial 434 finished with value: 0.19207257460511476 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007048241894028719, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.41180065350328904}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:06,008]\u001B[0m Trial 435 finished with value: 0.27332565898466177 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006222817212462941, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5831172864310268}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:08,245]\u001B[0m Trial 436 finished with value: 0.24753880113845328 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00605000344249766, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5043465981602706}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:15,245]\u001B[0m Trial 437 finished with value: 0.1689708933239618 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0073971815339405455, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.47195349709242973}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:16,998]\u001B[0m Trial 438 finished with value: 0.2080310312460834 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009484880580706137, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.3517881417690767}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:24,959]\u001B[0m Trial 439 finished with value: 0.22651234110056684 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00711365821711282, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5477058741377441}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:29,049]\u001B[0m Trial 440 finished with value: 0.2168183959220638 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007269406060358658, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.38943203149944866}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:37,232]\u001B[0m Trial 441 finished with value: 0.19487561969876516 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009123334524636371, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.533098246542986}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:40,310]\u001B[0m Trial 442 finished with value: 0.13524273840246762 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009383458598036179, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.42601567271920837}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:42,749]\u001B[0m Trial 443 finished with value: 0.21716489154554566 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00719007916656265, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5015026403491649}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:50,783]\u001B[0m Trial 444 finished with value: 0.2724082520608622 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006424612310487413, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.47204816769030733}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:54,776]\u001B[0m Trial 445 finished with value: 0.23182989030583542 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008837767287471144, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.27839870478288553}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:31:56,400]\u001B[0m Trial 446 finished with value: 0.2408591142919086 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00923162975391221, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5640041911575021}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:04,309]\u001B[0m Trial 447 finished with value: 0.17033984952342873 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009581290242324925, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4492532776177593}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:11,570]\u001B[0m Trial 448 finished with value: 0.27286058824099063 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007067649591577547, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8394135955807602}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:19,690]\u001B[0m Trial 449 finished with value: 0.1762612453364006 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005070129548689351, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5228957760878225}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:21,939]\u001B[0m Trial 450 finished with value: 0.19871448333588043 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009286646386610725, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5901697372415431}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:26,014]\u001B[0m Trial 451 finished with value: 0.27796572347980125 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0076425605115336935, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.3685318966150383}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:27,841]\u001B[0m Trial 452 finished with value: 0.18493162796919133 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006281843288297687, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4058666154276386}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:34,970]\u001B[0m Trial 453 finished with value: 0.24270189487059016 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006540358162022686, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.12718364432345008}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:39,178]\u001B[0m Trial 454 finished with value: 0.2136027564572554 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005734288761444397, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.492994555343368}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:47,207]\u001B[0m Trial 455 finished with value: 0.19797554854522334 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.006106795474626334, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2084320246823227}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:55,275]\u001B[0m Trial 456 finished with value: 0.20175766561145803 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007161774072407572, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8753719388442727}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:32:57,440]\u001B[0m Trial 457 finished with value: 0.19366428067373995 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00941548789369593, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.31737268279050845}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:01,154]\u001B[0m Trial 458 finished with value: 0.2446432742831659 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007037470585194612, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.23839611779713415}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:09,335]\u001B[0m Trial 459 finished with value: 0.19961361947367023 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005982182253442818, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5149342892440371}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:10,797]\u001B[0m Trial 460 finished with value: 0.12337224366292765 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009501438443871586, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4367001276233519}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:18,683]\u001B[0m Trial 461 finished with value: 0.20452374848714397 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00806522939285381, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5487138828368864}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:26,657]\u001B[0m Trial 462 finished with value: 0.27575294293293456 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009743159222574004, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3957165903508069}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:34,611]\u001B[0m Trial 463 finished with value: 0.15653815579110397 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007290642991397615, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4599605471378937}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:36,233]\u001B[0m Trial 464 finished with value: 0.12350835600407307 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009188796004449223, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.5692626985469859}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:44,163]\u001B[0m Trial 465 finished with value: 0.25450123678869835 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005116562419642382, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4912889790559327}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:47,264]\u001B[0m Trial 466 finished with value: 0.23950829897948586 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007453906748767057, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.09884366228714794}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:49,014]\u001B[0m Trial 467 finished with value: 0.23137412478974595 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006499382896527609, 'reg_lambda': 0.8, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.6006771442679669}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:33:53,746]\u001B[0m Trial 468 finished with value: 0.2377373519644074 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006211105933604404, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5227672129942327}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:01,597]\u001B[0m Trial 469 finished with value: 0.18786358865914046 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0069694450665456886, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.7817279640587367}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:08,701]\u001B[0m Trial 470 finished with value: 0.18557798163874545 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007154916349896398, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4800897665333425}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:10,681]\u001B[0m Trial 471 finished with value: 0.21677686847303765 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0073330684224358605, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.43635192312450116}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:18,608]\u001B[0m Trial 472 finished with value: 0.2411032927347063 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005174752565505493, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3586273879045218}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:25,369]\u001B[0m Trial 473 finished with value: 0.2210568407799237 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005002062970077181, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5379667282805933}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:33,485]\u001B[0m Trial 474 finished with value: 0.23944294272833497 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006658985076652218, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.337249707182369}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:35,082]\u001B[0m Trial 475 finished with value: 0.17973338845978426 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008267742894039377, 'reg_lambda': 0.01, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.41558715231350496}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:42,504]\u001B[0m Trial 476 finished with value: 0.1952914954844057 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.009359298607272092, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3784197105330782}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:50,547]\u001B[0m Trial 477 finished with value: 0.12208801952954122 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007076467726812101, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5062507319596143}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:34:52,306]\u001B[0m Trial 478 finished with value: 0.17067147017173492 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00526180743899176, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.4606482735855374}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:00,411]\u001B[0m Trial 479 finished with value: 0.24103025622436783 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009081604188255007, 'reg_lambda': 20, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.6867869550226551}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:07,356]\u001B[0m Trial 480 finished with value: 0.23023179536049074 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006408274561670214, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.1885274266134996}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:11,750]\u001B[0m Trial 481 finished with value: 0.19908685318220715 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007199915025298092, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5569086833799171}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:13,634]\u001B[0m Trial 482 finished with value: 0.2235195464637704 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006979213686936937, 'reg_lambda': 0.3, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8525063523520513}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:28,704]\u001B[0m Trial 483 finished with value: 0.1936328032133988 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009629972328788, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.479461498904079}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:36,666]\u001B[0m Trial 484 finished with value: 0.2180592077091944 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00931198568111862, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8182676674172225}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:38,412]\u001B[0m Trial 485 finished with value: 0.20958255302948864 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008939048505271129, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.7231104210222702}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:46,650]\u001B[0m Trial 486 finished with value: 0.13990219004547189 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007556094782493154, 'reg_lambda': 100, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9028929786032628}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:53,518]\u001B[0m Trial 487 finished with value: 0.24554021410272012 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005818110636560277, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.5253384202030627}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:35:55,313]\u001B[0m Trial 488 finished with value: 0.19431620217213746 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007252974324801159, 'reg_lambda': 0.1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5829164755632983}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:03,274]\u001B[0m Trial 489 finished with value: 0.22975397186313795 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006009259873378869, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3913771372257417}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:06,396]\u001B[0m Trial 490 finished with value: 0.13453452292975218 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009465678886808682, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.4465387602617733}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:13,823]\u001B[0m Trial 491 finished with value: 0.16609254185039196 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006606972842076845, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4246845280805997}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:15,727]\u001B[0m Trial 492 finished with value: 0.20680223875426848 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007086128820833473, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.5402361124156116}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:23,652]\u001B[0m Trial 493 finished with value: 0.2031878630914901 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006275192384929501, 'reg_lambda': 1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4964523306849598}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:27,620]\u001B[0m Trial 494 finished with value: 0.2879994402617228 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0069348040122343855, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6153762660083906}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:31,802]\u001B[0m Trial 495 finished with value: 0.23558959822875222 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006836723329656112, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5781607289746266}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:33,301]\u001B[0m Trial 496 finished with value: 0.22197272518291394 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006941520721859998, 'reg_lambda': 10, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.6361705446903971}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:37,357]\u001B[0m Trial 497 finished with value: 0.2084276979270219 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006989365197091058, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6162145919952173}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:41,701]\u001B[0m Trial 498 finished with value: 0.25957765119756876 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0068074114446695895, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6136197795995348}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 16:36:45,882]\u001B[0m Trial 499 finished with value: 0.2553533708085021 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006756246893568134, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6595389029893962}. Best is trial 239 with value: 0.3740162595531689.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: GCN, mode: unsupervised, loss from LaplacianEigenMaps\n",
      "0\n",
      "Loss: 3889.2080, Epoch: 000, Train acc micro: 0.9986, Test acc micro: 0.2312,Train acc macro: 0.9986, Test acc macro: 0.2302\n",
      "1\n",
      "Loss: 2811.6147, Epoch: 001, Train acc micro: 0.8773, Test acc micro: 0.1960,Train acc macro: 0.8771, Test acc macro: 0.1963\n",
      "2\n",
      "Loss: 2084.5256, Epoch: 002, Train acc micro: 0.8017, Test acc micro: 0.2161,Train acc macro: 0.8017, Test acc macro: 0.2172\n",
      "3\n",
      "Loss: 1604.3389, Epoch: 003, Train acc micro: 1.0000, Test acc micro: 0.2312,Train acc macro: 1.0000, Test acc macro: 0.2312\n",
      "4\n",
      "Loss: 1291.1241, Epoch: 004, Train acc micro: 0.6705, Test acc micro: 0.2412,Train acc macro: 0.6709, Test acc macro: 0.2373\n",
      "5\n",
      "Loss: 1088.2509, Epoch: 005, Train acc micro: 0.9529, Test acc micro: 0.2010,Train acc macro: 0.9529, Test acc macro: 0.1970\n",
      "6\n",
      "Loss: 957.6191, Epoch: 006, Train acc micro: 0.9843, Test acc micro: 0.2663,Train acc macro: 0.9843, Test acc macro: 0.2611\n",
      "7\n",
      "Loss: 871.9427, Epoch: 007, Train acc micro: 0.7247, Test acc micro: 0.2261,Train acc macro: 0.7250, Test acc macro: 0.2241\n",
      "8\n",
      "Loss: 811.1633, Epoch: 008, Train acc micro: 0.9900, Test acc micro: 0.1960,Train acc macro: 0.9900, Test acc macro: 0.1933\n",
      "9\n",
      "Loss: 761.4093, Epoch: 009, Train acc micro: 0.9672, Test acc micro: 0.2513,Train acc macro: 0.9672, Test acc macro: 0.2469\n",
      "10\n",
      "Loss: 714.0010, Epoch: 010, Train acc micro: 0.9943, Test acc micro: 0.2312,Train acc macro: 0.9943, Test acc macro: 0.2308\n",
      "11\n",
      "Loss: 664.3995, Epoch: 011, Train acc micro: 0.9843, Test acc micro: 0.2714,Train acc macro: 0.9842, Test acc macro: 0.2599\n",
      "12\n",
      "Loss: 611.5184, Epoch: 012, Train acc micro: 0.8146, Test acc micro: 0.2312,Train acc macro: 0.8157, Test acc macro: 0.2332\n",
      "13\n",
      "Loss: 556.8792, Epoch: 013, Train acc micro: 0.9872, Test acc micro: 0.2764,Train acc macro: 0.9872, Test acc macro: 0.2744\n",
      "14\n",
      "Loss: 503.1259, Epoch: 014, Train acc micro: 0.9943, Test acc micro: 0.2060,Train acc macro: 0.9943, Test acc macro: 0.2047\n",
      "15\n",
      "Loss: 452.6048, Epoch: 015, Train acc micro: 0.5364, Test acc micro: 0.2211,Train acc macro: 0.5377, Test acc macro: 0.2175\n",
      "16\n",
      "Loss: 406.7098, Epoch: 016, Train acc micro: 0.8944, Test acc micro: 0.1910,Train acc macro: 0.8944, Test acc macro: 0.1895\n",
      "17\n",
      "Loss: 365.8908, Epoch: 017, Train acc micro: 0.5107, Test acc micro: 0.1608,Train acc macro: 0.5108, Test acc macro: 0.1545\n",
      "18\n",
      "Loss: 329.9494, Epoch: 018, Train acc micro: 0.9986, Test acc micro: 0.2060,Train acc macro: 0.9986, Test acc macro: 0.2076\n",
      "19\n",
      "Loss: 298.3552, Epoch: 019, Train acc micro: 0.5435, Test acc micro: 0.2261,Train acc macro: 0.5419, Test acc macro: 0.2147\n",
      "20\n",
      "Loss: 270.4590, Epoch: 020, Train acc micro: 0.9971, Test acc micro: 0.2814,Train acc macro: 0.9972, Test acc macro: 0.2789\n",
      "21\n",
      "Loss: 245.6030, Epoch: 021, Train acc micro: 0.9786, Test acc micro: 0.1809,Train acc macro: 0.9786, Test acc macro: 0.1783\n",
      "22\n",
      "Loss: 223.1764, Epoch: 022, Train acc micro: 0.8331, Test acc micro: 0.2010,Train acc macro: 0.8328, Test acc macro: 0.1984\n",
      "23\n",
      "Loss: 202.6644, Epoch: 023, Train acc micro: 0.9658, Test acc micro: 0.1960,Train acc macro: 0.9658, Test acc macro: 0.1956\n",
      "24\n",
      "Loss: 183.6856, Epoch: 024, Train acc micro: 0.8103, Test acc micro: 0.2060,Train acc macro: 0.8101, Test acc macro: 0.2065\n",
      "25\n",
      "Loss: 165.9746, Epoch: 025, Train acc micro: 0.9372, Test acc micro: 0.2261,Train acc macro: 0.9374, Test acc macro: 0.2240\n",
      "26\n",
      "Loss: 149.3318, Epoch: 026, Train acc micro: 0.4123, Test acc micro: 0.2111,Train acc macro: 0.4064, Test acc macro: 0.1912\n",
      "27\n",
      "Loss: 133.6118, Epoch: 027, Train acc micro: 0.4765, Test acc micro: 0.2211,Train acc macro: 0.4763, Test acc macro: 0.2115\n",
      "28\n",
      "Loss: 118.7638, Epoch: 028, Train acc micro: 0.9558, Test acc micro: 0.2111,Train acc macro: 0.9557, Test acc macro: 0.2120\n",
      "29\n",
      "Loss: 104.8657, Epoch: 029, Train acc micro: 0.6534, Test acc micro: 0.2211,Train acc macro: 0.6529, Test acc macro: 0.2186\n",
      "30\n",
      "Loss: 92.0939, Epoch: 030, Train acc micro: 0.7746, Test acc micro: 0.2261,Train acc macro: 0.7747, Test acc macro: 0.2234\n",
      "31\n",
      "Loss: 80.6299, Epoch: 031, Train acc micro: 0.7989, Test acc micro: 0.1960,Train acc macro: 0.7991, Test acc macro: 0.1982\n",
      "32\n",
      "Loss: 70.5388, Epoch: 032, Train acc micro: 0.6676, Test acc micro: 0.1960,Train acc macro: 0.6682, Test acc macro: 0.1872\n",
      "33\n",
      "Loss: 61.6862, Epoch: 033, Train acc micro: 0.7874, Test acc micro: 0.2111,Train acc macro: 0.7872, Test acc macro: 0.2028\n",
      "34\n",
      "Loss: 53.7420, Epoch: 034, Train acc micro: 0.4879, Test acc micro: 0.1960,Train acc macro: 0.4859, Test acc macro: 0.1813\n",
      "35\n",
      "Loss: 46.2788, Epoch: 035, Train acc micro: 0.8274, Test acc micro: 0.2161,Train acc macro: 0.8274, Test acc macro: 0.2140\n",
      "36\n",
      "Loss: 38.9247, Epoch: 036, Train acc micro: 0.9800, Test acc micro: 0.2362,Train acc macro: 0.9801, Test acc macro: 0.2350\n",
      "37\n",
      "Loss: 31.4897, Epoch: 037, Train acc micro: 0.9957, Test acc micro: 0.2211,Train acc macro: 0.9956, Test acc macro: 0.2171\n",
      "38\n",
      "Loss: 24.0003, Epoch: 038, Train acc micro: 0.7703, Test acc micro: 0.2060,Train acc macro: 0.7710, Test acc macro: 0.2047\n",
      "39\n",
      "Loss: 16.6317, Epoch: 039, Train acc micro: 0.6234, Test acc micro: 0.1709,Train acc macro: 0.6237, Test acc macro: 0.1688\n",
      "40\n",
      "Loss: 9.5938, Epoch: 040, Train acc micro: 1.0000, Test acc micro: 0.1809,Train acc macro: 1.0000, Test acc macro: 0.1792\n",
      "41\n",
      "Loss: 3.0336, Epoch: 041, Train acc micro: 0.8959, Test acc micro: 0.1759,Train acc macro: 0.8958, Test acc macro: 0.1767\n",
      "42\n",
      "Loss: -3.0116, Epoch: 042, Train acc micro: 0.8887, Test acc micro: 0.1960,Train acc macro: 0.8889, Test acc macro: 0.1942\n",
      "43\n",
      "Loss: -8.6047, Epoch: 043, Train acc micro: 0.5706, Test acc micro: 0.1960,Train acc macro: 0.5704, Test acc macro: 0.1916\n",
      "44\n",
      "Loss: -13.8603, Epoch: 044, Train acc micro: 0.9529, Test acc micro: 0.1759,Train acc macro: 0.9530, Test acc macro: 0.1731\n",
      "45\n",
      "Loss: -18.8895, Epoch: 045, Train acc micro: 0.9857, Test acc micro: 0.2261,Train acc macro: 0.9857, Test acc macro: 0.2185\n",
      "46\n",
      "Loss: -23.7623, Epoch: 046, Train acc micro: 0.8602, Test acc micro: 0.2211,Train acc macro: 0.8607, Test acc macro: 0.2175\n",
      "47\n",
      "Loss: -28.5049, Epoch: 047, Train acc micro: 0.9971, Test acc micro: 0.2010,Train acc macro: 0.9972, Test acc macro: 0.2022\n",
      "48\n",
      "Loss: -33.1218, Epoch: 048, Train acc micro: 0.9986, Test acc micro: 0.2513,Train acc macro: 0.9986, Test acc macro: 0.2491\n",
      "49\n",
      "Loss: -37.6197, Epoch: 049, Train acc micro: 1.0000, Test acc micro: 0.2663,Train acc macro: 1.0000, Test acc macro: 0.2658\n",
      "50\n",
      "Loss: -42.0155, Epoch: 050, Train acc micro: 0.3666, Test acc micro: 0.2362,Train acc macro: 0.3477, Test acc macro: 0.2073\n",
      "51\n",
      "Loss: -46.3253, Epoch: 051, Train acc micro: 0.9515, Test acc micro: 0.2261,Train acc macro: 0.9512, Test acc macro: 0.2267\n",
      "52\n",
      "Loss: -50.5547, Epoch: 052, Train acc micro: 0.3780, Test acc micro: 0.2261,Train acc macro: 0.3726, Test acc macro: 0.2186\n",
      "53\n",
      "Loss: -54.6996, Epoch: 053, Train acc micro: 0.3752, Test acc micro: 0.1960,Train acc macro: 0.3697, Test acc macro: 0.1863\n",
      "54\n",
      "Loss: -58.7579, Epoch: 054, Train acc micro: 0.9558, Test acc micro: 0.2261,Train acc macro: 0.9557, Test acc macro: 0.2268\n",
      "55\n",
      "Loss: -62.7376, Epoch: 055, Train acc micro: 0.8944, Test acc micro: 0.2211,Train acc macro: 0.8943, Test acc macro: 0.2183\n",
      "56\n",
      "Loss: -66.6533, Epoch: 056, Train acc micro: 0.7561, Test acc micro: 0.1859,Train acc macro: 0.7567, Test acc macro: 0.1876\n",
      "57\n",
      "Loss: -70.5174, Epoch: 057, Train acc micro: 0.3466, Test acc micro: 0.2111,Train acc macro: 0.3328, Test acc macro: 0.1840\n",
      "58\n",
      "Loss: -74.3376, Epoch: 058, Train acc micro: 0.9772, Test acc micro: 0.1960,Train acc macro: 0.9772, Test acc macro: 0.1978\n",
      "59\n",
      "Loss: -78.1210, Epoch: 059, Train acc micro: 0.5150, Test acc micro: 0.1809,Train acc macro: 0.5159, Test acc macro: 0.1827\n",
      "60\n",
      "Loss: -81.8783, Epoch: 060, Train acc micro: 0.3723, Test acc micro: 0.2412,Train acc macro: 0.3668, Test acc macro: 0.2326\n",
      "61\n",
      "Loss: -85.6226, Epoch: 061, Train acc micro: 0.7047, Test acc micro: 0.1859,Train acc macro: 0.7049, Test acc macro: 0.1861\n",
      "62\n",
      "Loss: -89.3633, Epoch: 062, Train acc micro: 0.9829, Test acc micro: 0.2513,Train acc macro: 0.9829, Test acc macro: 0.2511\n",
      "63\n",
      "Loss: -93.1050, Epoch: 063, Train acc micro: 0.3595, Test acc micro: 0.2211,Train acc macro: 0.3526, Test acc macro: 0.1951\n",
      "64\n",
      "Loss: -96.8521, Epoch: 064, Train acc micro: 0.8117, Test acc micro: 0.1508,Train acc macro: 0.8108, Test acc macro: 0.1507\n",
      "65\n",
      "Loss: -100.6140, Epoch: 065, Train acc micro: 0.9900, Test acc micro: 0.2111,Train acc macro: 0.9900, Test acc macro: 0.2093\n",
      "66\n",
      "Loss: -104.4028, Epoch: 066, Train acc micro: 0.5278, Test acc micro: 0.1658,Train acc macro: 0.5281, Test acc macro: 0.1657\n",
      "67\n",
      "Loss: -108.2266, Epoch: 067, Train acc micro: 0.8573, Test acc micro: 0.2261,Train acc macro: 0.8572, Test acc macro: 0.2214\n",
      "68\n",
      "Loss: -112.0837, Epoch: 068, Train acc micro: 0.7846, Test acc micro: 0.2513,Train acc macro: 0.7854, Test acc macro: 0.2470\n",
      "69\n",
      "Loss: -115.9671, Epoch: 069, Train acc micro: 0.9672, Test acc micro: 0.2362,Train acc macro: 0.9672, Test acc macro: 0.2353\n",
      "70\n",
      "Loss: -119.8729, Epoch: 070, Train acc micro: 0.9800, Test acc micro: 0.2513,Train acc macro: 0.9801, Test acc macro: 0.2471\n",
      "71\n",
      "Loss: -123.8069, Epoch: 071, Train acc micro: 0.7932, Test acc micro: 0.1910,Train acc macro: 0.7929, Test acc macro: 0.1923\n",
      "72\n",
      "Loss: -127.7848, Epoch: 072, Train acc micro: 0.7347, Test acc micro: 0.2211,Train acc macro: 0.7360, Test acc macro: 0.2194\n",
      "73\n",
      "Loss: -131.8235, Epoch: 073, Train acc micro: 0.9957, Test acc micro: 0.2312,Train acc macro: 0.9957, Test acc macro: 0.2327\n",
      "74\n",
      "Loss: -135.9359, Epoch: 074, Train acc micro: 0.9358, Test acc micro: 0.2010,Train acc macro: 0.9359, Test acc macro: 0.2012\n",
      "75\n",
      "Loss: -140.1269, Epoch: 075, Train acc micro: 0.6947, Test acc micro: 0.2111,Train acc macro: 0.6949, Test acc macro: 0.2117\n",
      "76\n",
      "Loss: -144.3954, Epoch: 076, Train acc micro: 0.3709, Test acc micro: 0.2111,Train acc macro: 0.3643, Test acc macro: 0.1923\n",
      "77\n",
      "Loss: -148.7393, Epoch: 077, Train acc micro: 0.7817, Test acc micro: 0.1910,Train acc macro: 0.7813, Test acc macro: 0.1879\n",
      "78\n",
      "Loss: -153.1584, Epoch: 078, Train acc micro: 0.4979, Test acc micro: 0.2161,Train acc macro: 0.4953, Test acc macro: 0.2152\n",
      "79\n",
      "Loss: -157.6557, Epoch: 079, Train acc micro: 0.6434, Test acc micro: 0.2161,Train acc macro: 0.6442, Test acc macro: 0.2128\n",
      "80\n",
      "Loss: -162.2368, Epoch: 080, Train acc micro: 0.5150, Test acc micro: 0.1910,Train acc macro: 0.5153, Test acc macro: 0.1829\n",
      "81\n",
      "Loss: -166.9087, Epoch: 081, Train acc micro: 0.3552, Test acc micro: 0.1809,Train acc macro: 0.3517, Test acc macro: 0.1732\n",
      "82\n",
      "Loss: -171.6776, Epoch: 082, Train acc micro: 0.8516, Test acc micro: 0.2261,Train acc macro: 0.8517, Test acc macro: 0.2252\n",
      "83\n",
      "Loss: -176.5492, Epoch: 083, Train acc micro: 0.8631, Test acc micro: 0.2312,Train acc macro: 0.8627, Test acc macro: 0.2276\n",
      "84\n",
      "Loss: -181.5291, Epoch: 084, Train acc micro: 0.8987, Test acc micro: 0.2161,Train acc macro: 0.8987, Test acc macro: 0.2109\n",
      "85\n",
      "Loss: -186.6216, Epoch: 085, Train acc micro: 0.8516, Test acc micro: 0.2362,Train acc macro: 0.8517, Test acc macro: 0.2276\n",
      "86\n",
      "Loss: -191.8319, Epoch: 086, Train acc micro: 0.7418, Test acc micro: 0.2513,Train acc macro: 0.7425, Test acc macro: 0.2493\n",
      "87\n",
      "Loss: -197.1639, Epoch: 087, Train acc micro: 0.6448, Test acc micro: 0.2010,Train acc macro: 0.6458, Test acc macro: 0.2034\n",
      "88\n",
      "Loss: -202.6224, Epoch: 088, Train acc micro: 0.8959, Test acc micro: 0.1960,Train acc macro: 0.8961, Test acc macro: 0.1845\n",
      "89\n",
      "Loss: -208.2124, Epoch: 089, Train acc micro: 0.7775, Test acc micro: 0.2060,Train acc macro: 0.7780, Test acc macro: 0.2022\n",
      "90\n",
      "Loss: -213.9395, Epoch: 090, Train acc micro: 0.8830, Test acc micro: 0.2111,Train acc macro: 0.8830, Test acc macro: 0.2128\n",
      "91\n",
      "Loss: -219.8094, Epoch: 091, Train acc micro: 0.7475, Test acc micro: 0.1658,Train acc macro: 0.7474, Test acc macro: 0.1636\n",
      "92\n",
      "Loss: -225.8276, Epoch: 092, Train acc micro: 0.9900, Test acc micro: 0.2362,Train acc macro: 0.9900, Test acc macro: 0.2348\n",
      "93\n",
      "Loss: -231.9995, Epoch: 093, Train acc micro: 0.8716, Test acc micro: 0.2060,Train acc macro: 0.8717, Test acc macro: 0.2042\n",
      "94\n",
      "Loss: -238.3306, Epoch: 094, Train acc micro: 0.9786, Test acc micro: 0.2010,Train acc macro: 0.9788, Test acc macro: 0.1906\n",
      "95\n",
      "Loss: -244.8269, Epoch: 095, Train acc micro: 0.9800, Test acc micro: 0.2060,Train acc macro: 0.9801, Test acc macro: 0.2059\n",
      "96\n",
      "Loss: -251.4955, Epoch: 096, Train acc micro: 0.5877, Test acc micro: 0.2010,Train acc macro: 0.5861, Test acc macro: 0.1983\n",
      "97\n",
      "Loss: -258.3428, Epoch: 097, Train acc micro: 0.9472, Test acc micro: 0.2211,Train acc macro: 0.9475, Test acc macro: 0.2199\n",
      "98\n",
      "Loss: -265.3759, Epoch: 098, Train acc micro: 0.9857, Test acc micro: 0.2060,Train acc macro: 0.9857, Test acc macro: 0.2055\n",
      "99\n",
      "Loss: -272.6013, Epoch: 099, Train acc micro: 0.9815, Test acc micro: 0.2714,Train acc macro: 0.9815, Test acc macro: 0.2702\n",
      "Loss: -272.6013, Epoch: 099, Train acc micro: 0.9815, Test acc micro: 0.2714,Train acc macro: 0.9815, Test acc macro: 0.2702\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = LapEigen\n",
    "loss_name = 'LapEigen'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "conv = 'GCN'\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-14 17:11:56,141]\u001B[0m A new study created in memory with name: HOPE_CommonNeighbors loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:11:58,813]\u001B[0m Trial 0 finished with value: 0.1888492410063381 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006959129564246061, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.1911165203963272}. Best is trial 0 with value: 0.1888492410063381.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:13,927]\u001B[0m Trial 1 finished with value: 0.26064390882760224 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00661145048905386, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.61765230035485}. Best is trial 1 with value: 0.26064390882760224.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:17,247]\u001B[0m Trial 2 finished with value: 0.22816851803140747 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006686915434233986, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.012783582014276762}. Best is trial 1 with value: 0.26064390882760224.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:19,732]\u001B[0m Trial 3 finished with value: 0.12175191748701415 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006176265484254587, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.10265987611624461}. Best is trial 1 with value: 0.26064390882760224.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:22,261]\u001B[0m Trial 4 finished with value: 0.19100027746258225 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005889499415151439, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.11886577515904329}. Best is trial 1 with value: 0.26064390882760224.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:28,689]\u001B[0m Trial 5 finished with value: 0.26048591562343176 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0083477929429936, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.24284302052970808}. Best is trial 1 with value: 0.26064390882760224.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:32,067]\u001B[0m Trial 6 finished with value: 0.2706640841002683 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007965062787005237, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.8252018632292069}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:35,600]\u001B[0m Trial 7 finished with value: 0.15306419515716263 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006307733556387493, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.3478965630155244}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:38,153]\u001B[0m Trial 8 finished with value: 0.2054062344061095 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008703566426082839, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.11025061184257234}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:42,171]\u001B[0m Trial 9 finished with value: 0.2098057228218195 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0055361040086011086, 'reg_lambda': 0.01, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.1606874227703251}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:45,071]\u001B[0m Trial 10 finished with value: 0.22277948925047125 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009787286757321604, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9184225980020113}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:12:58,123]\u001B[0m Trial 11 finished with value: 0.2516434345436988 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007743702192729997, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.7054228477884945}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:10,601]\u001B[0m Trial 12 finished with value: 0.1704938096378877 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007690452442057817, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.5876520063862309}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:14,050]\u001B[0m Trial 13 finished with value: 0.19614025588632383 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00886012160603674, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.8562726762585319}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:27,316]\u001B[0m Trial 14 finished with value: 0.16351151025543734 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007251136957634723, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.7540793282114293}. Best is trial 6 with value: 0.2706640841002683.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:30,174]\u001B[0m Trial 15 finished with value: 0.33970062643731047 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005176135187087295, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5140143566575845}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:33,084]\u001B[0m Trial 16 finished with value: 0.18678408580985728 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005023364841265965, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.35477012227818294}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:35,975]\u001B[0m Trial 17 finished with value: 0.1781700061768895 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008207832669096408, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.988905300936658}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:38,642]\u001B[0m Trial 18 finished with value: 0.2289128822889875 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009200358543027316, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.46603979095477865}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:41,679]\u001B[0m Trial 19 finished with value: 0.26800538544381275 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005316335333919887, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5143019624002695}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:46,830]\u001B[0m Trial 20 finished with value: 0.2783120027896114 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00814105400485784, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7747625981328623}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:51,950]\u001B[0m Trial 21 finished with value: 0.11930163064846942 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008036300968668107, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7958772021566582}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:13:57,115]\u001B[0m Trial 22 finished with value: 0.1204228749289841 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007302195898027228, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6651175429769758}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:02,141]\u001B[0m Trial 23 finished with value: 0.28047578623950176 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009351374091140442, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8336805831959471}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:07,246]\u001B[0m Trial 24 finished with value: 0.2692309132328081 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00987648383503322, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9989554263177534}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:12,436]\u001B[0m Trial 25 finished with value: 0.18910013835612124 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00928587397775511, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8922315349244769}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:17,620]\u001B[0m Trial 26 finished with value: 0.2793840368658168 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009486895509526506, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5115398275294036}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:22,701]\u001B[0m Trial 27 finished with value: 0.28726100225617607 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009368857677027947, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4291006865651635}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:25,116]\u001B[0m Trial 28 finished with value: 0.22602903919566353 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008664185557938167, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 5, 'lmbda': 0.42316247224325215}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:27,705]\u001B[0m Trial 29 finished with value: 0.1596734327889495 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009111003138392535, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.2559134581427547}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:33,417]\u001B[0m Trial 30 finished with value: 0.21257402176013104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009574105480488015, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3736419935034334}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:38,610]\u001B[0m Trial 31 finished with value: 0.26029897340472846 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00952883835654606, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.533096957859051}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:43,730]\u001B[0m Trial 32 finished with value: 0.17437633952412004 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009952007339938168, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5866135308366455}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:48,825]\u001B[0m Trial 33 finished with value: 0.2565840198876398 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009461179922506946, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.45595497282232295}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:53,948]\u001B[0m Trial 34 finished with value: 0.22637324274650608 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008942241365574642, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6646256520332161}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:14:59,036]\u001B[0m Trial 35 finished with value: 0.22972049249466725 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006856027392246259, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3023017044122247}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:02,123]\u001B[0m Trial 36 finished with value: 0.2058055932733445 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008536640329422286, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.5088529856612389}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:04,819]\u001B[0m Trial 37 finished with value: 0.24129533714002077 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006480049655280229, 'reg_lambda': 20, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.40677222265848656}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:09,002]\u001B[0m Trial 38 finished with value: 0.2682926993338735 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005906558949668654, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.5672705643872955}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:12,527]\u001B[0m Trial 39 finished with value: 0.17821951038998934 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0090260902070144, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.662563961166559}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:15,302]\u001B[0m Trial 40 finished with value: 0.21865759464289058 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00967448374049645, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.2214650266153868}. Best is trial 15 with value: 0.33970062643731047.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:20,422]\u001B[0m Trial 41 finished with value: 0.3440366735283108 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008361230852388987, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.76529788122724}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:25,567]\u001B[0m Trial 42 finished with value: 0.2593107665574262 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008384153780272184, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7100387815913427}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:30,768]\u001B[0m Trial 43 finished with value: 0.23393522672390696 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009316198584930536, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.043964396559432184}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:35,887]\u001B[0m Trial 44 finished with value: 0.18631516598372466 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008712618304501223, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9283822369305451}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:40,993]\u001B[0m Trial 45 finished with value: 0.22808608869543806 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007790810350855402, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3051350371806216}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:49,964]\u001B[0m Trial 46 finished with value: 0.21757912876602342 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009406792681070088, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8254852945800204}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:52,276]\u001B[0m Trial 47 finished with value: 0.2256638760775423 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009994516025925474, 'reg_lambda': 1, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.7148910101942565}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:15:54,788]\u001B[0m Trial 48 finished with value: 0.2334013506306047 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008378770167454403, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.6244140596894584}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:00,020]\u001B[0m Trial 49 finished with value: 0.1983073770599673 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009717479443462693, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4509752351380249}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:03,459]\u001B[0m Trial 50 finished with value: 0.15860191149868566 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008863956192527526, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.869910866515048}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:08,602]\u001B[0m Trial 51 finished with value: 0.24686701104175415 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007497738918632949, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8155543633984266}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:13,745]\u001B[0m Trial 52 finished with value: 0.24933883127104142 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007962485170466287, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7686281574236965}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:18,877]\u001B[0m Trial 53 finished with value: 0.22960912993758134 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008136920145296558, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7470277445004574}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:24,009]\u001B[0m Trial 54 finished with value: 0.22947507218759947 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00853961803951469, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.551701696623424}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:29,943]\u001B[0m Trial 55 finished with value: 0.23148097817757882 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006982788311890735, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 5, 'lmbda': 0.6379010198961603}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:35,146]\u001B[0m Trial 56 finished with value: 0.24785483133975897 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009133255487307137, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9180973932026097}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:38,061]\u001B[0m Trial 57 finished with value: 0.2650228518690735 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0060835861158481195, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7898754726681533}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:43,188]\u001B[0m Trial 58 finished with value: 0.20052934800230043 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007534916216703477, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4907029630057907}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:49,763]\u001B[0m Trial 59 finished with value: 0.19940214299445194 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008796265960894082, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.40621021956085523}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:52,862]\u001B[0m Trial 60 finished with value: 0.2378240369238521 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005549830051766452, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8447568394946553}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:56,215]\u001B[0m Trial 61 finished with value: 0.2734546562006201 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007899016920221016, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.7252761632759788}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:16:59,612]\u001B[0m Trial 62 finished with value: 0.2484818329731359 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007907263183113083, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.7287482569202695}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:03,085]\u001B[0m Trial 63 finished with value: 0.24000000000000002 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008179645929894766, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9490342424733651}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:06,569]\u001B[0m Trial 64 finished with value: 0.24793748029180887 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007113985991731834, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.6878881275457969}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:11,266]\u001B[0m Trial 65 finished with value: 0.18438390863262216 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007594291742057969, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.8661252919722378}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:14,247]\u001B[0m Trial 66 finished with value: 0.24105859471961055 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007326357749885742, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7771571301695548}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:17,871]\u001B[0m Trial 67 finished with value: 0.20375621976010172 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008493260688133736, 'reg_lambda': 20, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.4837745837047937}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:27,112]\u001B[0m Trial 68 finished with value: 0.20117262095247407 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008266289304403016, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.80728435474217}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:32,262]\u001B[0m Trial 69 finished with value: 0.19905738479552318 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009831954983251416, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.37550218778586664}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:34,745]\u001B[0m Trial 70 finished with value: 0.11304318228865862 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009213416758131324, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.5970444744687938}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:38,073]\u001B[0m Trial 71 finished with value: 0.2576091731734115 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007751994847073624, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.7448894078159051}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:41,552]\u001B[0m Trial 72 finished with value: 0.24443600896566853 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008064056411479814, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.8451904408860758}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:44,980]\u001B[0m Trial 73 finished with value: 0.19073523092342484 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007884601476403767, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.8922588841287106}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:50,072]\u001B[0m Trial 74 finished with value: 0.2702908486374314 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00902399062983713, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5226104644083063}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:53,888]\u001B[0m Trial 75 finished with value: 0.19034959762472875 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009372295828680934, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.319073835542395}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:17:58,983]\u001B[0m Trial 76 finished with value: 0.20970151904882287 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00960277866104008, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.43495898573303393}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:01,394]\u001B[0m Trial 77 finished with value: 0.16847212048532015 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006552664472143449, 'reg_lambda': 1, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.1606883536474813}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:05,067]\u001B[0m Trial 78 finished with value: 0.23352027793280142 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00860293259298371, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.6953507393812982}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:07,943]\u001B[0m Trial 79 finished with value: 0.18999704729380576 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005116289515427276, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9681661341676541}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:15,427]\u001B[0m Trial 80 finished with value: 0.20639901744086475 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007383385688321529, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.5589850096489076}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:20,577]\u001B[0m Trial 81 finished with value: 0.2494572240836318 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008909309030099047, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5253340725581404}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:25,647]\u001B[0m Trial 82 finished with value: 0.22794815178355005 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009021270701914094, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.60411500601593}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:30,683]\u001B[0m Trial 83 finished with value: 0.20169537994406908 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009532679908673706, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4806597020865809}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:35,905]\u001B[0m Trial 84 finished with value: 0.21138411968622003 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008338537124236278, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8229202033828694}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:40,934]\u001B[0m Trial 85 finished with value: 0.19523144038631512 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008771057327242036, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6481680636161632}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:48,967]\u001B[0m Trial 86 finished with value: 0.1826400212833941 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009203989518167408, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8944278192316897}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:52,999]\u001B[0m Trial 87 finished with value: 0.25152775167899977 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007636725011532466, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.540191289330284}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:18:58,572]\u001B[0m Trial 88 finished with value: 0.24119472935709077 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009751618531991904, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.401868506065486}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:00,996]\u001B[0m Trial 89 finished with value: 0.16562174050659312 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008004635050827987, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.7618204477924815}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:06,231]\u001B[0m Trial 90 finished with value: 0.24853985264139375 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009029333220740642, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7299684048439612}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:11,478]\u001B[0m Trial 91 finished with value: 0.27154187189392465 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009930628501002866, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9927776430494796}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:16,480]\u001B[0m Trial 92 finished with value: 0.18934258146270475 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009880296475745613, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7863314869697227}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:21,579]\u001B[0m Trial 93 finished with value: 0.13857338965915209 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009312567819461262, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.45286745025135683}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:26,678]\u001B[0m Trial 94 finished with value: 0.17556383774189127 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00967217113133564, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5057296733345561}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:31,617]\u001B[0m Trial 95 finished with value: 0.2390453871077854 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00947638340145566, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9658229615877666}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:36,737]\u001B[0m Trial 96 finished with value: 0.13362439094520828 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008101158250975403, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5764542261752488}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:40,132]\u001B[0m Trial 97 finished with value: 0.19184389912804906 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007801648211548848, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.8282790998707859}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:42,579]\u001B[0m Trial 98 finished with value: 0.17568287422352363 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008234044900700543, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.6765827937440663}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:46,005]\u001B[0m Trial 99 finished with value: 0.13759252817725418 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005633560386460805, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.9319004511498654}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:54,029]\u001B[0m Trial 100 finished with value: 0.1934114043664588 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009420856224433513, 'reg_lambda': 0.7, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8778703146410088}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:19:59,112]\u001B[0m Trial 101 finished with value: 0.17953145009283966 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009941295772640243, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9147981139271616}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:04,218]\u001B[0m Trial 102 finished with value: 0.21784120665435275 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009612692846776775, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8004441866957831}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:09,269]\u001B[0m Trial 103 finished with value: 0.2753681343721699 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009993905015867962, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9917549188723298}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:14,283]\u001B[0m Trial 104 finished with value: 0.22057437397623247 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009747934675196527, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9772200991071134}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:19,351]\u001B[0m Trial 105 finished with value: 0.2296903641628058 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00843068071933435, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9456190843042851}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:22,715]\u001B[0m Trial 106 finished with value: 0.25094547878831663 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00987370381569835, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9990145914277471}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:27,752]\u001B[0m Trial 107 finished with value: 0.1693251590018727 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009997035652907249, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8466357695606083}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:31,901]\u001B[0m Trial 108 finished with value: 0.190406143802531 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009253275488693856, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.34522762883230507}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:34,413]\u001B[0m Trial 109 finished with value: 0.13255726525328054 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009110603261676108, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.6230136079893831}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:39,509]\u001B[0m Trial 110 finished with value: 0.15106230443038998 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006715751208172817, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9037859463089627}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:44,492]\u001B[0m Trial 111 finished with value: 0.1971018254451502 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009669032690915257, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9974343184428338}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:49,503]\u001B[0m Trial 112 finished with value: 0.24820572375657404 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009799378664297764, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4328233446277938}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:54,633]\u001B[0m Trial 113 finished with value: 0.18323677110698686 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009541550324077086, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9438360095212024}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:20:59,684]\u001B[0m Trial 114 finished with value: 0.13274016518186796 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00990666607479325, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9715702404299134}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:03,168]\u001B[0m Trial 115 finished with value: 0.2300552088720721 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007857537991107433, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.7205510154415142}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:08,121]\u001B[0m Trial 116 finished with value: 0.2023350448283734 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00979925325765142, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9617438869414693}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:13,151]\u001B[0m Trial 117 finished with value: 0.15427509873748668 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009368016480631701, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4682500125786548}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:15,494]\u001B[0m Trial 118 finished with value: 0.3001435723469087 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007683367908665614, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8777488072820193}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:17,941]\u001B[0m Trial 119 finished with value: 0.2393243578117403 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0077037010439398165, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8745435337930795}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:20,373]\u001B[0m Trial 120 finished with value: 0.20922814260398434 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007490522666069, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.7493824500412523}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:22,744]\u001B[0m Trial 121 finished with value: 0.20679114575478794 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007945909027000143, 'reg_lambda': 30, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8230205892335639}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:25,173]\u001B[0m Trial 122 finished with value: 0.23400935709687293 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008298153409265263, 'reg_lambda': 0.8, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5222368479795426}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:27,584]\u001B[0m Trial 123 finished with value: 0.22280467332239196 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007161822178912088, 'reg_lambda': 0.001, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8516483736599171}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:30,467]\u001B[0m Trial 124 finished with value: 0.20606028040561128 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008162912576063571, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7819670008761869}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:35,533]\u001B[0m Trial 125 finished with value: 0.23517863555875207 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009460405276976344, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9225970881875446}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:40,146]\u001B[0m Trial 126 finished with value: 0.21061680977415018 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008019125957360729, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 3, 'lmbda': 0.8059606047897119}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:45,316]\u001B[0m Trial 127 finished with value: 0.23701002728044515 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00968908402097915, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.988478429776356}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:48,353]\u001B[0m Trial 128 finished with value: 0.2792349809317382 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009580153354316775, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.38937992783322195}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:51,350]\u001B[0m Trial 129 finished with value: 0.14040575636226163 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008638282235823646, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4144753338706094}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:55,055]\u001B[0m Trial 130 finished with value: 0.24614590116283647 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00960310042038681, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.387349348683612}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:21:58,119]\u001B[0m Trial 131 finished with value: 0.23579619849200956 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009134776240854433, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4959299886304258}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:01,162]\u001B[0m Trial 132 finished with value: 0.20743055108942757 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009822744129428766, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.764535307477675}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:04,163]\u001B[0m Trial 133 finished with value: 0.197141097977239 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00999466380568195, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.26135934212195666}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:09,311]\u001B[0m Trial 134 finished with value: 0.19114163940213366 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006334015032278621, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3409000250371486}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:13,237]\u001B[0m Trial 135 finished with value: 0.18718024041890818 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009519390302953696, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.5539781957799234}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:18,281]\u001B[0m Trial 136 finished with value: 0.1776163068176806 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007446629236317257, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.07894407015529331}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:20,963]\u001B[0m Trial 137 finished with value: 0.2463577517805618 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007598763269962841, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.4693541434865059}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:25,943]\u001B[0m Trial 138 finished with value: 0.2516241349872082 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007705207110760428, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.36695594179699453}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:28,258]\u001B[0m Trial 139 finished with value: 0.20857957929903598 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00931702725338152, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.83331708016088}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:33,462]\u001B[0m Trial 140 finished with value: 0.27552432505945107 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009724694720390024, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8791948907748776}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:38,592]\u001B[0m Trial 141 finished with value: 0.1599293127521815 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009720233628647237, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8691550871952737}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:43,617]\u001B[0m Trial 142 finished with value: 0.24279303727343365 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009912397396208587, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8890677584519162}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:48,783]\u001B[0m Trial 143 finished with value: 0.2399377868743095 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009424663298396448, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9534970027460056}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:22:53,797]\u001B[0m Trial 144 finished with value: 0.21984273750875655 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007837732809025, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9103021715469873}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:01,140]\u001B[0m Trial 145 finished with value: 0.22268965327569112 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009610207004675074, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.43936048821852863}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:04,028]\u001B[0m Trial 146 finished with value: 0.2205097162081118 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009734269580200064, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.796255336182742}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:09,255]\u001B[0m Trial 147 finished with value: 0.2082384501480694 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008979566315806898, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9782845901998796}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:14,787]\u001B[0m Trial 148 finished with value: 0.2408696468593024 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009834042672685167, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9295711707923768}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:17,679]\u001B[0m Trial 149 finished with value: 0.1890675349166145 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008103752135260291, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7310221243748022}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:21,080]\u001B[0m Trial 150 finished with value: 0.2139711130355012 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009537374499716075, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.8522252069308329}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:25,302]\u001B[0m Trial 151 finished with value: 0.21568414445449144 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009258847125844587, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.5703071643753947}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:29,569]\u001B[0m Trial 152 finished with value: 0.2468481801092908 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005873068091786434, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.5352900600792869}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:33,829]\u001B[0m Trial 153 finished with value: 0.23737954740877928 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005325440089466022, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.49328266737334747}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:37,975]\u001B[0m Trial 154 finished with value: 0.22124892694211848 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005988764234540472, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.5162717776987858}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:50,870]\u001B[0m Trial 155 finished with value: 0.23650151909924746 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005234840466476707, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.8086618975971607}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:23:55,872]\u001B[0m Trial 156 finished with value: 0.22924340760347856 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005424629536198546, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6967067256033272}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:01,513]\u001B[0m Trial 157 finished with value: 0.24560713743013068 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005110243648960629, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7702184405109473}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:04,258]\u001B[0m Trial 158 finished with value: 0.2558234406745675 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009423182953652518, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.8320429190973697}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:09,422]\u001B[0m Trial 159 finished with value: 0.22701526542488443 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007988558979098915, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6055644110585822}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:11,777]\u001B[0m Trial 160 finished with value: 0.19946017288413564 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00967852436406896, 'reg_lambda': 0.8, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.4510408193438836}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:14,739]\u001B[0m Trial 161 finished with value: 0.23411912503228427 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009912126422529978, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5063258360684998}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:17,599]\u001B[0m Trial 162 finished with value: 0.2388579525621295 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00567886665426762, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.573166387844637}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:20,524]\u001B[0m Trial 163 finished with value: 0.26080925939197064 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005026247951393229, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5384121640578847}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:23,383]\u001B[0m Trial 164 finished with value: 0.261318796249362 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005491103872082326, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9996509041286914}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:30,374]\u001B[0m Trial 165 finished with value: 0.18676452296691742 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00843887615458886, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.4829425434274115}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:33,261]\u001B[0m Trial 166 finished with value: 0.24433521993298407 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0052561567876722335, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.518830003516277}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:36,323]\u001B[0m Trial 167 finished with value: 0.16312769310482844 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005820616234656243, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.398471990081103}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:41,434]\u001B[0m Trial 168 finished with value: 0.21929587701561454 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006190407368823189, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9421073308395148}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:44,461]\u001B[0m Trial 169 finished with value: 0.2677509894183302 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007896521513966819, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5568444177137596}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:50,000]\u001B[0m Trial 170 finished with value: 0.20547755565819473 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009781034027768162, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8873329987742666}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:52,911]\u001B[0m Trial 171 finished with value: 0.2344312526105796 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00791552614867208, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5509765921252188}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:55,918]\u001B[0m Trial 172 finished with value: 0.20212410658815935 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007792884633785885, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5861109483085365}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:24:58,849]\u001B[0m Trial 173 finished with value: 0.2689542081339339 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008187833265867746, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4658895070828172}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:01,769]\u001B[0m Trial 174 finished with value: 0.21626462379970887 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008216146932184509, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.47656326071472005}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:04,774]\u001B[0m Trial 175 finished with value: 0.3355975544841151 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00833570372772837, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.41605793121474766}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:07,743]\u001B[0m Trial 176 finished with value: 0.22993658134627223 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008529544016838793, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.43255081948645835}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:10,144]\u001B[0m Trial 177 finished with value: 0.11388858291767621 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008283503042222848, 'reg_lambda': 0.6, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.3756953833464416}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:15,322]\u001B[0m Trial 178 finished with value: 0.23439734635423123 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008330544841207781, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4584416313380448}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:18,173]\u001B[0m Trial 179 finished with value: 0.25353823166847955 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008062347870086709, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.42877905126017385}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:23,192]\u001B[0m Trial 180 finished with value: 0.2349088492619621 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008135687205615595, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.40714376942084207}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:26,193]\u001B[0m Trial 181 finished with value: 0.22690267005892223 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00837392444522074, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5061943241404528}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:29,124]\u001B[0m Trial 182 finished with value: 0.2661766330841233 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009972053771976915, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7819601735647314}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:32,075]\u001B[0m Trial 183 finished with value: 0.23302761117978316 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008218931869546486, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4607478103640119}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:35,094]\u001B[0m Trial 184 finished with value: 0.23962427487655688 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009623655444495137, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4151683164625683}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:37,667]\u001B[0m Trial 185 finished with value: 0.18381158472596823 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005342185302395857, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.7430417482598808}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:45,642]\u001B[0m Trial 186 finished with value: 0.2435316444565136 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005119577304791678, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9601762575691962}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:49,654]\u001B[0m Trial 187 finished with value: 0.23251694081104665 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007703464165083755, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.48499030353116823}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:55,267]\u001B[0m Trial 188 finished with value: 0.2353188020004746 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009319415445738685, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3877168018681073}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:25:58,656]\u001B[0m Trial 189 finished with value: 0.18890449235973114 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008702023462568589, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9784335484258462}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:03,837]\u001B[0m Trial 190 finished with value: 0.18601831956593945 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008849076664423132, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8673600671815818}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:06,779]\u001B[0m Trial 191 finished with value: 0.283865203518893 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007915470208845678, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5291253779290611}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:09,695]\u001B[0m Trial 192 finished with value: 0.20386665482576652 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007952677330578566, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5277691607678461}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:12,693]\u001B[0m Trial 193 finished with value: 0.2686690907683648 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008036861482672906, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.49336702200834914}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:15,665]\u001B[0m Trial 194 finished with value: 0.16457897623024972 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008084060659215107, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.47655193720020533}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:18,566]\u001B[0m Trial 195 finished with value: 0.20937841494896192 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008011476957989346, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.44192421066424165}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:21,543]\u001B[0m Trial 196 finished with value: 0.2598408651828711 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.0077901284162914895, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4998282410979355}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:26,631]\u001B[0m Trial 197 finished with value: 0.22017059861193458 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0075691174805094, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8207258858233802}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:28,983]\u001B[0m Trial 198 finished with value: 0.25411562547746447 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009835105826144615, 'reg_lambda': 100, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5323304366139531}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:32,180]\u001B[0m Trial 199 finished with value: 0.15010777239151654 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009498902665247892, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8467851510465458}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:37,327]\u001B[0m Trial 200 finished with value: 0.24680463038471834 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008164397171534171, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.36148550438689925}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:40,286]\u001B[0m Trial 201 finished with value: 0.2641262277114925 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00788169054340629, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5259851276730796}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:43,360]\u001B[0m Trial 202 finished with value: 0.1449075835343843 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008043876683716809, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5065199105946302}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:46,320]\u001B[0m Trial 203 finished with value: 0.2499940581587414 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009133609502252858, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.49480234810777235}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:49,448]\u001B[0m Trial 204 finished with value: 0.18517544947953302 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008272008557945423, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4593019216713973}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:52,712]\u001B[0m Trial 205 finished with value: 0.1377889734958445 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00990523580866451, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.5497231500329254}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:26:55,599]\u001B[0m Trial 206 finished with value: 0.19910130297858733 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007660700607774643, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9025728834173159}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:02,887]\u001B[0m Trial 207 finished with value: 0.22571715282514535 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00971407503738582, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.650225813114765}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:05,824]\u001B[0m Trial 208 finished with value: 0.2954898468899318 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00847447955612782, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9908060490984513}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:08,460]\u001B[0m Trial 209 finished with value: 0.2692628077739028 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008457501869748571, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.999673765563494}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:11,328]\u001B[0m Trial 210 finished with value: 0.16958338514258775 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0084594764199711, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9892902845622031}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:14,031]\u001B[0m Trial 211 finished with value: 0.20884050256775785 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008580521349197092, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.9962184531740913}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:16,677]\u001B[0m Trial 212 finished with value: 0.22535213519338224 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008383062075493214, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.9712598103843777}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:19,311]\u001B[0m Trial 213 finished with value: 0.20704881559635172 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00818433267054147, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.9502039498077719}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:22,044]\u001B[0m Trial 214 finished with value: 0.23991226466531906 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008433447039042127, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 5, 'lmbda': 0.9730993640061216}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:26,137]\u001B[0m Trial 215 finished with value: 0.17791023573227605 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008309190732970784, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.9606742800823154}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:37,340]\u001B[0m Trial 216 finished with value: 0.2336524543418848 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008537633897615375, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9989504126169438}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:40,457]\u001B[0m Trial 217 finished with value: 0.21858296713023403 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007967178339618661, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9310067345869439}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:42,825]\u001B[0m Trial 218 finished with value: 0.18878704592636228 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008160511451576553, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8048249974096562}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:48,077]\u001B[0m Trial 219 finished with value: 0.23524374314411828 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009550613889534324, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7539267968836615}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:51,494]\u001B[0m Trial 220 finished with value: 0.21880987052518572 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00941373108185345, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9779793688356454}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:54,472]\u001B[0m Trial 221 finished with value: 0.25727894023608855 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005220641711413654, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4853078461414754}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:27:57,588]\u001B[0m Trial 222 finished with value: 0.2498116677108457 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009996543419688501, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7694505844628196}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:00,458]\u001B[0m Trial 223 finished with value: 0.26946781763932487 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007826817657693413, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5176834783211304}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:03,332]\u001B[0m Trial 224 finished with value: 0.21884738475189935 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007794062932757554, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5130420888087129}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:06,247]\u001B[0m Trial 225 finished with value: 0.22769232968023986 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007842188624441589, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5344400589495293}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:11,322]\u001B[0m Trial 226 finished with value: 0.17075917285662645 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007951136813966746, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.43178732836953715}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:19,429]\u001B[0m Trial 227 finished with value: 0.2651050850813113 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008096209686416224, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.7093194699090992}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:22,021]\u001B[0m Trial 228 finished with value: 0.2218055628538356 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009820826646318616, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.9985294480224312}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:26,017]\u001B[0m Trial 229 finished with value: 0.21314735710013527 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0077427366333319364, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.7945852328934515}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:28,927]\u001B[0m Trial 230 finished with value: 0.20845260537537735 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008219306751512698, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3317934524964417}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:31,950]\u001B[0m Trial 231 finished with value: 0.23837743305450337 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008051988763297933, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5577018570329627}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:34,818]\u001B[0m Trial 232 finished with value: 0.26447981882058164 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00865376340297086, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.513179337584177}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:37,669]\u001B[0m Trial 233 finished with value: 0.1687150619992694 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008341790606954296, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4647935641697372}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:40,605]\u001B[0m Trial 234 finished with value: 0.2608788110686807 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007864167529566157, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4958218393196462}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:46,165]\u001B[0m Trial 235 finished with value: 0.21989440771202945 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0069156537999353045, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5360320095569978}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:49,215]\u001B[0m Trial 236 finished with value: 0.23297244819111468 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00967405070920891, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.41619760911838416}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:54,447]\u001B[0m Trial 237 finished with value: 0.2215968909367393 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008464343382338367, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8587262872585514}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:28:57,778]\u001B[0m Trial 238 finished with value: 0.24636943745774353 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005737541362333855, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9558211261467273}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:02,851]\u001B[0m Trial 239 finished with value: 0.21707626622131704 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007956395150498393, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9823895934620014}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:05,860]\u001B[0m Trial 240 finished with value: 0.1790631566788985 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007653075995976131, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5150316225902655}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:08,826]\u001B[0m Trial 241 finished with value: 0.20938506456564157 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007859027419157375, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5733461938790504}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:11,792]\u001B[0m Trial 242 finished with value: 0.2793598568273247 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00788517590862082, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5673564563894704}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:14,788]\u001B[0m Trial 243 finished with value: 0.26783781355497904 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008082587058893793, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.6057497330471501}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:17,741]\u001B[0m Trial 244 finished with value: 0.14646257269789165 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009882101770971567, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3907020129221642}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:20,202]\u001B[0m Trial 245 finished with value: 0.2351811998863094 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005028221256667308, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5573824575960861}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:23,129]\u001B[0m Trial 246 finished with value: 0.22269538081983414 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008005403435196626, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.47780758304712884}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:26,273]\u001B[0m Trial 247 finished with value: 0.22481355883993986 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009781825874955246, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.5349760639214262}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:29,295]\u001B[0m Trial 248 finished with value: 0.2446464742273989 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007755197229426371, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8416585658890074}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:33,383]\u001B[0m Trial 249 finished with value: 0.2509328876784187 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009199080991161852, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.5161325036830142}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:36,288]\u001B[0m Trial 250 finished with value: 0.15933973888794595 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008242464230542916, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8788845638921723}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:41,161]\u001B[0m Trial 251 finished with value: 0.1561282497055427 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009487188740941385, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4447200116038269}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:44,646]\u001B[0m Trial 252 finished with value: 0.2499376181613846 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00934398522641223, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.5912007600015067}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:49,746]\u001B[0m Trial 253 finished with value: 0.19725994001504654 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009634845632694697, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.978342048924729}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:52,576]\u001B[0m Trial 254 finished with value: 0.24911889007216423 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008797799892924035, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.49494451386753907}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:29:57,765]\u001B[0m Trial 255 finished with value: 0.26740950526831225 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0063786363934755855, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6776249833273523}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:00,733]\u001B[0m Trial 256 finished with value: 0.2170877861761935 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008137179937585394, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7827757085478079}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:03,118]\u001B[0m Trial 257 finished with value: 0.17383709414761928 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007562724449042387, 'reg_lambda': 0.3, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.5428345311031151}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:07,278]\u001B[0m Trial 258 finished with value: 0.25771844856613085 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007899521766623759, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.8148357749831308}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:15,380]\u001B[0m Trial 259 finished with value: 0.23668293113241648 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008385519402282578, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.9081315995635888}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:18,261]\u001B[0m Trial 260 finished with value: 0.25352557625673944 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009899482028128305, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.7395627802166308}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:26,019]\u001B[0m Trial 261 finished with value: 0.2897109554713096 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007981460863973786, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9424344913605013}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:33,581]\u001B[0m Trial 262 finished with value: 0.2586701348924428 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008021423741339942, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9397871363194608}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:41,081]\u001B[0m Trial 263 finished with value: 0.211345634461736 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007931268096759102, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9963397626812404}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:48,853]\u001B[0m Trial 264 finished with value: 0.264685899839333 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0078225106833503, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9649915309647128}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:30:56,444]\u001B[0m Trial 265 finished with value: 0.22826833496684995 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0067009217604102195, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.943743531591306}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:04,055]\u001B[0m Trial 266 finished with value: 0.20792060910507162 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008227869512256628, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.4119353292679809}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:11,890]\u001B[0m Trial 267 finished with value: 0.19941810853451716 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007676555944412131, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9788258759266765}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:17,052]\u001B[0m Trial 268 finished with value: 0.23292532421980724 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008112421924204367, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9292531113904964}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:21,271]\u001B[0m Trial 269 finished with value: 0.2554057822193636 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007411000699136971, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.9962988361712394}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:26,888]\u001B[0m Trial 270 finished with value: 0.23932888598039226 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007987826016725577, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8957486991262736}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:31,865]\u001B[0m Trial 271 finished with value: 0.20589483462882027 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009042841711442567, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6278146969197661}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:34,502]\u001B[0m Trial 272 finished with value: 0.25498698808380066 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008287716707822829, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.96023678305129}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:36,959]\u001B[0m Trial 273 finished with value: 0.21957322947202648 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007753792672995161, 'reg_lambda': 0.5, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.9999396342710959}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:39,477]\u001B[0m Trial 274 finished with value: 0.1767721450013866 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009565907675691206, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.8618099015110494}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:44,616]\u001B[0m Trial 275 finished with value: 0.23863420114370973 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008529380964893397, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4687121661535604}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:48,118]\u001B[0m Trial 276 finished with value: 0.26119644887643545 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009998222610991585, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.920443015338001}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:53,306]\u001B[0m Trial 277 finished with value: 0.1878949360691907 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007890853974261956, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9787753181945236}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:31:56,346]\u001B[0m Trial 278 finished with value: 0.19870973994426808 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009232830557181453, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5703782497188086}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:00,429]\u001B[0m Trial 279 finished with value: 0.22180132362467672 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009736025408435574, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.8292094402829281}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:03,417]\u001B[0m Trial 280 finished with value: 0.22663722462641808 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008064396249948261, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.45069332113829924}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:08,430]\u001B[0m Trial 281 finished with value: 0.24105179400371812 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009830394069326263, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4957257074133661}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:11,371]\u001B[0m Trial 282 finished with value: 0.22185580106694366 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009368364801521409, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3875472741395786}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:16,405]\u001B[0m Trial 283 finished with value: 0.19126536612779968 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008146457554423671, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.42964234591685524}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:19,931]\u001B[0m Trial 284 finished with value: 0.29672591649526286 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.0061211939472366975, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9611363218586982}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:23,497]\u001B[0m Trial 285 finished with value: 0.3021683474844771 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008342577750442587, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9660159251839093}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:26,986]\u001B[0m Trial 286 finished with value: 0.19416797327677104 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.006039235684529984, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9526972684466233}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:30,408]\u001B[0m Trial 287 finished with value: 0.2319569486187004 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008333470041893767, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9688768377518172}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:33,984]\u001B[0m Trial 288 finished with value: 0.22696618813059322 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008310928258442145, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9455906547879137}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:37,430]\u001B[0m Trial 289 finished with value: 0.20899070789741062 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0084726011465192, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9817148089157162}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:40,850]\u001B[0m Trial 290 finished with value: 0.1869961651145974 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008592756331457445, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9211374121239839}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:53,413]\u001B[0m Trial 291 finished with value: 0.22040686359630907 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007057997524990723, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 9, 'lmbda': 0.9634209672542291}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:55,960]\u001B[0m Trial 292 finished with value: 0.2292578390850765 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009465061994107744, 'reg_lambda': 0.4, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.9814764295088028}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:32:59,369]\u001B[0m Trial 293 finished with value: 0.26083416633839934 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007224985604272498, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9458056216036775}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:02,789]\u001B[0m Trial 294 finished with value: 0.22591541883816127 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008401099097612589, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9591357686623686}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:06,210]\u001B[0m Trial 295 finished with value: 0.23643551206182256 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0097386835551571, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.8855426520753129}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:08,753]\u001B[0m Trial 296 finished with value: 0.2298996350719073 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006241552553437661, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.9994196985449695}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:12,211]\u001B[0m Trial 297 finished with value: 0.20299777882552855 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006510905109115783, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.7907839623428918}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:15,099]\u001B[0m Trial 298 finished with value: 0.20913766275523113 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008194303057929973, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9690413126176071}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:20,074]\u001B[0m Trial 299 finished with value: 0.2154068376413767 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007778407454766446, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7540945714723705}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:22,507]\u001B[0m Trial 300 finished with value: 0.22854562229614492 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009911596505564304, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 9, 'lmbda': 0.9092186134237563}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:25,369]\u001B[0m Trial 301 finished with value: 0.22956273641524996 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009586914563263119, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.8478081556072969}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:30,468]\u001B[0m Trial 302 finished with value: 0.22296285309138256 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008435261431856262, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8263815994544211}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:33,394]\u001B[0m Trial 303 finished with value: 0.25360598597308714 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007939927017313766, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9344396972057757}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:38,428]\u001B[0m Trial 304 finished with value: 0.2208895325545907 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008698456350463613, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9817668195311107}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:41,874]\u001B[0m Trial 305 finished with value: 0.25212329805041017 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007663120724874178, 'reg_lambda': 0.5, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.7162742678617788}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:47,088]\u001B[0m Trial 306 finished with value: 0.20949434070608872 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008898272831575122, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3682881392413347}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:49,553]\u001B[0m Trial 307 finished with value: 0.21228235301318338 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008256960359083096, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.769340528314291}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:54,677]\u001B[0m Trial 308 finished with value: 0.19424230136570686 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009658152903136366, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8080795641753837}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:33:57,715]\u001B[0m Trial 309 finished with value: 0.2296815377007421 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007843888437119834, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.29823634660174825}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:05,779]\u001B[0m Trial 310 finished with value: 0.20952693780207038 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009815272354402545, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8729536519745612}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:13,239]\u001B[0m Trial 311 finished with value: 0.237766137234129 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009388269767719505, 'reg_lambda': 0.7, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.4082516628323486}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:16,392]\u001B[0m Trial 312 finished with value: 0.29004400640559397 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009290035891256924, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9776686554628129}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:19,241]\u001B[0m Trial 313 finished with value: 0.18888037700100838 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009224070373343192, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9559218760157437}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:24,419]\u001B[0m Trial 314 finished with value: 0.33596317319946506 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009059662822238272, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9991417202134442}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:29,524]\u001B[0m Trial 315 finished with value: 0.22718003620949653 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009088694157560796, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9834878800771241}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:32,068]\u001B[0m Trial 316 finished with value: 0.2438742251267227 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009339170731791935, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.9976238160393364}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:35,591]\u001B[0m Trial 317 finished with value: 0.22832604399302162 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009192307598619859, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9293538751232937}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:40,668]\u001B[0m Trial 318 finished with value: 0.215120310448548 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009016639246155003, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9728871344365273}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:43,696]\u001B[0m Trial 319 finished with value: 0.16133730214741976 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.00927610831834982, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9605410985601587}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:48,783]\u001B[0m Trial 320 finished with value: 0.23579626328384964 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006820815276669525, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9989620150554358}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:51,827]\u001B[0m Trial 321 finished with value: 0.21111775640790395 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009472634327838791, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9418309712249475}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:34:58,233]\u001B[0m Trial 322 finished with value: 0.18809676274955595 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.00894014214197354, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9756770631766455}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:01,299]\u001B[0m Trial 323 finished with value: 0.256647545002885 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.0075077340241885135, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5269295110790658}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:04,892]\u001B[0m Trial 324 finished with value: 0.1775438298612811 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.00932793479602538, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.3573660371161481}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:07,986]\u001B[0m Trial 325 finished with value: 0.1784770730842121 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009566959867125063, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9160426413073116}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:12,877]\u001B[0m Trial 326 finished with value: 0.21916113155531636 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.00942077489202049, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9570784265223399}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:16,332]\u001B[0m Trial 327 finished with value: 0.217196209792867 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009088916152186028, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9795361187901653}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:18,734]\u001B[0m Trial 328 finished with value: 0.18715841897545 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009140385612450834, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8991518929971266}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:21,903]\u001B[0m Trial 329 finished with value: 0.13999178957862238 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008506455928525726, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9978387059544145}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:27,060]\u001B[0m Trial 330 finished with value: 0.21153168778433212 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007731388145462023, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8555820300393214}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:29,557]\u001B[0m Trial 331 finished with value: 0.2013295323429333 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00787331599838627, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.5460974531634651}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:37,108]\u001B[0m Trial 332 finished with value: 0.1709477880030807 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008725659560446911, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9343123658468251}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:43,597]\u001B[0m Trial 333 finished with value: 0.21766131856297458 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00949167183967542, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9667879583047605}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:53,126]\u001B[0m Trial 334 finished with value: 0.23794449069170015 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009272295090553304, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7322856888432462}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:35:56,185]\u001B[0m Trial 335 finished with value: 0.2302501568643656 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007618229228890169, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.20556125611348058}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:04,439]\u001B[0m Trial 336 finished with value: 0.16745507944594507 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00863671780542797, 'reg_lambda': 0.1, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8315333500537309}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:11,910]\u001B[0m Trial 337 finished with value: 0.2217266908674835 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007918767373652982, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.7970882030665428}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:15,059]\u001B[0m Trial 338 finished with value: 0.23765911545765717 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00806033238674727, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.5090807481334929}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:20,263]\u001B[0m Trial 339 finished with value: 0.23557178265740436 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008377285217996543, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7739806172638167}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:23,102]\u001B[0m Trial 340 finished with value: 0.2512270877474165 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007991435517361586, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9480617069087296}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:27,093]\u001B[0m Trial 341 finished with value: 0.16871192004038113 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0077585401639467914, 'reg_lambda': 0.001, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9825254615176807}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:32,190]\u001B[0m Trial 342 finished with value: 0.15563797320183548 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009407528438404538, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8737703963154752}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:35,054]\u001B[0m Trial 343 finished with value: 0.18379568989060938 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005612591110063849, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3880798536008764}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:40,378]\u001B[0m Trial 344 finished with value: 0.2232133822721915 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008859104240438547, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.5175636719626235}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:42,714]\u001B[0m Trial 345 finished with value: 0.17528162118044985 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005463001775167191, 'reg_lambda': 0.4, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.1430692330492218}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:46,154]\u001B[0m Trial 346 finished with value: 0.2097617696340303 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009606259305861389, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.9796815845652249}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:51,347]\u001B[0m Trial 347 finished with value: 0.3023995651976106 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008539584361245254, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9995140035857889}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:36:56,547]\u001B[0m Trial 348 finished with value: 0.2908063936754227 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00813230763979793, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9555236732922848}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:01,794]\u001B[0m Trial 349 finished with value: 0.2335385131185081 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008161287085389723, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9212534714774143}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:06,935]\u001B[0m Trial 350 finished with value: 0.22373782428259995 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00831116415701842, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9512393827180853}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:12,204]\u001B[0m Trial 351 finished with value: 0.21363892264118411 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008081509351905948, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8891637734197303}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:17,412]\u001B[0m Trial 352 finished with value: 0.24243827212194383 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008540491495681129, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.937584793123599}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:22,717]\u001B[0m Trial 353 finished with value: 0.22254603150209265 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009995742625237754, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9616744048783165}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:28,590]\u001B[0m Trial 354 finished with value: 0.25511961492498675 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008242632303514037, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.010499764551727464}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:33,914]\u001B[0m Trial 355 finished with value: 0.26952934875098156 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009287220120988779, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9996991032717292}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:39,369]\u001B[0m Trial 356 finished with value: 0.22868519932147932 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009517370551262994, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9672756217042153}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:47,103]\u001B[0m Trial 357 finished with value: 0.1780287236349605 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008148176918521906, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9058626385256614}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:52,479]\u001B[0m Trial 358 finished with value: 0.22308263753013952 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006121938116468934, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9457127639964156}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:37:57,829]\u001B[0m Trial 359 finished with value: 0.22710443630321292 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00917303612740034, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.7564644845572012}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:03,213]\u001B[0m Trial 360 finished with value: 0.2433310575649586 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008017005571479052, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9776342535663435}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:08,415]\u001B[0m Trial 361 finished with value: 0.21110066854920106 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009008930225039213, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6946260593963363}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:16,151]\u001B[0m Trial 362 finished with value: 0.19854992776794264 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008353119206669273, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.8468066665307274}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:21,361]\u001B[0m Trial 363 finished with value: 0.18582849812991703 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008248302617310226, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8079070655034136}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:26,505]\u001B[0m Trial 364 finished with value: 0.2361483171220383 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009669977021148139, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9646462009629582}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:28,949]\u001B[0m Trial 365 finished with value: 0.17241785717436095 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008802665104222004, 'reg_lambda': 20, 'n_estimators': 5, 'max_depth': 1, 'lmbda': 0.9332339838489466}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:34,506]\u001B[0m Trial 366 finished with value: 0.22436106658410626 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00595664819894354, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9820975671725988}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:42,134]\u001B[0m Trial 367 finished with value: 0.1883762287119664 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00941595806040386, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.3111121721152429}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:50,389]\u001B[0m Trial 368 finished with value: 0.2640128788524414 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00795543147649543, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.913991546135465}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:38:55,503]\u001B[0m Trial 369 finished with value: 0.2885655466207726 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008611216008375819, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.33697633827898454}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:00,642]\u001B[0m Trial 370 finished with value: 0.15549301450284672 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008538807747853148, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6601076952349544}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:05,850]\u001B[0m Trial 371 finished with value: 0.232291478017018 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008553947130244577, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.28595451003232664}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:13,371]\u001B[0m Trial 372 finished with value: 0.2258194562018624 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008653614098128386, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 9, 'lmbda': 0.9994405263109839}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:18,410]\u001B[0m Trial 373 finished with value: 0.24714668667904077 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008391646550178117, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3308772321247161}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:20,850]\u001B[0m Trial 374 finished with value: 0.14250344412780866 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0084462338676266, 'reg_lambda': 0.4, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.35065917735695973}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:26,044]\u001B[0m Trial 375 finished with value: 0.26652327290415795 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008115452846673305, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3302323963969728}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:31,202]\u001B[0m Trial 376 finished with value: 0.2914033024685261 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009736038976661102, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.400281512584984}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:36,404]\u001B[0m Trial 377 finished with value: 0.2427252315874456 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009809632779561704, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3843008938380897}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:41,401]\u001B[0m Trial 378 finished with value: 0.2537491617917514 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009668635114845614, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.25083616516306123}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:46,654]\u001B[0m Trial 379 finished with value: 0.2572034784298611 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009764170407743154, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3629199682228702}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:51,983]\u001B[0m Trial 380 finished with value: 0.22008183937204334 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009579103295314488, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3763312333157396}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:39:57,229]\u001B[0m Trial 381 finished with value: 0.23642010467484756 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009929619255572847, 'reg_lambda': 100, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4048840668394828}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:03,000]\u001B[0m Trial 382 finished with value: 0.22781287505564934 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009839043586561949, 'reg_lambda': 30, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.276652784616994}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:08,278]\u001B[0m Trial 383 finished with value: 0.18524947292932586 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009741624971569347, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4283827253736041}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:11,730]\u001B[0m Trial 384 finished with value: 0.1853320049548637 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008625422900094784, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.9540313750649968}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:16,992]\u001B[0m Trial 385 finished with value: 0.24661261875256998 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009501074167779629, 'reg_lambda': 0.6, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.41410358785572304}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:22,305]\u001B[0m Trial 386 finished with value: 0.22801777191458242 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006595134857806737, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9747865212017602}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:27,494]\u001B[0m Trial 387 finished with value: 0.1969793858913205 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008507208194140374, 'reg_lambda': 0.001, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3994388577267659}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:30,087]\u001B[0m Trial 388 finished with value: 0.19747446857511194 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008290722560594956, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.9850153742985602}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:35,396]\u001B[0m Trial 389 finished with value: 0.2566067723327574 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009912249958223011, 'reg_lambda': 0.9, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.44020892519248417}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:40,422]\u001B[0m Trial 390 finished with value: 0.23117690399942842 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009628918022238843, 'reg_lambda': 0.5, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9380051672387096}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:48,583]\u001B[0m Trial 391 finished with value: 0.2796931060199068 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00841188135097387, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3479957761448933}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:40:56,765]\u001B[0m Trial 392 finished with value: 0.1886481167220912 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008444915959965573, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3510861276356104}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:04,904]\u001B[0m Trial 393 finished with value: 0.1919082909175885 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008351725229614162, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.35695828117348527}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:08,998]\u001B[0m Trial 394 finished with value: 0.2236432683878708 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008590651901367843, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 1, 'lmbda': 0.3861420557486553}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:17,297]\u001B[0m Trial 395 finished with value: 0.23481097977972729 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008200247483186344, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.31919201178991125}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:25,495]\u001B[0m Trial 396 finished with value: 0.21181866736552357 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008421075173136684, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3741372063019257}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:33,441]\u001B[0m Trial 397 finished with value: 0.1781225429855253 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008301494223089227, 'reg_lambda': 0.6, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3339940542868357}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:41,644]\u001B[0m Trial 398 finished with value: 0.21587114859611353 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.00935254137309915, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3345063825825684}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:44,513]\u001B[0m Trial 399 finished with value: 0.26062744189620163 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008709502486427788, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.34620748501014703}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:52,653]\u001B[0m Trial 400 finished with value: 0.27833202822505937 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008509907531931232, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.31905334155393833}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:41:57,891]\u001B[0m Trial 401 finished with value: 0.187870968582145 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008513649833569906, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3396076619750625}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:06,032]\u001B[0m Trial 402 finished with value: 0.18819143995106893 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.006422985485623787, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2889431884484413}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:11,152]\u001B[0m Trial 403 finished with value: 0.22429002438270407 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008402315814455236, 'reg_lambda': 0.8, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.3029608355500227}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:19,342]\u001B[0m Trial 404 finished with value: 0.2023752495410302 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008747023596079595, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3693145957663436}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:27,635]\u001B[0m Trial 405 finished with value: 0.20410751004698505 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008573923111197658, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.30591953596739196}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:35,650]\u001B[0m Trial 406 finished with value: 0.21516196421857414 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.00846194662120156, 'reg_lambda': 0.8, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3103073320142843}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:44,003]\u001B[0m Trial 407 finished with value: 0.24237467772161517 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008333869835605487, 'reg_lambda': 30, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.2757821705828265}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:42:52,919]\u001B[0m Trial 408 finished with value: 0.21353152847185727 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009504088515766828, 'reg_lambda': 0.9, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.4227540353217992}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:00,818]\u001B[0m Trial 409 finished with value: 0.17036756799669422 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008653515664699313, 'reg_lambda': 0.001, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3203864483235123}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:03,302]\u001B[0m Trial 410 finished with value: 0.11026629734760007 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008214616030333485, 'reg_lambda': 0.8, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.8951190723503692}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:11,489]\u001B[0m Trial 411 finished with value: 0.19779082921412744 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009402910709921332, 'reg_lambda': 0.2, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.35236032055300565}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:16,727]\u001B[0m Trial 412 finished with value: 0.3069064141549371 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009256540467456525, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9193828052582543}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:22,047]\u001B[0m Trial 413 finished with value: 0.23922095596720686 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009169629646455867, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9193502043052543}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:28,104]\u001B[0m Trial 414 finished with value: 0.2685332928364911 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009263467601473526, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 3, 'lmbda': 0.8928813746533231}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:32,053]\u001B[0m Trial 415 finished with value: 0.22827737420223293 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009300180869298338, 'reg_lambda': 0.9, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.9142177929778833}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:38,935]\u001B[0m Trial 416 finished with value: 0.20639965240835315 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009217523034439243, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8683866817496135}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:47,275]\u001B[0m Trial 417 finished with value: 0.22500791241406196 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009368097644579453, 'reg_lambda': 10, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3932242929501043}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:52,684]\u001B[0m Trial 418 finished with value: 0.22437092463934544 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008459852371614873, 'reg_lambda': 20, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9341490399615573}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:43:55,683]\u001B[0m Trial 419 finished with value: 0.21812520027038196 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009463641994507619, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9479540604092453}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:00,820]\u001B[0m Trial 420 finished with value: 0.24012096432433952 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00836892493378272, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.8866046808549629}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:06,361]\u001B[0m Trial 421 finished with value: 0.25119137020066173 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008578596936825557, 'reg_lambda': 0.01, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.40054914585000156}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:09,329]\u001B[0m Trial 422 finished with value: 0.20842405531006053 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005860021464714286, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9198750630598915}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:12,586]\u001B[0m Trial 423 finished with value: 0.16091119847016072 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007319579386313014, 'reg_lambda': 1, 'n_estimators': 250, 'max_depth': 1, 'lmbda': 0.3739452859334756}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:15,680]\u001B[0m Trial 424 finished with value: 0.2501405593613409 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.008239072648502543, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9026483101210896}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:20,909]\u001B[0m Trial 425 finished with value: 0.16447079079776147 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009581830066131392, 'reg_lambda': 10, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.4562853268766644}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:25,758]\u001B[0m Trial 426 finished with value: 0.21542651158642517 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009284209788848538, 'reg_lambda': 0.1, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.9570976737533484}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:28,704]\u001B[0m Trial 427 finished with value: 0.2101306806743706 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008481162580260838, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.41738676413799963}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:36,742]\u001B[0m Trial 428 finished with value: 0.20914986406089028 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009061985449255017, 'reg_lambda': 0.5, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.8645714884893593}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:39,223]\u001B[0m Trial 429 finished with value: 0.19858602265765493 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008332612763574937, 'reg_lambda': 100, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.940814555673894}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:44,334]\u001B[0m Trial 430 finished with value: 0.22835986208816325 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005749026811887997, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.36196847318782727}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:47,191]\u001B[0m Trial 431 finished with value: 0.2863683257393036 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008777072598049452, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3201516647196912}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:50,068]\u001B[0m Trial 432 finished with value: 0.2401757737415687 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00879628614341496, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.31720657982357436}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:53,046]\u001B[0m Trial 433 finished with value: 0.24170763283439323 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008901336593326724, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.29580658642672647}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:55,964]\u001B[0m Trial 434 finished with value: 0.19948444171619237 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008668365243424436, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.2797721903110569}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:44:58,996]\u001B[0m Trial 435 finished with value: 0.20337888921095584 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008681506981747562, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3162916356825887}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:01,935]\u001B[0m Trial 436 finished with value: 0.18200054426293666 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009129132004172126, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.346175765078827}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:04,513]\u001B[0m Trial 437 finished with value: 0.3100407816775922 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008711965984349979, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.3330940241209451}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:07,070]\u001B[0m Trial 438 finished with value: 0.11322770341445958 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008946317195927997, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.3232962836998018}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:09,796]\u001B[0m Trial 439 finished with value: 0.25735238769181257 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008784350681491297, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.34265704414055376}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:12,408]\u001B[0m Trial 440 finished with value: 0.17956806752768387 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008803898403072621, 'reg_lambda': 0.8, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.33289884352874693}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:14,995]\u001B[0m Trial 441 finished with value: 0.19112679631684523 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008568445200140188, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.3037970325529384}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:17,888]\u001B[0m Trial 442 finished with value: 0.18913416490076018 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008723888881781269, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.25674932830627983}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:20,508]\u001B[0m Trial 443 finished with value: 0.25196741552744173 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008556437109086228, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.35841207198225816}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:23,108]\u001B[0m Trial 444 finished with value: 0.2720704831721722 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008663193593713701, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.3759036889794412}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:25,754]\u001B[0m Trial 445 finished with value: 0.2203257538736729 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008890334865109855, 'reg_lambda': 0.3, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.32200986910993795}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:28,295]\u001B[0m Trial 446 finished with value: 0.20206695110186737 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00866042637751866, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.33595759867312475}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:31,224]\u001B[0m Trial 447 finished with value: 0.16876502200711269 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008548855428446073, 'reg_lambda': 0.7, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3957900178163764}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:34,385]\u001B[0m Trial 448 finished with value: 0.1528199221552731 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008450715021973157, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.2219440660874078}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:37,487]\u001B[0m Trial 449 finished with value: 0.20597257633516244 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008601237062072832, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9597797220873915}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:45,749]\u001B[0m Trial 450 finished with value: 0.18784705676506414 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005375667529112572, 'reg_lambda': 0.4, 'n_estimators': 500, 'max_depth': 7, 'lmbda': 0.3617979642617384}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:48,692]\u001B[0m Trial 451 finished with value: 0.21261031942461542 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009017713758787295, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.29327732925036}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:51,227]\u001B[0m Trial 452 finished with value: 0.24640809107666273 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008762777631750799, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.9728462137700086}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:53,646]\u001B[0m Trial 453 finished with value: 0.21450977807269073 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00916435931914497, 'reg_lambda': 0.7, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.48143273411203336}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:56,777]\u001B[0m Trial 454 finished with value: 0.2634251253715317 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009381744918918904, 'reg_lambda': 0.6, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3396432569220875}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:45:59,694]\u001B[0m Trial 455 finished with value: 0.28435637962229526 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008468446833014412, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3842924311941108}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:02,637]\u001B[0m Trial 456 finished with value: 0.27889738523949786 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008413148623143843, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3891559544306965}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:06,118]\u001B[0m Trial 457 finished with value: 0.15768251234385128 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009255031314918703, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.4209832847514612}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:09,045]\u001B[0m Trial 458 finished with value: 0.22645058253954198 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006269550654050797, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.38062642713338435}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:11,961]\u001B[0m Trial 459 finished with value: 0.280327993471868 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005541209134138332, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.39453592309430074}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:14,892]\u001B[0m Trial 460 finished with value: 0.23583290541717053 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005207630802184668, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4244726938905455}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:17,863]\u001B[0m Trial 461 finished with value: 0.22554337046006057 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005542894732954339, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4440508954246051}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:20,938]\u001B[0m Trial 462 finished with value: 0.25004099917913714 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005003480887480929, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4094774750910408}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:23,869]\u001B[0m Trial 463 finished with value: 0.2876324593799847 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00549249647822107, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3659570618092621}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:27,294]\u001B[0m Trial 464 finished with value: 0.20763410865491985 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005136505107509862, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.3657702772019686}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:30,142]\u001B[0m Trial 465 finished with value: 0.22439527371670903 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005354855322011523, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.37923623527441636}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:33,094]\u001B[0m Trial 466 finished with value: 0.279230786900032 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005424941248281805, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4005080964981012}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:36,004]\u001B[0m Trial 467 finished with value: 0.1553915060308 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005659333970828656, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.35883898329390806}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:38,900]\u001B[0m Trial 468 finished with value: 0.1707166835623034 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005195196756844907, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.3973794056802423}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:41,326]\u001B[0m Trial 469 finished with value: 0.25784878548166223 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005741256729792228, 'reg_lambda': 0.2, 'n_estimators': 5, 'max_depth': 3, 'lmbda': 0.34875513829613974}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:44,250]\u001B[0m Trial 470 finished with value: 0.18234897422482022 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0054719509213681525, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.36991808423708866}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:46,783]\u001B[0m Trial 471 finished with value: 0.1639238598694836 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008950348789126233, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.9268942941547391}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:49,796]\u001B[0m Trial 472 finished with value: 0.28693441191115193 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005336571965811065, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.048327980292357464}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:52,701]\u001B[0m Trial 473 finished with value: 0.2327457906756372 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005382028420569714, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9694115157671866}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:56,114]\u001B[0m Trial 474 finished with value: 0.16499250532283113 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0051791579243432775, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.13072140761489195}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:46:59,061]\u001B[0m Trial 475 finished with value: 0.24759401507870965 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00550235520824618, 'reg_lambda': 0.4, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9463068608600516}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:01,966]\u001B[0m Trial 476 finished with value: 0.21302041898759194 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0052186331110546606, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.06926919519603603}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:04,856]\u001B[0m Trial 477 finished with value: 0.16765122270791868 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005091573253352122, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.15292845836645527}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:07,908]\u001B[0m Trial 478 finished with value: 0.16857583923582004 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00529228713867113, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.43453397202899496}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:10,875]\u001B[0m Trial 479 finished with value: 0.21442592373584063 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005557233592050577, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9852972569230101}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:14,334]\u001B[0m Trial 480 finished with value: 0.19966066064852997 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0053298045958720605, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.09856511929424933}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:17,333]\u001B[0m Trial 481 finished with value: 0.21535019616429354 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005427316197154126, 'reg_lambda': 0.01, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.04771868818862207}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:20,278]\u001B[0m Trial 482 finished with value: 0.17680742365838362 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005573677486950204, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.0933646009890388}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:23,205]\u001B[0m Trial 483 finished with value: 0.16604043316191525 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0051228600093617275, 'reg_lambda': 20, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.20950850448560188}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:25,698]\u001B[0m Trial 484 finished with value: 0.21373371387154647 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005303500591236687, 'reg_lambda': 0.3, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.41277606345321216}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:28,479]\u001B[0m Trial 485 finished with value: 0.2041547109868618 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.0083620199045903, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 3, 'lmbda': 0.39427298012896844}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:31,402]\u001B[0m Trial 486 finished with value: 0.20898564544006362 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005286524949989239, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9527121603594966}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:34,924]\u001B[0m Trial 487 finished with value: 0.2526113766567061 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00886400532518518, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.38316349051861}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:37,841]\u001B[0m Trial 488 finished with value: 0.2530526759706719 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008624887865988562, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.16142970736207207}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:40,717]\u001B[0m Trial 489 finished with value: 0.15008126906575425 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009072222488383217, 'reg_lambda': 0.1, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9265299574865423}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:43,718]\u001B[0m Trial 490 finished with value: 0.1796300209826051 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008490956540866422, 'reg_lambda': 30, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9641473702515008}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:46,885]\u001B[0m Trial 491 finished with value: 0.2006672078740499 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007446489795531638, 'reg_lambda': 100, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9721580939736512}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:49,417]\u001B[0m Trial 492 finished with value: 0.2142774806405877 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00838586072140025, 'reg_lambda': 0.4, 'n_estimators': 5, 'max_depth': 7, 'lmbda': 0.027424339393671893}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:47:57,731]\u001B[0m Trial 493 finished with value: 0.2588431155024451 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00874784760926453, 'reg_lambda': 0.2, 'n_estimators': 250, 'max_depth': 5, 'lmbda': 0.2338788753771998}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:48:00,777]\u001B[0m Trial 494 finished with value: 0.16823088807240988 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008302142049485418, 'reg_lambda': 0.2, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.9952771484038675}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:48:04,153]\u001B[0m Trial 495 finished with value: 0.18924802459950493 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0054480114283568795, 'reg_lambda': 1, 'n_estimators': 50, 'max_depth': 9, 'lmbda': 0.3684798936377645}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:48:09,347]\u001B[0m Trial 496 finished with value: 0.2364009025694573 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008576541588917247, 'reg_lambda': 0.3, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.936589055826584}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:48:11,871]\u001B[0m Trial 497 finished with value: 0.275605572222533 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008479269553682433, 'reg_lambda': 0.9, 'n_estimators': 50, 'max_depth': 1, 'lmbda': 0.9994378751240695}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:48:17,330]\u001B[0m Trial 498 finished with value: 0.23147233734781375 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00560529083256067, 'reg_lambda': 0.4, 'n_estimators': 250, 'max_depth': 7, 'lmbda': 0.6347298211781296}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n",
      "\u001B[32m[I 2022-11-14 17:48:20,280]\u001B[0m Trial 499 finished with value: 0.2308713652698994 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008224166986611308, 'reg_lambda': 10, 'n_estimators': 50, 'max_depth': 7, 'lmbda': 0.4137827947977779}. Best is trial 41 with value: 0.3440366735283108.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: GCN, mode: unsupervised, loss from HOPE_CommonNeighbors\n",
      "0\n",
      "Loss: 273953792.0000, Epoch: 000, Train acc micro: 0.9943, Test acc micro: 0.2864,Train acc macro: 0.9943, Test acc macro: 0.2851\n",
      "1\n",
      "Loss: 109783032.0000, Epoch: 001, Train acc micro: 0.9986, Test acc micro: 0.2312,Train acc macro: 0.9986, Test acc macro: 0.2299\n",
      "2\n",
      "Loss: 70899864.0000, Epoch: 002, Train acc micro: 0.9971, Test acc micro: 0.2563,Train acc macro: 0.9971, Test acc macro: 0.2582\n",
      "3\n",
      "Loss: 57940492.0000, Epoch: 003, Train acc micro: 0.9829, Test acc micro: 0.1809,Train acc macro: 0.9829, Test acc macro: 0.1808\n",
      "4\n",
      "Loss: 53736840.0000, Epoch: 004, Train acc micro: 0.9715, Test acc micro: 0.2412,Train acc macro: 0.9714, Test acc macro: 0.2380\n",
      "5\n",
      "Loss: 51871388.0000, Epoch: 005, Train acc micro: 1.0000, Test acc micro: 0.2412,Train acc macro: 1.0000, Test acc macro: 0.2379\n",
      "6\n",
      "Loss: 49540684.0000, Epoch: 006, Train acc micro: 0.9757, Test acc micro: 0.2211,Train acc macro: 0.9757, Test acc macro: 0.2174\n",
      "7\n",
      "Loss: 46153624.0000, Epoch: 007, Train acc micro: 0.9971, Test acc micro: 0.2462,Train acc macro: 0.9972, Test acc macro: 0.2211\n",
      "8\n",
      "Loss: 41985340.0000, Epoch: 008, Train acc micro: 1.0000, Test acc micro: 0.2261,Train acc macro: 1.0000, Test acc macro: 0.2077\n",
      "9\n",
      "Loss: 37763656.0000, Epoch: 009, Train acc micro: 0.8031, Test acc micro: 0.2462,Train acc macro: 0.8035, Test acc macro: 0.2250\n",
      "10\n",
      "Loss: 34033868.0000, Epoch: 010, Train acc micro: 0.9986, Test acc micro: 0.2261,Train acc macro: 0.9986, Test acc macro: 0.2250\n",
      "11\n",
      "Loss: 30893994.0000, Epoch: 011, Train acc micro: 0.9829, Test acc micro: 0.2111,Train acc macro: 0.9828, Test acc macro: 0.1986\n",
      "12\n",
      "Loss: 28195982.0000, Epoch: 012, Train acc micro: 0.9929, Test acc micro: 0.2362,Train acc macro: 0.9928, Test acc macro: 0.2289\n",
      "13\n",
      "Loss: 25777628.0000, Epoch: 013, Train acc micro: 0.9900, Test acc micro: 0.2563,Train acc macro: 0.9900, Test acc macro: 0.2528\n",
      "14\n",
      "Loss: 23557492.0000, Epoch: 014, Train acc micro: 0.9187, Test acc micro: 0.2060,Train acc macro: 0.9188, Test acc macro: 0.1988\n",
      "15\n",
      "Loss: 21521848.0000, Epoch: 015, Train acc micro: 0.9929, Test acc micro: 0.2412,Train acc macro: 0.9929, Test acc macro: 0.2278\n",
      "16\n",
      "Loss: 19679744.0000, Epoch: 016, Train acc micro: 0.8317, Test acc micro: 0.2312,Train acc macro: 0.8312, Test acc macro: 0.2263\n",
      "17\n",
      "Loss: 18033242.0000, Epoch: 017, Train acc micro: 1.0000, Test acc micro: 0.2211,Train acc macro: 1.0000, Test acc macro: 0.2160\n",
      "18\n",
      "Loss: 16570513.0000, Epoch: 018, Train acc micro: 1.0000, Test acc micro: 0.2161,Train acc macro: 1.0000, Test acc macro: 0.2083\n",
      "19\n",
      "Loss: 15272127.0000, Epoch: 019, Train acc micro: 0.6819, Test acc micro: 0.2161,Train acc macro: 0.6816, Test acc macro: 0.2140\n",
      "20\n",
      "Loss: 14118224.0000, Epoch: 020, Train acc micro: 0.5449, Test acc micro: 0.2111,Train acc macro: 0.5451, Test acc macro: 0.1981\n",
      "21\n",
      "Loss: 13091845.0000, Epoch: 021, Train acc micro: 1.0000, Test acc micro: 0.2563,Train acc macro: 1.0000, Test acc macro: 0.2522\n",
      "22\n",
      "Loss: 12178453.0000, Epoch: 022, Train acc micro: 0.7461, Test acc micro: 0.2412,Train acc macro: 0.7463, Test acc macro: 0.2325\n",
      "23\n",
      "Loss: 11364452.0000, Epoch: 023, Train acc micro: 1.0000, Test acc micro: 0.2362,Train acc macro: 1.0000, Test acc macro: 0.2315\n",
      "24\n",
      "Loss: 10636345.0000, Epoch: 024, Train acc micro: 0.9743, Test acc micro: 0.2161,Train acc macro: 0.9743, Test acc macro: 0.2153\n",
      "25\n",
      "Loss: 9981041.0000, Epoch: 025, Train acc micro: 0.8659, Test acc micro: 0.2362,Train acc macro: 0.8657, Test acc macro: 0.2360\n",
      "26\n",
      "Loss: 9386818.0000, Epoch: 026, Train acc micro: 1.0000, Test acc micro: 0.2111,Train acc macro: 1.0000, Test acc macro: 0.2062\n",
      "27\n",
      "Loss: 8844223.0000, Epoch: 027, Train acc micro: 0.9815, Test acc micro: 0.2312,Train acc macro: 0.9813, Test acc macro: 0.2273\n",
      "28\n",
      "Loss: 8346292.0000, Epoch: 028, Train acc micro: 0.9772, Test acc micro: 0.2111,Train acc macro: 0.9771, Test acc macro: 0.2117\n",
      "29\n",
      "Loss: 7888179.5000, Epoch: 029, Train acc micro: 0.9772, Test acc micro: 0.1658,Train acc macro: 0.9772, Test acc macro: 0.1674\n",
      "30\n",
      "Loss: 7466466.0000, Epoch: 030, Train acc micro: 0.8759, Test acc micro: 0.1960,Train acc macro: 0.8760, Test acc macro: 0.1948\n",
      "31\n",
      "Loss: 7078347.5000, Epoch: 031, Train acc micro: 0.9287, Test acc micro: 0.2211,Train acc macro: 0.9287, Test acc macro: 0.2213\n",
      "32\n",
      "Loss: 6721206.5000, Epoch: 032, Train acc micro: 0.5478, Test acc micro: 0.1960,Train acc macro: 0.5469, Test acc macro: 0.1977\n",
      "33\n",
      "Loss: 6392350.5000, Epoch: 033, Train acc micro: 1.0000, Test acc micro: 0.1658,Train acc macro: 1.0000, Test acc macro: 0.1663\n",
      "34\n",
      "Loss: 6089031.5000, Epoch: 034, Train acc micro: 1.0000, Test acc micro: 0.2211,Train acc macro: 1.0000, Test acc macro: 0.2193\n",
      "35\n",
      "Loss: 5808596.5000, Epoch: 035, Train acc micro: 1.0000, Test acc micro: 0.1859,Train acc macro: 1.0000, Test acc macro: 0.1852\n",
      "36\n",
      "Loss: 5548554.5000, Epoch: 036, Train acc micro: 0.3723, Test acc micro: 0.2111,Train acc macro: 0.3615, Test acc macro: 0.2044\n",
      "37\n",
      "Loss: 5306710.0000, Epoch: 037, Train acc micro: 0.9886, Test acc micro: 0.2613,Train acc macro: 0.9886, Test acc macro: 0.2608\n",
      "38\n",
      "Loss: 5081191.0000, Epoch: 038, Train acc micro: 0.3894, Test acc micro: 0.1910,Train acc macro: 0.3843, Test acc macro: 0.1824\n",
      "39\n",
      "Loss: 4870431.0000, Epoch: 039, Train acc micro: 0.6591, Test acc micro: 0.2111,Train acc macro: 0.6599, Test acc macro: 0.2141\n",
      "40\n",
      "Loss: 4673122.0000, Epoch: 040, Train acc micro: 0.9829, Test acc micro: 0.2111,Train acc macro: 0.9828, Test acc macro: 0.2061\n",
      "41\n",
      "Loss: 4488226.5000, Epoch: 041, Train acc micro: 0.4237, Test acc micro: 0.2010,Train acc macro: 0.4176, Test acc macro: 0.1978\n",
      "42\n",
      "Loss: 4314832.0000, Epoch: 042, Train acc micro: 0.9986, Test acc micro: 0.1508,Train acc macro: 0.9986, Test acc macro: 0.1495\n",
      "43\n",
      "Loss: 4152159.7500, Epoch: 043, Train acc micro: 0.9886, Test acc micro: 0.1508,Train acc macro: 0.9887, Test acc macro: 0.1475\n",
      "44\n",
      "Loss: 3999508.2500, Epoch: 044, Train acc micro: 1.0000, Test acc micro: 0.1910,Train acc macro: 1.0000, Test acc macro: 0.1807\n",
      "45\n",
      "Loss: 3856207.2500, Epoch: 045, Train acc micro: 0.6262, Test acc micro: 0.1608,Train acc macro: 0.6255, Test acc macro: 0.1583\n",
      "46\n",
      "Loss: 3721620.5000, Epoch: 046, Train acc micro: 1.0000, Test acc micro: 0.1759,Train acc macro: 1.0000, Test acc macro: 0.1724\n",
      "47\n",
      "Loss: 3595120.2500, Epoch: 047, Train acc micro: 1.0000, Test acc micro: 0.1709,Train acc macro: 1.0000, Test acc macro: 0.1677\n",
      "48\n",
      "Loss: 3476105.5000, Epoch: 048, Train acc micro: 0.9686, Test acc micro: 0.1508,Train acc macro: 0.9687, Test acc macro: 0.1505\n",
      "49\n",
      "Loss: 3364003.7500, Epoch: 049, Train acc micro: 0.7660, Test acc micro: 0.1809,Train acc macro: 0.7656, Test acc macro: 0.1767\n",
      "50\n",
      "Loss: 3258276.2500, Epoch: 050, Train acc micro: 1.0000, Test acc micro: 0.1658,Train acc macro: 1.0000, Test acc macro: 0.1624\n",
      "51\n",
      "Loss: 3158410.5000, Epoch: 051, Train acc micro: 0.8160, Test acc micro: 0.1910,Train acc macro: 0.8157, Test acc macro: 0.1896\n",
      "52\n",
      "Loss: 3063941.5000, Epoch: 052, Train acc micro: 0.6676, Test acc micro: 0.2412,Train acc macro: 0.6675, Test acc macro: 0.2391\n",
      "53\n",
      "Loss: 2974447.5000, Epoch: 053, Train acc micro: 1.0000, Test acc micro: 0.2714,Train acc macro: 1.0000, Test acc macro: 0.2640\n",
      "54\n",
      "Loss: 2889539.5000, Epoch: 054, Train acc micro: 0.6904, Test acc micro: 0.2010,Train acc macro: 0.6900, Test acc macro: 0.1989\n",
      "55\n",
      "Loss: 2808876.5000, Epoch: 055, Train acc micro: 0.9087, Test acc micro: 0.1608,Train acc macro: 0.9085, Test acc macro: 0.1595\n",
      "56\n",
      "Loss: 2732144.2500, Epoch: 056, Train acc micro: 0.9729, Test acc micro: 0.1558,Train acc macro: 0.9728, Test acc macro: 0.1525\n",
      "57\n",
      "Loss: 2659069.5000, Epoch: 057, Train acc micro: 0.9272, Test acc micro: 0.1910,Train acc macro: 0.9274, Test acc macro: 0.1920\n",
      "58\n",
      "Loss: 2589391.7500, Epoch: 058, Train acc micro: 0.4465, Test acc micro: 0.1709,Train acc macro: 0.4451, Test acc macro: 0.1594\n",
      "59\n",
      "Loss: 2522889.2500, Epoch: 059, Train acc micro: 1.0000, Test acc micro: 0.1608,Train acc macro: 1.0000, Test acc macro: 0.1569\n",
      "60\n",
      "Loss: 2459349.2500, Epoch: 060, Train acc micro: 0.9786, Test acc micro: 0.1608,Train acc macro: 0.9786, Test acc macro: 0.1603\n",
      "61\n",
      "Loss: 2398585.2500, Epoch: 061, Train acc micro: 0.5735, Test acc micro: 0.1809,Train acc macro: 0.5729, Test acc macro: 0.1794\n",
      "62\n",
      "Loss: 2340419.2500, Epoch: 062, Train acc micro: 1.0000, Test acc micro: 0.1809,Train acc macro: 1.0000, Test acc macro: 0.1762\n",
      "63\n",
      "Loss: 2284695.2500, Epoch: 063, Train acc micro: 0.6262, Test acc micro: 0.2010,Train acc macro: 0.6264, Test acc macro: 0.2011\n",
      "64\n",
      "Loss: 2231259.0000, Epoch: 064, Train acc micro: 0.9486, Test acc micro: 0.1859,Train acc macro: 0.9487, Test acc macro: 0.1778\n",
      "65\n",
      "Loss: 2179979.5000, Epoch: 065, Train acc micro: 1.0000, Test acc micro: 0.1759,Train acc macro: 1.0000, Test acc macro: 0.1704\n",
      "66\n",
      "Loss: 2130726.7500, Epoch: 066, Train acc micro: 0.8245, Test acc micro: 0.1960,Train acc macro: 0.8248, Test acc macro: 0.1965\n",
      "67\n",
      "Loss: 2083384.1250, Epoch: 067, Train acc micro: 0.9315, Test acc micro: 0.1407,Train acc macro: 0.9316, Test acc macro: 0.1433\n",
      "68\n",
      "Loss: 2037843.1250, Epoch: 068, Train acc micro: 0.9957, Test acc micro: 0.1910,Train acc macro: 0.9957, Test acc macro: 0.1904\n",
      "69\n",
      "Loss: 1994001.3750, Epoch: 069, Train acc micro: 0.8845, Test acc micro: 0.1658,Train acc macro: 0.8842, Test acc macro: 0.1619\n",
      "70\n",
      "Loss: 1951763.2500, Epoch: 070, Train acc micro: 0.7746, Test acc micro: 0.1608,Train acc macro: 0.7745, Test acc macro: 0.1609\n",
      "71\n",
      "Loss: 1911043.8750, Epoch: 071, Train acc micro: 0.9586, Test acc micro: 0.2211,Train acc macro: 0.9584, Test acc macro: 0.2200\n",
      "72\n",
      "Loss: 1871758.6250, Epoch: 072, Train acc micro: 0.8260, Test acc micro: 0.1960,Train acc macro: 0.8260, Test acc macro: 0.1936\n",
      "73\n",
      "Loss: 1833833.8750, Epoch: 073, Train acc micro: 0.6006, Test acc micro: 0.1960,Train acc macro: 0.6003, Test acc macro: 0.1970\n",
      "74\n",
      "Loss: 1797197.5000, Epoch: 074, Train acc micro: 0.8716, Test acc micro: 0.1809,Train acc macro: 0.8713, Test acc macro: 0.1754\n",
      "75\n",
      "Loss: 1761782.2500, Epoch: 075, Train acc micro: 0.8217, Test acc micro: 0.2111,Train acc macro: 0.8213, Test acc macro: 0.2096\n",
      "76\n",
      "Loss: 1727523.7500, Epoch: 076, Train acc micro: 0.7076, Test acc micro: 0.1910,Train acc macro: 0.7056, Test acc macro: 0.1906\n",
      "77\n",
      "Loss: 1694368.6250, Epoch: 077, Train acc micro: 0.9358, Test acc micro: 0.1960,Train acc macro: 0.9358, Test acc macro: 0.1950\n",
      "78\n",
      "Loss: 1662259.1250, Epoch: 078, Train acc micro: 0.6262, Test acc micro: 0.1558,Train acc macro: 0.6262, Test acc macro: 0.1524\n",
      "79\n",
      "Loss: 1631146.0000, Epoch: 079, Train acc micro: 0.4422, Test acc micro: 0.1809,Train acc macro: 0.4394, Test acc macro: 0.1703\n",
      "80\n",
      "Loss: 1600980.3750, Epoch: 080, Train acc micro: 0.9957, Test acc micro: 0.1307,Train acc macro: 0.9957, Test acc macro: 0.1311\n",
      "81\n",
      "Loss: 1571718.8750, Epoch: 081, Train acc micro: 0.6348, Test acc micro: 0.1658,Train acc macro: 0.6341, Test acc macro: 0.1634\n",
      "82\n",
      "Loss: 1543317.8750, Epoch: 082, Train acc micro: 0.4151, Test acc micro: 0.2312,Train acc macro: 0.4013, Test acc macro: 0.2139\n",
      "83\n",
      "Loss: 1515741.5000, Epoch: 083, Train acc micro: 0.8716, Test acc micro: 0.1859,Train acc macro: 0.8716, Test acc macro: 0.1863\n",
      "84\n",
      "Loss: 1488953.3750, Epoch: 084, Train acc micro: 0.4194, Test acc micro: 0.2362,Train acc macro: 0.4184, Test acc macro: 0.2355\n",
      "85\n",
      "Loss: 1462916.3750, Epoch: 085, Train acc micro: 0.9544, Test acc micro: 0.1809,Train acc macro: 0.9544, Test acc macro: 0.1769\n",
      "86\n",
      "Loss: 1437601.5000, Epoch: 086, Train acc micro: 0.7147, Test acc micro: 0.1960,Train acc macro: 0.7144, Test acc macro: 0.1936\n",
      "87\n",
      "Loss: 1412978.6250, Epoch: 087, Train acc micro: 0.7803, Test acc micro: 0.2060,Train acc macro: 0.7803, Test acc macro: 0.2045\n",
      "88\n",
      "Loss: 1389016.6250, Epoch: 088, Train acc micro: 0.9914, Test acc micro: 0.1809,Train acc macro: 0.9915, Test acc macro: 0.1743\n",
      "89\n",
      "Loss: 1365694.1250, Epoch: 089, Train acc micro: 0.9358, Test acc micro: 0.1759,Train acc macro: 0.9361, Test acc macro: 0.1725\n",
      "90\n",
      "Loss: 1342980.2500, Epoch: 090, Train acc micro: 0.4094, Test acc micro: 0.2161,Train acc macro: 0.4077, Test acc macro: 0.2171\n",
      "91\n",
      "Loss: 1320855.7500, Epoch: 091, Train acc micro: 0.5763, Test acc micro: 0.1809,Train acc macro: 0.5766, Test acc macro: 0.1774\n",
      "92\n",
      "Loss: 1299297.1250, Epoch: 092, Train acc micro: 0.7589, Test acc micro: 0.2060,Train acc macro: 0.7584, Test acc macro: 0.2079\n",
      "93\n",
      "Loss: 1278283.8750, Epoch: 093, Train acc micro: 0.7233, Test acc micro: 0.2261,Train acc macro: 0.7222, Test acc macro: 0.2249\n",
      "94\n",
      "Loss: 1257795.2500, Epoch: 094, Train acc micro: 0.4394, Test acc micro: 0.2060,Train acc macro: 0.4362, Test acc macro: 0.1888\n",
      "95\n",
      "Loss: 1237810.3750, Epoch: 095, Train acc micro: 0.6334, Test acc micro: 0.2161,Train acc macro: 0.6330, Test acc macro: 0.2077\n",
      "96\n",
      "Loss: 1218313.8750, Epoch: 096, Train acc micro: 0.9986, Test acc micro: 0.1859,Train acc macro: 0.9986, Test acc macro: 0.1856\n",
      "97\n",
      "Loss: 1199285.7500, Epoch: 097, Train acc micro: 0.6405, Test acc micro: 0.2161,Train acc macro: 0.6397, Test acc macro: 0.2101\n",
      "98\n",
      "Loss: 1180712.2500, Epoch: 098, Train acc micro: 0.4308, Test acc micro: 0.1859,Train acc macro: 0.4282, Test acc macro: 0.1822\n",
      "99\n",
      "Loss: 1162575.6250, Epoch: 099, Train acc micro: 0.7361, Test acc micro: 0.2211,Train acc macro: 0.7365, Test acc macro: 0.2175\n",
      "Loss: 1162575.6250, Epoch: 099, Train acc micro: 0.7361, Test acc micro: 0.2211,Train acc macro: 0.7365, Test acc macro: 0.2175\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = HOPE_CN\n",
    "loss_name = 'HOPE_CN'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis=analysis.drop(columns=['Unnamed: 0'])\n",
    "conv = 'GCN'\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:24,410]\u001B[0m A new study created in memory with name: Node2Vec loss,GCN conv\u001B[0m\n",
      "\u001B[33m[W 2022-11-09 13:33:24,426]\u001B[0m Trial 0 failed because of the following error: TypeError(\"'NoneType' object is not callable\")\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1420\\2232532568.py\", line 48, in objective\n",
      "    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,loss_to_train)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1420\\1223343394.py\", line 56, in train\n",
      "    samples = self.sampling(Sampler,epoch, indices_of_train_data,loss)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1420\\1223343394.py\", line 41, in sampling\n",
      "    self.samples = Sampler.sample(nodes)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\", line 84, in sample\n",
      "    return (self.pos_sample(batch), self.neg_sample(batch))\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\", line 148, in pos_sample\n",
      "    rw = RW(rowptr, col, start, self.walk_length, self.p, self.q)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\2516108346.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m                 \u001B[0mMO\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMainOptuna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'unsupervised'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m                 \u001B[0mbest_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMO\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m500\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m                 \u001B[0mloss_trgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\2232532568.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, number_of_trials)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m         \u001B[0mstudy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"maximize\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstudy_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Name\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" loss,\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_trials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m         \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    426\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m             \u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    429\u001B[0m         )\n\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0mprogress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             )\n\u001B[0;32m     78\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m             \u001B[0mfrozen_trial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     ):\n\u001B[1;32m--> 234\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\2232532568.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mLossSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss_to_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\1223343394.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, model, data, optimizer, Sampler, train_loader, dropout, epoch, loss)\u001B[0m\n\u001B[0;32m     54\u001B[0m                 \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minference\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m                 \u001B[1;31m#print('after',out, sum(sum(out)))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m                 \u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msampling\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices_of_train_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m                 \u001B[1;31m#print('loss',loss)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\1223343394.py\u001B[0m in \u001B[0;36msampling\u001B[1;34m(self, Sampler, epoch, nodes, loss)\u001B[0m\n\u001B[0;32m     39\u001B[0m                         \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSampler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnodes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\u001B[0m in \u001B[0;36msample\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     82\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m             \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos_sample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mneg_sample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mabc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabstractmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\u001B[0m in \u001B[0;36mpos_sample\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    146\u001B[0m             \u001B[0md2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m             \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwalks_per_node\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 148\u001B[1;33m             \u001B[0mrw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRW\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrowptr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwalk_length\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    149\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "loss = Node2Vec\n",
    "loss_name = 'Node2Vec'\n",
    "device= 'cpu'\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "for name in ['Cornell']:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"walks_per_node\"] = best_values['walk_length']\n",
    "                loss_trgt[\"walk_length\"] = best_values['walk_length']\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"context_size\"] = best_values['context_size']\n",
    "                loss_trgt[\"p\"] = best_values['p']\n",
    "                loss_trgt[\"q\"] = best_values['q']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:33,835]\u001B[0m A new study created in memory with name: VERSE_PPR loss,GCN conv\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:38,054]\u001B[0m Trial 0 finished with value: 0.34455272098781475 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007864763188679938, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.6846051283705041}. Best is trial 0 with value: 0.34455272098781475.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:40,382]\u001B[0m Trial 1 finished with value: 0.5937950762616616 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008292555042793134, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.24370564174009957}. Best is trial 1 with value: 0.5937950762616616.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:41,694]\u001B[0m Trial 2 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00838311001505726, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.8825197474187313}. Best is trial 1 with value: 0.5937950762616616.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:43,288]\u001B[0m Trial 3 finished with value: 0.5060742150229659 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008503600728225862, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.7378805460311791}. Best is trial 1 with value: 0.5937950762616616.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:44,554]\u001B[0m Trial 4 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007423543266483855, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.29435392308483377}. Best is trial 1 with value: 0.5937950762616616.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:45,085]\u001B[0m Trial 5 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007414262947416338, 'num_negative_samples': 16, 'alpha': 0.7, 'lmbda': 0.27469109483896226}. Best is trial 1 with value: 0.5937950762616616.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:46,444]\u001B[0m Trial 6 finished with value: 0.6362023392900426 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00843129304959346, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9266987788592684}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:46,991]\u001B[0m Trial 7 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008408806453731276, 'num_negative_samples': 11, 'alpha': 0.7, 'lmbda': 0.8210711244035053}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:48,648]\u001B[0m Trial 8 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005584313824556686, 'num_negative_samples': 6, 'alpha': 0.2, 'lmbda': 0.8776363274652687}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:49,913]\u001B[0m Trial 9 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005130636464931892, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.9354831615368193}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:50,554]\u001B[0m Trial 10 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009867352870014773, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.5530993271178664}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:51,960]\u001B[0m Trial 11 finished with value: 0.590668171555645 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009469115407001606, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.0012895582579492693}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:52,976]\u001B[0m Trial 12 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.006536298307563684, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.3177809379810911}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:54,398]\u001B[0m Trial 13 finished with value: 0.47919685895217384 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009190621455411673, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.08697705746559947}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:56,116]\u001B[0m Trial 14 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006651525776019276, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.4720000839644628}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:33:57,866]\u001B[0m Trial 15 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0090799737152562, 'num_negative_samples': 16, 'alpha': 0.8, 'lmbda': 0.4620566180597056}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:58,507]\u001B[0m Trial 16 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006813361935546516, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.1742999584848134}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:33:59,898]\u001B[0m Trial 17 finished with value: 0.5868938953886336 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008052513935058816, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.5956565619183319}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:01,288]\u001B[0m Trial 18 finished with value: 0.4039280811442083 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00876488196961329, 'num_negative_samples': 1, 'alpha': 0.3, 'lmbda': 0.998078579162295}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:01,960]\u001B[0m Trial 19 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007764208659280456, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.3894842271907923}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:03,335]\u001B[0m Trial 20 finished with value: 0.36371359845261 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009891727449324716, 'num_negative_samples': 16, 'alpha': 0.5, 'lmbda': 0.1825390507220206}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:04,710]\u001B[0m Trial 21 finished with value: 0.5477623325720284 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009190488570332821, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.014526969639288123}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:06,069]\u001B[0m Trial 22 finished with value: 0.5859465277082315 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009682820984846817, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.028795280513376192}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:07,444]\u001B[0m Trial 23 finished with value: 0.485912657903775 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008878434894802454, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.1616004329867724}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:08,804]\u001B[0m Trial 24 finished with value: 0.4388537257362555 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009312803995581901, 'num_negative_samples': 1, 'alpha': 0.1, 'lmbda': 0.10595965700324594}. Best is trial 6 with value: 0.6362023392900426.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:10,179]\u001B[0m Trial 25 finished with value: 0.7564060233433313 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009532900570990644, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23179621691937463}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:11,554]\u001B[0m Trial 26 finished with value: 0.5084900112128733 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008056269732675408, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.38319477951376113}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:12,944]\u001B[0m Trial 27 finished with value: 0.7274384280931732 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007212502521862741, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2516859539095196}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:14,116]\u001B[0m Trial 28 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007048650019708419, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.6554442868293399}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:14,757]\u001B[0m Trial 29 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.006156117800245046, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3987739818705071}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:16,023]\u001B[0m Trial 30 finished with value: 0.5849976258261415 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007739109915224301, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.7260478711389963}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:17,398]\u001B[0m Trial 31 finished with value: 0.5107313979447131 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00706013635892268, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.257192610328388}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:18,788]\u001B[0m Trial 32 finished with value: 0.6582805886043833 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008195852318534274, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2347567646028911}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:20,194]\u001B[0m Trial 33 finished with value: 0.5211323702941711 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008647136202597631, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3413273600460475}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:21,585]\u001B[0m Trial 34 finished with value: 0.5981452814975453 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008068209432767532, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23542625820847662}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:22,990]\u001B[0m Trial 35 finished with value: 0.600389736968671 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007575965069633546, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.20917607933667304}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:24,255]\u001B[0m Trial 36 finished with value: 0.594418483337567 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007242094411018631, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.10277862994642303}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:25,646]\u001B[0m Trial 37 finished with value: 0.5711964916723189 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008443245860454487, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.5311051554093502}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:26,177]\u001B[0m Trial 38 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008296022568401566, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.7878268483662216}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:27,458]\u001B[0m Trial 39 finished with value: 0.5350621331130491 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00619050615534749, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.4350282511643353}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:28,677]\u001B[0m Trial 40 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009512602945901873, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.33455991739036395}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:30,052]\u001B[0m Trial 41 finished with value: 0.6068631050598053 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007599182610313218, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.22092533741158024}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:31,433]\u001B[0m Trial 42 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007569529839915861, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2794138805480402}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:32,823]\u001B[0m Trial 43 finished with value: 0.49209475201861536 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007347879879647446, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2850618151421027}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:34,214]\u001B[0m Trial 44 finished with value: 0.7218802609235906 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008150470940352244, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.28932928590811824}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:35,589]\u001B[0m Trial 45 finished with value: 0.5497474167490214 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007998815720371448, 'num_negative_samples': 11, 'alpha': 0.2, 'lmbda': 0.1401909220386402}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:36,979]\u001B[0m Trial 46 finished with value: 0.5420342882056847 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008593180681644013, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.33604658862264236}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:37,589]\u001B[0m Trial 47 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008253209533854177, 'num_negative_samples': 11, 'alpha': 0.1, 'lmbda': 0.8808969847475779}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:38,979]\u001B[0m Trial 48 finished with value: 0.39368230209872906 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008877846285853327, 'num_negative_samples': 16, 'alpha': 0.7, 'lmbda': 0.05972112810729591}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:39,510]\u001B[0m Trial 49 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007843276062528244, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.20299427604584597}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:40,885]\u001B[0m Trial 50 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008229784036168628, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.6132877748574566}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:42,276]\u001B[0m Trial 51 finished with value: 0.5824596632036069 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007112355143096558, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2737330528767419}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:43,666]\u001B[0m Trial 52 finished with value: 0.6130730673081193 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007519168059963936, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.13109979756816295}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:45,041]\u001B[0m Trial 53 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006805760764435774, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.15156538900577524}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:46,447]\u001B[0m Trial 54 finished with value: 0.5993262210114948 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008982600781235863, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.12698081286916946}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:47,822]\u001B[0m Trial 55 finished with value: 0.42677286260108355 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007415400627964527, 'num_negative_samples': 11, 'alpha': 0.5, 'lmbda': 0.05996190138970034}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:49,291]\u001B[0m Trial 56 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007936880199504006, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.3039086817698276}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:50,588]\u001B[0m Trial 57 finished with value: 0.43296981873272894 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006378698133439817, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.24209079282566304}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:51,963]\u001B[0m Trial 58 finished with value: 0.590668171555645 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008488279797570974, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9382560968712202}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:53,369]\u001B[0m Trial 59 finished with value: 0.38078865529319544 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007734602007589865, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.18525799888091976}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:54,744]\u001B[0m Trial 60 finished with value: 0.6673607497975667 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005089437061115552, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.3760961453813324}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:56,104]\u001B[0m Trial 61 finished with value: 0.43974545861903835 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005367143150768379, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.3776458551456864}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:57,447]\u001B[0m Trial 62 finished with value: 0.47764856133788175 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0060559398531638605, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.4249825498223879}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:34:58,807]\u001B[0m Trial 63 finished with value: 0.3927922024247863 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005266071523348327, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.36045182778744744}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:00,151]\u001B[0m Trial 64 finished with value: 0.594418483337567 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009639128608417096, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.5005918589049526}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:01,557]\u001B[0m Trial 65 finished with value: 0.338296385503074 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005604714627759827, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.31557725088083727}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:02,791]\u001B[0m Trial 66 finished with value: 0.43945613333038497 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005710728728181749, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24171905163428092}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:03,447]\u001B[0m Trial 67 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008728672535318916, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.18721288646603093}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:04,619]\u001B[0m Trial 68 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009301972122412195, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.42134639321917233}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:05,994]\u001B[0m Trial 69 finished with value: 0.5876729338026236 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008159587246740227, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.8087592911996007}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:07,385]\u001B[0m Trial 70 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005028222036374863, 'num_negative_samples': 11, 'alpha': 0.5, 'lmbda': 0.08009815414647514}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:08,807]\u001B[0m Trial 71 finished with value: 0.658200207556571 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007604700694220485, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28226434568143177}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:10,197]\u001B[0m Trial 72 finished with value: 0.5815846806276286 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007285763335009061, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.26811739232763115}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:11,572]\u001B[0m Trial 73 finished with value: 0.5724620515980234 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008367510731695912, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.16376058999771587}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:12,963]\u001B[0m Trial 74 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006949307915094559, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.30004081926754245}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:14,354]\u001B[0m Trial 75 finished with value: 0.5362664443598958 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0069891635723972265, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.36616746077546947}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:15,729]\u001B[0m Trial 76 finished with value: 0.5263430792145338 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006846185328359063, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3064592960583564}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:17,119]\u001B[0m Trial 77 finished with value: 0.5007184380950696 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006596762020209192, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.21446118830308264}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:18,354]\u001B[0m Trial 78 finished with value: 0.505616601930898 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007724404173606268, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.4508105727195654}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:18,916]\u001B[0m Trial 79 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009976438169100285, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3439008385420069}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:20,231]\u001B[0m Trial 80 finished with value: 0.42745297914825214 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007184744374039648, 'num_negative_samples': 11, 'alpha': 0.2, 'lmbda': 0.49000203436854745}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:21,590]\u001B[0m Trial 81 finished with value: 0.48666426339228763 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007512384073089061, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.252710939063539}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:22,965]\u001B[0m Trial 82 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007881668551134712, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28839352237334903}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:24,340]\u001B[0m Trial 83 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0076246319992977355, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.4074168544254009}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:25,715]\u001B[0m Trial 84 finished with value: 0.6531599602878279 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007334289606157517, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.22461886872586362}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:27,122]\u001B[0m Trial 85 finished with value: 0.3819279328210309 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00693778291748971, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.22961298651132878}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:27,747]\u001B[0m Trial 86 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008127516582813743, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.3144246687849066}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:29,137]\u001B[0m Trial 87 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00859310575587678, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.19898317691683798}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:30,481]\u001B[0m Trial 88 finished with value: 0.4353647708073435 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007208461929839659, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.26004280294869475}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:31,856]\u001B[0m Trial 89 finished with value: 0.6068631050598053 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007325893037805552, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.33491047985035893}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:33,231]\u001B[0m Trial 90 finished with value: 0.3001591667593096 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009161576805217547, 'num_negative_samples': 11, 'alpha': 0.1, 'lmbda': 0.22545898921375215}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:34,622]\u001B[0m Trial 91 finished with value: 0.5897197839303827 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007424556494938082, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.11708988116442298}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:36,028]\u001B[0m Trial 92 finished with value: 0.4122312949338949 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006725498056908377, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.1445758133164851}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:37,419]\u001B[0m Trial 93 finished with value: 0.5170493857844406 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005931722645828675, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2944995827398351}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:38,794]\u001B[0m Trial 94 finished with value: 0.5214359259166952 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00782762475341584, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.17067917230269863}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:40,200]\u001B[0m Trial 95 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0064239099823814325, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.25350203350339473}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:41,592]\u001B[0m Trial 96 finished with value: 0.5421395981805276 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008014554562213559, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28371444966057713}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:42,827]\u001B[0m Trial 97 finished with value: 0.47381739518152793 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007638850731804473, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.7212906925964564}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:44,108]\u001B[0m Trial 98 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007119879103297505, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.849070328443041}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:45,499]\u001B[0m Trial 99 finished with value: 0.53777119759482 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009749187041482548, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.20273751784073574}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:46,139]\u001B[0m Trial 100 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008362437298016692, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.9975944154296892}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:47,514]\u001B[0m Trial 101 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008632655729045284, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.19916521324257486}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:48,905]\u001B[0m Trial 102 finished with value: 0.5211573066470477 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008558526777177401, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.2350553084610543}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:50,280]\u001B[0m Trial 103 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00875754115787721, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.14111882340948567}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:51,655]\u001B[0m Trial 104 finished with value: 0.47840056688565297 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008916510884209505, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.18597264421177806}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:53,045]\u001B[0m Trial 105 finished with value: 0.5671308728156006 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007430553175422913, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.34828172523760825}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:54,436]\u001B[0m Trial 106 finished with value: 0.43221478067527724 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007507718908324585, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.2745911761805696}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:55,811]\u001B[0m Trial 107 finished with value: 0.5671308728156006 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007932299273999925, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.5804379889778998}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:57,202]\u001B[0m Trial 108 finished with value: 0.40170092900519455 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008205921650403281, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.21719014335633183}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:58,577]\u001B[0m Trial 109 finished with value: 0.5420342882056847 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00848305804733229, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.0788790721267411}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:35:59,967]\u001B[0m Trial 110 finished with value: 0.507331864675414 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007779980044684835, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.3179931070481786}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:01,358]\u001B[0m Trial 111 finished with value: 0.594418483337567 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009392775228958075, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24929781227168218}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:02,749]\u001B[0m Trial 112 finished with value: 0.6869147340477214 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009037837589906887, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.27710019232582267}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:04,124]\u001B[0m Trial 113 finished with value: 0.445896321370523 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007682102787256717, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.37949486544435707}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:05,483]\u001B[0m Trial 114 finished with value: 0.34815531191139565 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009014777409941886, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.16905454317982754}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:06,874]\u001B[0m Trial 115 finished with value: 0.3086066999241838 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008811451324187506, 'num_negative_samples': 6, 'alpha': 0.3, 'lmbda': 0.26576248977727357}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:08,264]\u001B[0m Trial 116 finished with value: 0.48666426339228763 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009564541811636112, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.2983590199476597}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:09,530]\u001B[0m Trial 117 finished with value: 0.3854062943127764 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007572905449859943, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.3235249981275764}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:10,874]\u001B[0m Trial 118 finished with value: 0.4109609335312651 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007365307005555699, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.6551161939343618}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:11,452]\u001B[0m Trial 119 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00910857276326621, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.19149748075399867}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:12,092]\u001B[0m Trial 120 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00931330959119818, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28076104430672993}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:13,467]\u001B[0m Trial 121 finished with value: 0.4281744192888376 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008377184900917357, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.235184824373938}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:14,842]\u001B[0m Trial 122 finished with value: 0.5804909103247844 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008132128036225537, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.21597983794267497}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:16,249]\u001B[0m Trial 123 finished with value: 0.5867482460762062 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00828781539563848, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.26333383577962466}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:17,639]\u001B[0m Trial 124 finished with value: 0.34689750898700683 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006943884966972864, 'num_negative_samples': 16, 'alpha': 0.6, 'lmbda': 0.36002716429148135}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:19,030]\u001B[0m Trial 125 finished with value: 0.5025859056843841 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007163430506107648, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.12415906562170814}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:20,405]\u001B[0m Trial 126 finished with value: 0.3790570016848598 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009833300750270927, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.30116870648414923}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:21,827]\u001B[0m Trial 127 finished with value: 0.53777119759482 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007284325043585071, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.24611005305730266}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:23,202]\u001B[0m Trial 128 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008064999245478021, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.16128941048302364}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:24,577]\u001B[0m Trial 129 finished with value: 0.4425306015783918 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00796017433663759, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.09805453368840031}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:25,936]\u001B[0m Trial 130 finished with value: 0.5007184380950696 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007510526949032662, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.21104033653602483}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:27,327]\u001B[0m Trial 131 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008707414884668774, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.1544585165613413}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:28,727]\u001B[0m Trial 132 finished with value: 0.4166666666666667 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008690703367359935, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.15547552194192849}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:30,133]\u001B[0m Trial 133 finished with value: 0.6552619260426573 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008500491526105328, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.280218241480342}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:31,508]\u001B[0m Trial 134 finished with value: 0.5060742150229659 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008447677732393877, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2741122188045612}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:32,920]\u001B[0m Trial 135 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008648964981176068, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.18225888208153232}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:34,295]\u001B[0m Trial 136 finished with value: 0.31429593859487137 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008833196964456991, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3304503057689738}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:35,701]\u001B[0m Trial 137 finished with value: 0.2981423969999719 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00806649612772091, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.13126114635749786}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:36,966]\u001B[0m Trial 138 finished with value: 0.4623045426946164 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007045931054483079, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.3082800371202571}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:38,373]\u001B[0m Trial 139 finished with value: 0.4 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008505712626036704, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28398642146085884}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:38,951]\u001B[0m Trial 140 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008318059802857795, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.15877730747134236}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:40,341]\u001B[0m Trial 141 finished with value: 0.5235208439728777 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008583824492279958, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.03312894938710825}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:41,716]\u001B[0m Trial 142 finished with value: 0.5472516663721834 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00817207546052837, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24202550544939772}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:43,107]\u001B[0m Trial 143 finished with value: 0.5724820435923648 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008981790682974299, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.1969559006798639}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:44,482]\u001B[0m Trial 144 finished with value: 0.3512815008087638 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0078110431450395265, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.22669239778197534}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:45,873]\u001B[0m Trial 145 finished with value: 0.5490732933602595 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005427230757971519, 'num_negative_samples': 6, 'alpha': 0.3, 'lmbda': 0.2610017507710936}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:47,232]\u001B[0m Trial 146 finished with value: 0.49923689043066977 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008222035168463204, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.29825801802516416}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:48,529]\u001B[0m Trial 147 finished with value: 0.4303314829119352 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007440046039942683, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3510758129633737}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:49,904]\u001B[0m Trial 148 finished with value: 0.5497474167490214 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007256892776591342, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3994361040562153}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:51,295]\u001B[0m Trial 149 finished with value: 0.445435403187374 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00769458353434801, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.5243084855363028}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:51,951]\u001B[0m Trial 150 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007883224880199042, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.22660402106674243}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:53,357]\u001B[0m Trial 151 finished with value: 0.47764856133788175 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008425088438714992, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.1800407491982567}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:54,748]\u001B[0m Trial 152 finished with value: 0.594418483337567 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008294605067598557, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.770258935256693}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:56,123]\u001B[0m Trial 153 finished with value: 0.5356977317285162 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008537796191016285, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.10826997132263608}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:57,482]\u001B[0m Trial 154 finished with value: 0.619750683009635 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008087417305389677, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.201413265663849}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:36:58,857]\u001B[0m Trial 155 finished with value: 0.4890331677437014 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00874446497576026, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.20821628094280092}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:00,248]\u001B[0m Trial 156 finished with value: 0.34689750898700683 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007995706884456902, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.24735245979445405}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:01,635]\u001B[0m Trial 157 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008116960760700887, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.16494018764094504}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:03,011]\u001B[0m Trial 158 finished with value: 0.4216370213557839 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007631422893556591, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.27874418230149595}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:04,433]\u001B[0m Trial 159 finished with value: 0.5419983240157367 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008937908174976233, 'num_negative_samples': 16, 'alpha': 0.6, 'lmbda': 0.2572818326398919}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:05,839]\u001B[0m Trial 160 finished with value: 0.5039351320199363 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0073476491222877515, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.22770853831882157}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:07,249]\u001B[0m Trial 161 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00586630130475077, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.18394314245186744}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:08,639]\u001B[0m Trial 162 finished with value: 0.5354354178526918 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008412991136021597, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.20679081940092786}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:10,023]\u001B[0m Trial 163 finished with value: 0.5472516663721834 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008071831358587602, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.13677695558250058}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:11,473]\u001B[0m Trial 164 finished with value: 0.7218802609235906 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009237700671479438, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.32774141575863386}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:12,883]\u001B[0m Trial 165 finished with value: 0.5205054523498538 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00941947669951121, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.3251411610064837}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:14,308]\u001B[0m Trial 166 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009081128141047931, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2932092646839537}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:15,746]\u001B[0m Trial 167 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00958424973904818, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.30604140275458996}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:17,058]\u001B[0m Trial 168 finished with value: 0.5555277770832986 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009258869144339495, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27370793570884433}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:18,514]\u001B[0m Trial 169 finished with value: 0.552593410315562 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009504392957097197, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.9127589121724232}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:19,794]\u001B[0m Trial 170 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008659797600682173, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.33891529489269856}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:21,200]\u001B[0m Trial 171 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008202036717539274, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2442529170540769}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:22,644]\u001B[0m Trial 172 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008219538519585208, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24545157070359103}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:24,035]\u001B[0m Trial 173 finished with value: 0.5939084716749481 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009719613637538592, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2734749234834726}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:25,456]\u001B[0m Trial 174 finished with value: 0.3551765656924165 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008342697766079075, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.15523681097284342}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:26,894]\u001B[0m Trial 175 finished with value: 0.40170092900519455 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00916193027836537, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.22941688572994337}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:28,300]\u001B[0m Trial 176 finished with value: 0.4654746681256314 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007544872677191659, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29010065797666124}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:29,613]\u001B[0m Trial 177 finished with value: 0.33554819712314443 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008223464169614888, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.1968011044514557}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:30,253]\u001B[0m Trial 178 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00854923830927502, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.372264605605446}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:31,683]\u001B[0m Trial 179 finished with value: 0.6073622386096199 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00881035417194093, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2638606714674755}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:33,058]\u001B[0m Trial 180 finished with value: 0.5887638742179041 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007970232634191754, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.318978654997928}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:34,496]\u001B[0m Trial 181 finished with value: 0.49909971859391894 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008403218605927278, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.21504180411304682}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:35,886]\u001B[0m Trial 182 finished with value: 0.585397350933135 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0077553180496834125, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24787981928754568}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:37,293]\u001B[0m Trial 183 finished with value: 0.5824596632036069 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008070364472001242, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.17305093684656206}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:38,699]\u001B[0m Trial 184 finished with value: 0.5244044240850758 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007870732266710718, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.29620535197450615}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:40,121]\u001B[0m Trial 185 finished with value: 0.3371708921694098 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008273610195326998, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.2580134809500993}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:41,548]\u001B[0m Trial 186 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009277107505811495, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.22926335288447308}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:42,982]\u001B[0m Trial 187 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007421519135022214, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.31530946877185434}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:44,420]\u001B[0m Trial 188 finished with value: 0.5887638742179041 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007217731938074022, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.20544454781739963}. Best is trial 25 with value: 0.7564060233433313.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:45,889]\u001B[0m Trial 189 finished with value: 0.7845457173236026 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00849154890512438, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27264892483184944}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:47,342]\u001B[0m Trial 190 finished with value: 0.38297084310253526 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008513478768474211, 'num_negative_samples': 16, 'alpha': 0.1, 'lmbda': 0.28089718712594636}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:48,764]\u001B[0m Trial 191 finished with value: 0.6457775309877385 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008648402003690502, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2417448085007723}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:50,155]\u001B[0m Trial 192 finished with value: 0.438631577543972 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008701062753591771, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23320289936832572}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:51,608]\u001B[0m Trial 193 finished with value: 0.6531599602878279 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008837751560119988, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.258342749087347}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:53,585]\u001B[0m Trial 194 finished with value: 0.38873012632302 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008879424955042984, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.25713643884998716}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:55,212]\u001B[0m Trial 195 finished with value: 0.6018490028422596 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008666595184344398, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23868078245193697}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:56,731]\u001B[0m Trial 196 finished with value: 0.5270256078080107 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008947236449575624, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27387796045980267}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:58,271]\u001B[0m Trial 197 finished with value: 0.3535533905932738 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00907381489528245, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29771192565569815}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:37:59,762]\u001B[0m Trial 198 finished with value: 0.5978798520274098 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008812721480382117, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2664424430385343}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:01,191]\u001B[0m Trial 199 finished with value: 0.5456684072723902 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008584656735822501, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.21485192238694967}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:02,487]\u001B[0m Trial 200 finished with value: 0.44112695305392047 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008462947047685708, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.3320501864941644}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:03,918]\u001B[0m Trial 201 finished with value: 0.5571089394098522 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008749326368212936, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24980678085461178}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:05,346]\u001B[0m Trial 202 finished with value: 0.4720972537448868 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008602659482131498, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.19158367319812547}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:06,759]\u001B[0m Trial 203 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008161287739231866, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28571757134016}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:08,177]\u001B[0m Trial 204 finished with value: 0.34985509724063724 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00836300873766437, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.3104184730494487}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:09,580]\u001B[0m Trial 205 finished with value: 0.6128258770283411 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007092659702369577, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2645918635349501}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:11,009]\u001B[0m Trial 206 finished with value: 0.4353647708073435 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0070069423326609625, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.26086372605031033}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:12,276]\u001B[0m Trial 207 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006890443095670503, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24151683697115203}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:13,650]\u001B[0m Trial 208 finished with value: 0.2924988129130707 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006756291426354309, 'num_negative_samples': 6, 'alpha': 0.5, 'lmbda': 0.2910718700952292}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:15,090]\u001B[0m Trial 209 finished with value: 0.5751574568914715 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007084507315913165, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2810479594343974}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:16,378]\u001B[0m Trial 210 finished with value: 0.47764856133788175 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0063113457164976185, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.21811488421350805}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:17,790]\u001B[0m Trial 211 finished with value: 0.491082086989147 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00718072536272028, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.1482565000762316}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:19,227]\u001B[0m Trial 212 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007401823251460287, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2627922529334577}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:20,612]\u001B[0m Trial 213 finished with value: 0.497152384915491 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007559302931236863, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24288419241921805}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:22,049]\u001B[0m Trial 214 finished with value: 0.44534630719624624 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007305037332552499, 'num_negative_samples': 11, 'alpha': 0.7, 'lmbda': 0.30515289410920365}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:22,698]\u001B[0m Trial 215 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.009005385188056521, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.4526835959683658}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:24,132]\u001B[0m Trial 216 finished with value: 0.5456684072723902 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008468062196929431, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.11977711974179936}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:25,513]\u001B[0m Trial 217 finished with value: 0.34665021214205866 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008742079624171156, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.2207106677297765}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:26,946]\u001B[0m Trial 218 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008115852508386583, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27119508204424875}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:28,377]\u001B[0m Trial 219 finished with value: 0.45180148198581543 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005052391618886171, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.19015260810060422}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:29,784]\u001B[0m Trial 220 finished with value: 0.42646376754566123 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00827806506302758, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.3232557248731489}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:31,212]\u001B[0m Trial 221 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008856560397812758, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23714081236403903}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:32,608]\u001B[0m Trial 222 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008592255485993608, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.6854138031411979}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:34,055]\u001B[0m Trial 223 finished with value: 0.5436502143433364 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008488604455766388, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.20651071339243773}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:35,466]\u001B[0m Trial 224 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00712669823897677, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.17594397699241965}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:36,889]\u001B[0m Trial 225 finished with value: 0.5346574472113764 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008351682084139469, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.253204183826299}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:38,322]\u001B[0m Trial 226 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0074957602009806425, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2845499078578173}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:39,695]\u001B[0m Trial 227 finished with value: 0.6078847008469694 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008657165028448176, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.14050634780271912}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:41,104]\u001B[0m Trial 228 finished with value: 0.5340273262532407 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008032913048595892, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.22615789959578786}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:42,487]\u001B[0m Trial 229 finished with value: 0.443471156521669 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009411847020145374, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.16276879000964364}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:43,916]\u001B[0m Trial 230 finished with value: 0.5436502143433364 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00921319433498036, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3557178010321555}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:45,320]\u001B[0m Trial 231 finished with value: 0.45656001088001874 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008661833354678006, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.13925604002462705}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:46,690]\u001B[0m Trial 232 finished with value: 0.629300022658921 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008593240339822134, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.11389145370501197}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:48,102]\u001B[0m Trial 233 finished with value: 0.47871355387816905 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008555287470624512, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.08850538878554615}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:49,496]\u001B[0m Trial 234 finished with value: 0.38873012632302 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008175057032724687, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.2710448026605817}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:50,922]\u001B[0m Trial 235 finished with value: 0.6981456921068893 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008415081473926488, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.29808513703517003}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:52,346]\u001B[0m Trial 236 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008450036257764006, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.06233483532351233}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:53,730]\u001B[0m Trial 237 finished with value: 0.6289320754704402 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008275742103931439, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.10386656406314884}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:55,180]\u001B[0m Trial 238 finished with value: 0.49846267922753223 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008282987998390536, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.10621919993842442}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:56,583]\u001B[0m Trial 239 finished with value: 0.5976384502119296 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0083760268460685, 'num_negative_samples': 11, 'alpha': 0.7, 'lmbda': 0.07470242059067322}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:57,868]\u001B[0m Trial 240 finished with value: 0.30266307715280527 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008231294494169641, 'num_negative_samples': 11, 'alpha': 0.1, 'lmbda': 0.09669216214487138}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:38:59,319]\u001B[0m Trial 241 finished with value: 0.5066228051190221 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008505557503394214, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.11851344175900314}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:00,708]\u001B[0m Trial 242 finished with value: 0.6428620419174487 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008410963127501241, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2986362561874141}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:02,149]\u001B[0m Trial 243 finished with value: 0.35374240605216134 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008400765638389316, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.30494189803869226}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:03,549]\u001B[0m Trial 244 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008579723155733543, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2934868945669053}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:04,961]\u001B[0m Trial 245 finished with value: 0.4387482193696061 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005227290658506894, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.3317664135980186}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:06,400]\u001B[0m Trial 246 finished with value: 0.5228688295026747 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00874105015890523, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2539839197315647}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:07,779]\u001B[0m Trial 247 finished with value: 0.4444444444444444 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007306992359656314, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.28298605938363497}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:09,094]\u001B[0m Trial 248 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008307737566685059, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.30476384162375336}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:10,518]\u001B[0m Trial 249 finished with value: 0.5925462944877059 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008454231870065488, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.25712234228385633}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:11,929]\u001B[0m Trial 250 finished with value: 0.5371966557170477 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008145393197593569, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.9822239970611073}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:13,361]\u001B[0m Trial 251 finished with value: 0.5585317107897025 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008613674409149907, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.23788638710027357}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:14,008]\u001B[0m Trial 252 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007671233945325187, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2758170638034504}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:15,435]\u001B[0m Trial 253 finished with value: 0.44305337860837524 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008334491493794182, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.30824311775704916}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:16,811]\u001B[0m Trial 254 finished with value: 0.39852669849304284 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008244009976889382, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.1261912440739827}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:18,250]\u001B[0m Trial 255 finished with value: 0.5388602512436507 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007223250735542504, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2689634886398432}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:19,684]\u001B[0m Trial 256 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008908600216835318, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.3234738842530114}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:21,071]\u001B[0m Trial 257 finished with value: 0.5268956705260043 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00847434547924638, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.47506719335459086}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:22,503]\u001B[0m Trial 258 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009103289687583354, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2889811548038868}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:23,930]\u001B[0m Trial 259 finished with value: 0.5815846806276286 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006520480993723769, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.5742696745372805}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:25,377]\u001B[0m Trial 260 finished with value: 0.5767461881775571 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007985407868247448, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.859316830244963}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:26,800]\u001B[0m Trial 261 finished with value: 0.5919209156385424 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005503470317107907, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.257026325114636}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:28,210]\u001B[0m Trial 262 finished with value: 0.24845199749997662 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008715022729166695, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.21905860681053188}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:29,627]\u001B[0m Trial 263 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007464495322580398, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3413234393691841}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:31,024]\u001B[0m Trial 264 finished with value: 0.5222708919053315 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00821986488841308, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.0995721656902752}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:32,460]\u001B[0m Trial 265 finished with value: 0.35276684147527876 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00894633036602988, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.3189879103953097}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:33,839]\u001B[0m Trial 266 finished with value: 0.6018490028422595 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008783776739776261, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.3429414860809391}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:35,265]\u001B[0m Trial 267 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008094005451443419, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24385958735107036}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:36,533]\u001B[0m Trial 268 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007012640086069965, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.17228137798777268}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:37,930]\u001B[0m Trial 269 finished with value: 0.5106277908033803 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008416716020347168, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.2939807865787416}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:39,227]\u001B[0m Trial 270 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006091410967163592, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.27237212695678115}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:40,660]\u001B[0m Trial 271 finished with value: 0.4013864859597432 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008540871476505466, 'num_negative_samples': 16, 'alpha': 0.2, 'lmbda': 0.2111896435114076}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:42,055]\u001B[0m Trial 272 finished with value: 0.4811252243246881 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007340444171095361, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2416953185223827}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:43,353]\u001B[0m Trial 273 finished with value: 0.38315459141851343 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008336102520224712, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.28198792767074765}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:44,785]\u001B[0m Trial 274 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008616340418663493, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.04812191172215563}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:45,425]\u001B[0m Trial 275 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005914923049421887, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.259048011951029}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:46,808]\u001B[0m Trial 276 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008937284175577315, 'num_negative_samples': 1, 'alpha': 0.1, 'lmbda': 0.6174761763284554}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:48,242]\u001B[0m Trial 277 finished with value: 0.5868938953886336 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00994806543493492, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.3882915889486532}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:49,645]\u001B[0m Trial 278 finished with value: 0.44112695305392047 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009336569548038166, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2313071753258198}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:51,086]\u001B[0m Trial 279 finished with value: 0.5804909103247844 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008883248842594602, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.31823591877802015}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:52,455]\u001B[0m Trial 280 finished with value: 0.45656001088001874 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008802434487884817, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.315712337524542}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:53,908]\u001B[0m Trial 281 finished with value: 0.5263430792145338 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007573461111386693, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29532632463046077}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:55,305]\u001B[0m Trial 282 finished with value: 0.5352973097975958 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008519306422970848, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.1954348505137649}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:56,722]\u001B[0m Trial 283 finished with value: 0.5490732933602595 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009011604080607572, 'num_negative_samples': 11, 'alpha': 0.5, 'lmbda': 0.33689638383617443}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:58,149]\u001B[0m Trial 284 finished with value: 0.5436502143433364 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0074155175608155545, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27164107878938704}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:39:59,571]\u001B[0m Trial 285 finished with value: 0.6786300321520707 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007086523102550581, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.25636933913764026}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:01,012]\u001B[0m Trial 286 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006829481327366394, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23974994847754988}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:02,408]\u001B[0m Trial 287 finished with value: 0.48097716301195775 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0071270548211246915, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.2607175715890821}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:03,820]\u001B[0m Trial 288 finished with value: 0.5107995490769662 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009628202410156663, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.08196661446560558}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:05,263]\u001B[0m Trial 289 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006963653038142705, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.29208854592717126}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:06,534]\u001B[0m Trial 290 finished with value: 0.538631095268481 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0071981102837266435, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.25108965286755436}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:07,945]\u001B[0m Trial 291 finished with value: 0.544491127783818 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005677974679271117, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.22526136526951915}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:09,361]\u001B[0m Trial 292 finished with value: 0.47919685895217384 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007120716147846282, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.27314991144582373}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:10,611]\u001B[0m Trial 293 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008403135929912047, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.11943773568739685}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:12,039]\u001B[0m Trial 294 finished with value: 0.438631577543972 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008269188593411645, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3652933594681634}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:13,455]\u001B[0m Trial 295 finished with value: 0.3551765656924165 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007036464359356242, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.5300839726250124}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:14,767]\u001B[0m Trial 296 finished with value: 0.5456684072723902 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008148935058804605, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.23544541282268766}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:15,446]\u001B[0m Trial 297 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.008452420078928552, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.4269675203319692}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:16,865]\u001B[0m Trial 298 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007293517368431286, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29914444688409547}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:18,276]\u001B[0m Trial 299 finished with value: 0.5868938953886336 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00918854130892512, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.259147234059248}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:19,659]\u001B[0m Trial 300 finished with value: 0.4611141535739958 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009484422355340095, 'num_negative_samples': 6, 'alpha': 0.4, 'lmbda': 0.2077243834276665}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:21,101]\u001B[0m Trial 301 finished with value: 0.530876695061553 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006900154066425306, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27846153787446587}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:22,533]\u001B[0m Trial 302 finished with value: 0.3929942040850532 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008634437192748552, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.22426170925440475}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:23,946]\u001B[0m Trial 303 finished with value: 0.4303314829119352 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008388852500430342, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2500886585648181}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:25,387]\u001B[0m Trial 304 finished with value: 0.5064111390119688 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009851604205224008, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.3042937071464929}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:26,808]\u001B[0m Trial 305 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008283062556323441, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.14036397037239495}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:28,201]\u001B[0m Trial 306 finished with value: 0.400126242704737 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007220623852040249, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2799177903696314}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:29,634]\u001B[0m Trial 307 finished with value: 0.42646376754566123 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00868987527960052, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.7824232311265638}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:31,023]\u001B[0m Trial 308 finished with value: 0.5897197839303827 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00851063779964687, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.10316987585890755}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:32,408]\u001B[0m Trial 309 finished with value: 0.47381739518152793 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008324008051370234, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.26217572378857695}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:33,800]\u001B[0m Trial 310 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007935546034252953, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23881338509653563}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:35,226]\u001B[0m Trial 311 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008542870681692094, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.1902943189588771}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:36,526]\u001B[0m Trial 312 finished with value: 0.34403862152295517 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006652787118066492, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.2915107447868078}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:37,899]\u001B[0m Trial 313 finished with value: 0.540975342310215 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008174910460938916, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.2168018746797818}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:39,308]\u001B[0m Trial 314 finished with value: 0.3929942040850532 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007065287034086675, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.31508333835615654}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:40,720]\u001B[0m Trial 315 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009085391629779864, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2693809569125782}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:41,961]\u001B[0m Trial 316 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008755503548439082, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24834015718688898}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:43,412]\u001B[0m Trial 317 finished with value: 0.5708992257184501 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007823554830873115, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2874694545881419}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:44,848]\u001B[0m Trial 318 finished with value: 0.42745297914825214 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008033245193673282, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.1292402230104467}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:46,278]\u001B[0m Trial 319 finished with value: 0.5897197839303827 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008407983243370927, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.15376136080165745}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:46,945]\u001B[0m Trial 320 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.008659273253246752, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3523387467750162}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:48,392]\u001B[0m Trial 321 finished with value: 0.5147568187266321 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008324675784768485, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.06935621807207623}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:49,796]\u001B[0m Trial 322 finished with value: 0.5107995490769662 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007341479319590185, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2337372523595426}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:51,195]\u001B[0m Trial 323 finished with value: 0.438631577543972 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008187818762207043, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.822816337836589}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:52,602]\u001B[0m Trial 324 finished with value: 0.5762170977946156 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008553440688075379, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.7362629465900098}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:54,011]\u001B[0m Trial 325 finished with value: 0.648454953840661 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007190377271220866, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.20009635537763998}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:55,392]\u001B[0m Trial 326 finished with value: 0.40490815907308 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008818742257071275, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.17668862828926313}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:56,835]\u001B[0m Trial 327 finished with value: 0.50709255283711 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007292329286599904, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.19743743127031343}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:58,240]\u001B[0m Trial 328 finished with value: 0.40688518719112343 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007482057070778784, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.20863800972069566}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:40:59,643]\u001B[0m Trial 329 finished with value: 0.40721779250446916 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007167375989871593, 'num_negative_samples': 6, 'alpha': 0.4, 'lmbda': 0.16177610140211957}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:01,054]\u001B[0m Trial 330 finished with value: 0.5876729338026236 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008448976795769626, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.21954404447817968}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:02,455]\u001B[0m Trial 331 finished with value: 0.491082086989147 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009771292682428425, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.19487078722598422}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:03,877]\u001B[0m Trial 332 finished with value: 0.4661372658534007 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008248452323785318, 'num_negative_samples': 11, 'alpha': 0.2, 'lmbda': 0.31044491770752247}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:05,306]\u001B[0m Trial 333 finished with value: 0.5244044240850758 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008086527947851875, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.24816627440219025}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:06,595]\u001B[0m Trial 334 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008594857022985373, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.7008284708078782}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:07,992]\u001B[0m Trial 335 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006255203074255837, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.10509402842484905}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:09,396]\u001B[0m Trial 336 finished with value: 0.5060742150229659 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008384256870343672, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.5068990425307658}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:10,667]\u001B[0m Trial 337 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.00937790265708259, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.22812324871709466}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:12,045]\u001B[0m Trial 338 finished with value: 0.5101892200870578 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008684910084313041, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.3284221183859142}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:13,438]\u001B[0m Trial 339 finished with value: 0.5214359259166952 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007227745438119274, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.17960946470299}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:14,869]\u001B[0m Trial 340 finished with value: 0.49441323247304414 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00736706124382533, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27714051496360864}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:16,163]\u001B[0m Trial 341 finished with value: 0.7297595628752276 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007671786305667676, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29571122937894484}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:17,487]\u001B[0m Trial 342 finished with value: 0.5868938953886336 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007744353597866779, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2946855310252039}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:18,164]\u001B[0m Trial 343 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00790250255133203, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.6467159376187264}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:19,573]\u001B[0m Trial 344 finished with value: 0.44305337860837524 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009246382927203376, 'num_negative_samples': 6, 'alpha': 0.1, 'lmbda': 0.30719321609541694}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:20,858]\u001B[0m Trial 345 finished with value: 0.5470459388929408 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009031671564317506, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.9193418900006021}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:22,158]\u001B[0m Trial 346 finished with value: 0.4985669699940256 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007634825914849914, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.33106300932361354}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:23,454]\u001B[0m Trial 347 finished with value: 0.3615719057323796 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008473648019317628, 'num_negative_samples': 11, 'alpha': 0.7, 'lmbda': 0.26252192216525116}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:24,779]\u001B[0m Trial 348 finished with value: 0.4908690058991105 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008858112212547162, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24769829431065724}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:26,054]\u001B[0m Trial 349 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008199945536593803, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.28317151066190155}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:27,460]\u001B[0m Trial 350 finished with value: 0.5107995490769662 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008319114683462102, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3049481638564401}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:28,871]\u001B[0m Trial 351 finished with value: 0.5421395981805276 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008536645389887892, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.22229070434711784}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:30,260]\u001B[0m Trial 352 finished with value: 0.5824018536989036 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008049990537080935, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.2685269504506291}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:31,694]\u001B[0m Trial 353 finished with value: 0.3472581680740104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008743163759539237, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.25007092768370154}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:33,101]\u001B[0m Trial 354 finished with value: 0.6601066131624048 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008380611603629533, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2889330781235454}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:34,516]\u001B[0m Trial 355 finished with value: 0.5005552472560403 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008452291292798378, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.35775519364756403}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:35,925]\u001B[0m Trial 356 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00836608878735566, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3224673905563455}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:37,164]\u001B[0m Trial 357 finished with value: 0.49209475201861536 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00868047150317835, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29206567507661585}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:38,578]\u001B[0m Trial 358 finished with value: 0.6909345644781222 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008536057181143697, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28527683340980486}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:39,879]\u001B[0m Trial 359 finished with value: 0.5521886278272619 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008618257527181379, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2885943086044491}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:41,284]\u001B[0m Trial 360 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008549751068925453, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3040393977145962}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:42,769]\u001B[0m Trial 361 finished with value: 0.4469956020210052 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008482066459861614, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.34187991058753364}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:43,329]\u001B[0m Trial 362 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005813034520154764, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2677419226455159}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:44,785]\u001B[0m Trial 363 finished with value: 0.6347936380926977 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008874375757623608, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.41341036866944897}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:46,196]\u001B[0m Trial 364 finished with value: 0.5211323702941711 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008861297615224358, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3761813474329299}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:47,610]\u001B[0m Trial 365 finished with value: 0.5024630690931117 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00913884033684507, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.43456099367426}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:48,275]\u001B[0m Trial 366 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008960097237923181, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3827090578714629}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:49,710]\u001B[0m Trial 367 finished with value: 0.45656001088001874 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008800815654320164, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.4675123569011673}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:51,101]\u001B[0m Trial 368 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008996627817324755, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3306226846361018}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:52,470]\u001B[0m Trial 369 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009479728919510518, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3545523374147588}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:53,917]\u001B[0m Trial 370 finished with value: 0.4228753118967395 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008795378372119462, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.3136892624725366}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:55,298]\u001B[0m Trial 371 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0070134091374564715, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3940588124133749}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:56,705]\u001B[0m Trial 372 finished with value: 0.5671308728156006 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008894218005995087, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2850513885376019}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:58,145]\u001B[0m Trial 373 finished with value: 0.5507966106632127 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008693741048354204, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.5523323269323583}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:41:59,516]\u001B[0m Trial 374 finished with value: 0.4747969026493666 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007116449363345112, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2693621466596451}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:00,944]\u001B[0m Trial 375 finished with value: 0.5620182627186002 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0075252984539768975, 'num_negative_samples': 6, 'alpha': 0.3, 'lmbda': 0.29970678818243446}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:02,364]\u001B[0m Trial 376 finished with value: 0.5490732933602595 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009666514051497427, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2503111880367928}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:03,822]\u001B[0m Trial 377 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007253671941540209, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.279687932003414}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:05,247]\u001B[0m Trial 378 finished with value: 0.3079201435678004 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007233746589799654, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2753338859669728}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:06,708]\u001B[0m Trial 379 finished with value: 0.44543540318737396 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007282656530800002, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.23623370105444141}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:08,101]\u001B[0m Trial 380 finished with value: 0.5106277908033803 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007111432314247807, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2802449728969813}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:09,547]\u001B[0m Trial 381 finished with value: 0.438631577543972 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0073263237552500995, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.315444686362912}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:10,960]\u001B[0m Trial 382 finished with value: 0.5388602512436507 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0069837600890191535, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.256082657204297}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:12,245]\u001B[0m Trial 383 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007206477217079981, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2954357066356518}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:13,686]\u001B[0m Trial 384 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007483608473722199, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.26894047329934595}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:15,110]\u001B[0m Trial 385 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007419845631653207, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24604876104769177}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:16,579]\u001B[0m Trial 386 finished with value: 0.48749802152178456 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006415773310034935, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.2893197088950846}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:18,022]\u001B[0m Trial 387 finished with value: 0.48819395052922704 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005305861338195896, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.22893215046681856}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:19,370]\u001B[0m Trial 388 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007648072755080225, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.31760010037854575}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:20,772]\u001B[0m Trial 389 finished with value: 0.6428052996037393 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00740090133370827, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.9593944297957202}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:21,450]\u001B[0m Trial 390 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007400768862809661, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.2642404609585548}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:22,890]\u001B[0m Trial 391 finished with value: 0.4337717080871482 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007292072642687316, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.2849551081225681}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:24,302]\u001B[0m Trial 392 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00742237240930453, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.30774732709019265}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:25,725]\u001B[0m Trial 393 finished with value: 0.6350955272909149 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007573337104805482, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.23483807668086593}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:27,179]\u001B[0m Trial 394 finished with value: 0.4840033669916556 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0071735401973065365, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.3317963817139431}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:28,582]\u001B[0m Trial 395 finished with value: 0.5018484351393873 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00691617749946224, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.2572649344034407}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:30,022]\u001B[0m Trial 396 finished with value: 0.4959091912093644 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007717716926844652, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.21208429676521695}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:31,423]\u001B[0m Trial 397 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007391190171421512, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.27856713049502474}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:32,863]\u001B[0m Trial 398 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007261778672006439, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.278554329157341}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:34,289]\u001B[0m Trial 399 finished with value: 0.3929942040850532 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009269397015397808, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3027365537041619}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:35,707]\u001B[0m Trial 400 finished with value: 0.5228688295026747 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007031698526675271, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2571907548921307}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:37,053]\u001B[0m Trial 401 finished with value: 0.43390275977259196 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008410533216154105, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2849851446573941}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:38,445]\u001B[0m Trial 402 finished with value: 0.544491127783818 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006792572208974746, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.23856259913127364}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:39,920]\u001B[0m Trial 403 finished with value: 0.49027581050911573 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007182491072361431, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.2666255587546653}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:41,219]\u001B[0m Trial 404 finished with value: 0.5900408021045224 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007817147967403893, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3022656132771263}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:42,663]\u001B[0m Trial 405 finished with value: 0.3079201435678004 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007344179603852976, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.3299697530266589}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:44,116]\u001B[0m Trial 406 finished with value: 0.355473846820579 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005194043659107059, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.24918943775989888}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:45,517]\u001B[0m Trial 407 finished with value: 0.5490732933602595 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007611541601446973, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.21653903693124926}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:46,147]\u001B[0m Trial 408 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.009575850089884593, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28530879758400873}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:47,555]\u001B[0m Trial 409 finished with value: 0.594418483337567 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006006067351817659, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.2712854730385046}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:49,011]\u001B[0m Trial 410 finished with value: 0.47840056688565297 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008536143411028084, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3196268224781404}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:50,438]\u001B[0m Trial 411 finished with value: 0.7069013463242263 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007114716717652388, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2422215424976612}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:51,116]\u001B[0m Trial 412 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007148530538487829, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.23053736818708886}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:52,547]\u001B[0m Trial 413 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006913729646575773, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.20150708422253455}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:53,898]\u001B[0m Trial 414 finished with value: 0.6209312003399052 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0070914023948764745, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23852087583813925}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:55,317]\u001B[0m Trial 415 finished with value: 0.438631577543972 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007077118112270798, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2541088938628434}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:56,760]\u001B[0m Trial 416 finished with value: 0.6386259760257971 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007265069002178708, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.21753517876269204}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:58,184]\u001B[0m Trial 417 finished with value: 0.29814239699997197 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0075380291376706725, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.26649756214797204}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:42:59,601]\u001B[0m Trial 418 finished with value: 0.5170493857844406 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009144069689661501, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24393093151375045}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:01,041]\u001B[0m Trial 419 finished with value: 0.39852669849304284 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007198221488815802, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.23005713406149786}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:02,453]\u001B[0m Trial 420 finished with value: 0.5591826045087465 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0073404925024433, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.20542265907845753}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:03,928]\u001B[0m Trial 421 finished with value: 0.5388602512436507 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0070657478303365355, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2836422964047652}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:05,359]\u001B[0m Trial 422 finished with value: 0.5195187671041669 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007474613609113171, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2601299938765591}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:06,748]\u001B[0m Trial 423 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00904932726229403, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.27161244468162016}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:08,219]\u001B[0m Trial 424 finished with value: 0.48608076469237244 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006956926624845002, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.30433553077300013}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:09,625]\u001B[0m Trial 425 finished with value: 0.47840056688565297 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007241875611306623, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3451676156090533}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:10,991]\u001B[0m Trial 426 finished with value: 0.4623231446277371 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00861441767004483, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.24758839524847423}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:12,424]\u001B[0m Trial 427 finished with value: 0.4981447060324421 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005429523319139164, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2202058105357027}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:13,709]\u001B[0m Trial 428 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009410452105870243, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.00016273589525866994}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:15,150]\u001B[0m Trial 429 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007366052821341026, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.28904606786130577}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:16,606]\u001B[0m Trial 430 finished with value: 0.6769468816753806 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00871102778326845, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.259824453621044}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:17,922]\u001B[0m Trial 431 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007160387443641079, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27262437139185924}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:19,359]\u001B[0m Trial 432 finished with value: 0.6338709917210089 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006534729501143344, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2986863159569453}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:20,797]\u001B[0m Trial 433 finished with value: 0.4270589526587819 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00793177899210113, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.3193474587486645}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:22,274]\u001B[0m Trial 434 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008222583304626678, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.18710689968545027}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:22,944]\u001B[0m Trial 435 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005572014614401594, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.2606099144991295}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:24,359]\u001B[0m Trial 436 finished with value: 0.35093859111936104 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008713612767131533, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.280559278633649}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:25,800]\u001B[0m Trial 437 finished with value: 0.600653239170064 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006651254016112508, 'num_negative_samples': 6, 'alpha': 0.5, 'lmbda': 0.24910769910113925}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:27,278]\u001B[0m Trial 438 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006989506264866457, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2984776858825458}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:28,578]\u001B[0m Trial 439 finished with value: 0.45656001088001874 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008331928139797721, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.229481572559094}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:29,991]\u001B[0m Trial 440 finished with value: 0.47764856133788175 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009331522865605787, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.26908772331506225}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:31,445]\u001B[0m Trial 441 finished with value: 0.5472516663721834 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007470910581035485, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3148962402742592}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:32,886]\u001B[0m Trial 442 finished with value: 0.48608076469237244 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007313341114562972, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.3402461920958237}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:34,328]\u001B[0m Trial 443 finished with value: 0.4720587952499556 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009180371741949191, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28411538420431387}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:35,772]\u001B[0m Trial 444 finished with value: 0.338296385503074 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008731248645707979, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.25076853507954205}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:37,262]\u001B[0m Trial 445 finished with value: 0.5420342882056847 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006872986091161937, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2025665321509061}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:38,751]\u001B[0m Trial 446 finished with value: 0.3427248421989825 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007105043345447165, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.23515066515509597}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:40,209]\u001B[0m Trial 447 finished with value: 0.648454953840661 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00975521750350007, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29781758347444287}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:41,669]\u001B[0m Trial 448 finished with value: 0.5490732933602595 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0076604245411305, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.2710105552563874}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:42,991]\u001B[0m Trial 449 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008988473126845859, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.21751686806731318}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:44,453]\u001B[0m Trial 450 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009656282524551642, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3012228000916757}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:45,908]\u001B[0m Trial 451 finished with value: 0.5887638742179041 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005043344365986875, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.25511790541342844}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:47,240]\u001B[0m Trial 452 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008474359639748349, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2836341210958829}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:48,708]\u001B[0m Trial 453 finished with value: 0.5170493857844406 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00722537200209759, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.3202666033351788}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:50,148]\u001B[0m Trial 454 finished with value: 0.6348451168907949 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007745956810333386, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.23577144346016815}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:51,595]\u001B[0m Trial 455 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009671123124315478, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3622301366250325}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:53,069]\u001B[0m Trial 456 finished with value: 0.5420342882056847 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008180525768681427, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2600432349452158}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:53,774]\u001B[0m Trial 457 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008639006249820634, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.33416600676430036}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:55,254]\u001B[0m Trial 458 finished with value: 0.6498365807642306 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009947796319895385, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.30171330437074284}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:56,705]\u001B[0m Trial 459 finished with value: 0.6110100926607787 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00987734285703457, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3194914548874412}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:58,178]\u001B[0m Trial 460 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009503520552413509, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.29841422687853486}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:43:59,701]\u001B[0m Trial 461 finished with value: 0.3596980901386366 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008821838095390042, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2793928774035278}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:01,157]\u001B[0m Trial 462 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009790671011727889, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.31211725028168713}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:02,641]\u001B[0m Trial 463 finished with value: 0.355473846820579 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009093002369409735, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.2838262358262145}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:04,100]\u001B[0m Trial 464 finished with value: 0.5481450200110942 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008286450650817581, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.34122473862743713}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:05,470]\u001B[0m Trial 465 finished with value: 0.5485671571703195 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009952123439966171, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.26991402792729463}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:06,959]\u001B[0m Trial 466 finished with value: 0.5849976258261415 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0085017461957192, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3031226569821407}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:08,422]\u001B[0m Trial 467 finished with value: 0.5343239463281865 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008359060273104516, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.2888745045982159}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:09,877]\u001B[0m Trial 468 finished with value: 0.4720587952499556 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008895727285117555, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.25875302041938336}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:11,359]\u001B[0m Trial 469 finished with value: 0.3551765656924165 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008011344122860031, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.328911109074954}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:12,826]\u001B[0m Trial 470 finished with value: 0.5073318646754141 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008583620788655589, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.3571645865923315}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:14,289]\u001B[0m Trial 471 finished with value: 0.47381739518152793 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009243914029756864, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.30996553659390425}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:15,616]\u001B[0m Trial 472 finished with value: 0.4927841893871409 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007569359121267614, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27314243384405645}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:17,119]\u001B[0m Trial 473 finished with value: 0.7377417504393537 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008118744602182407, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.25599660341125013}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:17,722]\u001B[0m Trial 474 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007986107185196288, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.2445479694951616}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:19,190]\u001B[0m Trial 475 finished with value: 0.5151305437694245 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007890598003881467, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.2553670183927441}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:20,695]\u001B[0m Trial 476 finished with value: 0.3569417423157558 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008077830053539936, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.23117642812435402}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:22,162]\u001B[0m Trial 477 finished with value: 0.4035102388050554 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008300577694556086, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.26738583147186096}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:23,535]\u001B[0m Trial 478 finished with value: 0.40688518719112343 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00820816781199507, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.25468405501731645}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:25,023]\u001B[0m Trial 479 finished with value: 0.3178208630818641 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008070790589373628, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.23443666588977702}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:25,730]\u001B[0m Trial 480 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008158610889253865, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.28155740493695786}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:27,218]\u001B[0m Trial 481 finished with value: 0.585397350933135 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008434624048834232, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.22094222083074444}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:28,673]\u001B[0m Trial 482 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008132050483896579, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.28815568776486794}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:30,131]\u001B[0m Trial 483 finished with value: 0.44664857493889926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008275229201890003, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.2519506396930097}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:31,579]\u001B[0m Trial 484 finished with value: 0.4185536593740414 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008797781433656681, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.2655870044994708}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:33,006]\u001B[0m Trial 485 finished with value: 0.4039280811442083 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005732433917102223, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.24120037868586314}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:34,479]\u001B[0m Trial 486 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007406287649209687, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.27934171806841546}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:35,928]\u001B[0m Trial 487 finished with value: 0.6909345644781222 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008388457402686976, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2957432243599441}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:37,359]\u001B[0m Trial 488 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008384179785133212, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.31850285609964324}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:38,823]\u001B[0m Trial 489 finished with value: 0.41899350299921784 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008564271350553482, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.30273704751070335}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:40,177]\u001B[0m Trial 490 finished with value: 0.5025859056843841 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006203805133494769, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.29020987161264633}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:41,630]\u001B[0m Trial 491 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008396309870778966, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.3427929600265568}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:43,101]\u001B[0m Trial 492 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008264403758209134, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2659581664008149}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:44,550]\u001B[0m Trial 493 finished with value: 0.39119087799986213 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008497631184048789, 'num_negative_samples': 11, 'alpha': 0.4, 'lmbda': 0.23867084450690818}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:46,006]\u001B[0m Trial 494 finished with value: 0.5856675985127676 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008691805804275985, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.32695282105565754}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:47,343]\u001B[0m Trial 495 finished with value: 0.515201027527539 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007792768889086936, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.220705760946034}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:48,781]\u001B[0m Trial 496 finished with value: 0.45584785943905204 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008363132896465736, 'num_negative_samples': 11, 'alpha': 0.5, 'lmbda': 0.2988926681447394}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:50,248]\u001B[0m Trial 497 finished with value: 0.3371708921694098 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00825007125175402, 'num_negative_samples': 11, 'alpha': 0.2, 'lmbda': 0.2742200879032035}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:50,834]\u001B[0m Trial 498 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008118051624159964, 'num_negative_samples': 11, 'alpha': 0.9, 'lmbda': 0.2531545539035048}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:44:52,538]\u001B[0m Trial 499 finished with value: 0.5744562646538028 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008493625717039125, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.20714750652215258}. Best is trial 189 with value: 0.7845457173236026.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: GCN, mode: unsupervised, loss from VERSE_PPR\n",
      "0\n",
      "Loss: 0.7476, Epoch: 000, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2817\n",
      "1\n",
      "Loss: 0.7623, Epoch: 001, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2157\n",
      "2\n",
      "Loss: 0.7480, Epoch: 002, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.3357\n",
      "3\n",
      "Loss: 0.7508, Epoch: 003, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2741\n",
      "4\n",
      "Loss: 0.7556, Epoch: 004, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.2756\n",
      "5\n",
      "Loss: 0.7521, Epoch: 005, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.3151\n",
      "6\n",
      "Loss: 0.7477, Epoch: 006, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.1995\n",
      "7\n",
      "Loss: 0.7476, Epoch: 007, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1520\n",
      "8\n",
      "Loss: 0.7504, Epoch: 008, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2599\n",
      "9\n",
      "Loss: 0.7514, Epoch: 009, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1520\n",
      "10\n",
      "Loss: 0.7495, Epoch: 010, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2284\n",
      "11\n",
      "Loss: 0.7474, Epoch: 011, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2133\n",
      "12\n",
      "Loss: 0.7472, Epoch: 012, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2250\n",
      "13\n",
      "Loss: 0.7485, Epoch: 013, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2083\n",
      "14\n",
      "Loss: 0.7493, Epoch: 014, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2320\n",
      "15\n",
      "Loss: 0.7487, Epoch: 015, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2421\n",
      "16\n",
      "Loss: 0.7475, Epoch: 016, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2197\n",
      "17\n",
      "Loss: 0.7471, Epoch: 017, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2562\n",
      "18\n",
      "Loss: 0.7475, Epoch: 018, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2803\n",
      "19\n",
      "Loss: 0.7481, Epoch: 019, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2803\n",
      "20\n",
      "Loss: 0.7481, Epoch: 020, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2389\n",
      "21\n",
      "Loss: 0.7475, Epoch: 021, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2351\n",
      "22\n",
      "Loss: 0.7471, Epoch: 022, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2882\n",
      "23\n",
      "Loss: 0.7472, Epoch: 023, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2583\n",
      "24\n",
      "Loss: 0.7474, Epoch: 024, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2532\n",
      "25\n",
      "Loss: 0.7476, Epoch: 025, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.1947\n",
      "26\n",
      "Loss: 0.7474, Epoch: 026, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3358\n",
      "27\n",
      "Loss: 0.7471, Epoch: 027, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2841\n",
      "28\n",
      "Loss: 0.7470, Epoch: 028, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1956\n",
      "29\n",
      "Loss: 0.7471, Epoch: 029, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2011\n",
      "30\n",
      "Loss: 0.7472, Epoch: 030, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2700\n",
      "31\n",
      "Loss: 0.7472, Epoch: 031, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1983\n",
      "32\n",
      "Loss: 0.7471, Epoch: 032, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2773\n",
      "33\n",
      "Loss: 0.7470, Epoch: 033, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2883\n",
      "34\n",
      "Loss: 0.7470, Epoch: 034, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2551\n",
      "35\n",
      "Loss: 0.7471, Epoch: 035, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2485\n",
      "36\n",
      "Loss: 0.7471, Epoch: 036, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1884\n",
      "37\n",
      "Loss: 0.7470, Epoch: 037, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2078\n",
      "38\n",
      "Loss: 0.7469, Epoch: 038, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2980\n",
      "39\n",
      "Loss: 0.7469, Epoch: 039, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.1935\n",
      "40\n",
      "Loss: 0.7470, Epoch: 040, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1983\n",
      "41\n",
      "Loss: 0.7470, Epoch: 041, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2412\n",
      "42\n",
      "Loss: 0.7469, Epoch: 042, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2440\n",
      "43\n",
      "Loss: 0.7469, Epoch: 043, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2389\n",
      "44\n",
      "Loss: 0.7469, Epoch: 044, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1983\n",
      "45\n",
      "Loss: 0.7469, Epoch: 045, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1914\n",
      "46\n",
      "Loss: 0.7469, Epoch: 046, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2490\n",
      "47\n",
      "Loss: 0.7469, Epoch: 047, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2700\n",
      "48\n",
      "Loss: 0.7469, Epoch: 048, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.1440\n",
      "49\n",
      "Loss: 0.7469, Epoch: 049, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.1817\n",
      "50\n",
      "Loss: 0.7469, Epoch: 050, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2433\n",
      "51\n",
      "Loss: 0.7469, Epoch: 051, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1944\n",
      "52\n",
      "Loss: 0.7469, Epoch: 052, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1956\n",
      "53\n",
      "Loss: 0.7468, Epoch: 053, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2431\n",
      "54\n",
      "Loss: 0.7468, Epoch: 054, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.1804\n",
      "55\n",
      "Loss: 0.7468, Epoch: 055, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2144\n",
      "56\n",
      "Loss: 0.7468, Epoch: 056, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.2962\n",
      "57\n",
      "Loss: 0.7468, Epoch: 057, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2174\n",
      "58\n",
      "Loss: 0.7468, Epoch: 058, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2721\n",
      "59\n",
      "Loss: 0.7468, Epoch: 059, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3020\n",
      "60\n",
      "Loss: 0.7468, Epoch: 060, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2062\n",
      "61\n",
      "Loss: 0.7468, Epoch: 061, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2281\n",
      "62\n",
      "Loss: 0.7468, Epoch: 062, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2490\n",
      "63\n",
      "Loss: 0.7468, Epoch: 063, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1896\n",
      "64\n",
      "Loss: 0.7468, Epoch: 064, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.3384\n",
      "65\n",
      "Loss: 0.7468, Epoch: 065, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2469\n",
      "66\n",
      "Loss: 0.7468, Epoch: 066, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2440\n",
      "67\n",
      "Loss: 0.7467, Epoch: 067, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1382\n",
      "68\n",
      "Loss: 0.7467, Epoch: 068, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1956\n",
      "69\n",
      "Loss: 0.7467, Epoch: 069, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2128\n",
      "70\n",
      "Loss: 0.7467, Epoch: 070, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.1983\n",
      "71\n",
      "Loss: 0.7467, Epoch: 071, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2033\n",
      "72\n",
      "Loss: 0.7467, Epoch: 072, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2551\n",
      "73\n",
      "Loss: 0.7467, Epoch: 073, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2412\n",
      "74\n",
      "Loss: 0.7467, Epoch: 074, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2358\n",
      "75\n",
      "Loss: 0.7467, Epoch: 075, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3051\n",
      "76\n",
      "Loss: 0.7467, Epoch: 076, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2912\n",
      "77\n",
      "Loss: 0.7466, Epoch: 077, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2051\n",
      "78\n",
      "Loss: 0.7466, Epoch: 078, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2389\n",
      "79\n",
      "Loss: 0.7466, Epoch: 079, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2041\n",
      "80\n",
      "Loss: 0.7466, Epoch: 080, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2421\n",
      "81\n",
      "Loss: 0.7466, Epoch: 081, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2247\n",
      "82\n",
      "Loss: 0.7466, Epoch: 082, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.1832\n",
      "83\n",
      "Loss: 0.7466, Epoch: 083, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2191\n",
      "84\n",
      "Loss: 0.7465, Epoch: 084, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.1860\n",
      "85\n",
      "Loss: 0.7465, Epoch: 085, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2622\n",
      "86\n",
      "Loss: 0.7465, Epoch: 086, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2251\n",
      "87\n",
      "Loss: 0.7465, Epoch: 087, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2320\n",
      "88\n",
      "Loss: 0.7465, Epoch: 088, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2247\n",
      "89\n",
      "Loss: 0.7465, Epoch: 089, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2583\n",
      "90\n",
      "Loss: 0.7464, Epoch: 090, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2800\n",
      "91\n",
      "Loss: 0.7464, Epoch: 091, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2571\n",
      "92\n",
      "Loss: 0.7464, Epoch: 092, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3379\n",
      "93\n",
      "Loss: 0.7464, Epoch: 093, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3300\n",
      "94\n",
      "Loss: 0.7464, Epoch: 094, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3143\n",
      "95\n",
      "Loss: 0.7463, Epoch: 095, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3103\n",
      "96\n",
      "Loss: 0.7463, Epoch: 096, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.3886\n",
      "97\n",
      "Loss: 0.7463, Epoch: 097, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3163\n",
      "98\n",
      "Loss: 0.7463, Epoch: 098, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.3488\n",
      "99\n",
      "Loss: 0.7462, Epoch: 099, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3071\n",
      "Loss: 0.7462, Epoch: 099, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3071\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:45,802]\u001B[0m A new study created in memory with name: VERSE_PPR loss,GCN conv\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:46,853]\u001B[0m Trial 0 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00564101295491182, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.1368131298328581}. Best is trial 0 with value: 0.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:47,763]\u001B[0m Trial 1 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007804629749084796, 'num_negative_samples': 11, 'alpha': 0.1, 'lmbda': 0.05177305933306242}. Best is trial 0 with value: 0.0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:49,452]\u001B[0m Trial 2 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009445576325985881, 'num_negative_samples': 6, 'alpha': 0.2, 'lmbda': 0.008036278563008148}. Best is trial 2 with value: 0.4226493565977341.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:50,451]\u001B[0m Trial 3 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005029582389527643, 'num_negative_samples': 11, 'alpha': 0.7, 'lmbda': 0.8121285853388114}. Best is trial 2 with value: 0.4226493565977341.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:46:51,098]\u001B[0m Trial 4 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.006390956341751774, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.10228594026314974}. Best is trial 2 with value: 0.4226493565977341.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:52,701]\u001B[0m Trial 5 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005634166060996228, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.006583535498717263}. Best is trial 5 with value: 0.4499657051403686.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:53,673]\u001B[0m Trial 6 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0076354617976102, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.4496832524735993}. Best is trial 5 with value: 0.4499657051403686.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:46:54,662]\u001B[0m Trial 7 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007071321919110311, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9567919982793704}. Best is trial 5 with value: 0.4499657051403686.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:46:55,917]\u001B[0m Trial 8 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008392060957332092, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.209797672895367}. Best is trial 8 with value: 0.5114083119567587.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:46:57,342]\u001B[0m Trial 9 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008711104766641699, 'num_negative_samples': 6, 'alpha': 0.4, 'lmbda': 0.23177802630514832}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:46:57,973]\u001B[0m Trial 10 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009951273378938745, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.41540526576291115}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:46:59,223]\u001B[0m Trial 11 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008612349535058121, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.2793606342867596}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:47:00,872]\u001B[0m Trial 12 finished with value: 0.3878955567713595 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008691016958778693, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.2750992754332604}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:02,176]\u001B[0m Trial 13 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008601196048651002, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.6265744410935374}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 13:47:03,834]\u001B[0m Trial 14 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009248349503924575, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.2532842337530365}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:05,118]\u001B[0m Trial 15 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008101392907197205, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.5830417722297454}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:05,811]\u001B[0m Trial 16 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007011435725602027, 'num_negative_samples': 11, 'alpha': 0.1, 'lmbda': 0.3602173220786785}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:07,067]\u001B[0m Trial 17 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008254509316352465, 'num_negative_samples': 6, 'alpha': 0.3, 'lmbda': 0.16292547088664283}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:08,530]\u001B[0m Trial 18 finished with value: 0.49690399499995325 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009125546238040216, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.5462779532187058}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:09,098]\u001B[0m Trial 19 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009900737229463432, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.7001325701681942}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:10,390]\u001B[0m Trial 20 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006831052436488876, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.203859036155915}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:11,846]\u001B[0m Trial 21 finished with value: 0.49690399499995325 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00915184828668746, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.5315710489036976}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:13,256]\u001B[0m Trial 22 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00894302016998029, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.3740397938171266}. Best is trial 9 with value: 0.5399664674850008.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:14,687]\u001B[0m Trial 23 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008093134377563642, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7183020956050495}. Best is trial 23 with value: 0.5958964613022909.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:15,326]\u001B[0m Trial 24 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008102408629132458, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.7857992278071588}. Best is trial 23 with value: 0.5958964613022909.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:16,772]\u001B[0m Trial 25 finished with value: 0.6673607497975667 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007513132443623835, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9669054790323278}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:18,176]\u001B[0m Trial 26 finished with value: 0.3713906763541037 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007405995297482385, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9704046833634346}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:18,813]\u001B[0m Trial 27 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007851501347146444, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8908962861616656}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:19,437]\u001B[0m Trial 28 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007369371177772977, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7022841327879139}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:20,023]\u001B[0m Trial 29 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006450128525285866, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.8466403087476421}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:20,675]\u001B[0m Trial 30 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006548995965553639, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.7190281388589526}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:22,085]\u001B[0m Trial 31 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008290725163523435, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.9147437753259394}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:22,651]\u001B[0m Trial 32 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007897391014468978, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.09025451124031406}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:24,051]\u001B[0m Trial 33 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008401629857027117, 'num_negative_samples': 6, 'alpha': 0.1, 'lmbda': 0.33300959771800637}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:24,624]\u001B[0m Trial 34 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009473554061192003, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.45390635027148163}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:25,291]\u001B[0m Trial 35 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008794923189022323, 'num_negative_samples': 11, 'alpha': 0.7, 'lmbda': 0.15705153463372445}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:26,529]\u001B[0m Trial 36 finished with value: 0.32075014954979214 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007802926004200242, 'num_negative_samples': 6, 'alpha': 0.2, 'lmbda': 0.7899838936784294}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:27,973]\u001B[0m Trial 37 finished with value: 0.4069376986693302 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005895136179607501, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.6463344844979475}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:28,641]\u001B[0m Trial 38 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007554331964833012, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.048523220852081494}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:30,020]\u001B[0m Trial 39 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008457563342392635, 'num_negative_samples': 16, 'alpha': 0.6, 'lmbda': 0.21747045525646097}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:31,506]\u001B[0m Trial 40 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00961037609281719, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.9990607941432029}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:32,926]\u001B[0m Trial 41 finished with value: 0.5919942667545484 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009051162017734671, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.5060735454536371}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:33,545]\u001B[0m Trial 42 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00804871757180447, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.32896533765002856}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:34,958]\u001B[0m Trial 43 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008979589035430125, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.4759850338296463}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:36,404]\u001B[0m Trial 44 finished with value: 0.4433747811741175 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008875455677338384, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.47248707949774055}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:37,875]\u001B[0m Trial 45 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009392411573006557, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.6040434384673845}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:38,536]\u001B[0m Trial 46 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009686885397083523, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.6104555530091121}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:39,209]\u001B[0m Trial 47 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.00937712979146763, 'num_negative_samples': 1, 'alpha': 0.3, 'lmbda': 0.5228513075609678}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:39,821]\u001B[0m Trial 48 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0086118398245886, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.4032049948733836}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:40,467]\u001B[0m Trial 49 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007206595039565198, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.5774777384683268}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:41,859]\u001B[0m Trial 50 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009325442122953673, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.6711902126872658}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:43,265]\u001B[0m Trial 51 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008906248637916846, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.7608860225734146}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:44,686]\u001B[0m Trial 52 finished with value: 0.3849001794597505 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009112043097520168, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.48821718081586885}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:46,114]\u001B[0m Trial 53 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005011655848204357, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.8623300299694441}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:47,583]\u001B[0m Trial 54 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005510699675939502, 'num_negative_samples': 16, 'alpha': 0.9, 'lmbda': 0.8625469042657619}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:48,926]\u001B[0m Trial 55 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006088179886458861, 'num_negative_samples': 6, 'alpha': 0.2, 'lmbda': 0.921224105731563}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:49,482]\u001B[0m Trial 56 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0051137999031627066, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7507584183453987}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:50,106]\u001B[0m Trial 57 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.009856897321255475, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.8322761706881822}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:51,498]\u001B[0m Trial 58 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007654502269585376, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.5666774621754019}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:52,145]\u001B[0m Trial 59 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006765405685209483, 'num_negative_samples': 1, 'alpha': 0.3, 'lmbda': 0.6113046115597424}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:53,639]\u001B[0m Trial 60 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008726802157173648, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.8824773511611144}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:55,114]\u001B[0m Trial 61 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008708337113091802, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.8922671150653249}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:56,599]\u001B[0m Trial 62 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008488304634006572, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.9510860373796415}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:58,056]\u001B[0m Trial 63 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008200841155139462, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.8026177220695759}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:47:59,529]\u001B[0m Trial 64 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008196289617216083, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.7988406490613952}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:01,004]\u001B[0m Trial 65 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008018374590920183, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8218514308766441}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:02,482]\u001B[0m Trial 66 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007996990060783998, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8264453834868705}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:03,068]\u001B[0m Trial 67 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007747730866760314, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8639962899017709}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:04,518]\u001B[0m Trial 68 finished with value: 0.44035242296398963 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007327332235363239, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9283278587388057}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:05,959]\u001B[0m Trial 69 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008253353999246588, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7512120725402048}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:07,435]\u001B[0m Trial 70 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008309757382786718, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.7347105928859052}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:08,922]\u001B[0m Trial 71 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008176885739879123, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.7629630165049669}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:10,388]\u001B[0m Trial 72 finished with value: 0.49690399499995325 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008326407061615011, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.7187826924358526}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:11,842]\u001B[0m Trial 73 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008514024432106505, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.6693489273784177}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:13,304]\u001B[0m Trial 74 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007901461835103388, 'num_negative_samples': 16, 'alpha': 0.7, 'lmbda': 0.8565883638257084}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:13,957]\u001B[0m Trial 75 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0076499377262088004, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.8900217985519816}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:15,522]\u001B[0m Trial 76 finished with value: 0.49690399499995325 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0070287641577944085, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9697125036986066}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:16,811]\u001B[0m Trial 77 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007470016481075448, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.8117811538025546}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:18,269]\u001B[0m Trial 78 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007998288966372396, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7271495794267395}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:18,850]\u001B[0m Trial 79 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007175576112030509, 'num_negative_samples': 16, 'alpha': 0.6, 'lmbda': 0.6846773422200527}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:19,545]\u001B[0m Trial 80 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008348791563855044, 'num_negative_samples': 11, 'alpha': 0.1, 'lmbda': 0.7396728114144973}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:21,004]\u001B[0m Trial 81 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008201167873450883, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7912511915591212}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:22,504]\u001B[0m Trial 82 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008731139720900503, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9973161432052589}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:23,975]\u001B[0m Trial 83 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008565242275857143, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.773397169435479}. Best is trial 25 with value: 0.6673607497975667.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:25,435]\u001B[0m Trial 84 finished with value: 0.6851601597031488 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007943035214649615, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.897008934845326}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:26,092]\u001B[0m Trial 85 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007730147431941507, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.9383691542752116}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:27,576]\u001B[0m Trial 86 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007856500285881233, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.899129737061033}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:28,249]\u001B[0m Trial 87 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0075329286748668815, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8268805156846653}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:29,670]\u001B[0m Trial 88 finished with value: 0.6157651067303722 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009007734083932477, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.8588131463518262}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:31,129]\u001B[0m Trial 89 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009141509756706925, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.8460477502241771}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:32,571]\u001B[0m Trial 90 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00881565262899857, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.8675635214922804}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:34,004]\u001B[0m Trial 91 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008051520430621083, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9046360594121641}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:35,435]\u001B[0m Trial 92 finished with value: 0.6359594676112971 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009240652557037562, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.877042448915967}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:36,866]\u001B[0m Trial 93 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009038767507914765, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8172114126359054}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:38,301]\u001B[0m Trial 94 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009262756429209667, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8764253452181636}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:39,735]\u001B[0m Trial 95 finished with value: 0.46837294901949594 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00904099718033593, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9390857525592549}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:41,176]\u001B[0m Trial 96 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009524872757157923, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9702651818297041}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:42,590]\u001B[0m Trial 97 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009255041920884636, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8730078881889767}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:44,035]\u001B[0m Trial 98 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009291332105569, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9147253238255298}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:45,451]\u001B[0m Trial 99 finished with value: 0.49749371855331 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00972736809314956, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.803348983862609}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:46,894]\u001B[0m Trial 100 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008994109450246607, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.7830324311059575}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:48,343]\u001B[0m Trial 101 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009184429755596302, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8772521046145696}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:49,755]\u001B[0m Trial 102 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009468645281788608, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9494151974794727}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:51,167]\u001B[0m Trial 103 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009518301884889294, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9503765411828267}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:52,560]\u001B[0m Trial 104 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009992852159431556, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9181913391628227}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:53,973]\u001B[0m Trial 105 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00964215159617927, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.8420747072987691}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:55,419]\u001B[0m Trial 106 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009444169862389041, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9713842645803276}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:56,834]\u001B[0m Trial 107 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009076116097525599, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.9878120421134382}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:58,290]\u001B[0m Trial 108 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008887651389774645, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.8544489546271716}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:48:59,697]\u001B[0m Trial 109 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009790071243215084, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.9054581731368515}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:01,091]\u001B[0m Trial 110 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009186214060912596, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.9387394428860958}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:02,513]\u001B[0m Trial 111 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00922008166592525, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.9340149295554611}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:03,941]\u001B[0m Trial 112 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009362704561730311, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.956648967947164}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:05,342]\u001B[0m Trial 113 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006880689651432584, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.8840733518276639}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:06,721]\u001B[0m Trial 114 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008987897000452114, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.8405414005062203}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:08,130]\u001B[0m Trial 115 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009589677662781312, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.9791732102431403}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:09,529]\u001B[0m Trial 116 finished with value: 0.3528251645047713 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009294475608078308, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.8158839308107493}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:10,830]\u001B[0m Trial 117 finished with value: 0.3528251645047713 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006200715962416178, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.9147605859242078}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:11,388]\u001B[0m Trial 118 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009446422065160841, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9462235565118013}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:12,807]\u001B[0m Trial 119 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0055443585427665445, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.8928639179962634}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:14,175]\u001B[0m Trial 120 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005081141115198996, 'num_negative_samples': 6, 'alpha': 0.3, 'lmbda': 0.8929512456242629}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:15,597]\u001B[0m Trial 121 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005429962936250664, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.8665798977001655}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:17,006]\u001B[0m Trial 122 finished with value: 0.5119213729309336 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005250538040869781, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.9348589289711939}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:18,435]\u001B[0m Trial 123 finished with value: 0.314970394174356 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005760362424643834, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.8396858709166449}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:19,862]\u001B[0m Trial 124 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0053940049947845395, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.42503882857449377}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:21,297]\u001B[0m Trial 125 finished with value: 0.5284498644708495 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005193593347458907, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.8971869256085957}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:22,700]\u001B[0m Trial 126 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009116529731100444, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8092699241799672}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:23,327]\u001B[0m Trial 127 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007314381930828506, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.9620469237421068}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:24,753]\u001B[0m Trial 128 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005662522150196518, 'num_negative_samples': 11, 'alpha': 0.5, 'lmbda': 0.3042605129790229}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:26,180]\u001B[0m Trial 129 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008868059486324381, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9196541281686281}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:26,840]\u001B[0m Trial 130 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008660701710861432, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.877235324244294}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:28,271]\u001B[0m Trial 131 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009911799439020588, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.9267278569804349}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:29,710]\u001B[0m Trial 132 finished with value: 0.6060395619242064 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009243254157954094, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9077172222959222}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:31,128]\u001B[0m Trial 133 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009191607601079455, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8322205933513512}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:32,532]\u001B[0m Trial 134 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00904259795091416, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.854829036877138}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:33,942]\u001B[0m Trial 135 finished with value: 0.505372372185007 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008955562166280817, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8507848826230078}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:35,372]\u001B[0m Trial 136 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009060470501882, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7729283199847208}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:36,766]\u001B[0m Trial 137 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00930191605551478, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.643267866776615}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:38,257]\u001B[0m Trial 138 finished with value: 0.4370036867375632 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008783553209689163, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.5180152124804843}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:39,653]\u001B[0m Trial 139 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007927927736022664, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.7948547901454468}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:41,144]\u001B[0m Trial 140 finished with value: 0.37374127372092536 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006628821827795658, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8582552369212504}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:42,567]\u001B[0m Trial 141 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009208244371895727, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.8872867449806747}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:44,006]\u001B[0m Trial 142 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005003909595549268, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9002767123223793}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:45,419]\u001B[0m Trial 143 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009417571918140974, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8722691901451726}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:46,844]\u001B[0m Trial 144 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009337076166625649, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8183630249913545}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:48,268]\u001B[0m Trial 145 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009101800080059886, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8795790880295902}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:49,701]\u001B[0m Trial 146 finished with value: 0.6157651067303722 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008131109565874725, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8618405594768707}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:51,112]\u001B[0m Trial 147 finished with value: 0.6273105439242341 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008138276061041956, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8635449873201548}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:52,525]\u001B[0m Trial 148 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008108682302498258, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8559052620363415}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:53,956]\u001B[0m Trial 149 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008115403235662707, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8443792134427113}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:55,372]\u001B[0m Trial 150 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00837595307534491, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8288544287596314}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:56,805]\u001B[0m Trial 151 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008170628619976274, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8555666250204741}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:58,250]\u001B[0m Trial 152 finished with value: 0.5559827417436706 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008122398034855432, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7972892053618638}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:49:59,674]\u001B[0m Trial 153 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007751419199732654, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8673453583515707}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:01,083]\u001B[0m Trial 154 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007954355867467955, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8415583553533608}. Best is trial 84 with value: 0.6851601597031488.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:02,501]\u001B[0m Trial 155 finished with value: 0.743921234687385 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008239115679402303, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9054869344096962}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:03,910]\u001B[0m Trial 156 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008484869744017756, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9113558032242247}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:05,313]\u001B[0m Trial 157 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008270792514834115, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.864673596094611}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:06,731]\u001B[0m Trial 158 finished with value: 0.6359594676112971 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008056612895615697, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8240143018003059}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:08,159]\u001B[0m Trial 159 finished with value: 0.6308430573153381 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008075036273977395, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8120604793964751}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:09,584]\u001B[0m Trial 160 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007864871660626965, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8100748126808465}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:11,019]\u001B[0m Trial 161 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008029894157198153, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8273787238534452}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:12,450]\u001B[0m Trial 162 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007612854847778201, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9100409246013373}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:13,881]\u001B[0m Trial 163 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00805910553480736, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9322669572483011}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:15,307]\u001B[0m Trial 164 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0076038257731847764, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.776473017739623}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:16,733]\u001B[0m Trial 165 finished with value: 0.6805446536716203 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007669848199303703, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7818387456664321}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:18,176]\u001B[0m Trial 166 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007591607645279238, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7593951941506389}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:19,621]\u001B[0m Trial 167 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007476565799622134, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7777768883132289}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:21,050]\u001B[0m Trial 168 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0076110613168292205, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7775454931831713}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:22,466]\u001B[0m Trial 169 finished with value: 0.314970394174356 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007703609855124529, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7398140351521657}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:23,870]\u001B[0m Trial 170 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007426087368132137, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7023571703164236}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:25,265]\u001B[0m Trial 171 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007229941898232627, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7920411136983868}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:26,629]\u001B[0m Trial 172 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007488200121292233, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8075578601116739}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:28,022]\u001B[0m Trial 173 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007539383869620045, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7691560767224758}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:29,434]\u001B[0m Trial 174 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0078057834245487834, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9096052355395545}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:30,831]\u001B[0m Trial 175 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007730737925862422, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.818391928994182}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:32,222]\u001B[0m Trial 176 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007840959148688995, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.788421681929508}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:32,800]\u001B[0m Trial 177 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007789032090437481, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7528620799370194}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:34,260]\u001B[0m Trial 178 finished with value: 0.47366546671567095 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007363518788996326, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.9849257706967685}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:35,691]\u001B[0m Trial 179 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007653272206848161, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9545497420821643}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:37,101]\u001B[0m Trial 180 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007919260590851601, 'num_negative_samples': 11, 'alpha': 0.3, 'lmbda': 0.927889366143332}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:38,544]\u001B[0m Trial 181 finished with value: 0.5864429587908307 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008238799799570174, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9062979910346692}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:39,956]\u001B[0m Trial 182 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007822882169331627, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8945047398708569}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:41,387]\u001B[0m Trial 183 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007440122362849969, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8330484730037704}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:42,841]\u001B[0m Trial 184 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007944321451626712, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.920945541754771}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:44,272]\u001B[0m Trial 185 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00798772687437727, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8826890874781883}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:45,728]\u001B[0m Trial 186 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007657949921887696, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9700999936178593}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:47,169]\u001B[0m Trial 187 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007557430160855633, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9397962131004817}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:48,575]\u001B[0m Trial 188 finished with value: 0.44035242296398963 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008421519501939725, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9171265865383937}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:50,003]\u001B[0m Trial 189 finished with value: 0.5007710104811096 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007919462448314407, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.843978460932722}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:51,466]\u001B[0m Trial 190 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008220984482101555, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.823169705592845}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:52,899]\u001B[0m Trial 191 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0077834558940364194, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8865422476895742}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:54,316]\u001B[0m Trial 192 finished with value: 0.4887626099538393 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008017171803628258, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9037687836309877}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:55,732]\u001B[0m Trial 193 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007269585822666495, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9162118329469092}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:57,158]\u001B[0m Trial 194 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007498612328012565, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9469522626024404}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:50:58,590]\u001B[0m Trial 195 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007095118249199918, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8653644911493632}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:00,018]\u001B[0m Trial 196 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007926045271096027, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.8634722458130248}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:01,456]\u001B[0m Trial 197 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008157693753844458, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.8028204764057301}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:02,910]\u001B[0m Trial 198 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006980414129179227, 'num_negative_samples': 16, 'alpha': 0.4, 'lmbda': 0.8778348154720337}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:04,340]\u001B[0m Trial 199 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008349555495214076, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7799762420026087}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:05,658]\u001B[0m Trial 200 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007823709862576526, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8511085702294233}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:07,096]\u001B[0m Trial 201 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00769312699399987, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8951493541662585}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:08,528]\u001B[0m Trial 202 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008045440997222902, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9278367968245255}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:09,971]\u001B[0m Trial 203 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007132729799629133, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9980782012220989}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:11,434]\u001B[0m Trial 204 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00896829721909877, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8376936665800904}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:12,022]\u001B[0m Trial 205 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007373008518352193, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9077903723844071}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:13,465]\u001B[0m Trial 206 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007607187281675972, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8691413204093609}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:14,914]\u001B[0m Trial 207 finished with value: 0.5451809077932042 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007631948204472033, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.8677093586234723}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:16,356]\u001B[0m Trial 208 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00754162900542298, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8102023978544072}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:17,813]\u001B[0m Trial 209 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007745638818425926, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.8523557006356471}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:19,271]\u001B[0m Trial 210 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007998489859337371, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8217575089850258}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:20,711]\u001B[0m Trial 211 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008103312196496197, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8779621190768611}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:22,167]\u001B[0m Trial 212 finished with value: 0.5245305283129621 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009129082638664267, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9052234021524157}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:23,606]\u001B[0m Trial 213 finished with value: 0.5245305283129621 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007881180676483279, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8858260345590463}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:25,049]\u001B[0m Trial 214 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008155398349055713, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9581414269435736}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:26,496]\u001B[0m Trial 215 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007641058775754955, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9254683534061553}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:27,924]\u001B[0m Trial 216 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0074560312216254004, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.8573288398744267}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:29,371]\u001B[0m Trial 217 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00825679770994695, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.7955590334063531}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:30,776]\u001B[0m Trial 218 finished with value: 0.3268602252303067 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009228347989303574, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8356772865315858}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:32,218]\u001B[0m Trial 219 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007794185113003819, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8945547435963207}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:33,621]\u001B[0m Trial 220 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009051936916403925, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.767414685798846}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:35,065]\u001B[0m Trial 221 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009191524282970558, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8736657060720623}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:36,485]\u001B[0m Trial 222 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008090255328450195, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.83852194037094}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:37,919]\u001B[0m Trial 223 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008117268762369298, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8583037407006584}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:39,340]\u001B[0m Trial 224 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00930675157882766, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8768635591939247}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:40,782]\u001B[0m Trial 225 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009405720991161107, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.916317173529283}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:42,206]\u001B[0m Trial 226 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009307047827534347, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8912467736244385}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:43,668]\u001B[0m Trial 227 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008907048021555694, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9453536569004573}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:45,112]\u001B[0m Trial 228 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007580582859008894, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8118028981281749}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:46,584]\u001B[0m Trial 229 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007960575452595549, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8675528910446233}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:48,019]\u001B[0m Trial 230 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0077179875588707664, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.92781311248176}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:49,449]\u001B[0m Trial 231 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00935332024384425, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8696461410243396}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:50,879]\u001B[0m Trial 232 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009170023324448292, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8811840338975953}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:52,311]\u001B[0m Trial 233 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008157744370681274, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.836952614907328}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:53,733]\u001B[0m Trial 234 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008228783021820774, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8296112151624732}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:55,143]\u001B[0m Trial 235 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008294285989837924, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8248520585061072}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:55,740]\u001B[0m Trial 236 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008246345659254622, 'num_negative_samples': 16, 'alpha': 0.1, 'lmbda': 0.7864521165433108}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:57,150]\u001B[0m Trial 237 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008413367161285067, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.837723558286054}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:51:58,590]\u001B[0m Trial 238 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008178728519038824, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.8049649502263542}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:00,034]\u001B[0m Trial 239 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008005530101552511, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.11018002771138519}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:01,449]\u001B[0m Trial 240 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007898785230141219, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.8507667197364059}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:02,874]\u001B[0m Trial 241 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009030346337590906, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8999999914449565}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:04,324]\u001B[0m Trial 242 finished with value: 0.4637031120573672 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008063663310228418, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8206795354681503}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:05,792]\u001B[0m Trial 243 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008158260132765471, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8477694501348709}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:07,242]\u001B[0m Trial 244 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008304682125223787, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9067654430484866}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:08,693]\u001B[0m Trial 245 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006772317524189852, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7868874839956076}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:10,143]\u001B[0m Trial 246 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007548759392512945, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.8285985738265699}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:11,578]\u001B[0m Trial 247 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007349509991921289, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.8625823002624327}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:12,940]\u001B[0m Trial 248 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007847862137822783, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8860112011907133}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:13,617]\u001B[0m Trial 249 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007692582117443155, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9357132657471491}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:15,046]\u001B[0m Trial 250 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007966515239083887, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8082295364960326}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:16,480]\u001B[0m Trial 251 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007449329833774354, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8507604745985768}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:17,919]\u001B[0m Trial 252 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009529136075275352, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.5508663802001067}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:19,355]\u001B[0m Trial 253 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009114529611998861, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7516132519037352}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:20,033]\u001B[0m Trial 254 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008325749039428726, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.9118068827399127}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:21,472]\u001B[0m Trial 255 finished with value: 0.48386670078337085 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008212700633013888, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8751184936353236}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:22,896]\u001B[0m Trial 256 finished with value: 0.5451809077932042 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006964906255654331, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.967326419060377}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:24,317]\u001B[0m Trial 257 finished with value: 0.3268602252303067 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007788983004603681, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.8307160438498694}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:25,738]\u001B[0m Trial 258 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00805680857783901, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8911871075372828}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:27,174]\u001B[0m Trial 259 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006627972391209426, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.7715038399635356}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:28,606]\u001B[0m Trial 260 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008565302326861736, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8512577260605467}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:30,049]\u001B[0m Trial 261 finished with value: 0.44035242296398963 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009263397148783603, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.2461311176923539}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:31,355]\u001B[0m Trial 262 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007150656593724727, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.9204267933154249}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:32,794]\u001B[0m Trial 263 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00762361754805604, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.03484694050469345}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:33,403]\u001B[0m Trial 264 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007602545669127357, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.050272326827708276}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:34,848]\u001B[0m Trial 265 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0076519944662568435, 'num_negative_samples': 16, 'alpha': 0.6, 'lmbda': 0.810706783255388}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:36,310]\u001B[0m Trial 266 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007501952938020424, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.2726542028790001}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:37,762]\u001B[0m Trial 267 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007851711410881668, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.7924313770570147}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:39,340]\u001B[0m Trial 268 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007726445774619114, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8351171158109117}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:40,680]\u001B[0m Trial 269 finished with value: 0.6608722544880642 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007402687415831842, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.8720976785885307}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:42,002]\u001B[0m Trial 270 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007227690751521259, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.8731668503344758}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:43,340]\u001B[0m Trial 271 finished with value: 0.6359594676112971 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007414350059528263, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9448271692590485}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:44,699]\u001B[0m Trial 272 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007362805164265089, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.39749638240775237}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:46,049]\u001B[0m Trial 273 finished with value: 0.6273105439242341 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0074133927994622945, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9528172318309192}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:46,732]\u001B[0m Trial 274 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.00755023780612341, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9825638666314305}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:48,049]\u001B[0m Trial 275 finished with value: 0.49690399499995325 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007274171476753516, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.4495313545716623}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:49,371]\u001B[0m Trial 276 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0074626174250994205, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9429788715643115}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:50,701]\u001B[0m Trial 277 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0076048118051458375, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.9263598833012947}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:52,049]\u001B[0m Trial 278 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007105725974628898, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9595278108409288}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:53,386]\u001B[0m Trial 279 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007381342428862577, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.16223381884498056}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:54,730]\u001B[0m Trial 280 finished with value: 0.32075014954979214 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007452136746658072, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.18302356205058018}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:55,420]\u001B[0m Trial 281 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.007281225901298216, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9610453558004911}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:56,768]\u001B[0m Trial 282 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00741926155440158, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9441190399459718}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:58,100]\u001B[0m Trial 283 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007521114566523192, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.9763910275465487}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:52:59,433]\u001B[0m Trial 284 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007330356457891743, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9540188745997462}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:00,877]\u001B[0m Trial 285 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007687671364215482, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.3369478210326128}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:01,480]\u001B[0m Trial 286 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.007579389436974445, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9286890906555118}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:02,789]\u001B[0m Trial 287 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007920879232759352, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.7328786277647477}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:03,449]\u001B[0m Trial 288 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007738299269481754, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8918605213209491}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:04,750]\u001B[0m Trial 289 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007479722085289385, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.7772228678820393}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:06,174]\u001B[0m Trial 290 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007845707688785902, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8036221863486782}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:07,604]\u001B[0m Trial 291 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008040209175301627, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8318710043685873}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:08,939]\u001B[0m Trial 292 finished with value: 0.48240651880205354 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00763756076709952, 'num_negative_samples': 16, 'alpha': 0.6, 'lmbda': 0.9095974319063915}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:10,289]\u001B[0m Trial 293 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007422160563357452, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.5980066480861541}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:11,605]\u001B[0m Trial 294 finished with value: 0.6166416411338492 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007553402900800209, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.7547142383023941}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:12,307]\u001B[0m Trial 295 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0072707194421876495, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.8143346642691479}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:13,640]\u001B[0m Trial 296 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0077572098585834, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.5948982635453636}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:14,956]\u001B[0m Trial 297 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007034347743769675, 'num_negative_samples': 6, 'alpha': 0.9, 'lmbda': 0.010966922429057335}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:16,417]\u001B[0m Trial 298 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007642666229549034, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.8980452997820149}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:17,843]\u001B[0m Trial 299 finished with value: 0.5007710104811096 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007385141007003617, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.6549715438836758}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:19,309]\u001B[0m Trial 300 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0074948442698428855, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.7001886112725008}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:19,986]\u001B[0m Trial 301 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007956570286246079, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7965803612433416}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:21,337]\u001B[0m Trial 302 finished with value: 0.3878955567713595 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007790306639245508, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8470820737206668}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:22,765]\u001B[0m Trial 303 finished with value: 0.5119213729309336 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007488697858429241, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.48469226389098835}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:24,222]\u001B[0m Trial 304 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007162798327390836, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.6195454364848697}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:25,653]\u001B[0m Trial 305 finished with value: 0.4433747811741175 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007646967474649267, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.8795722811446218}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:27,002]\u001B[0m Trial 306 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008457349164256868, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9140227148878054}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:27,589]\u001B[0m Trial 307 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00783131613479211, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7794305792065925}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:29,049]\u001B[0m Trial 308 finished with value: 0.3713906763541037 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007583624393376902, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.8178347841713134}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:30,517]\u001B[0m Trial 309 finished with value: 0.5765428486372022 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008808902052840399, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.9335153181792042}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:31,939]\u001B[0m Trial 310 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007346594970748921, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9996480943943112}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:33,386]\u001B[0m Trial 311 finished with value: 0.42218567093251846 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008240933429492768, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.8781137617535257}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:34,731]\u001B[0m Trial 312 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007711523840513043, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8387433244731206}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:36,188]\u001B[0m Trial 313 finished with value: 0.46027367060462177 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009334777949257541, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.8972312390185541}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:37,636]\u001B[0m Trial 314 finished with value: 0.5450701324374344 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007997169449244465, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8620004372210721}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:39,220]\u001B[0m Trial 315 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006922940660610082, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.767687366819596}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:40,720]\u001B[0m Trial 316 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007241349485717701, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7445446397495769}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:42,277]\u001B[0m Trial 317 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007535715839836591, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7693250722053351}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:42,939]\u001B[0m Trial 318 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006728707117552806, 'num_negative_samples': 16, 'alpha': 0.8, 'lmbda': 0.9208957937667901}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:43,622]\u001B[0m Trial 319 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006975530131396117, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7689019192382732}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:44,288]\u001B[0m Trial 320 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007023106929089109, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.7244540422441135}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:44,986]\u001B[0m Trial 321 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0074169657639144345, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8911872346061547}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:45,675]\u001B[0m Trial 322 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00712479945383924, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.5779642246385952}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:47,080]\u001B[0m Trial 323 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006939091685655554, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.784563533097239}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:47,805]\u001B[0m Trial 324 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0068591321744812415, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8695865503403745}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:49,266]\u001B[0m Trial 325 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00909302728715236, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9416322254253888}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:50,709]\u001B[0m Trial 326 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009458859729757782, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.7970498783903465}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:52,035]\u001B[0m Trial 327 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007644208437175154, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.5072391176223663}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:53,464]\u001B[0m Trial 328 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006785130085528709, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.09218019120291045}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:54,902]\u001B[0m Trial 329 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007711696924882995, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.8474843191981912}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:56,355]\u001B[0m Trial 330 finished with value: 0.47366546671567095 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006893914273259883, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.9057098490290914}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:56,955]\u001B[0m Trial 331 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009214364228185948, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8261055228589386}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:58,314]\u001B[0m Trial 332 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007876957370623924, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.7553422639216563}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:53:59,772]\u001B[0m Trial 333 finished with value: 0.6157651067303722 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006332123014747832, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9178021138057815}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:01,258]\u001B[0m Trial 334 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0073491578233375425, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8851639410559577}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:02,705]\u001B[0m Trial 335 finished with value: 0.3713906763541037 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007550980672963491, 'num_negative_samples': 1, 'alpha': 0.1, 'lmbda': 0.9698589374431641}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:04,033]\u001B[0m Trial 336 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0074464986812725915, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8573248859698792}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:05,604]\u001B[0m Trial 337 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00892973864181047, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.7989847710895606}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:07,033]\u001B[0m Trial 338 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007769419202079743, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.37490156397821794}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:08,507]\u001B[0m Trial 339 finished with value: 0.32075014954979214 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007783948743871994, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9353392896689281}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:09,870]\u001B[0m Trial 340 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00787272962971647, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.3634970761636315}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:11,316]\u001B[0m Trial 341 finished with value: 0.6308430573153381 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00760945300216457, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.2864887415388358}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:12,757]\u001B[0m Trial 342 finished with value: 0.4714045207910317 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007745342530303888, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.20469671979003382}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:14,260]\u001B[0m Trial 343 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008374380926805477, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8157826352178948}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:15,749]\u001B[0m Trial 344 finished with value: 0.5451809077932042 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007948557829286513, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.6804656414906775}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:17,175]\u001B[0m Trial 345 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008202650077198878, 'num_negative_samples': 16, 'alpha': 0.7, 'lmbda': 0.8412061120781602}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:18,544]\u001B[0m Trial 346 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007213547089574708, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.4644255745289838}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:19,986]\u001B[0m Trial 347 finished with value: 0.3992747047523452 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007695946455154002, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.1140934668941449}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:21,464]\u001B[0m Trial 348 finished with value: 0.49690399499995325 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007627485729458819, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.899049437883312}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:22,870]\u001B[0m Trial 349 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009614649719147814, 'num_negative_samples': 6, 'alpha': 0.6, 'lmbda': 0.9806804687326787}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:24,313]\u001B[0m Trial 350 finished with value: 0.665624184923862 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00916026335313523, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.71863866325435}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:25,723]\u001B[0m Trial 351 finished with value: 0.4705497521443999 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009127382427488022, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.7216786619105008}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:27,069]\u001B[0m Trial 352 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007523059375205658, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.6345767982990431}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:27,668]\u001B[0m Trial 353 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009022625872457392, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.7377839002411706}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:29,001]\u001B[0m Trial 354 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007501660109957354, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.5480315326961103}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:30,456]\u001B[0m Trial 355 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008092921181074787, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.06874721465832839}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:31,923]\u001B[0m Trial 356 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007291261081993467, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.023604676578400374}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:33,354]\u001B[0m Trial 357 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009113759887556725, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.1455116379281223}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:34,817]\u001B[0m Trial 358 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007795150370411864, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.796714536240128}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:36,164]\u001B[0m Trial 359 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007093410681646105, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.4212536460511042}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:36,825]\u001B[0m Trial 360 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009384818966327412, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.6588567459876806}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:38,219]\u001B[0m Trial 361 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009224848544168416, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.7139659233381717}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:39,557]\u001B[0m Trial 362 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007429408795913679, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.7666062822012935}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:41,001]\u001B[0m Trial 363 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00761710932303961, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7404820880182558}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:42,339]\u001B[0m Trial 364 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007712767218824914, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.9497701630061929}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:43,017]\u001B[0m Trial 365 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009271273492156944, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8612057997514375}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:44,464]\u001B[0m Trial 366 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008944433742430077, 'num_negative_samples': 1, 'alpha': 0.9, 'lmbda': 0.6901624557333836}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:45,923]\u001B[0m Trial 367 finished with value: 0.3787055246443274 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008672807705477608, 'num_negative_samples': 1, 'alpha': 0.5, 'lmbda': 0.38859525897986097}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:47,401]\u001B[0m Trial 368 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007968467995239691, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7819990520711014}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:48,772]\u001B[0m Trial 369 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007391620982464569, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.7607328160728766}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:49,432]\u001B[0m Trial 370 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007876646053981223, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.81996883792265}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:50,886]\u001B[0m Trial 371 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009759772642278395, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8792788311762771}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:52,243]\u001B[0m Trial 372 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007560404772882408, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9156881981925753}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:53,667]\u001B[0m Trial 373 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009313757601617869, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8729357910656576}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:55,140]\u001B[0m Trial 374 finished with value: 0.5007710104811096 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007302126574307002, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9332606696038371}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:56,573]\u001B[0m Trial 375 finished with value: 0.46027367060462177 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007787241876645726, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9033804336777809}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:58,110]\u001B[0m Trial 376 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008343479379978059, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.22431853665379098}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:54:58,713]\u001B[0m Trial 377 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009149107363854053, 'num_negative_samples': 1, 'alpha': 0.1, 'lmbda': 0.8368715212057753}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:00,188]\u001B[0m Trial 378 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008499592794739979, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8040325718306502}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:01,631]\u001B[0m Trial 379 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008396051629454023, 'num_negative_samples': 16, 'alpha': 0.8, 'lmbda': 0.7858860754348942}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:03,072]\u001B[0m Trial 380 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008505465459726743, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8095218101743735}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:04,510]\u001B[0m Trial 381 finished with value: 0.3528251645047713 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008597111737743702, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7601060779524244}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:06,079]\u001B[0m Trial 382 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008181253187889028, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.4440702400515295}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:07,527]\u001B[0m Trial 383 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008279921083022022, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7785294667167434}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:08,858]\u001B[0m Trial 384 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008791398469388607, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.3329931960653694}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:10,308]\u001B[0m Trial 385 finished with value: 0.3488074922742725 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0066509200953511795, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.8014492321924872}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:11,761]\u001B[0m Trial 386 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009017053349095673, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.8343379201992549}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:13,305]\u001B[0m Trial 387 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007931241917455282, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7515667393262601}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:14,735]\u001B[0m Trial 388 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007692407160017152, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.8537981573193907}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:16,188]\u001B[0m Trial 389 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007806705425175527, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7829666331114354}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:17,609]\u001B[0m Trial 390 finished with value: 0.4714045207910317 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007631357081328069, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.8207237712478708}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:19,034]\u001B[0m Trial 391 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008525188103651158, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7148441107325494}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:20,479]\u001B[0m Trial 392 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008100659463754078, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.5695441470956145}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:21,136]\u001B[0m Trial 393 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008228643029753322, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8901062971594853}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:22,557]\u001B[0m Trial 394 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007518118296374779, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.7967536063127316}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:23,969]\u001B[0m Trial 395 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006881750235829452, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.5949420557448263}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:25,387]\u001B[0m Trial 396 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007727611805567078, 'num_negative_samples': 21, 'alpha': 0.3, 'lmbda': 0.8433865153613671}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:26,798]\u001B[0m Trial 397 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008025658548366238, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8631548744696659}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:28,292]\u001B[0m Trial 398 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00786033995456975, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8232853640974339}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:28,853]\u001B[0m Trial 399 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008852463522401228, 'num_negative_samples': 16, 'alpha': 0.2, 'lmbda': 0.7684012569513604}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:30,137]\u001B[0m Trial 400 finished with value: 0.4433747811741175 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00840483138484183, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.7998733243498154}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:31,573]\u001B[0m Trial 401 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00757021941983713, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.9074807619493943}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:33,001]\u001B[0m Trial 402 finished with value: 0.5451809077932042 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008734010635428984, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8850739214310065}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:34,451]\u001B[0m Trial 403 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007688830328041427, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8519854357878109}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:35,908]\u001B[0m Trial 404 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009026185134636768, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.9226529208142745}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:37,354]\u001B[0m Trial 405 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008292872705103016, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7444006403334104}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:38,810]\u001B[0m Trial 406 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00953196324809378, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8735453184531569}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:40,285]\u001B[0m Trial 407 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007046036255323157, 'num_negative_samples': 21, 'alpha': 0.1, 'lmbda': 0.8161096673943391}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:41,651]\u001B[0m Trial 408 finished with value: 0.5119213729309336 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007936017161824599, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.834467565398667}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:42,354]\u001B[0m Trial 409 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007483042008116808, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.5168230333583187}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:43,795]\u001B[0m Trial 410 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007186477097985175, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.8943599383807128}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:45,244]\u001B[0m Trial 411 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007782467649688337, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7791976914449248}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:46,572]\u001B[0m Trial 412 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008135468702754467, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.8612336508789591}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:48,001]\u001B[0m Trial 413 finished with value: 0.416110740246089 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009196844913114169, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.6166509833366587}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:48,688]\u001B[0m Trial 414 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007595340634690039, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.9634803913984961}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:50,141]\u001B[0m Trial 415 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007671347486706322, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.3093849520240598}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:51,479]\u001B[0m Trial 416 finished with value: 0.4370036867375632 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007855053173508193, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.9098272088823259}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:52,922]\u001B[0m Trial 417 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00935693584198724, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7903445854464217}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:54,385]\u001B[0m Trial 418 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009442417316897975, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.5328787504884497}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:55,838]\u001B[0m Trial 419 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009363567169664206, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.7383932992349785}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:57,338]\u001B[0m Trial 420 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00930154403408305, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7918033574904965}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:58,651]\u001B[0m Trial 421 finished with value: 0.28867513459481287 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008029928670870672, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.7690042192792494}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:55:59,938]\u001B[0m Trial 422 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009444472546609763, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8115126078619168}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:00,542]\u001B[0m Trial 423 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009141125643735357, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8423882046772467}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:01,954]\u001B[0m Trial 424 finished with value: 0.5451809077932042 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009580649856700367, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.8774521353756588}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:03,400]\u001B[0m Trial 425 finished with value: 0.6060395619242064 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009265424283845318, 'num_negative_samples': 16, 'alpha': 0.3, 'lmbda': 0.9251238539989799}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:04,855]\u001B[0m Trial 426 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007505874821750112, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.19240758219040724}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:06,298]\u001B[0m Trial 427 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006458099076077921, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.8959607697443456}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:07,754]\u001B[0m Trial 428 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007348123491042426, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7575309227518408}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:09,172]\u001B[0m Trial 429 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0077686738189462114, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7897703303270392}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:10,499]\u001B[0m Trial 430 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008873142831066674, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.8172982013623743}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:11,204]\u001B[0m Trial 431 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009058683287029544, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8361594070556617}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:12,680]\u001B[0m Trial 432 finished with value: 0.6273105439242341 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007612294668663098, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.775429780755831}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:14,120]\u001B[0m Trial 433 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009383559864422804, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9459941172612639}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:15,557]\u001B[0m Trial 434 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009377700916219674, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9756739942301362}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:16,985]\u001B[0m Trial 435 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009354595207707556, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9571652187764244}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:18,338]\u001B[0m Trial 436 finished with value: 0.6157651067303722 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009506285273283784, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7594630540813462}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:19,782]\u001B[0m Trial 437 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007453125797894351, 'num_negative_samples': 11, 'alpha': 0.6, 'lmbda': 0.9277021607353486}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:21,353]\u001B[0m Trial 438 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008156646051074136, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8035273899870905}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:22,809]\u001B[0m Trial 439 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008341266317833329, 'num_negative_samples': 6, 'alpha': 0.8, 'lmbda': 0.805441813217499}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:24,141]\u001B[0m Trial 440 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0091559025880565, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.9474516238653491}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:25,603]\u001B[0m Trial 441 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009464204711449728, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9297193524054076}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:26,315]\u001B[0m Trial 442 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00965799897010592, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8546486962289844}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:27,746]\u001B[0m Trial 443 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008950695546516643, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9920227962876865}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:29,111]\u001B[0m Trial 444 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.009368242204107828, 'num_negative_samples': 1, 'alpha': 0.4, 'lmbda': 0.6706945131354396}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:30,467]\u001B[0m Trial 445 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008216674003451023, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7054097459212523}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:31,810]\u001B[0m Trial 446 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008241690123585922, 'num_negative_samples': 1, 'alpha': 0.1, 'lmbda': 0.6805420837597476}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:33,170]\u001B[0m Trial 447 finished with value: 0.6157651067303722 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009294674380750654, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9623241857825717}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:34,541]\u001B[0m Trial 448 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008445649058204727, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7272705656784488}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:36,094]\u001B[0m Trial 449 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008238665000721004, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.70846353001783}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:37,548]\u001B[0m Trial 450 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008620972066629661, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7831802313532096}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:38,988]\u001B[0m Trial 451 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007265701278546823, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.7372012410133635}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:40,432]\u001B[0m Trial 452 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005983089315558086, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.906303789466512}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:41,893]\u001B[0m Trial 453 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0076850421669127965, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.934553848472565}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:42,556]\u001B[0m Trial 454 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007937961500142648, 'num_negative_samples': 1, 'alpha': 0.2, 'lmbda': 0.9481138470085404}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:43,867]\u001B[0m Trial 455 finished with value: 0.5188864579073903 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008102983368646526, 'num_negative_samples': 16, 'alpha': 0.8, 'lmbda': 0.6990186669225308}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:45,219]\u001B[0m Trial 456 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009171093948585686, 'num_negative_samples': 6, 'alpha': 0.7, 'lmbda': 0.8768299893015076}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:46,579]\u001B[0m Trial 457 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00924973004344126, 'num_negative_samples': 1, 'alpha': 0.3, 'lmbda': 0.6374241429371108}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:47,918]\u001B[0m Trial 458 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008293828420361594, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.6527455354448387}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:48,634]\u001B[0m Trial 459 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007820741754693756, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9131787148820757}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:50,094]\u001B[0m Trial 460 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008013184916573613, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.756179127147242}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:51,524]\u001B[0m Trial 461 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009090152803260029, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8946767218097111}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:52,969]\u001B[0m Trial 462 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00760705769423848, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.49228250987105227}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:54,420]\u001B[0m Trial 463 finished with value: 0.416110740246089 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00952785886808023, 'num_negative_samples': 1, 'alpha': 0.8, 'lmbda': 0.88386974638753}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:55,846]\u001B[0m Trial 464 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006793930749908516, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8344732379742095}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:57,353]\u001B[0m Trial 465 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00921499996226768, 'num_negative_samples': 11, 'alpha': 0.4, 'lmbda': 0.7213022423910466}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:56:58,717]\u001B[0m Trial 466 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0074941472099599405, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.863627190910768}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:00,172]\u001B[0m Trial 467 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007426659187927739, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9743607029875883}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:01,634]\u001B[0m Trial 468 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.00939803936050802, 'num_negative_samples': 21, 'alpha': 0.5, 'lmbda': 0.9171890832400809}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:03,063]\u001B[0m Trial 469 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0074032121888349955, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9851906945943582}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:03,686]\u001B[0m Trial 470 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008968524511169808, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9475902482166196}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:05,142]\u001B[0m Trial 471 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007756723103630539, 'num_negative_samples': 21, 'alpha': 0.4, 'lmbda': 0.9007939861028694}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:06,559]\u001B[0m Trial 472 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006935328770366317, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.9707081234216882}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:08,078]\u001B[0m Trial 473 finished with value: 0.6838074236161762 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00744305487958776, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9997667688626771}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:09,400]\u001B[0m Trial 474 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007297153168216219, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9945737602708578}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:10,969]\u001B[0m Trial 475 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007548106852944916, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9971650724286797}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:12,293]\u001B[0m Trial 476 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0074217846448844625, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.8488858233656499}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:12,969]\u001B[0m Trial 477 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007184466280157839, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9884707290875079}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:14,478]\u001B[0m Trial 478 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008182143609692067, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9548948704633934}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:15,163]\u001B[0m Trial 479 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007193501833145122, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.975963117898886}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:16,655]\u001B[0m Trial 480 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007882942666038856, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.7913431843154057}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:18,078]\u001B[0m Trial 481 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007044952500460286, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9981154337275681}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:19,572]\u001B[0m Trial 482 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007535957975219892, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9923873262150437}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:21,187]\u001B[0m Trial 483 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0073600430862214355, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9737960584356243}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:21,875]\u001B[0m Trial 484 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009283102753156386, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.7982529181990777}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:23,307]\u001B[0m Trial 485 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.009080087160182085, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9625375779860968}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:24,762]\u001B[0m Trial 486 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007541095038682583, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.98861507757022}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:26,238]\u001B[0m Trial 487 finished with value: 0.44035242296398963 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008459360395854253, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9817903112074519}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:27,762]\u001B[0m Trial 488 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007649547096978449, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9511260019722412}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:29,109]\u001B[0m Trial 489 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0076938886592203826, 'num_negative_samples': 6, 'alpha': 0.1, 'lmbda': 0.9425780031871055}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:30,713]\u001B[0m Trial 490 finished with value: 0.46027367060462177 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007583116296394598, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.9366497751772558}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:31,417]\u001B[0m Trial 491 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008340664436662338, 'num_negative_samples': 16, 'alpha': 0.8, 'lmbda': 0.8672456595160303}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:32,113]\u001B[0m Trial 492 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00799811684002075, 'num_negative_samples': 11, 'alpha': 0.8, 'lmbda': 0.2687443362270142}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:32,729]\u001B[0m Trial 493 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0081735906417915, 'num_negative_samples': 21, 'alpha': 0.6, 'lmbda': 0.7661632868597946}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:34,094]\u001B[0m Trial 494 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008105256489784515, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.8249044705092783}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:35,462]\u001B[0m Trial 495 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007866222798677179, 'num_negative_samples': 21, 'alpha': 0.2, 'lmbda': 0.6054511600374903}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:36,156]\u001B[0m Trial 496 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007553522207262471, 'num_negative_samples': 21, 'alpha': 0.9, 'lmbda': 0.06457784311126019}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:37,572]\u001B[0m Trial 497 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007740040561392164, 'num_negative_samples': 21, 'alpha': 0.8, 'lmbda': 0.9982840645079776}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:39,062]\u001B[0m Trial 498 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0070895548532917034, 'num_negative_samples': 21, 'alpha': 0.7, 'lmbda': 0.8148712892936925}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 13:57:39,766]\u001B[0m Trial 499 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006690899361532365, 'num_negative_samples': 1, 'alpha': 0.6, 'lmbda': 0.8390182754560596}. Best is trial 155 with value: 0.743921234687385.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: GCN, mode: unsupervised, loss from VERSE_PPR\n",
      "0\n",
      "Loss: 0.7611, Epoch: 000, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3113\n",
      "1\n",
      "Loss: 0.7764, Epoch: 001, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9790, Test acc macro: 0.4083\n",
      "2\n",
      "Loss: 0.7615, Epoch: 002, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4399\n",
      "3\n",
      "Loss: 0.7640, Epoch: 003, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3986\n",
      "4\n",
      "Loss: 0.7693, Epoch: 004, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4697\n",
      "5\n",
      "Loss: 0.7659, Epoch: 005, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4055\n",
      "6\n",
      "Loss: 0.7611, Epoch: 006, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2882\n",
      "7\n",
      "Loss: 0.7609, Epoch: 007, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.4593\n",
      "8\n",
      "Loss: 0.7638, Epoch: 008, Train acc micro: 0.9845, Test acc micro: 0.5833,Train acc macro: 0.9790, Test acc macro: 0.3011\n",
      "9\n",
      "Loss: 0.7649, Epoch: 009, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9790, Test acc macro: 0.3986\n",
      "10\n",
      "Loss: 0.7631, Epoch: 010, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9790, Test acc macro: 0.3564\n",
      "11\n",
      "Loss: 0.7608, Epoch: 011, Train acc micro: 0.9767, Test acc micro: 0.5000,Train acc macro: 0.9735, Test acc macro: 0.3019\n",
      "12\n",
      "Loss: 0.7606, Epoch: 012, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4304\n",
      "13\n",
      "Loss: 0.7619, Epoch: 013, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4464\n",
      "14\n",
      "Loss: 0.7628, Epoch: 014, Train acc micro: 1.0000, Test acc micro: 0.6944,Train acc macro: 1.0000, Test acc macro: 0.5471\n",
      "15\n",
      "Loss: 0.7622, Epoch: 015, Train acc micro: 0.9922, Test acc micro: 0.6111,Train acc macro: 0.9899, Test acc macro: 0.4681\n",
      "16\n",
      "Loss: 0.7610, Epoch: 016, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3709\n",
      "17\n",
      "Loss: 0.7605, Epoch: 017, Train acc micro: 0.9845, Test acc micro: 0.5833,Train acc macro: 0.9790, Test acc macro: 0.3582\n",
      "18\n",
      "Loss: 0.7609, Epoch: 018, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4457\n",
      "19\n",
      "Loss: 0.7615, Epoch: 019, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4035\n",
      "20\n",
      "Loss: 0.7615, Epoch: 020, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.4650\n",
      "21\n",
      "Loss: 0.7610, Epoch: 021, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3735\n",
      "22\n",
      "Loss: 0.7606, Epoch: 022, Train acc micro: 0.9922, Test acc micro: 0.5278,Train acc macro: 0.9899, Test acc macro: 0.3103\n",
      "23\n",
      "Loss: 0.7605, Epoch: 023, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4764\n",
      "24\n",
      "Loss: 0.7608, Epoch: 024, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4111\n",
      "25\n",
      "Loss: 0.7609, Epoch: 025, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.5038\n",
      "26\n",
      "Loss: 0.7608, Epoch: 026, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4323\n",
      "27\n",
      "Loss: 0.7606, Epoch: 027, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3797\n",
      "28\n",
      "Loss: 0.7604, Epoch: 028, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4139\n",
      "29\n",
      "Loss: 0.7605, Epoch: 029, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4489\n",
      "30\n",
      "Loss: 0.7606, Epoch: 030, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4097\n",
      "31\n",
      "Loss: 0.7606, Epoch: 031, Train acc micro: 1.0000, Test acc micro: 0.6944,Train acc macro: 1.0000, Test acc macro: 0.5250\n",
      "32\n",
      "Loss: 0.7605, Epoch: 032, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4616\n",
      "33\n",
      "Loss: 0.7604, Epoch: 033, Train acc micro: 1.0000, Test acc micro: 0.6944,Train acc macro: 1.0000, Test acc macro: 0.4929\n",
      "34\n",
      "Loss: 0.7604, Epoch: 034, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.4593\n",
      "35\n",
      "Loss: 0.7604, Epoch: 035, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.5197\n",
      "36\n",
      "Loss: 0.7605, Epoch: 036, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3904\n",
      "37\n",
      "Loss: 0.7604, Epoch: 037, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4000\n",
      "38\n",
      "Loss: 0.7603, Epoch: 038, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4348\n",
      "39\n",
      "Loss: 0.7603, Epoch: 039, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4568\n",
      "40\n",
      "Loss: 0.7604, Epoch: 040, Train acc micro: 1.0000, Test acc micro: 0.7222,Train acc macro: 1.0000, Test acc macro: 0.5815\n",
      "41\n",
      "Loss: 0.7604, Epoch: 041, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.4820\n",
      "42\n",
      "Loss: 0.7604, Epoch: 042, Train acc micro: 0.9922, Test acc micro: 0.6111,Train acc macro: 0.9899, Test acc macro: 0.4840\n",
      "43\n",
      "Loss: 0.7603, Epoch: 043, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4242\n",
      "44\n",
      "Loss: 0.7603, Epoch: 044, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4810\n",
      "45\n",
      "Loss: 0.7603, Epoch: 045, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4665\n",
      "46\n",
      "Loss: 0.7603, Epoch: 046, Train acc micro: 1.0000, Test acc micro: 0.7500,Train acc macro: 1.0000, Test acc macro: 0.6263\n",
      "47\n",
      "Loss: 0.7603, Epoch: 047, Train acc micro: 0.9922, Test acc micro: 0.6667,Train acc macro: 0.9899, Test acc macro: 0.4820\n",
      "48\n",
      "Loss: 0.7603, Epoch: 048, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.5207\n",
      "49\n",
      "Loss: 0.7603, Epoch: 049, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.4750\n",
      "50\n",
      "Loss: 0.7603, Epoch: 050, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4472\n",
      "51\n",
      "Loss: 0.7603, Epoch: 051, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4366\n",
      "52\n",
      "Loss: 0.7603, Epoch: 052, Train acc micro: 1.0000, Test acc micro: 0.7222,Train acc macro: 1.0000, Test acc macro: 0.5521\n",
      "53\n",
      "Loss: 0.7603, Epoch: 053, Train acc micro: 0.9767, Test acc micro: 0.6389,Train acc macro: 0.9672, Test acc macro: 0.4320\n",
      "54\n",
      "Loss: 0.7603, Epoch: 054, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4659\n",
      "55\n",
      "Loss: 0.7603, Epoch: 055, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4709\n",
      "56\n",
      "Loss: 0.7603, Epoch: 056, Train acc micro: 0.9690, Test acc micro: 0.6389,Train acc macro: 0.9618, Test acc macro: 0.4390\n",
      "57\n",
      "Loss: 0.7603, Epoch: 057, Train acc micro: 0.9690, Test acc micro: 0.6667,Train acc macro: 0.9618, Test acc macro: 0.5098\n",
      "58\n",
      "Loss: 0.7603, Epoch: 058, Train acc micro: 0.9380, Test acc micro: 0.6944,Train acc macro: 0.9233, Test acc macro: 0.5441\n",
      "59\n",
      "Loss: 0.7603, Epoch: 059, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4014\n",
      "60\n",
      "Loss: 0.7603, Epoch: 060, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4848\n",
      "61\n",
      "Loss: 0.7603, Epoch: 061, Train acc micro: 0.9922, Test acc micro: 0.6389,Train acc macro: 0.9899, Test acc macro: 0.4457\n",
      "62\n",
      "Loss: 0.7603, Epoch: 062, Train acc micro: 0.9767, Test acc micro: 0.6111,Train acc macro: 0.9672, Test acc macro: 0.4405\n",
      "63\n",
      "Loss: 0.7603, Epoch: 063, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3915\n",
      "64\n",
      "Loss: 0.7603, Epoch: 064, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.5207\n",
      "65\n",
      "Loss: 0.7603, Epoch: 065, Train acc micro: 0.9922, Test acc micro: 0.6667,Train acc macro: 0.9899, Test acc macro: 0.4521\n",
      "66\n",
      "Loss: 0.7603, Epoch: 066, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9790, Test acc macro: 0.4323\n",
      "67\n",
      "Loss: 0.7603, Epoch: 067, Train acc micro: 0.9922, Test acc micro: 0.6111,Train acc macro: 0.9899, Test acc macro: 0.3818\n",
      "68\n",
      "Loss: 0.7603, Epoch: 068, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.4987\n",
      "69\n",
      "Loss: 0.7603, Epoch: 069, Train acc micro: 0.9922, Test acc micro: 0.6389,Train acc macro: 0.9899, Test acc macro: 0.4848\n",
      "70\n",
      "Loss: 0.7603, Epoch: 070, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9790, Test acc macro: 0.4250\n",
      "71\n",
      "Loss: 0.7603, Epoch: 071, Train acc micro: 0.9690, Test acc micro: 0.6389,Train acc macro: 0.9610, Test acc macro: 0.4590\n",
      "72\n",
      "Loss: 0.7603, Epoch: 072, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4318\n",
      "73\n",
      "Loss: 0.7603, Epoch: 073, Train acc micro: 1.0000, Test acc micro: 0.6389,Train acc macro: 1.0000, Test acc macro: 0.4318\n",
      "74\n",
      "Loss: 0.7603, Epoch: 074, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4320\n",
      "75\n",
      "Loss: 0.7603, Epoch: 075, Train acc micro: 0.9922, Test acc micro: 0.6389,Train acc macro: 0.9899, Test acc macro: 0.4742\n",
      "76\n",
      "Loss: 0.7603, Epoch: 076, Train acc micro: 0.9690, Test acc micro: 0.6389,Train acc macro: 0.9544, Test acc macro: 0.4318\n",
      "77\n",
      "Loss: 0.7603, Epoch: 077, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4250\n",
      "78\n",
      "Loss: 0.7603, Epoch: 078, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4250\n",
      "79\n",
      "Loss: 0.7603, Epoch: 079, Train acc micro: 0.9922, Test acc micro: 0.6111,Train acc macro: 0.9899, Test acc macro: 0.3866\n",
      "80\n",
      "Loss: 0.7603, Epoch: 080, Train acc micro: 0.9922, Test acc micro: 0.6389,Train acc macro: 0.9899, Test acc macro: 0.4321\n",
      "81\n",
      "Loss: 0.7603, Epoch: 081, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9790, Test acc macro: 0.4131\n",
      "82\n",
      "Loss: 0.7603, Epoch: 082, Train acc micro: 0.9767, Test acc micro: 0.6389,Train acc macro: 0.9672, Test acc macro: 0.4415\n",
      "83\n",
      "Loss: 0.7603, Epoch: 083, Train acc micro: 0.9845, Test acc micro: 0.6389,Train acc macro: 0.9790, Test acc macro: 0.4265\n",
      "84\n",
      "Loss: 0.7603, Epoch: 084, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.4593\n",
      "85\n",
      "Loss: 0.7603, Epoch: 085, Train acc micro: 0.9922, Test acc micro: 0.6111,Train acc macro: 0.9899, Test acc macro: 0.3909\n",
      "86\n",
      "Loss: 0.7603, Epoch: 086, Train acc micro: 0.9845, Test acc micro: 0.5833,Train acc macro: 0.9790, Test acc macro: 0.3559\n",
      "87\n",
      "Loss: 0.7603, Epoch: 087, Train acc micro: 0.9070, Test acc micro: 0.6111,Train acc macro: 0.8978, Test acc macro: 0.4197\n",
      "88\n",
      "Loss: 0.7603, Epoch: 088, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4197\n",
      "89\n",
      "Loss: 0.7603, Epoch: 089, Train acc micro: 0.9922, Test acc micro: 0.6111,Train acc macro: 0.9899, Test acc macro: 0.4432\n",
      "90\n",
      "Loss: 0.7603, Epoch: 090, Train acc micro: 0.9845, Test acc micro: 0.6944,Train acc macro: 0.9790, Test acc macro: 0.5820\n",
      "91\n",
      "Loss: 0.7603, Epoch: 091, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.4750\n",
      "92\n",
      "Loss: 0.7603, Epoch: 092, Train acc micro: 0.9457, Test acc micro: 0.6667,Train acc macro: 0.9364, Test acc macro: 0.4821\n",
      "93\n",
      "Loss: 0.7603, Epoch: 093, Train acc micro: 0.9845, Test acc micro: 0.6944,Train acc macro: 0.9790, Test acc macro: 0.5606\n",
      "94\n",
      "Loss: 0.7603, Epoch: 094, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4071\n",
      "95\n",
      "Loss: 0.7603, Epoch: 095, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.4208\n",
      "96\n",
      "Loss: 0.7603, Epoch: 096, Train acc micro: 0.9845, Test acc micro: 0.5833,Train acc macro: 0.9790, Test acc macro: 0.3315\n",
      "97\n",
      "Loss: 0.7603, Epoch: 097, Train acc micro: 0.9457, Test acc micro: 0.6389,Train acc macro: 0.9295, Test acc macro: 0.4041\n",
      "98\n",
      "Loss: 0.7603, Epoch: 098, Train acc micro: 0.9845, Test acc micro: 0.6667,Train acc macro: 0.9790, Test acc macro: 0.5214\n",
      "99\n",
      "Loss: 0.7603, Epoch: 099, Train acc micro: 0.9767, Test acc micro: 0.6111,Train acc macro: 0.9672, Test acc macro: 0.4211\n",
      "Loss: 0.7603, Epoch: 099, Train acc micro: 0.9767, Test acc micro: 0.6111,Train acc macro: 0.9672, Test acc macro: 0.4211\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = VERSE_PPR\n",
    "loss_name = 'VERSE_PPR'\n",
    "\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "for name in datasets_names[:2]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 14:39:50,547]\u001B[0m A new study created in memory with name: VERSE_Adj loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:39:53,722]\u001B[0m Trial 0 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.008982276210820553, 'num_negative_samples': 11, 'lmbda': 0.565553085572354}. Best is trial 0 with value: 0.30281331944409007.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:39:55,390]\u001B[0m Trial 1 finished with value: 0.3083315267085868 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008817898892478766, 'num_negative_samples': 6, 'lmbda': 0.45384609898567596}. Best is trial 1 with value: 0.3083315267085868.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:39:56,051]\u001B[0m Trial 2 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008064633051462688, 'num_negative_samples': 6, 'lmbda': 0.2812351697501775}. Best is trial 1 with value: 0.3083315267085868.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:39:56,633]\u001B[0m Trial 3 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005467861963854078, 'num_negative_samples': 16, 'lmbda': 0.3020075356910884}. Best is trial 1 with value: 0.3083315267085868.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:39:57,982]\u001B[0m Trial 4 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.009699595125528615, 'num_negative_samples': 16, 'lmbda': 0.45179234483204156}. Best is trial 1 with value: 0.3083315267085868.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:39:59,435]\u001B[0m Trial 5 finished with value: 0.47587290998230447 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005800503438623905, 'num_negative_samples': 11, 'lmbda': 0.1760005747336445}. Best is trial 5 with value: 0.47587290998230447.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:00,088]\u001B[0m Trial 6 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.006967404536826049, 'num_negative_samples': 16, 'lmbda': 0.2970985472848946}. Best is trial 5 with value: 0.47587290998230447.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:01,593]\u001B[0m Trial 7 finished with value: 0.31269438398822863 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0056572282283887925, 'num_negative_samples': 16, 'lmbda': 0.7719176254209494}. Best is trial 5 with value: 0.47587290998230447.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:02,985]\u001B[0m Trial 8 finished with value: 0.3124969135650052 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0050444967694618014, 'num_negative_samples': 16, 'lmbda': 0.7644051485147402}. Best is trial 5 with value: 0.47587290998230447.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:03,635]\u001B[0m Trial 9 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00977628610100015, 'num_negative_samples': 6, 'lmbda': 0.13065629877008245}. Best is trial 5 with value: 0.47587290998230447.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:05,033]\u001B[0m Trial 10 finished with value: 0.47794494719477854 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006657629602385342, 'num_negative_samples': 1, 'lmbda': 0.002606281954013301}. Best is trial 10 with value: 0.47794494719477854.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:06,419]\u001B[0m Trial 11 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006571817451217194, 'num_negative_samples': 1, 'lmbda': 0.011796852795168294}. Best is trial 10 with value: 0.47794494719477854.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:07,783]\u001B[0m Trial 12 finished with value: 0.5170493857844406 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006336236082261067, 'num_negative_samples': 11, 'lmbda': 0.0008216394454059884}. Best is trial 12 with value: 0.5170493857844406.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:09,151]\u001B[0m Trial 13 finished with value: 0.5497276013898588 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006615677334567103, 'num_negative_samples': 1, 'lmbda': 0.02973518335352002}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:10,500]\u001B[0m Trial 14 finished with value: 0.44112695305392047 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00767333875120752, 'num_negative_samples': 21, 'lmbda': 0.9279456672177543}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:11,043]\u001B[0m Trial 15 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0061119151414711845, 'num_negative_samples': 11, 'lmbda': 0.10700335714080697}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:12,383]\u001B[0m Trial 16 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007205683761887375, 'num_negative_samples': 1, 'lmbda': 0.18368476799403574}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:13,721]\u001B[0m Trial 17 finished with value: 0.4395245364957663 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006394306777269983, 'num_negative_samples': 21, 'lmbda': 0.5648417789343462}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:14,237]\u001B[0m Trial 18 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007808493549852472, 'num_negative_samples': 1, 'lmbda': 0.0009817395468451006}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:15,612]\u001B[0m Trial 19 finished with value: 0.3474776838024864 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.008312221460353247, 'num_negative_samples': 11, 'lmbda': 0.373391427967557}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:16,947]\u001B[0m Trial 20 finished with value: 0.30393211029577855 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007212934317379882, 'num_negative_samples': 11, 'lmbda': 0.10319260130949126}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:18,321]\u001B[0m Trial 21 finished with value: 0.3472581680740104 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006723312518985437, 'num_negative_samples': 1, 'lmbda': 0.002964723141684676}. Best is trial 13 with value: 0.5497276013898588.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:19,708]\u001B[0m Trial 22 finished with value: 0.5708992257184501 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006166427060897552, 'num_negative_samples': 1, 'lmbda': 0.2058919941316805}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:21,075]\u001B[0m Trial 23 finished with value: 0.5178302310102686 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00611717536278208, 'num_negative_samples': 1, 'lmbda': 0.2241479265799018}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:22,469]\u001B[0m Trial 24 finished with value: 0.34641016151377546 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006014394881560437, 'num_negative_samples': 1, 'lmbda': 0.2313512004658818}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:23,841]\u001B[0m Trial 25 finished with value: 0.5356977317285162 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005440473327331618, 'num_negative_samples': 1, 'lmbda': 0.37268771961766534}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:25,211]\u001B[0m Trial 26 finished with value: 0.552593410315562 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005213124887870637, 'num_negative_samples': 1, 'lmbda': 0.3777761554657125}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:26,570]\u001B[0m Trial 27 finished with value: 0.4507304013896135 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0052719466741379, 'num_negative_samples': 1, 'lmbda': 0.38851253631069177}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:27,179]\u001B[0m Trial 28 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0057973940500818414, 'num_negative_samples': 1, 'lmbda': 0.5749408882605128}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:28,358]\u001B[0m Trial 29 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005109319146003318, 'num_negative_samples': 21, 'lmbda': 0.678194889386378}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:29,735]\u001B[0m Trial 30 finished with value: 0.45338235029118146 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007094911239739801, 'num_negative_samples': 1, 'lmbda': 0.08937245857780324}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:31,100]\u001B[0m Trial 31 finished with value: 0.4469956020210052 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0055234522357886055, 'num_negative_samples': 1, 'lmbda': 0.36947050642104823}. Best is trial 22 with value: 0.5708992257184501.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:32,485]\u001B[0m Trial 32 finished with value: 0.573488351136175 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005455666380660489, 'num_negative_samples': 1, 'lmbda': 0.46225614470490334}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:33,897]\u001B[0m Trial 33 finished with value: 0.338296385503074 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006256116853726333, 'num_negative_samples': 1, 'lmbda': 0.534620632558638}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:35,267]\u001B[0m Trial 34 finished with value: 0.49835913091045436 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005858859939618538, 'num_negative_samples': 6, 'lmbda': 0.4580623609600222}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:36,524]\u001B[0m Trial 35 finished with value: 0.5587684871413403 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005335291640306915, 'num_negative_samples': 1, 'lmbda': 0.30757359443804616}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:37,777]\u001B[0m Trial 36 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005269920726190898, 'num_negative_samples': 1, 'lmbda': 0.3104221155920762}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:38,325]\u001B[0m Trial 37 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005409495394236887, 'num_negative_samples': 6, 'lmbda': 0.2510281821751289}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:38,957]\u001B[0m Trial 38 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008790780743999846, 'num_negative_samples': 1, 'lmbda': 0.441127584115818}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:40,224]\u001B[0m Trial 39 finished with value: 0.5264948286999456 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005629474498722128, 'num_negative_samples': 1, 'lmbda': 0.30389317803050875}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:41,470]\u001B[0m Trial 40 finished with value: 0.2684153192828811 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005006157400838682, 'num_negative_samples': 16, 'lmbda': 0.3212151692781481}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:42,725]\u001B[0m Trial 41 finished with value: 0.44095855184409843 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005234889558178172, 'num_negative_samples': 1, 'lmbda': 0.49490186160415306}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:44,013]\u001B[0m Trial 42 finished with value: 0.4353647708073435 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005803761585728965, 'num_negative_samples': 1, 'lmbda': 0.42598631967843414}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:45,303]\u001B[0m Trial 43 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005291348231971204, 'num_negative_samples': 1, 'lmbda': 0.32702521106983407}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:46,578]\u001B[0m Trial 44 finished with value: 0.47840056688565297 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005592775648398122, 'num_negative_samples': 1, 'lmbda': 0.18185570653251426}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:47,863]\u001B[0m Trial 45 finished with value: 0.25689154519615076 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0052475009583930286, 'num_negative_samples': 6, 'lmbda': 0.6311398682322257}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:49,224]\u001B[0m Trial 46 finished with value: 0.485912657903775 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0059183910559698315, 'num_negative_samples': 1, 'lmbda': 0.2603087575819406}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:49,886]\u001B[0m Trial 47 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.009488592186474696, 'num_negative_samples': 16, 'lmbda': 0.340870583804497}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:51,142]\u001B[0m Trial 48 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00502452136735898, 'num_negative_samples': 21, 'lmbda': 0.49337972242901273}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:52,438]\u001B[0m Trial 49 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005687804533105595, 'num_negative_samples': 1, 'lmbda': 0.40443289209198596}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:53,688]\u001B[0m Trial 50 finished with value: 0.5185449728701349 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0054456562679677765, 'num_negative_samples': 1, 'lmbda': 0.15055452295249538}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:55,048]\u001B[0m Trial 51 finished with value: 0.47871355387816905 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006759651949939202, 'num_negative_samples': 1, 'lmbda': 0.0651990502432235}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:56,421]\u001B[0m Trial 52 finished with value: 0.2265764736148083 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006435379636972112, 'num_negative_samples': 1, 'lmbda': 0.22227202314333672}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:57,813]\u001B[0m Trial 53 finished with value: 0.5673198849430997 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006168193100441321, 'num_negative_samples': 1, 'lmbda': 0.2800340974717741}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:40:59,219]\u001B[0m Trial 54 finished with value: 0.48384146587757865 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006269351223224411, 'num_negative_samples': 1, 'lmbda': 0.27244309656016813}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:00,630]\u001B[0m Trial 55 finished with value: 0.3505098327538656 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0060865753768366325, 'num_negative_samples': 11, 'lmbda': 0.20196797202032565}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:02,024]\u001B[0m Trial 56 finished with value: 0.5434798711731377 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005699492262577623, 'num_negative_samples': 1, 'lmbda': 0.14863000854203318}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:03,442]\u001B[0m Trial 57 finished with value: 0.25152379839481986 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005208201921232006, 'num_negative_samples': 21, 'lmbda': 0.284711855718419}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:04,076]\u001B[0m Trial 58 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005462417058330812, 'num_negative_samples': 16, 'lmbda': 0.3575846214788916}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:05,476]\u001B[0m Trial 59 finished with value: 0.4840033669916556 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005975420212724452, 'num_negative_samples': 1, 'lmbda': 0.4671212945678446}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:06,733]\u001B[0m Trial 60 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006540153753078479, 'num_negative_samples': 1, 'lmbda': 0.40336968537008255}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:08,128]\u001B[0m Trial 61 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0074291635963190435, 'num_negative_samples': 1, 'lmbda': 0.04617345217066071}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:09,481]\u001B[0m Trial 62 finished with value: 0.29742828244876995 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006872273200348252, 'num_negative_samples': 1, 'lmbda': 0.05167330813674004}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:10,842]\u001B[0m Trial 63 finished with value: 0.3929942040850532 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00743655638405313, 'num_negative_samples': 1, 'lmbda': 0.2982216653218132}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:12,257]\u001B[0m Trial 64 finished with value: 0.5625571866355402 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008031806139935442, 'num_negative_samples': 1, 'lmbda': 0.13273315848103043}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:13,624]\u001B[0m Trial 65 finished with value: 0.4524623986832743 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007913380876630188, 'num_negative_samples': 1, 'lmbda': 0.13866767850151565}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:15,011]\u001B[0m Trial 66 finished with value: 0.35686191636321657 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008357246870055905, 'num_negative_samples': 11, 'lmbda': 0.9381174856249104}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:16,391]\u001B[0m Trial 67 finished with value: 0.3415650255319866 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007474436583368959, 'num_negative_samples': 1, 'lmbda': 0.9917525839781824}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:17,735]\u001B[0m Trial 68 finished with value: 0.32564226536224283 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008172000789028102, 'num_negative_samples': 6, 'lmbda': 0.09315372376473849}. Best is trial 32 with value: 0.573488351136175.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:19,077]\u001B[0m Trial 69 finished with value: 0.586736107001486 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008444009021133769, 'num_negative_samples': 1, 'lmbda': 0.03945628396264578}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:19,686]\u001B[0m Trial 70 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.008665577551301503, 'num_negative_samples': 1, 'lmbda': 0.1701938109926607}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:21,038]\u001B[0m Trial 71 finished with value: 0.508844336632097 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0085703377616871, 'num_negative_samples': 1, 'lmbda': 0.03807238195709864}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:22,414]\u001B[0m Trial 72 finished with value: 0.42679985901839246 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00929962086519752, 'num_negative_samples': 1, 'lmbda': 0.10797683245187006}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:23,800]\u001B[0m Trial 73 finished with value: 0.5849976258261415 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007675428126872481, 'num_negative_samples': 1, 'lmbda': 0.20951116557101024}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:25,148]\u001B[0m Trial 74 finished with value: 0.5507570547286101 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007716715876258272, 'num_negative_samples': 1, 'lmbda': 0.20912781367766836}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:26,526]\u001B[0m Trial 75 finished with value: 0.3480716106691928 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00801240597438933, 'num_negative_samples': 1, 'lmbda': 0.235423463559958}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:27,889]\u001B[0m Trial 76 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007589417295616581, 'num_negative_samples': 1, 'lmbda': 0.2559275171679003}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:29,124]\u001B[0m Trial 77 finished with value: 0.29814239699997197 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008318136926591934, 'num_negative_samples': 21, 'lmbda': 0.19558853808814503}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:29,639]\u001B[0m Trial 78 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007288674886080718, 'num_negative_samples': 1, 'lmbda': 0.16659471215009225}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:30,952]\u001B[0m Trial 79 finished with value: 0.4837219533002148 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008954430062761642, 'num_negative_samples': 16, 'lmbda': 0.3094633275591576}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:32,187]\u001B[0m Trial 80 finished with value: 0.5195187671041669 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008145244193592282, 'num_negative_samples': 1, 'lmbda': 0.07479103572984408}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:33,560]\u001B[0m Trial 81 finished with value: 0.44095855184409843 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0073249707659460706, 'num_negative_samples': 1, 'lmbda': 0.12395392979361668}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:34,935]\u001B[0m Trial 82 finished with value: 0.5490732933602595 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007842585472484852, 'num_negative_samples': 1, 'lmbda': 0.03944614310805872}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:36,279]\u001B[0m Trial 83 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008465476167022363, 'num_negative_samples': 1, 'lmbda': 0.12033765204897069}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:37,654]\u001B[0m Trial 84 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009998023371315551, 'num_negative_samples': 1, 'lmbda': 0.35053506784512456}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:39,029]\u001B[0m Trial 85 finished with value: 0.37786944737026235 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007067906529371907, 'num_negative_samples': 1, 'lmbda': 0.019219960543092083}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:40,388]\u001B[0m Trial 86 finished with value: 0.3535533905932738 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008100935591948761, 'num_negative_samples': 11, 'lmbda': 0.0763069573949216}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:41,632]\u001B[0m Trial 87 finished with value: 0.29814239699997197 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005339219440652588, 'num_negative_samples': 6, 'lmbda': 0.24254361076847}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:42,984]\u001B[0m Trial 88 finished with value: 0.39791121287711073 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005139497107780315, 'num_negative_samples': 1, 'lmbda': 0.7623726663066641}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:43,609]\u001B[0m Trial 89 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005546046485755032, 'num_negative_samples': 1, 'lmbda': 0.15348315707790317}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:44,844]\u001B[0m Trial 90 finished with value: 0.49731304169296475 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007605796573227725, 'num_negative_samples': 1, 'lmbda': 0.2754986260048701}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:46,203]\u001B[0m Trial 91 finished with value: 0.5852688976356787 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005135700089604444, 'num_negative_samples': 1, 'lmbda': 0.3993606853862665}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:47,563]\u001B[0m Trial 92 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00534624941680974, 'num_negative_samples': 1, 'lmbda': 0.4083200925146957}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:48,906]\u001B[0m Trial 93 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005095960163002965, 'num_negative_samples': 1, 'lmbda': 0.317594731648649}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:50,302]\u001B[0m Trial 94 finished with value: 0.4303314829119352 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005099614063680034, 'num_negative_samples': 1, 'lmbda': 0.3304091168613641}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:51,683]\u001B[0m Trial 95 finished with value: 0.4353647708073435 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005774995515644642, 'num_negative_samples': 1, 'lmbda': 0.5215463063256548}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:52,219]\u001B[0m Trial 96 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005157100962564527, 'num_negative_samples': 1, 'lmbda': 0.28432861877502213}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:53,529]\u001B[0m Trial 97 finished with value: 0.44112695305392047 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005403409060009445, 'num_negative_samples': 21, 'lmbda': 0.46817239275578376}. Best is trial 69 with value: 0.586736107001486.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:54,942]\u001B[0m Trial 98 finished with value: 0.590668171555645 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0055410816251687525, 'num_negative_samples': 1, 'lmbda': 0.3769483606431198}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:56,372]\u001B[0m Trial 99 finished with value: 0.3592426178323267 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005571087569913061, 'num_negative_samples': 16, 'lmbda': 0.3890909680738869}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:57,772]\u001B[0m Trial 100 finished with value: 0.5229151797423661 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005025626262801268, 'num_negative_samples': 1, 'lmbda': 0.4231192807077616}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:41:59,157]\u001B[0m Trial 101 finished with value: 0.5030123681333558 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00618159707759405, 'num_negative_samples': 1, 'lmbda': 0.3173079505548748}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:00,533]\u001B[0m Trial 102 finished with value: 0.3592426178323267 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005679841645666082, 'num_negative_samples': 1, 'lmbda': 0.22318733904243288}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:01,952]\u001B[0m Trial 103 finished with value: 0.4837219533002147 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0053356769370920985, 'num_negative_samples': 1, 'lmbda': 0.34350087975535276}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:03,233]\u001B[0m Trial 104 finished with value: 0.34689750898700683 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005891847596618617, 'num_negative_samples': 1, 'lmbda': 0.3634394965054484}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:04,622]\u001B[0m Trial 105 finished with value: 0.3083315267085868 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00548281710003101, 'num_negative_samples': 1, 'lmbda': 0.26404960255173404}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:06,022]\u001B[0m Trial 106 finished with value: 0.4066695426990622 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005172389963559572, 'num_negative_samples': 1, 'lmbda': 0.2931064685508931}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:07,440]\u001B[0m Trial 107 finished with value: 0.40061680838488767 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008001442517082857, 'num_negative_samples': 6, 'lmbda': 0.37889577617945536}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:08,067]\u001B[0m Trial 108 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005251223976421514, 'num_negative_samples': 11, 'lmbda': 0.20006666433615145}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:09,467]\u001B[0m Trial 109 finished with value: 0.4270589526587819 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006014438966994125, 'num_negative_samples': 1, 'lmbda': 0.4204249574972864}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:10,838]\u001B[0m Trial 110 finished with value: 0.24873416908154553 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008234245011673967, 'num_negative_samples': 1, 'lmbda': 0.33271706727841993}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:12,237]\u001B[0m Trial 111 finished with value: 0.47840056688565297 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006404207017528019, 'num_negative_samples': 1, 'lmbda': 0.3075680277740307}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:13,611]\u001B[0m Trial 112 finished with value: 0.25152379839481986 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007780602005581352, 'num_negative_samples': 1, 'lmbda': 0.058267756372126445}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:15,003]\u001B[0m Trial 113 finished with value: 0.5420342882056847 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005757411502610406, 'num_negative_samples': 1, 'lmbda': 0.4548114897344129}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:16,410]\u001B[0m Trial 114 finished with value: 0.49209475201861536 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00557710383177296, 'num_negative_samples': 1, 'lmbda': 0.24717496591826554}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:17,688]\u001B[0m Trial 115 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00509733759289954, 'num_negative_samples': 1, 'lmbda': 0.43453996141632817}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:18,958]\u001B[0m Trial 116 finished with value: 0.5613035973473373 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008773087865687394, 'num_negative_samples': 1, 'lmbda': 0.48629599865337425}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:20,258]\u001B[0m Trial 117 finished with value: 0.49065338146265813 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008615804734907643, 'num_negative_samples': 1, 'lmbda': 0.5526385624182233}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:21,527]\u001B[0m Trial 118 finished with value: 0.4031128874149275 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009207955449822069, 'num_negative_samples': 1, 'lmbda': 0.48637446561964753}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:22,838]\u001B[0m Trial 119 finished with value: 0.5649210586171627 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054020582463467645, 'num_negative_samples': 21, 'lmbda': 0.3876231795825995}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:24,137]\u001B[0m Trial 120 finished with value: 0.4849043979304324 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008776819401908432, 'num_negative_samples': 21, 'lmbda': 0.3924993718363189}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:25,443]\u001B[0m Trial 121 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00893556561948482, 'num_negative_samples': 21, 'lmbda': 0.5164965467515948}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:26,737]\u001B[0m Trial 122 finished with value: 0.5323247544065163 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005412757075373142, 'num_negative_samples': 21, 'lmbda': 0.35002638579147705}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:28,028]\u001B[0m Trial 123 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009084393267997848, 'num_negative_samples': 21, 'lmbda': 0.3674068974322911}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:29,298]\u001B[0m Trial 124 finished with value: 0.4307995302853958 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005487471739213486, 'num_negative_samples': 1, 'lmbda': 0.4408957523042951}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:30,569]\u001B[0m Trial 125 finished with value: 0.30393211029577855 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0052856689165290075, 'num_negative_samples': 16, 'lmbda': 0.46845910107969235}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:31,866]\u001B[0m Trial 126 finished with value: 0.5416025603090641 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00847610602386541, 'num_negative_samples': 1, 'lmbda': 0.5779788576587711}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:33,137]\u001B[0m Trial 127 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005231648845921541, 'num_negative_samples': 21, 'lmbda': 0.18284816464241}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:34,343]\u001B[0m Trial 128 finished with value: 0.5487359211051442 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0050198792895515985, 'num_negative_samples': 1, 'lmbda': 0.22099837716229762}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:34,968]\u001B[0m Trial 129 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005645994886257182, 'num_negative_samples': 1, 'lmbda': 0.27500771876558605}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:36,345]\u001B[0m Trial 130 finished with value: 0.469717916025055 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005364175347555465, 'num_negative_samples': 1, 'lmbda': 0.4020084125141784}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:37,714]\u001B[0m Trial 131 finished with value: 0.4353647708073435 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006521031402813268, 'num_negative_samples': 1, 'lmbda': 0.02980837081730611}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:39,089]\u001B[0m Trial 132 finished with value: 0.5419983240157367 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008843120915725016, 'num_negative_samples': 1, 'lmbda': 0.31230393846714544}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:40,464]\u001B[0m Trial 133 finished with value: 0.38315459141851343 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007022981307346245, 'num_negative_samples': 1, 'lmbda': 0.1032052110333068}. Best is trial 98 with value: 0.590668171555645.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:41,824]\u001B[0m Trial 134 finished with value: 0.5948118774794626 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007924712139276329, 'num_negative_samples': 1, 'lmbda': 0.48482625993260864}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:43,207]\u001B[0m Trial 135 finished with value: 0.5211573066470477 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00799660685824921, 'num_negative_samples': 1, 'lmbda': 0.5039584012871732}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:44,566]\u001B[0m Trial 136 finished with value: 0.34167540363327853 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007846656230327037, 'num_negative_samples': 11, 'lmbda': 0.3331636280679401}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:45,816]\u001B[0m Trial 137 finished with value: 0.31622776601683794 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007646124958257432, 'num_negative_samples': 6, 'lmbda': 0.4518326290590874}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:47,191]\u001B[0m Trial 138 finished with value: 0.49209475201861536 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006866195315072438, 'num_negative_samples': 1, 'lmbda': 0.4780356708436182}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:47,722]\u001B[0m Trial 139 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008414397977960881, 'num_negative_samples': 1, 'lmbda': 0.5466354092211604}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:49,100]\u001B[0m Trial 140 finished with value: 0.497152384915491 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007515341272462103, 'num_negative_samples': 1, 'lmbda': 0.4113390294626218}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:50,521]\u001B[0m Trial 141 finished with value: 0.49646901361664203 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007902385319393593, 'num_negative_samples': 1, 'lmbda': 0.011631704683656416}. Best is trial 134 with value: 0.5948118774794626.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:51,918]\u001B[0m Trial 142 finished with value: 0.6509252673723026 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00517252933615221, 'num_negative_samples': 1, 'lmbda': 0.37944880262283615}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:53,291]\u001B[0m Trial 143 finished with value: 0.4714045207910316 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005272139238115129, 'num_negative_samples': 1, 'lmbda': 0.35304030146518534}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:54,650]\u001B[0m Trial 144 finished with value: 0.49731304169296475 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005135436085621593, 'num_negative_samples': 1, 'lmbda': 0.36820081601240373}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:56,010]\u001B[0m Trial 145 finished with value: 0.3637626043496394 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00549286417165861, 'num_negative_samples': 1, 'lmbda': 0.3826346527083015}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:57,273]\u001B[0m Trial 146 finished with value: 0.3599242344514392 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005380646267872999, 'num_negative_samples': 1, 'lmbda': 0.428178109399245}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:42:58,675]\u001B[0m Trial 147 finished with value: 0.49846267922753223 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008268423886832726, 'num_negative_samples': 1, 'lmbda': 0.29498996306002223}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:00,058]\u001B[0m Trial 148 finished with value: 0.31101772641409176 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005095504814991856, 'num_negative_samples': 1, 'lmbda': 0.26226803541336774}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:01,381]\u001B[0m Trial 149 finished with value: 0.5876729338026236 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00520632527054125, 'num_negative_samples': 21, 'lmbda': 0.5824277470321092}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:02,709]\u001B[0m Trial 150 finished with value: 0.2981423969999719 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0077285725335426774, 'num_negative_samples': 21, 'lmbda': 0.5873659178856451}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:04,005]\u001B[0m Trial 151 finished with value: 0.2684153192828811 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0052285555179861, 'num_negative_samples': 21, 'lmbda': 0.49979033947224416}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:05,283]\u001B[0m Trial 152 finished with value: 0.4120977570959453 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0051912265829867545, 'num_negative_samples': 21, 'lmbda': 0.6223501640838156}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:06,549]\u001B[0m Trial 153 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005004910946294288, 'num_negative_samples': 21, 'lmbda': 0.7352575916140188}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:07,849]\u001B[0m Trial 154 finished with value: 0.415704772063468 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005310479888517209, 'num_negative_samples': 1, 'lmbda': 0.3293585587454573}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:09,243]\u001B[0m Trial 155 finished with value: 0.34689750898700683 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054990664382360156, 'num_negative_samples': 21, 'lmbda': 0.6038682822066005}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:10,669]\u001B[0m Trial 156 finished with value: 0.29814239699997197 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005617313080431974, 'num_negative_samples': 16, 'lmbda': 0.386609303078069}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:11,921]\u001B[0m Trial 157 finished with value: 0.4472135954999579 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005407310114423006, 'num_negative_samples': 1, 'lmbda': 0.5324832073045184}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:12,565]\u001B[0m Trial 158 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005101844644152591, 'num_negative_samples': 1, 'lmbda': 0.4432230024660192}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:13,866]\u001B[0m Trial 159 finished with value: 0.3901135119276852 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005302819821246612, 'num_negative_samples': 1, 'lmbda': 0.1345506511314294}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:15,266]\u001B[0m Trial 160 finished with value: 0.5151305437694245 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008720457442691261, 'num_negative_samples': 1, 'lmbda': 0.15869954714196985}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:16,664]\u001B[0m Trial 161 finished with value: 0.41932485418030413 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008115233714792617, 'num_negative_samples': 1, 'lmbda': 0.0619647632594439}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:18,077]\u001B[0m Trial 162 finished with value: 0.49065338146265813 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00672574528803713, 'num_negative_samples': 1, 'lmbda': 0.08537961192831309}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:19,487]\u001B[0m Trial 163 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005160068265559119, 'num_negative_samples': 1, 'lmbda': 0.29017763494428717}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:20,898]\u001B[0m Trial 164 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007381412496970491, 'num_negative_samples': 1, 'lmbda': 0.3186628839947597}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:22,296]\u001B[0m Trial 165 finished with value: 0.36881829676269584 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005856382495342627, 'num_negative_samples': 1, 'lmbda': 0.24327397039138393}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:23,700]\u001B[0m Trial 166 finished with value: 0.47381739518152793 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0054167381136645334, 'num_negative_samples': 6, 'lmbda': 0.5157098486474083}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:24,864]\u001B[0m Trial 167 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.008547045699247887, 'num_negative_samples': 11, 'lmbda': 0.3494739403158371}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:26,212]\u001B[0m Trial 168 finished with value: 0.6337319319839908 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007964323593069315, 'num_negative_samples': 1, 'lmbda': 0.678995464381526}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:27,498]\u001B[0m Trial 169 finished with value: 0.47840056688565297 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007922524864345505, 'num_negative_samples': 1, 'lmbda': 0.8543464305361648}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:28,873]\u001B[0m Trial 170 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007774821756563744, 'num_negative_samples': 21, 'lmbda': 0.7135061970571271}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:30,248]\u001B[0m Trial 171 finished with value: 0.5824596632036069 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007551030659459868, 'num_negative_samples': 1, 'lmbda': 0.6706466819237207}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:31,635]\u001B[0m Trial 172 finished with value: 0.42646376754566123 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008007265673570482, 'num_negative_samples': 1, 'lmbda': 0.6943548683410918}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:33,010]\u001B[0m Trial 173 finished with value: 0.3088367156914222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007666934469176077, 'num_negative_samples': 1, 'lmbda': 0.6522424307663363}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:34,357]\u001B[0m Trial 174 finished with value: 0.37712361663282534 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007468305540123399, 'num_negative_samples': 1, 'lmbda': 0.6546707901616601}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:35,727]\u001B[0m Trial 175 finished with value: 0.544491127783818 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007610773588248438, 'num_negative_samples': 1, 'lmbda': 0.6715254936731869}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:37,126]\u001B[0m Trial 176 finished with value: 0.356066883788698 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007239682981942155, 'num_negative_samples': 1, 'lmbda': 0.7045888740402189}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:38,560]\u001B[0m Trial 177 finished with value: 0.3317346030940278 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005220877894715922, 'num_negative_samples': 1, 'lmbda': 0.47857866535296917}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:39,953]\u001B[0m Trial 178 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007521252446678917, 'num_negative_samples': 1, 'lmbda': 0.6225624675505338}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:41,232]\u001B[0m Trial 179 finished with value: 0.48749802152178456 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00822236772331619, 'num_negative_samples': 1, 'lmbda': 0.7265658195970507}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:42,528]\u001B[0m Trial 180 finished with value: 0.3596980901386366 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0062319100322843915, 'num_negative_samples': 1, 'lmbda': 0.4135261692492874}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:43,933]\u001B[0m Trial 181 finished with value: 0.28631330503833613 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007922815994713584, 'num_negative_samples': 1, 'lmbda': 0.637209240965644}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:45,323]\u001B[0m Trial 182 finished with value: 0.26738119759257223 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007173620869912655, 'num_negative_samples': 1, 'lmbda': 0.19025211916103604}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:46,723]\u001B[0m Trial 183 finished with value: 0.5824596632036069 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007529960124839267, 'num_negative_samples': 1, 'lmbda': 0.6124462177440084}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:48,140]\u001B[0m Trial 184 finished with value: 0.37573457465108967 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007551036945399003, 'num_negative_samples': 1, 'lmbda': 0.5919290509050413}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:49,539]\u001B[0m Trial 185 finished with value: 0.540975342310215 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0077420232001382625, 'num_negative_samples': 1, 'lmbda': 0.6759227368120665}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:50,944]\u001B[0m Trial 186 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00532755404008165, 'num_negative_samples': 1, 'lmbda': 0.5463408664313332}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:52,372]\u001B[0m Trial 187 finished with value: 0.47794494719477854 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00806160950677337, 'num_negative_samples': 21, 'lmbda': 0.21540679173202276}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:53,770]\u001B[0m Trial 188 finished with value: 0.6454748690985627 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007370618186725446, 'num_negative_samples': 1, 'lmbda': 0.6538443134474864}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:55,154]\u001B[0m Trial 189 finished with value: 0.5151305437694245 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0073538579511131545, 'num_negative_samples': 1, 'lmbda': 0.6859522071969842}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:55,778]\u001B[0m Trial 190 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.007838911000149754, 'num_negative_samples': 16, 'lmbda': 0.652337602898009}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:57,157]\u001B[0m Trial 191 finished with value: 0.573488351136175 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008354812423824916, 'num_negative_samples': 1, 'lmbda': 0.6620694685020387}. Best is trial 142 with value: 0.6509252673723026.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:58,532]\u001B[0m Trial 192 finished with value: 0.6546132587402416 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008402845038343687, 'num_negative_samples': 1, 'lmbda': 0.6143605954188887}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:43:59,907]\u001B[0m Trial 193 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0083630452410856, 'num_negative_samples': 1, 'lmbda': 0.5978211270088334}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:01,267]\u001B[0m Trial 194 finished with value: 0.5470459388929408 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008536515573427795, 'num_negative_samples': 1, 'lmbda': 0.607430591872975}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:02,635]\u001B[0m Trial 195 finished with value: 0.43221478067527724 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00832323698448597, 'num_negative_samples': 1, 'lmbda': 0.6425777803268414}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:04,012]\u001B[0m Trial 196 finished with value: 0.4185536593740414 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008163775317763472, 'num_negative_samples': 1, 'lmbda': 0.6751963084392433}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:05,419]\u001B[0m Trial 197 finished with value: 0.4508524967838252 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008422372860992665, 'num_negative_samples': 1, 'lmbda': 0.6630296798110361}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:06,794]\u001B[0m Trial 198 finished with value: 0.44112695305392047 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008234207265607222, 'num_negative_samples': 1, 'lmbda': 0.6217082661743463}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:08,173]\u001B[0m Trial 199 finished with value: 0.47794494719477854 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005062508312330476, 'num_negative_samples': 1, 'lmbda': 0.6291198245967237}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:09,469]\u001B[0m Trial 200 finished with value: 0.3458942860800929 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007673298129241984, 'num_negative_samples': 21, 'lmbda': 0.5724074766361362}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:10,881]\u001B[0m Trial 201 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008686085449430883, 'num_negative_samples': 1, 'lmbda': 0.566076422101975}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:12,308]\u001B[0m Trial 202 finished with value: 0.48124364057662267 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00807418705808083, 'num_negative_samples': 1, 'lmbda': 0.7514533787955844}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:13,720]\u001B[0m Trial 203 finished with value: 0.3600411499115478 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00851403191035295, 'num_negative_samples': 1, 'lmbda': 0.6442431770647877}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:15,138]\u001B[0m Trial 204 finished with value: 0.4109609335312651 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00515507372726011, 'num_negative_samples': 1, 'lmbda': 0.6145961344734546}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:15,691]\u001B[0m Trial 205 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008892290967837786, 'num_negative_samples': 1, 'lmbda': 0.700028162021128}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:17,115]\u001B[0m Trial 206 finished with value: 0.594418483337567 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00912701292791241, 'num_negative_samples': 1, 'lmbda': 0.7939412734271798}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:18,536]\u001B[0m Trial 207 finished with value: 0.5867482460762062 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009070676373549368, 'num_negative_samples': 1, 'lmbda': 0.45722393878578055}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:19,936]\u001B[0m Trial 208 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009002398994164565, 'num_negative_samples': 6, 'lmbda': 0.459578161974553}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:21,332]\u001B[0m Trial 209 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009435009622952933, 'num_negative_samples': 11, 'lmbda': 0.44010759570020774}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:22,744]\u001B[0m Trial 210 finished with value: 0.35686191636321657 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009036688399609232, 'num_negative_samples': 1, 'lmbda': 0.5098870642521771}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:24,153]\u001B[0m Trial 211 finished with value: 0.5408560367835904 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009254844959843975, 'num_negative_samples': 1, 'lmbda': 0.4008166707304941}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:25,531]\u001B[0m Trial 212 finished with value: 0.40624214421766003 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008780704461875464, 'num_negative_samples': 1, 'lmbda': 0.8222646934884477}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:26,925]\u001B[0m Trial 213 finished with value: 0.4288946459026396 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009561357376038353, 'num_negative_samples': 1, 'lmbda': 0.808152164267119}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:28,300]\u001B[0m Trial 214 finished with value: 0.3961715179789607 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006318460159626215, 'num_negative_samples': 1, 'lmbda': 0.3756366670605985}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:29,660]\u001B[0m Trial 215 finished with value: 0.5436301767407516 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009075448126760198, 'num_negative_samples': 1, 'lmbda': 0.4732909177367918}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:31,033]\u001B[0m Trial 216 finished with value: 0.3428277471231447 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009347357614995817, 'num_negative_samples': 1, 'lmbda': 0.42471630316849424}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:32,319]\u001B[0m Trial 217 finished with value: 0.5182387756347729 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007957552071244926, 'num_negative_samples': 1, 'lmbda': 0.4933663533771014}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:33,662]\u001B[0m Trial 218 finished with value: 0.4509623081444871 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0068878072108834905, 'num_negative_samples': 1, 'lmbda': 0.9069112762604234}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:35,037]\u001B[0m Trial 219 finished with value: 0.32329198028671313 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00914289839655381, 'num_negative_samples': 21, 'lmbda': 0.7822001438659678}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:36,381]\u001B[0m Trial 220 finished with value: 0.5159194118330622 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008628295922477925, 'num_negative_samples': 1, 'lmbda': 0.5322690173987723}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:37,751]\u001B[0m Trial 221 finished with value: 0.5106277908033803 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009145296534505633, 'num_negative_samples': 1, 'lmbda': 0.4608562824183976}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:39,134]\u001B[0m Trial 222 finished with value: 0.3026259929062465 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005234348149582346, 'num_negative_samples': 1, 'lmbda': 0.6553706626572804}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:40,496]\u001B[0m Trial 223 finished with value: 0.5252593986759646 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007857253017604213, 'num_negative_samples': 1, 'lmbda': 0.4828919233572356}. Best is trial 192 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:41,778]\u001B[0m Trial 224 finished with value: 0.6687467549246293 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005554618980266689, 'num_negative_samples': 1, 'lmbda': 0.34407650483096536}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:43,062]\u001B[0m Trial 225 finished with value: 0.5126185499743233 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005538220540648833, 'num_negative_samples': 1, 'lmbda': 0.39994266339974255}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:44,456]\u001B[0m Trial 226 finished with value: 0.4720587952499556 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005726760767447497, 'num_negative_samples': 1, 'lmbda': 0.3620662641060485}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:45,753]\u001B[0m Trial 227 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008397546380844487, 'num_negative_samples': 1, 'lmbda': 0.37677545185809425}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:47,070]\u001B[0m Trial 228 finished with value: 0.6286375626584726 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00847156960428369, 'num_negative_samples': 1, 'lmbda': 0.423920181749555}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:48,383]\u001B[0m Trial 229 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008351222430713554, 'num_negative_samples': 1, 'lmbda': 0.396436739362835}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:49,024]\u001B[0m Trial 230 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.008206686831544003, 'num_negative_samples': 1, 'lmbda': 0.4189733088918922}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:50,328]\u001B[0m Trial 231 finished with value: 0.35686191636321657 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008587946604027539, 'num_negative_samples': 1, 'lmbda': 0.3754847764643289}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:51,739]\u001B[0m Trial 232 finished with value: 0.49938233453876074 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008325413140921672, 'num_negative_samples': 1, 'lmbda': 0.34271183542468364}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:53,145]\u001B[0m Trial 233 finished with value: 0.34318767136623335 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006101056406873636, 'num_negative_samples': 1, 'lmbda': 0.3866066104968826}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:55,102]\u001B[0m Trial 234 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007580156885469293, 'num_negative_samples': 1, 'lmbda': 0.3552171644366932}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:44:59,274]\u001B[0m Trial 235 finished with value: 0.5470459388929408 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00846318610682958, 'num_negative_samples': 1, 'lmbda': 0.4152529997914176}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:01,097]\u001B[0m Trial 236 finished with value: 0.39791121287711073 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008480807454035151, 'num_negative_samples': 1, 'lmbda': 0.42989487152138584}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:02,612]\u001B[0m Trial 237 finished with value: 0.24873416908154553 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007454585797135585, 'num_negative_samples': 21, 'lmbda': 0.11377564367626287}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:04,144]\u001B[0m Trial 238 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005635737443812021, 'num_negative_samples': 16, 'lmbda': 0.3771707948946259}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:05,788]\u001B[0m Trial 239 finished with value: 0.46017899330842227 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009920407254564464, 'num_negative_samples': 1, 'lmbda': 0.6794360227287122}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:07,306]\u001B[0m Trial 240 finished with value: 0.3472581680740104 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008389451579133523, 'num_negative_samples': 1, 'lmbda': 0.33758168518106646}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:08,708]\u001B[0m Trial 241 finished with value: 0.544491127783818 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006617033806734815, 'num_negative_samples': 1, 'lmbda': 0.3275195427924107}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:09,974]\u001B[0m Trial 242 finished with value: 0.4714045207910317 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008711957560489399, 'num_negative_samples': 1, 'lmbda': 0.639359639978243}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:11,358]\u001B[0m Trial 243 finished with value: 0.45946829173634074 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054458751832772555, 'num_negative_samples': 1, 'lmbda': 0.28437759821440983}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:12,631]\u001B[0m Trial 244 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008456118067667287, 'num_negative_samples': 1, 'lmbda': 0.44716763249704544}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:13,901]\u001B[0m Trial 245 finished with value: 0.47794494719477854 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008835495230397027, 'num_negative_samples': 1, 'lmbda': 0.8795216870890562}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:14,435]\u001B[0m Trial 246 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005991540400080527, 'num_negative_samples': 1, 'lmbda': 0.6067367040577182}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:15,726]\u001B[0m Trial 247 finished with value: 0.5228688295026747 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.008261741713518636, 'num_negative_samples': 1, 'lmbda': 0.44819854123472574}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:17,148]\u001B[0m Trial 248 finished with value: 0.3961715179789607 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005271029875027557, 'num_negative_samples': 1, 'lmbda': 0.3024996566732047}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:18,547]\u001B[0m Trial 249 finished with value: 0.39770583933420295 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008081771814114234, 'num_negative_samples': 1, 'lmbda': 0.9834570012354142}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:19,885]\u001B[0m Trial 250 finished with value: 0.32385514490610595 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008943982835646834, 'num_negative_samples': 6, 'lmbda': 0.38791297401499736}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:21,658]\u001B[0m Trial 251 finished with value: 0.3079201435678004 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005074161589118712, 'num_negative_samples': 11, 'lmbda': 0.3487165186609183}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:23,205]\u001B[0m Trial 252 finished with value: 0.39940431835899015 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0053488427376316835, 'num_negative_samples': 21, 'lmbda': 0.32161188953760045}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:24,711]\u001B[0m Trial 253 finished with value: 0.3415650255319866 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008615336402541949, 'num_negative_samples': 1, 'lmbda': 0.17679758165357}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:26,227]\u001B[0m Trial 254 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007788802129770312, 'num_negative_samples': 1, 'lmbda': 0.49335380990176436}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:27,758]\u001B[0m Trial 255 finished with value: 0.3900119595344697 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00554615576384429, 'num_negative_samples': 1, 'lmbda': 0.7137098849310095}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:29,273]\u001B[0m Trial 256 finished with value: 0.33518006953329677 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007382454948536051, 'num_negative_samples': 1, 'lmbda': 0.5848753166247145}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:30,659]\u001B[0m Trial 257 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008145486890247154, 'num_negative_samples': 1, 'lmbda': 0.6616761078745879}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:32,018]\u001B[0m Trial 258 finished with value: 0.4093683153132611 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008026636301282117, 'num_negative_samples': 1, 'lmbda': 0.669861490482616}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:33,409]\u001B[0m Trial 259 finished with value: 0.44664857493889926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008167088791360761, 'num_negative_samples': 1, 'lmbda': 0.6897881319807311}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:34,774]\u001B[0m Trial 260 finished with value: 0.3512138360675392 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008181501406158611, 'num_negative_samples': 1, 'lmbda': 0.6263469932787824}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:35,415]\u001B[0m Trial 261 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.008269450915757232, 'num_negative_samples': 21, 'lmbda': 0.6583208884269129}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:36,790]\u001B[0m Trial 262 finished with value: 0.4053217416888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008120455525170817, 'num_negative_samples': 1, 'lmbda': 0.13760828352506418}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:38,165]\u001B[0m Trial 263 finished with value: 0.3436984942806125 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007984678370960658, 'num_negative_samples': 1, 'lmbda': 0.3658559812153469}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:39,524]\u001B[0m Trial 264 finished with value: 0.4840033669916556 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005404303646459013, 'num_negative_samples': 1, 'lmbda': 0.6377126817950167}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:40,790]\u001B[0m Trial 265 finished with value: 0.3472581680740104 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008357586325820137, 'num_negative_samples': 1, 'lmbda': 0.45975072384573473}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:42,149]\u001B[0m Trial 266 finished with value: 0.34815531191139565 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007686606781953439, 'num_negative_samples': 1, 'lmbda': 0.4049232349518218}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:43,493]\u001B[0m Trial 267 finished with value: 0.3521909447138889 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00787426573628685, 'num_negative_samples': 1, 'lmbda': 0.6553505293027514}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:44,855]\u001B[0m Trial 268 finished with value: 0.16265001215808886 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008515506016388463, 'num_negative_samples': 16, 'lmbda': 0.4266949032265814}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:46,120]\u001B[0m Trial 269 finished with value: 0.25962936545662046 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008304182791888106, 'num_negative_samples': 1, 'lmbda': 0.7340259448757225}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:47,370]\u001B[0m Trial 270 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.007523511667579873, 'num_negative_samples': 21, 'lmbda': 0.6966066623191601}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:48,761]\u001B[0m Trial 271 finished with value: 0.36201399289824565 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005009696078201159, 'num_negative_samples': 1, 'lmbda': 0.3639026824593752}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:50,151]\u001B[0m Trial 272 finished with value: 0.4360859320947423 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008368279701292466, 'num_negative_samples': 1, 'lmbda': 0.48027777865418775}. Best is trial 224 with value: 0.6687467549246293.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:51,562]\u001B[0m Trial 273 finished with value: 0.7048652472884563 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005157851123399837, 'num_negative_samples': 1, 'lmbda': 0.606492717280537}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:52,939]\u001B[0m Trial 274 finished with value: 0.5182387756347729 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005203164926943227, 'num_negative_samples': 1, 'lmbda': 0.6096662481887178}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:54,359]\u001B[0m Trial 275 finished with value: 0.5007184380950696 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006481225126748264, 'num_negative_samples': 1, 'lmbda': 0.5902946150712803}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:55,770]\u001B[0m Trial 276 finished with value: 0.4270589526587819 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007943852428808991, 'num_negative_samples': 1, 'lmbda': 0.554538112674816}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:57,182]\u001B[0m Trial 277 finished with value: 0.43176353839389886 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005834718690072476, 'num_negative_samples': 6, 'lmbda': 0.6314886238231339}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:45:58,607]\u001B[0m Trial 278 finished with value: 0.26309409114886667 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054852203865546215, 'num_negative_samples': 11, 'lmbda': 0.20175327569169602}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:00,003]\u001B[0m Trial 279 finished with value: 0.3464101615137755 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007283267250093003, 'num_negative_samples': 1, 'lmbda': 0.615802846476881}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:01,406]\u001B[0m Trial 280 finished with value: 0.3605551275463989 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009632547695686963, 'num_negative_samples': 1, 'lmbda': 0.673399972324595}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:02,826]\u001B[0m Trial 281 finished with value: 0.2605089705696844 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005134444000615709, 'num_negative_samples': 1, 'lmbda': 0.40886799289900605}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:04,239]\u001B[0m Trial 282 finished with value: 0.3472581680740104 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005680927118614538, 'num_negative_samples': 21, 'lmbda': 0.2464974994646088}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:05,638]\u001B[0m Trial 283 finished with value: 0.5321166677977192 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007724511481018495, 'num_negative_samples': 1, 'lmbda': 0.5671849423359744}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:07,016]\u001B[0m Trial 284 finished with value: 0.4346134936801766 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008089230396082624, 'num_negative_samples': 1, 'lmbda': 0.6403663823297163}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:07,641]\u001B[0m Trial 285 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005287575525390106, 'num_negative_samples': 1, 'lmbda': 0.16362271850246984}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:09,000]\u001B[0m Trial 286 finished with value: 0.4509249752822894 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007639228033922086, 'num_negative_samples': 1, 'lmbda': 0.6004819846194456}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:10,391]\u001B[0m Trial 287 finished with value: 0.49731304169296475 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00920991806004999, 'num_negative_samples': 1, 'lmbda': 0.43726722895606757}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:11,735]\u001B[0m Trial 288 finished with value: 0.2981423969999719 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005183451761744123, 'num_negative_samples': 1, 'lmbda': 0.3896518597189495}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:13,094]\u001B[0m Trial 289 finished with value: 0.5073891191462742 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0071248421445727714, 'num_negative_samples': 1, 'lmbda': 0.6617814193059349}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:14,453]\u001B[0m Trial 290 finished with value: 0.4360859320947423 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005594061582778262, 'num_negative_samples': 21, 'lmbda': 0.7156426424600848}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:15,000]\u001B[0m Trial 291 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.007805684804270273, 'num_negative_samples': 1, 'lmbda': 0.6861439708442545}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:16,344]\u001B[0m Trial 292 finished with value: 0.5101892200870578 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00536952750366819, 'num_negative_samples': 1, 'lmbda': 0.2287347320429374}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:17,719]\u001B[0m Trial 293 finished with value: 0.485996227026055 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008258145533357228, 'num_negative_samples': 1, 'lmbda': 0.3992937773858368}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:19,000]\u001B[0m Trial 294 finished with value: 0.48468611999997996 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00804079285444414, 'num_negative_samples': 1, 'lmbda': 0.6260391935251487}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:20,413]\u001B[0m Trial 295 finished with value: 0.4051436956703314 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008415017722967317, 'num_negative_samples': 1, 'lmbda': 0.38371034283495536}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:21,806]\u001B[0m Trial 296 finished with value: 0.39791121287711073 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008152942062159926, 'num_negative_samples': 16, 'lmbda': 0.7747461152838256}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:23,223]\u001B[0m Trial 297 finished with value: 0.44823985105840247 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007421819844102359, 'num_negative_samples': 1, 'lmbda': 0.5839516634679807}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:24,541]\u001B[0m Trial 298 finished with value: 0.3066220703359333 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007598650931014268, 'num_negative_samples': 1, 'lmbda': 0.07925679136189318}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:25,928]\u001B[0m Trial 299 finished with value: 0.5890743136553714 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005486857350938685, 'num_negative_samples': 1, 'lmbda': 0.4352328022090945}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:27,319]\u001B[0m Trial 300 finished with value: 0.6687467549246293 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005750932046881932, 'num_negative_samples': 1, 'lmbda': 0.4324750288525227}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:28,721]\u001B[0m Trial 301 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005964095653915905, 'num_negative_samples': 1, 'lmbda': 0.46761731350589936}. Best is trial 273 with value: 0.7048652472884563.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:30,122]\u001B[0m Trial 302 finished with value: 0.7651163637701996 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005706100817624174, 'num_negative_samples': 1, 'lmbda': 0.44513804455545253}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:31,580]\u001B[0m Trial 303 finished with value: 0.6296187362892084 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005631669815469429, 'num_negative_samples': 1, 'lmbda': 0.4407866664441978}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:32,979]\u001B[0m Trial 304 finished with value: 0.36201399289824565 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005600540934839428, 'num_negative_samples': 1, 'lmbda': 0.44378424796647964}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:34,391]\u001B[0m Trial 305 finished with value: 0.49846267922753223 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005754361428691732, 'num_negative_samples': 1, 'lmbda': 0.42936454079175496}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:35,794]\u001B[0m Trial 306 finished with value: 0.5381099233077657 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005739291970154056, 'num_negative_samples': 1, 'lmbda': 0.5104928608588695}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:37,169]\u001B[0m Trial 307 finished with value: 0.5993823981893857 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005542231381738423, 'num_negative_samples': 1, 'lmbda': 0.46217885991578833}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:38,512]\u001B[0m Trial 308 finished with value: 0.3967460238079361 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005539147028161845, 'num_negative_samples': 1, 'lmbda': 0.4643171628370238}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:39,872]\u001B[0m Trial 309 finished with value: 0.39126259692575577 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005662063812667354, 'num_negative_samples': 1, 'lmbda': 0.4500449351100325}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:40,497]\u001B[0m Trial 310 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0057592178909672935, 'num_negative_samples': 1, 'lmbda': 0.42932844017941607}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:41,840]\u001B[0m Trial 311 finished with value: 0.40170092900519455 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005617186726919159, 'num_negative_samples': 1, 'lmbda': 0.4139860417528865}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:43,200]\u001B[0m Trial 312 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005518635853337148, 'num_negative_samples': 6, 'lmbda': 0.45152715468820404}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:44,583]\u001B[0m Trial 313 finished with value: 0.30393211029577855 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005500780019473556, 'num_negative_samples': 11, 'lmbda': 0.4611691184781959}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:46,022]\u001B[0m Trial 314 finished with value: 0.6944222218666553 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0056809691653039104, 'num_negative_samples': 1, 'lmbda': 0.42463967153236104}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:47,417]\u001B[0m Trial 315 finished with value: 0.6509252673723026 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005809267497102237, 'num_negative_samples': 1, 'lmbda': 0.43580223662837486}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:48,838]\u001B[0m Trial 316 finished with value: 0.3464101615137755 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00569697278197244, 'num_negative_samples': 1, 'lmbda': 0.4279555274002076}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:50,235]\u001B[0m Trial 317 finished with value: 0.6348451168907949 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00578023150423727, 'num_negative_samples': 1, 'lmbda': 0.4438226650417382}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:50,791]\u001B[0m Trial 318 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005846433072999532, 'num_negative_samples': 1, 'lmbda': 0.4409155773566943}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:52,169]\u001B[0m Trial 319 finished with value: 0.4557678157153584 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005949961104617501, 'num_negative_samples': 1, 'lmbda': 0.418471611467773}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:53,576]\u001B[0m Trial 320 finished with value: 0.43296981873272894 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005815321363887421, 'num_negative_samples': 1, 'lmbda': 0.4810966149758183}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:54,968]\u001B[0m Trial 321 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005678623257431592, 'num_negative_samples': 1, 'lmbda': 0.41411128366164446}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:56,362]\u001B[0m Trial 322 finished with value: 0.6754970734920295 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005896097944824975, 'num_negative_samples': 1, 'lmbda': 0.4411912530620097}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:57,749]\u001B[0m Trial 323 finished with value: 0.4733416182649687 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005891612141973672, 'num_negative_samples': 1, 'lmbda': 0.4520209467916826}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:46:59,101]\u001B[0m Trial 324 finished with value: 0.3464101615137755 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005864080036880044, 'num_negative_samples': 1, 'lmbda': 0.436461877372032}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:00,454]\u001B[0m Trial 325 finished with value: 0.31101772641409176 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005741473384700839, 'num_negative_samples': 1, 'lmbda': 0.47093399233070943}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:01,798]\u001B[0m Trial 326 finished with value: 0.5939084716749481 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006055595789703007, 'num_negative_samples': 1, 'lmbda': 0.4963395331613862}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:03,185]\u001B[0m Trial 327 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005874340438258988, 'num_negative_samples': 1, 'lmbda': 0.49366435592023983}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:04,602]\u001B[0m Trial 328 finished with value: 0.25431941053151924 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0056362194059420235, 'num_negative_samples': 1, 'lmbda': 0.5348122405551871}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:05,958]\u001B[0m Trial 329 finished with value: 0.43176353839389886 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005778955594382784, 'num_negative_samples': 1, 'lmbda': 0.46652459691613724}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:07,302]\u001B[0m Trial 330 finished with value: 0.44594129250792236 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005950494194940023, 'num_negative_samples': 1, 'lmbda': 0.4963078291845817}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:08,692]\u001B[0m Trial 331 finished with value: 0.44305337860837524 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0060425525360166465, 'num_negative_samples': 16, 'lmbda': 0.414915803195646}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:10,067]\u001B[0m Trial 332 finished with value: 0.5937383704336889 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005588971594493863, 'num_negative_samples': 1, 'lmbda': 0.445065768191916}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:11,442]\u001B[0m Trial 333 finished with value: 0.2772975647097165 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005584894770974993, 'num_negative_samples': 1, 'lmbda': 0.4452486715396336}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:12,802]\u001B[0m Trial 334 finished with value: 0.4991871235073112 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0057675582544747025, 'num_negative_samples': 1, 'lmbda': 0.48187207522830033}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:14,145]\u001B[0m Trial 335 finished with value: 0.49721446300587663 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005653777564572358, 'num_negative_samples': 1, 'lmbda': 0.5167798285762593}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:15,395]\u001B[0m Trial 336 finished with value: 0.5276315586926118 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005553181155345156, 'num_negative_samples': 1, 'lmbda': 0.43559851866891736}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:16,034]\u001B[0m Trial 337 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00932253894933773, 'num_negative_samples': 1, 'lmbda': 0.46177337380406686}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:17,415]\u001B[0m Trial 338 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005468561759387261, 'num_negative_samples': 1, 'lmbda': 0.4757088789496281}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:18,849]\u001B[0m Trial 339 finished with value: 0.5188745216627708 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005481780337104721, 'num_negative_samples': 1, 'lmbda': 0.5035641473319666}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:20,251]\u001B[0m Trial 340 finished with value: 0.42745297914825214 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005720197044212512, 'num_negative_samples': 11, 'lmbda': 0.4791697727349839}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:21,666]\u001B[0m Trial 341 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005461422485760183, 'num_negative_samples': 1, 'lmbda': 0.4456165273966887}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:22,980]\u001B[0m Trial 342 finished with value: 0.5460094886133146 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00548508449628683, 'num_negative_samples': 1, 'lmbda': 0.4371618382324578}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:24,235]\u001B[0m Trial 343 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005425489556338906, 'num_negative_samples': 6, 'lmbda': 0.4064731213682931}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:25,625]\u001B[0m Trial 344 finished with value: 0.46017899330842227 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00565362724637786, 'num_negative_samples': 1, 'lmbda': 0.4717292846763132}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:26,990]\u001B[0m Trial 345 finished with value: 0.42906393528989223 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005565488185540056, 'num_negative_samples': 1, 'lmbda': 0.4248736731863073}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:28,344]\u001B[0m Trial 346 finished with value: 0.4674596437325029 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005840381172193223, 'num_negative_samples': 1, 'lmbda': 0.4547078495278994}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:29,638]\u001B[0m Trial 347 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005370223229271932, 'num_negative_samples': 1, 'lmbda': 0.4891766494873794}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:31,029]\u001B[0m Trial 348 finished with value: 0.47381739518152793 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006068374926176422, 'num_negative_samples': 1, 'lmbda': 0.39878523177368586}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:32,418]\u001B[0m Trial 349 finished with value: 0.3026259929062465 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005613568426380458, 'num_negative_samples': 1, 'lmbda': 0.43267780218655016}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:33,773]\u001B[0m Trial 350 finished with value: 0.40871194568479957 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005443563814789701, 'num_negative_samples': 1, 'lmbda': 0.8313154317531366}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:35,117]\u001B[0m Trial 351 finished with value: 0.4864254173146039 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005810448519663114, 'num_negative_samples': 1, 'lmbda': 0.4500239825764943}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:36,380]\u001B[0m Trial 352 finished with value: 0.41377786457484794 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005710763097173233, 'num_negative_samples': 1, 'lmbda': 0.41961105818438393}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:37,772]\u001B[0m Trial 353 finished with value: 0.4353647708073435 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005531904084508295, 'num_negative_samples': 1, 'lmbda': 0.4709789191460243}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:39,150]\u001B[0m Trial 354 finished with value: 0.41675437673324534 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005336837501297423, 'num_negative_samples': 1, 'lmbda': 0.5323343370676139}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:40,536]\u001B[0m Trial 355 finished with value: 0.648454953840661 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005907938933786082, 'num_negative_samples': 1, 'lmbda': 0.5052215662479012}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:41,911]\u001B[0m Trial 356 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005924854939491017, 'num_negative_samples': 1, 'lmbda': 0.5089903383363468}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:43,286]\u001B[0m Trial 357 finished with value: 0.4846116845975599 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006129292892335747, 'num_negative_samples': 1, 'lmbda': 0.37882540749400934}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:44,646]\u001B[0m Trial 358 finished with value: 0.39162352324294725 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005982408184337539, 'num_negative_samples': 1, 'lmbda': 0.44918132389162685}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:45,271]\u001B[0m Trial 359 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005788661318388974, 'num_negative_samples': 1, 'lmbda': 0.40996829843785565}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:46,693]\u001B[0m Trial 360 finished with value: 0.2981423969999719 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005698335024180984, 'num_negative_samples': 1, 'lmbda': 0.48490397135575974}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:48,052]\u001B[0m Trial 361 finished with value: 0.5916632145715366 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005858648965790252, 'num_negative_samples': 1, 'lmbda': 0.4334319851719665}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:49,409]\u001B[0m Trial 362 finished with value: 0.39051248379533277 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005914823281525523, 'num_negative_samples': 1, 'lmbda': 0.39331465256777315}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:50,800]\u001B[0m Trial 363 finished with value: 0.5887840577551897 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0058384806980787485, 'num_negative_samples': 1, 'lmbda': 0.7965744993651402}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:52,175]\u001B[0m Trial 364 finished with value: 0.44664857493889926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0058961391616405715, 'num_negative_samples': 16, 'lmbda': 0.4618245009895214}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:53,425]\u001B[0m Trial 365 finished with value: 0.16666666666666669 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006043336438600573, 'num_negative_samples': 1, 'lmbda': 0.4285788272258744}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:53,956]\u001B[0m Trial 366 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.00575588444975826, 'num_negative_samples': 1, 'lmbda': 0.5026550334178748}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:55,315]\u001B[0m Trial 367 finished with value: 0.45133546692422 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005619871263052629, 'num_negative_samples': 1, 'lmbda': 0.753031156744133}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:56,690]\u001B[0m Trial 368 finished with value: 0.30602417167732626 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006151015335556999, 'num_negative_samples': 1, 'lmbda': 0.3711932757811431}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:58,065]\u001B[0m Trial 369 finished with value: 0.5827180355644346 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005694112301261428, 'num_negative_samples': 1, 'lmbda': 0.4486530881893617}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:47:59,425]\u001B[0m Trial 370 finished with value: 0.44664857493889926 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005801507668243523, 'num_negative_samples': 1, 'lmbda': 0.4083091939339776}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:00,784]\u001B[0m Trial 371 finished with value: 0.39791121287711073 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006016966806836766, 'num_negative_samples': 1, 'lmbda': 0.478170396625447}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:02,159]\u001B[0m Trial 372 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005596867266323307, 'num_negative_samples': 11, 'lmbda': 0.44641265978344336}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:03,550]\u001B[0m Trial 373 finished with value: 0.30341966327759984 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005866320039386439, 'num_negative_samples': 6, 'lmbda': 0.5265111859657066}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:04,909]\u001B[0m Trial 374 finished with value: 0.693323277956244 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005709103017154979, 'num_negative_samples': 1, 'lmbda': 0.4181256342558925}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:06,253]\u001B[0m Trial 375 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0057723568111434555, 'num_negative_samples': 1, 'lmbda': 0.4231145424768874}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:07,627]\u001B[0m Trial 376 finished with value: 0.4774845054988204 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005870769205328773, 'num_negative_samples': 1, 'lmbda': 0.47193311704368385}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:09,017]\u001B[0m Trial 377 finished with value: 0.4053217416888888 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005687184761224288, 'num_negative_samples': 1, 'lmbda': 0.39880592076573307}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:10,417]\u001B[0m Trial 378 finished with value: 0.2961744388795462 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005625824192249432, 'num_negative_samples': 1, 'lmbda': 0.4367701544083738}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:11,820]\u001B[0m Trial 379 finished with value: 0.45542003404264886 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005990590834201459, 'num_negative_samples': 1, 'lmbda': 0.45866479477002486}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:13,195]\u001B[0m Trial 380 finished with value: 0.5066228051190221 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0057707673169044614, 'num_negative_samples': 1, 'lmbda': 0.4167247549531497}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:14,539]\u001B[0m Trial 381 finished with value: 0.3030707043774635 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005564174541860454, 'num_negative_samples': 1, 'lmbda': 0.49170923582953113}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:15,928]\u001B[0m Trial 382 finished with value: 0.3535533905932738 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006233117104529068, 'num_negative_samples': 1, 'lmbda': 0.4319942809474514}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:17,316]\u001B[0m Trial 383 finished with value: 0.5301991240195622 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005901573313859571, 'num_negative_samples': 1, 'lmbda': 0.45044280414541027}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:18,593]\u001B[0m Trial 384 finished with value: 0.5005443659750535 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005710344444495395, 'num_negative_samples': 1, 'lmbda': 0.3959196713054228}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:19,984]\u001B[0m Trial 385 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00977796535373086, 'num_negative_samples': 1, 'lmbda': 0.879096756290403}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:21,393]\u001B[0m Trial 386 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005792198500563148, 'num_negative_samples': 1, 'lmbda': 0.4702432133308536}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:22,040]\u001B[0m Trial 387 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005936275246333157, 'num_negative_samples': 1, 'lmbda': 0.420532812899704}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:23,401]\u001B[0m Trial 388 finished with value: 0.4774845054988204 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005494712422385393, 'num_negative_samples': 1, 'lmbda': 0.507466755083727}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:23,964]\u001B[0m Trial 389 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005628374656766352, 'num_negative_samples': 16, 'lmbda': 0.4399780305928743}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:25,320]\u001B[0m Trial 390 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006086640851796918, 'num_negative_samples': 1, 'lmbda': 0.3638548954115378}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:26,695]\u001B[0m Trial 391 finished with value: 0.45542003404264886 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0053900488858635315, 'num_negative_samples': 1, 'lmbda': 0.46278357805387776}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:28,085]\u001B[0m Trial 392 finished with value: 0.36201399289824565 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005699096857315291, 'num_negative_samples': 1, 'lmbda': 0.40130981193195736}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:29,445]\u001B[0m Trial 393 finished with value: 0.44112695305392047 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0058407691694924765, 'num_negative_samples': 1, 'lmbda': 0.4896216758433109}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:30,799]\u001B[0m Trial 394 finished with value: 0.5862624870343519 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005551503866592811, 'num_negative_samples': 1, 'lmbda': 0.5508436246513232}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:32,174]\u001B[0m Trial 395 finished with value: 0.5084900112128733 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005411781211519892, 'num_negative_samples': 1, 'lmbda': 0.42112311161210936}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:33,552]\u001B[0m Trial 396 finished with value: 0.4849589520621155 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005670786109476006, 'num_negative_samples': 1, 'lmbda': 0.4481379813641915}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:34,927]\u001B[0m Trial 397 finished with value: 0.505616601930898 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005950862807369191, 'num_negative_samples': 11, 'lmbda': 0.3815812069485367}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:36,287]\u001B[0m Trial 398 finished with value: 0.35856858280031806 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005787452658709025, 'num_negative_samples': 6, 'lmbda': 0.4773270858219751}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:37,662]\u001B[0m Trial 399 finished with value: 0.5106277908033803 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005474473778394823, 'num_negative_samples': 1, 'lmbda': 0.5174934179558316}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:38,943]\u001B[0m Trial 400 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0070191103571889705, 'num_negative_samples': 1, 'lmbda': 0.9476445968496937}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:40,287]\u001B[0m Trial 401 finished with value: 0.4143267631552018 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005606880680697029, 'num_negative_samples': 1, 'lmbda': 0.43608021414736453}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:41,646]\u001B[0m Trial 402 finished with value: 0.5185449728701349 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005764137142950033, 'num_negative_samples': 1, 'lmbda': 0.4088808747472794}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:43,037]\u001B[0m Trial 403 finished with value: 0.31283792055029264 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0060072832738942965, 'num_negative_samples': 1, 'lmbda': 0.4617977607386301}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:43,662]\u001B[0m Trial 404 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.0055515878922870595, 'num_negative_samples': 1, 'lmbda': 0.4322601045321037}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:45,006]\u001B[0m Trial 405 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009455083063742868, 'num_negative_samples': 1, 'lmbda': 0.35608022537278744}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:46,381]\u001B[0m Trial 406 finished with value: 0.3472581680740104 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006825038352450205, 'num_negative_samples': 1, 'lmbda': 0.3890225412961416}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:47,677]\u001B[0m Trial 407 finished with value: 0.3054721308482779 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005696518506584718, 'num_negative_samples': 1, 'lmbda': 0.49807989280543447}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:49,052]\u001B[0m Trial 408 finished with value: 0.6110100926607787 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005300662315902251, 'num_negative_samples': 1, 'lmbda': 0.4535938457011175}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:50,427]\u001B[0m Trial 409 finished with value: 0.6531599602878279 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0052206162583372144, 'num_negative_samples': 1, 'lmbda': 0.46837110848338165}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:51,803]\u001B[0m Trial 410 finished with value: 0.3903600291794133 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005268806941601858, 'num_negative_samples': 1, 'lmbda': 0.4848894267733489}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:53,177]\u001B[0m Trial 411 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005272745615993818, 'num_negative_samples': 1, 'lmbda': 0.4674108926860426}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:53,724]\u001B[0m Trial 412 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005104247410433683, 'num_negative_samples': 1, 'lmbda': 0.5220764979588298}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:54,990]\u001B[0m Trial 413 finished with value: 0.504608392349582 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005322163530929211, 'num_negative_samples': 1, 'lmbda': 0.5000664450383664}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:56,381]\u001B[0m Trial 414 finished with value: 0.40043835629592534 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005261101307973965, 'num_negative_samples': 16, 'lmbda': 0.45952140962283855}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:57,756]\u001B[0m Trial 415 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0051642641976464305, 'num_negative_samples': 1, 'lmbda': 0.48121339558175424}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:48:59,115]\u001B[0m Trial 416 finished with value: 0.3831780223674067 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005393607344219507, 'num_negative_samples': 1, 'lmbda': 0.40823277563245186}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:00,490]\u001B[0m Trial 417 finished with value: 0.4455760447958423 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005210759885815485, 'num_negative_samples': 1, 'lmbda': 0.4546769243056829}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:01,881]\u001B[0m Trial 418 finished with value: 0.5025859056843841 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005313956436640595, 'num_negative_samples': 1, 'lmbda': 0.41742995119397114}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:03,131]\u001B[0m Trial 419 finished with value: 0.4837219533002148 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005414031786034899, 'num_negative_samples': 1, 'lmbda': 0.4685755545275537}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:04,521]\u001B[0m Trial 420 finished with value: 0.4424098729984399 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005078779258275094, 'num_negative_samples': 1, 'lmbda': 0.3421168309839124}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:05,881]\u001B[0m Trial 421 finished with value: 0.4674596437325029 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008636816907793289, 'num_negative_samples': 1, 'lmbda': 0.44603311464488327}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:07,256]\u001B[0m Trial 422 finished with value: 0.3509623956702529 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0050161884696759435, 'num_negative_samples': 1, 'lmbda': 0.500527483573106}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:08,638]\u001B[0m Trial 423 finished with value: 0.31845898009689927 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006356199283406595, 'num_negative_samples': 11, 'lmbda': 0.5451587560910452}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:10,028]\u001B[0m Trial 424 finished with value: 0.507331864675414 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005442538885503498, 'num_negative_samples': 6, 'lmbda': 0.4233542934873004}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:11,293]\u001B[0m Trial 425 finished with value: 0.41231056256176607 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005207213870496386, 'num_negative_samples': 1, 'lmbda': 0.3878111397256026}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:12,694]\u001B[0m Trial 426 finished with value: 0.6463573143221772 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005327340459822657, 'num_negative_samples': 1, 'lmbda': 0.46587075634173153}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:13,977]\u001B[0m Trial 427 finished with value: 0.648454953840661 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005370766555521807, 'num_negative_samples': 1, 'lmbda': 0.45685460700758507}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:14,602]\u001B[0m Trial 428 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005324406240674942, 'num_negative_samples': 1, 'lmbda': 0.4372868657246326}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:15,892]\u001B[0m Trial 429 finished with value: 0.5228688295026747 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0052366331380222396, 'num_negative_samples': 1, 'lmbda': 0.4590787729268769}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:17,162]\u001B[0m Trial 430 finished with value: 0.4843221048378526 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00532642104373852, 'num_negative_samples': 1, 'lmbda': 0.4819258931580579}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:18,412]\u001B[0m Trial 431 finished with value: 0.573488351136175 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005417935007005449, 'num_negative_samples': 1, 'lmbda': 0.45480130975263805}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:19,693]\u001B[0m Trial 432 finished with value: 0.5708992257184501 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005491695209114003, 'num_negative_samples': 1, 'lmbda': 0.4291330327267365}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:20,959]\u001B[0m Trial 433 finished with value: 0.3124969135650052 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005353436967013429, 'num_negative_samples': 1, 'lmbda': 0.41031311532576153}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:21,506]\u001B[0m Trial 434 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.008545281358113586, 'num_negative_samples': 1, 'lmbda': 0.47371665396400425}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:22,771]\u001B[0m Trial 435 finished with value: 0.5497474167490214 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005093080809244025, 'num_negative_samples': 1, 'lmbda': 0.44681978456536614}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:24,053]\u001B[0m Trial 436 finished with value: 0.5532969963207519 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005218219938477002, 'num_negative_samples': 1, 'lmbda': 0.46863487168452134}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:25,318]\u001B[0m Trial 437 finished with value: 0.43221478067527724 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054711030256955565, 'num_negative_samples': 1, 'lmbda': 0.37931590393256315}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:26,678]\u001B[0m Trial 438 finished with value: 0.380058475033046 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005173392782297902, 'num_negative_samples': 1, 'lmbda': 0.42186391898386033}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:28,068]\u001B[0m Trial 439 finished with value: 0.4013864859597432 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005391335790094053, 'num_negative_samples': 1, 'lmbda': 0.4447080863410422}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:29,443]\u001B[0m Trial 440 finished with value: 0.3961715179789607 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005306435070299659, 'num_negative_samples': 16, 'lmbda': 0.4023344279804389}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:30,837]\u001B[0m Trial 441 finished with value: 0.43744488188954506 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005486288973213556, 'num_negative_samples': 1, 'lmbda': 0.4860799511774326}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:32,103]\u001B[0m Trial 442 finished with value: 0.36371359845261 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0055353619678614845, 'num_negative_samples': 1, 'lmbda': 0.3619193885643487}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:33,494]\u001B[0m Trial 443 finished with value: 0.31101772641409176 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00851209565618595, 'num_negative_samples': 1, 'lmbda': 0.4606402344277538}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:34,869]\u001B[0m Trial 444 finished with value: 0.48048329578754784 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005122196395373372, 'num_negative_samples': 1, 'lmbda': 0.43443196263476386}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:36,244]\u001B[0m Trial 445 finished with value: 0.39831375340784575 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005262501406213194, 'num_negative_samples': 1, 'lmbda': 0.3977169411698035}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:37,610]\u001B[0m Trial 446 finished with value: 0.3518657752744984 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005620091411434844, 'num_negative_samples': 1, 'lmbda': 0.4774615483345602}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:38,860]\u001B[0m Trial 447 finished with value: 0.2693375856480767 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008427698291254709, 'num_negative_samples': 1, 'lmbda': 0.4192751597581465}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:40,250]\u001B[0m Trial 448 finished with value: 0.31429593859487137 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005390201290673741, 'num_negative_samples': 11, 'lmbda': 0.44701041659001756}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:41,532]\u001B[0m Trial 449 finished with value: 0.4361601658057396 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005529363295151505, 'num_negative_samples': 1, 'lmbda': 0.4639266047515821}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:42,172]\u001B[0m Trial 450 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005316451933273026, 'num_negative_samples': 6, 'lmbda': 0.5107988795581824}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:43,532]\u001B[0m Trial 451 finished with value: 0.5887840577551897 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005163932191764412, 'num_negative_samples': 1, 'lmbda': 0.3737188292426461}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:44,891]\u001B[0m Trial 452 finished with value: 0.42646376754566123 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00565593629347976, 'num_negative_samples': 1, 'lmbda': 0.4363515997614121}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:46,251]\u001B[0m Trial 453 finished with value: 0.6283429118043863 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005404325190379388, 'num_negative_samples': 1, 'lmbda': 0.4156071814623567}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:47,626]\u001B[0m Trial 454 finished with value: 0.4774845054988204 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0054269659351527735, 'num_negative_samples': 1, 'lmbda': 0.39401267466703777}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:48,907]\u001B[0m Trial 455 finished with value: 0.45656001088001874 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00528093141331596, 'num_negative_samples': 1, 'lmbda': 0.4106380026306751}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:50,282]\u001B[0m Trial 456 finished with value: 0.600389736968671 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005485101406143623, 'num_negative_samples': 1, 'lmbda': 0.34454217698778283}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:50,844]\u001B[0m Trial 457 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005539225705729079, 'num_negative_samples': 1, 'lmbda': 0.33143035245299324}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:52,219]\u001B[0m Trial 458 finished with value: 0.48384146587757865 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005343764544849358, 'num_negative_samples': 1, 'lmbda': 0.35563075979429337}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:53,563]\u001B[0m Trial 459 finished with value: 0.5211573066470477 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005597353869520398, 'num_negative_samples': 1, 'lmbda': 0.3497593871127699}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:54,938]\u001B[0m Trial 460 finished with value: 0.4984544012479545 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005006559189104891, 'num_negative_samples': 1, 'lmbda': 0.3708815568842122}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:56,219]\u001B[0m Trial 461 finished with value: 0.22338875108890427 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005449890205703859, 'num_negative_samples': 1, 'lmbda': 0.3028186052220608}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:57,641]\u001B[0m Trial 462 finished with value: 0.4679096001787033 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0052148782894586585, 'num_negative_samples': 1, 'lmbda': 0.3233281366070264}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:49:59,016]\u001B[0m Trial 463 finished with value: 0.3066220703359333 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00572888376246659, 'num_negative_samples': 1, 'lmbda': 0.34370852697212206}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:00,407]\u001B[0m Trial 464 finished with value: 0.5321166677977192 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00556166567300124, 'num_negative_samples': 1, 'lmbda': 0.6975643965393953}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:01,797]\u001B[0m Trial 465 finished with value: 0.3066220703359333 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005337602428238074, 'num_negative_samples': 1, 'lmbda': 0.38450695824594494}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:03,110]\u001B[0m Trial 466 finished with value: 0.29742828244876995 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005725504169749244, 'num_negative_samples': 16, 'lmbda': 0.40724502050915085}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:04,469]\u001B[0m Trial 467 finished with value: 0.3083315267085868 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0051749053547669515, 'num_negative_samples': 1, 'lmbda': 0.3686948022893838}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:05,844]\u001B[0m Trial 468 finished with value: 0.25689154519615076 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005401196689515431, 'num_negative_samples': 1, 'lmbda': 0.42075955228523393}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:07,188]\u001B[0m Trial 469 finished with value: 0.4844813951249545 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005660727424914967, 'num_negative_samples': 1, 'lmbda': 0.39608007153015035}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:08,547]\u001B[0m Trial 470 finished with value: 0.3189191146817664 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005499652334268324, 'num_negative_samples': 1, 'lmbda': 0.43383422724818166}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:09,854]\u001B[0m Trial 471 finished with value: 0.3415650255319866 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005270950710699318, 'num_negative_samples': 1, 'lmbda': 0.33989467057042383}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:10,494]\u001B[0m Trial 472 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005824421842013547, 'num_negative_samples': 1, 'lmbda': 0.6404234309714596}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:11,869]\u001B[0m Trial 473 finished with value: 0.5352973097975958 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008723342218967074, 'num_negative_samples': 1, 'lmbda': 0.41533612636275385}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:13,260]\u001B[0m Trial 474 finished with value: 0.35136418446315326 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005628193260568708, 'num_negative_samples': 1, 'lmbda': 0.38599510538593124}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:14,635]\u001B[0m Trial 475 finished with value: 0.25769508655546347 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005123384725163099, 'num_negative_samples': 6, 'lmbda': 0.44706348924672096}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:16,025]\u001B[0m Trial 476 finished with value: 0.5296749527356902 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00544082400157158, 'num_negative_samples': 11, 'lmbda': 0.4263674997694643}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:17,418]\u001B[0m Trial 477 finished with value: 0.360436582375499 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008576610476397399, 'num_negative_samples': 1, 'lmbda': 0.68281569879444}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:18,684]\u001B[0m Trial 478 finished with value: 0.5434798711731377 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005529100613020699, 'num_negative_samples': 1, 'lmbda': 0.566285021348219}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:19,920]\u001B[0m Trial 479 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005750728721901508, 'num_negative_samples': 1, 'lmbda': 0.4626535505256231}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:21,310]\u001B[0m Trial 480 finished with value: 0.4846116845975599 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005367925209693986, 'num_negative_samples': 1, 'lmbda': 0.40072549020733444}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:22,701]\u001B[0m Trial 481 finished with value: 0.34403862152295517 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005625085387193702, 'num_negative_samples': 1, 'lmbda': 0.3641621408090103}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:24,076]\u001B[0m Trial 482 finished with value: 0.291976304591905 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005875499551519379, 'num_negative_samples': 1, 'lmbda': 0.7201895832401077}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:25,357]\u001B[0m Trial 483 finished with value: 0.5214359259166952 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005226292993791922, 'num_negative_samples': 1, 'lmbda': 0.42120290073408767}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:26,715]\u001B[0m Trial 484 finished with value: 0.4229227309611489 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006605799914157987, 'num_negative_samples': 1, 'lmbda': 0.4433299153751754}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:28,105]\u001B[0m Trial 485 finished with value: 0.44095855184409843 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005473978617265919, 'num_negative_samples': 1, 'lmbda': 0.4769129529984243}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:29,464]\u001B[0m Trial 486 finished with value: 0.338296385503074 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005578428587041426, 'num_negative_samples': 1, 'lmbda': 0.38929877603359875}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:30,909]\u001B[0m Trial 487 finished with value: 0.5886965907625427 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00842465484331642, 'num_negative_samples': 1, 'lmbda': 0.3118908667482683}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:32,196]\u001B[0m Trial 488 finished with value: 0.4981447060324421 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005700462124045525, 'num_negative_samples': 1, 'lmbda': 0.45585047758776864}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:33,576]\u001B[0m Trial 489 finished with value: 0.5060742150229659 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005327926653513089, 'num_negative_samples': 1, 'lmbda': 0.43197977494966383}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:34,967]\u001B[0m Trial 490 finished with value: 0.39791121287711073 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00511588178840628, 'num_negative_samples': 1, 'lmbda': 0.4077352427943914}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:36,342]\u001B[0m Trial 491 finished with value: 0.4774845054988204 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008319199221127296, 'num_negative_samples': 16, 'lmbda': 0.6044659290146741}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:37,732]\u001B[0m Trial 492 finished with value: 0.5436502143433364 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005800363469792373, 'num_negative_samples': 1, 'lmbda': 0.4894153325359541}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:39,000]\u001B[0m Trial 493 finished with value: 0.19069251784911845 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005414868932039258, 'num_negative_samples': 1, 'lmbda': 0.38031404423091}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:39,641]\u001B[0m Trial 494 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005280349969800554, 'num_negative_samples': 1, 'lmbda': 0.45548106771790525}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:41,021]\u001B[0m Trial 495 finished with value: 0.4424098729984399 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005543884106873521, 'num_negative_samples': 1, 'lmbda': 0.3454603538001855}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:42,384]\u001B[0m Trial 496 finished with value: 0.5887840577551897 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005644583058642936, 'num_negative_samples': 1, 'lmbda': 0.4293508536234665}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:43,759]\u001B[0m Trial 497 finished with value: 0.5228688295026747 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005961015734083312, 'num_negative_samples': 1, 'lmbda': 0.46708128959005013}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:45,150]\u001B[0m Trial 498 finished with value: 0.45946829173634074 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005197045966526095, 'num_negative_samples': 1, 'lmbda': 0.4061545476062183}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:50:46,469]\u001B[0m Trial 499 finished with value: 0.3551765656924165 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0057350645918480825, 'num_negative_samples': 11, 'lmbda': 0.6490644874961289}. Best is trial 302 with value: 0.7651163637701996.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: GCN, mode: unsupervised, loss from VERSE_Adj\n",
      "0\n",
      "Loss: 1.1100, Epoch: 000, Train acc micro: 1.0000, Test acc micro: 0.6667,Train acc macro: 1.0000, Test acc macro: 0.3311\n",
      "1\n",
      "Loss: 1.1180, Epoch: 001, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2136\n",
      "2\n",
      "Loss: 1.1099, Epoch: 002, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2268\n",
      "3\n",
      "Loss: 1.1114, Epoch: 003, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2697\n",
      "4\n",
      "Loss: 1.1139, Epoch: 004, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3228\n",
      "5\n",
      "Loss: 1.1118, Epoch: 005, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2826\n",
      "6\n",
      "Loss: 1.1093, Epoch: 006, Train acc micro: 1.0000, Test acc micro: 0.4167,Train acc macro: 1.0000, Test acc macro: 0.1699\n",
      "7\n",
      "Loss: 1.1095, Epoch: 007, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.1488\n",
      "8\n",
      "Loss: 1.1110, Epoch: 008, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.1968\n",
      "9\n",
      "Loss: 1.1112, Epoch: 009, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2299\n",
      "10\n",
      "Loss: 1.1099, Epoch: 010, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2578\n",
      "11\n",
      "Loss: 1.1089, Epoch: 011, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.2655\n",
      "12\n",
      "Loss: 1.1090, Epoch: 012, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2709\n",
      "13\n",
      "Loss: 1.1097, Epoch: 013, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.3162\n",
      "14\n",
      "Loss: 1.1099, Epoch: 014, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2389\n",
      "15\n",
      "Loss: 1.1093, Epoch: 015, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.1923\n",
      "16\n",
      "Loss: 1.1086, Epoch: 016, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.1988\n",
      "17\n",
      "Loss: 1.1085, Epoch: 017, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2096\n",
      "18\n",
      "Loss: 1.1088, Epoch: 018, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2099\n",
      "19\n",
      "Loss: 1.1089, Epoch: 019, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.1994\n",
      "20\n",
      "Loss: 1.1086, Epoch: 020, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2381\n",
      "21\n",
      "Loss: 1.1082, Epoch: 021, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.2130\n",
      "22\n",
      "Loss: 1.1079, Epoch: 022, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2857\n",
      "23\n",
      "Loss: 1.1079, Epoch: 023, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.2990\n",
      "24\n",
      "Loss: 1.1079, Epoch: 024, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.2643\n",
      "25\n",
      "Loss: 1.1076, Epoch: 025, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2535\n",
      "26\n",
      "Loss: 1.1073, Epoch: 026, Train acc micro: 0.9845, Test acc micro: 0.4444,Train acc macro: 0.9842, Test acc macro: 0.2465\n",
      "27\n",
      "Loss: 1.1069, Epoch: 027, Train acc micro: 0.9922, Test acc micro: 0.4722,Train acc macro: 0.9895, Test acc macro: 0.2095\n",
      "28\n",
      "Loss: 1.1067, Epoch: 028, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.4111\n",
      "29\n",
      "Loss: 1.1065, Epoch: 029, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4511\n",
      "30\n",
      "Loss: 1.1061, Epoch: 030, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2857\n",
      "31\n",
      "Loss: 1.1057, Epoch: 031, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2857\n",
      "32\n",
      "Loss: 1.1052, Epoch: 032, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3176\n",
      "33\n",
      "Loss: 1.1047, Epoch: 033, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4566\n",
      "34\n",
      "Loss: 1.1042, Epoch: 034, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4473\n",
      "35\n",
      "Loss: 1.1036, Epoch: 035, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.3282\n",
      "36\n",
      "Loss: 1.1029, Epoch: 036, Train acc micro: 1.0000, Test acc micro: 0.5833,Train acc macro: 1.0000, Test acc macro: 0.4652\n",
      "37\n",
      "Loss: 1.1021, Epoch: 037, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2595\n",
      "38\n",
      "Loss: 1.1013, Epoch: 038, Train acc micro: 0.9922, Test acc micro: 0.5833,Train acc macro: 0.9922, Test acc macro: 0.4629\n",
      "39\n",
      "Loss: 1.1004, Epoch: 039, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.4609\n",
      "40\n",
      "Loss: 1.0994, Epoch: 040, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.3349\n",
      "41\n",
      "Loss: 1.0982, Epoch: 041, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.3251\n",
      "42\n",
      "Loss: 1.0969, Epoch: 042, Train acc micro: 1.0000, Test acc micro: 0.6111,Train acc macro: 1.0000, Test acc macro: 0.3860\n",
      "43\n",
      "Loss: 1.0955, Epoch: 043, Train acc micro: 0.9070, Test acc micro: 0.4444,Train acc macro: 0.8753, Test acc macro: 0.1703\n",
      "44\n",
      "Loss: 1.0940, Epoch: 044, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2911\n",
      "45\n",
      "Loss: 1.0924, Epoch: 045, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3800\n",
      "46\n",
      "Loss: 1.0906, Epoch: 046, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.3596\n",
      "47\n",
      "Loss: 1.0886, Epoch: 047, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.3140\n",
      "48\n",
      "Loss: 1.0865, Epoch: 048, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.5155\n",
      "49\n",
      "Loss: 1.0842, Epoch: 049, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.4977\n",
      "50\n",
      "Loss: 1.0817, Epoch: 050, Train acc micro: 0.9767, Test acc micro: 0.4722,Train acc macro: 0.9720, Test acc macro: 0.3417\n",
      "51\n",
      "Loss: 1.0790, Epoch: 051, Train acc micro: 0.9302, Test acc micro: 0.4167,Train acc macro: 0.8986, Test acc macro: 0.2046\n",
      "52\n",
      "Loss: 1.0761, Epoch: 052, Train acc micro: 0.9535, Test acc micro: 0.4444,Train acc macro: 0.9356, Test acc macro: 0.3167\n",
      "53\n",
      "Loss: 1.0730, Epoch: 053, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3800\n",
      "54\n",
      "Loss: 1.0697, Epoch: 054, Train acc micro: 0.9845, Test acc micro: 0.4722,Train acc macro: 0.9772, Test acc macro: 0.2529\n",
      "55\n",
      "Loss: 1.0662, Epoch: 055, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.3682\n",
      "56\n",
      "Loss: 1.0624, Epoch: 056, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3595\n",
      "57\n",
      "Loss: 1.0585, Epoch: 057, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.3683\n",
      "58\n",
      "Loss: 1.0543, Epoch: 058, Train acc micro: 0.9922, Test acc micro: 0.4722,Train acc macro: 0.9877, Test acc macro: 0.3315\n",
      "59\n",
      "Loss: 1.0499, Epoch: 059, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2367\n",
      "60\n",
      "Loss: 1.0453, Epoch: 060, Train acc micro: 0.8217, Test acc micro: 0.4444,Train acc macro: 0.7722, Test acc macro: 0.1836\n",
      "61\n",
      "Loss: 1.0405, Epoch: 061, Train acc micro: 0.9690, Test acc micro: 0.4722,Train acc macro: 0.9566, Test acc macro: 0.2794\n",
      "62\n",
      "Loss: 1.0355, Epoch: 062, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.4073\n",
      "63\n",
      "Loss: 1.0304, Epoch: 063, Train acc micro: 0.9070, Test acc micro: 0.4722,Train acc macro: 0.8842, Test acc macro: 0.3571\n",
      "64\n",
      "Loss: 1.0250, Epoch: 064, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.2469\n",
      "65\n",
      "Loss: 1.0195, Epoch: 065, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2340\n",
      "66\n",
      "Loss: 1.0139, Epoch: 066, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2368\n",
      "67\n",
      "Loss: 1.0081, Epoch: 067, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.3062\n",
      "68\n",
      "Loss: 1.0023, Epoch: 068, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.2571\n",
      "69\n",
      "Loss: 0.9963, Epoch: 069, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.2676\n",
      "70\n",
      "Loss: 0.9903, Epoch: 070, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.1455\n",
      "71\n",
      "Loss: 0.9842, Epoch: 071, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.4051\n",
      "72\n",
      "Loss: 0.9781, Epoch: 072, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3165\n",
      "73\n",
      "Loss: 0.9720, Epoch: 073, Train acc micro: 0.8915, Test acc micro: 0.4722,Train acc macro: 0.8701, Test acc macro: 0.3095\n",
      "74\n",
      "Loss: 0.9660, Epoch: 074, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3446\n",
      "75\n",
      "Loss: 0.9599, Epoch: 075, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.3077\n",
      "76\n",
      "Loss: 0.9540, Epoch: 076, Train acc micro: 0.9612, Test acc micro: 0.4722,Train acc macro: 0.9502, Test acc macro: 0.3100\n",
      "77\n",
      "Loss: 0.9480, Epoch: 077, Train acc micro: 0.9380, Test acc micro: 0.5000,Train acc macro: 0.9107, Test acc macro: 0.3165\n",
      "78\n",
      "Loss: 0.9422, Epoch: 078, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3190\n",
      "79\n",
      "Loss: 0.9365, Epoch: 079, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3155\n",
      "80\n",
      "Loss: 0.9309, Epoch: 080, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.2729\n",
      "81\n",
      "Loss: 0.9254, Epoch: 081, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2729\n",
      "82\n",
      "Loss: 0.9201, Epoch: 082, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.3581\n",
      "83\n",
      "Loss: 0.9149, Epoch: 083, Train acc micro: 1.0000, Test acc micro: 0.5556,Train acc macro: 1.0000, Test acc macro: 0.3530\n",
      "84\n",
      "Loss: 0.9098, Epoch: 084, Train acc micro: 1.0000, Test acc micro: 0.5000,Train acc macro: 1.0000, Test acc macro: 0.3121\n",
      "85\n",
      "Loss: 0.9049, Epoch: 085, Train acc micro: 1.0000, Test acc micro: 0.4722,Train acc macro: 1.0000, Test acc macro: 0.3033\n",
      "86\n",
      "Loss: 0.9002, Epoch: 086, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.3286\n",
      "87\n",
      "Loss: 0.8955, Epoch: 087, Train acc micro: 1.0000, Test acc micro: 0.5278,Train acc macro: 1.0000, Test acc macro: 0.3887\n",
      "88\n",
      "Loss: 0.8910, Epoch: 088, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.3063\n",
      "89\n",
      "Loss: 0.8867, Epoch: 089, Train acc micro: 0.9690, Test acc micro: 0.5278,Train acc macro: 0.9507, Test acc macro: 0.3248\n",
      "90\n",
      "Loss: 0.8825, Epoch: 090, Train acc micro: 1.0000, Test acc micro: 0.4444,Train acc macro: 1.0000, Test acc macro: 0.2984\n",
      "91\n",
      "Loss: 0.8784, Epoch: 091, Train acc micro: 0.9845, Test acc micro: 0.6111,Train acc macro: 0.9833, Test acc macro: 0.4436\n",
      "92\n",
      "Loss: 0.8745, Epoch: 092, Train acc micro: 0.9612, Test acc micro: 0.5278,Train acc macro: 0.9529, Test acc macro: 0.2397\n",
      "93\n",
      "Loss: 0.8707, Epoch: 093, Train acc micro: 0.9612, Test acc micro: 0.5278,Train acc macro: 0.9445, Test acc macro: 0.3561\n",
      "94\n",
      "Loss: 0.8669, Epoch: 094, Train acc micro: 0.8295, Test acc micro: 0.5000,Train acc macro: 0.7842, Test acc macro: 0.2258\n",
      "95\n",
      "Loss: 0.8633, Epoch: 095, Train acc micro: 0.9535, Test acc micro: 0.5278,Train acc macro: 0.9409, Test acc macro: 0.2945\n",
      "96\n",
      "Loss: 0.8598, Epoch: 096, Train acc micro: 0.9457, Test acc micro: 0.5556,Train acc macro: 0.9346, Test acc macro: 0.2945\n",
      "97\n",
      "Loss: 0.8564, Epoch: 097, Train acc micro: 0.9457, Test acc micro: 0.4722,Train acc macro: 0.9330, Test acc macro: 0.2629\n",
      "98\n",
      "Loss: 0.8531, Epoch: 098, Train acc micro: 0.9612, Test acc micro: 0.5556,Train acc macro: 0.9445, Test acc macro: 0.3657\n",
      "99\n",
      "Loss: 0.8499, Epoch: 099, Train acc micro: 0.9690, Test acc micro: 0.5278,Train acc macro: 0.9598, Test acc macro: 0.3368\n",
      "Loss: 0.8499, Epoch: 099, Train acc micro: 0.9690, Test acc micro: 0.5278,Train acc macro: 0.9598, Test acc macro: 0.3368\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAADZO0lEQVR4nOydd5gUVdbG387dk5hIzjk4MAMoBhRhFeMqZndVMK0JddVdA+gqmBDzKqZ1ZcWwq585YEQxoaKgQ1CGHIeZYXLs3PX9UX1vha7qruowXc3c3/PwPEx3dfXtCrfOPec955g4juPAYDAYDAaD0Y0xp3sADAaDwWAwGOmGGUQMBoPBYDC6PcwgYjAYDAaD0e1hBhGDwWAwGIxuDzOIGAwGg8FgdHuYQcRgMBgMBqPbwwwiBoPBYDAY3R5mEDEYDAaDwej2MIOIwWAwGIwuIlW1kFmN5cRhBlEG4PF48OKLL+K8887DlClTUFpaiuOPPx733HMPampqFD9TW1uLBx98ECeeeCImTJiAqVOn4qqrrsKaNWsk2z355JMYNWoUXnzxRcX93HbbbZgxY0ayf1LSyZRxHgxcdNFFuOiii7rku0aNGoUnn3wy5Z9JBTU1NbjgggtQWlqKI444Am63O91Dwh133IGxY8eirq5OdZurrroKM2bMQCgUwttvv41Ro0ZF/bd9+3YAUN12/PjxmDFjBu6++260t7dLvqupqQmLFi3Ccccdh0MOOQSHHXYY5syZg88//1yy3erVq2OO45tvvonrmIRCIRx77LEYNWoUNm7cqPlzZO4kxJqDfD4f7r//fnzwwQdxjTMaTz/9NF544YWo28S6Hl9++eVuP4da0z0ARnRqa2tx+eWXo7q6Gn/+858xd+5cOJ1OVFZWYtmyZfjoo4/w6quvYujQofQza9euxdy5c1FQUIDZs2djyJAhaG5uxuuvv46LLroIixYtwqxZsyTf89hjj2H69OkYNGhQF/9CRqZx1113pXsIGcGyZctQUVGBhx56CL169YLL5Ur3kHDWWWfhjTfewPLly3HxxRdHvN/Q0IBvv/0WV199NcxmYb28ZMkSlJSUKO6zf//+kr/l27a0tODbb7/Fyy+/jMbGRjz++OMA+IXeBRdcgGAwiCuuuAKDBg1CW1sbPv74Y1x77bWYP38+5syZI9n3nXfeiXHjximOY9iwYVoOQQSrVq1CfX09hg4ditdeew333ntvXPu55pprMHv2bNX3Dxw4gGXLlmHRokVx7T8a//znP3HttddG3Sba9bh8+XI88MAD6NWrV9LHlkkwg8jAcByHW265BTU1NXjrrbckxsphhx2G0047DWeccQbuv/9+/Pvf/wYANDc344YbbsDgwYPxn//8R3LRn3DCCbjiiitw5513YurUqSguLqbv2e12zJ8/H6+88gpMJlPX/UhGxjF8+PB0DyEjaG5uRs+ePXHyySeneyiU8vJyDBs2DB988IGiQfTBBx8gFArhzDPPlLw+ZsyYCMNHDaVtp02bhoaGBnz88cfo6OhAdnY2PvnkE2zfvh2ffvopBg8eTLc97rjj4PF48MQTT+DCCy+ExWKh7w0fPhxlZWWaf68W3n77bZSXl+Poo4/GM888g9tuuw05OTm69zNw4MCkjivZKF2PDQ0N+Oc//4nXX38d+fn56RucQehWITOO4/Diiy/ipJNOwvjx43H88cfjhRdekMReV61ahT//+c+YNGkSpkyZgr/97W+orq6m77/99tsYO3Ys1q1bh/POOw+lpaWYPn26xF15wgkn4Prrr4/4/tNPPx1XX3013c+oUaOwevVq1fGuWbMGP/74I2644QZFz01+fj6uv/569OvXD6FQCADw7rvv4sCBA5g/f37EitRsNuPvf/87LrjgggjX9W233YY1a9bgpZdeinYINfH222+jtLQUa9aswVlnnYXS0lKccMIJ+PLLL7Fjxw7MmTMHEyZMwPHHH4/ly5dLPrtr1y5cf/31OOqoo1BWVoaLLroIa9eulWzT0tKCefPm4bDDDsOhhx6Khx56iP5+MStWrMCZZ56J0tJSHHXUUbj33nvR2dlJ39+3b1/M8Ao5T/v27ZO8PmPGDNx2223071GjRuHVV1/F7bffjsMOOwzl5eX461//ivr6errNnj17cNVVV2HKlCmYMGECzjvvPHz99df0fSWXOxnj22+/DUAIHXz33Xe44IILMH78eMycORP//e9/JZ8LhUL417/+heOPPx6HHHIITjjhBLz88suSbS666CL8/e9/x/XXX4+ysjJccsklmq5dechs1apVOPfcc1FeXo5DDz0UV199NQ2jEGKdCwD46aefcN5552HChAk44YQT8P3330eMIx4OHDiAefPmYdq0aRg/fjzOPvtsfPHFF5JtYv2GWOdOzowZM/D2229j//799Boj5+61117D9OnTMXHiRKxatYp+f6x5J957Ss5ZZ52FjRs3YufOnRHvvfPOOzjyyCPRt29fTcdWD7m5uTCZTHTBRe4NpXv3yiuvxDXXXAOfz5f0cYhpaWnBihUrMH36dJx66qlwu9147733Irbzer1YtGgRjjrqKJSXl2PevHnwer2SbaKFzPbt24c//OEPAIB58+ZJtluzZg0uvPBCTJgwAYcddhhuvfVWNDY20vdDoRAee+wxzJgxA4cccghmzJiBRx55BH6/HwBo2G7JkiWSEJ4YpesRAJ599ll89913ePLJJzF9+nRNxyyRa/Hnn3/GZZddhkMPPZT+lieffFJyDbS3t+Oee+7B0UcfjbKyMpx11ln46quvJL/l/vvvx5w5czB+/HjcfvvtALTd57HoVgbRgw8+iAcffBAzZszAs88+i7PPPhsPP/ww/vWvfwHgjYlLL70Uffr0waOPPop58+bh119/xXnnnYeGhga6n1AohBtuuAEnn3wy/vWvf2HixIl48MEH8e233wIATjvtNHz99dcSo2P79u2orKzE6aefDgA49thj8frrr6u6fwH+IWIymXDKKaeobnPGGWdg4cKF1L397bffori4GOPHj1fcfvTo0bj11lslKzKAnySPOeYYPPbYY9izZ0+Uo6iNQCCAv/3tbzj//PPxzDPPwOVy4e9//zuuuuoqHHvssXj22WfRs2dP3HrrrVQHtW3bNpx55pnYt28f7rjjDjz88MMwmUyYM2cOfvrpJwD8sb/88svx9ddf49Zbb8UDDzyAX375BR999JHk+z/44APMnTsXQ4cOxVNPPYVrr70W77//Pq655hpqAPfs2ROvv/46zjnnnIR/L8CHHUOhEB599FHccsstWLlyJe6//3467iuvvBJutxsPPvggnn76aeTn5+Pqq6/G7t27dX/XjTfeiLFjx+Kpp57CkUceiYULF0qMogULFuCJJ57AaaedhmeffRYnnngi7r//fjz11FOS/Xz88cfIzs7GM888g8svv1zTtStm7969uOaaa3DIIYfgmWeewX333YedO3fiiiuuoJOclnPx22+/4dJLL0Vubi6eeOIJzJ49GzfddJPu4yKnvr4eZ599NtasWYMbb7wRTz75JPr164e5c+fi/fff1/Qb4jl3S5YswbRp01BSUhJxjS1ZsgS33nor7rzzTpSXl2ued+K5p5Q4/fTTYbVaI7QslZWVqKysVLwfQqEQAoFAxD8lY0a8rd/vR0NDA95880288847OP7445GVlQUAOProo2G1WjFnzhwsWbIEFRUV9CE/fvx4XHbZZRGLOrVxBINB1d8bjQ8++ADBYBB//OMf0bdvXxx++OF4/fXXI7a7+eab8X//93+48sor8fjjj6OlpUVVd6lEz549sWTJEgDA1VdfTf//888/4+KLL4bT6cTjjz+O+fPn46effsLs2bPh8XgAAM8//zz+97//Ye7cuVi6dCn+9Kc/4YUXXsAzzzwDAHS8Z599tuLYAfXr8fzzz8enn36KmTNnav4tQHzXYmVlJS6++GLk5+fjsccewzPPPIPJkydjyZIl+PjjjwEAwWAQl156KT744ANceeWVePrppzF06FDMnTtXon999dVXUVpaiqeffhpnn322pvtcE1w3oaWlhRs7dix33333SV6/5557uMsuu4wLBoPcUUcdxV166aWS93fv3s2NGzeOW7x4McdxHPfWW29xI0eO5P7v//6PbuP1ernS0lLu7rvv5jiO4/bs2cONGjWKe+edd+g2jz/+ODd58mTO6/VqHvNVV13FTZkyJeL1QCDA+f1+yb9QKMRxHMedfPLJ3DnnnKP5O5544glu5MiRHMdxXHV1NTdp0iTuggsuoPu79dZbuenTp2veH8cJx+i///0vfW358uXcyJEjuccff5y+tmHDBm7kyJHc559/znEcx/31r3/lpkyZwrW1tdFt/H4/d8IJJ3BnnXUWx3Ect3LlSm7kyJHc119/Tbfp6OjgpkyZQscZCoW4Y445hrvssssk4/r++++5kSNHcitXrtT9W/bu3St5ffr06dytt95K/x45ciT3pz/9SbLNbbfdxpWVlXEcx3EHDhzgRo4cyb3//vv0/dbWVu7+++/ntmzZwnGc8rHeu3cvN3LkSO6tt97iOI7jfvzxR27kyJHcvHnzJNtdffXV3FFHHcWFQiFux44d3KhRo7jnnntOss1jjz3GlZaWco2NjRzHcdyFF17ITZgwQXJNarl2L7zwQu7CCy/kOI7jPvzwQ27kyJFcTU0N3X7dunXco48+yrW1tWk+F9dddx13zDHHcD6fj25DrpknnniC04P4Mw8++CA3btw4bt++fZJt5syZwx111FFcMBiM+Ru0nDsl5OeTnLunnnqKvqZ33tF7T6lxzTXXcMcff7zktUWLFnFTpkyRXA/ke9X+XXHFFZq2PfLII7n777+fa29vl3znp59+yh155JF0u/Hjx3OXXnop99FHH0m2I8dO7d8pp5wS9feqccYZZ3BXXnkl/fu9997jRo4cya1du5a+tmXLlohjHwwGuZNPPpnOnRwXe66U38scx3HnnXced+qpp3KBQIC+tmPHDm7MmDHcK6+8wnEcx1166aXcJZdcItnXyy+/zL377rv0by33SazxaZ3r470W33nnHe7yyy/ngsEg3SYYDHKTJk3i/vGPf3Acx3FffvllxPUbDAa58847j3vyySc5juPn3uOOO04yJi33uRa6jYaooqICgUAgwhK+4447APCr4Lq6Ovztb3+TvD9w4ECUl5dTDwWhvLyc/t9ut6OwsJCGAAYMGICJEyfio48+ouLl5cuX48QTT4Tdbtc8Zk4ljfLCCy/EL7/8InntpZdewpQpU2CxWOJeLfXu3Ru33nor7rjjDrz88stRBYJaEB+joqIiAMCECRPoayRm3draCoAPmUyfPl0Sv7darTjllFPw1FNPoaOjA2vWrIHNZsPRRx9Nt8nKysK0adPw888/AwB27NiBmpoaXHnllQgEAnS7Qw89FDk5OVi1ahWOPfbYhH6bEnJtQ+/evWkmR3FxMYYPH45//OMf+O677zB16lQcc8wxmDdvXlzfdcYZZ0j+njlzJr744gvs3LkTq1evBsdxmDFjhuT3z5gxA8888wzWrl2L4447DgAwdOhQyTWp99qdMGECHA4Hzj77bJx44ok45phjMGXKFOqh3L59u6ZzsXbtWkyfPh02m03ym8T6kXj46aefUF5ejn79+kleP+200zBv3jzs2LEj5m/Izs5O6rkbM2YM/f/OnTvjnne03FNqnHXWWbj66quxbt06TJgwAcFgEB988AFOP/10xfP8zDPPKIqq8/LyVLf1+/14++238e677+L666/HeeedF7HtzJkzMX36dPz444/4/vvvsXr1anz//ff47rvv8PHHH+Of//ynRNO4cOFCRa+60+mM+nuVqKysxG+//YYLL7yQHq/DDz8cWVlZeP311zFx4kQAoJ4JcZjLbDbjhBNOwLZt23R/L8HtdmPdunW47LLLwHEcvT8GDBiAYcOGYdWqVbjgggswZcoUPPLII/jzn/+MGTNm4Nhjj8WFF14Y9/cmC73X4qxZszBr1ix4vV7s3LkTu3fvxqZNmxAMBqlncO3atbDZbBHH+rXXXpN8t/geArTd51q0j93GIGpubgYAFBYWRn1fLDQmFBcX4/fff5e8Jr8BzWazxIA5/fTTcc8996CpqQn79u3D7t27afhEK3379sVXX32F9vZ2iZFw3333oaOjAwAfahBn/fTt2xfr16+Put/q6mr06dNH8b1zzjkHn3zyCR599FHNMWU1lISJ0TJtWlpaVI8/x3Fob29HS0sL8vPzI4Tf4smanMuFCxdi4cKFEfs7cOCA1p+gCyXNFrkmTCYTli5dimeeeQaff/453n33XdhsNhx33HFYuHAhevTooeu75NkgZEJqaWmhv18t1FpbW0v/n52dHfG+nmu3f//+eOWVV/Cvf/0Lb775Jl566SXk5eXhz3/+M2644QbN56KlpQUFBQWS96xWa8RremlpacGAAQMiXifXWWtrK4YPHx71NyT73JGQEaB/3tF7T6lxzDHHoKSkBB988AEmTJiA7777DvX19arh45EjR2oWVYu3nThxIgKBAO68807k5OQoXpNkgUMWObW1tbj33nvx6aef4quvvpLMQ0OGDEFpaanen6vIm2++CYDX9MiN248//hjz589Hjx490NLSAgAR16Ja1p1WWltbEQqF8Pzzz+P555+PeN/hcAAALr/8cmRnZ+Ott97Cww8/jIceeggjRozAHXfcgcMPPzyhMSSC3mvR4/HgnnvuwXvvvYdAIID+/fujvLwcVquVzpPNzc3Iz8+XZDgqIb6HAG33uRa6jUFEVjKNjY2SFPX9+/djz5499GIXi2AJdXV1uifmk046Cffeey9WrFiBHTt2oF+/fpg0aZKufcyYMQOvvvoqPvvsM0nWh3j8cmHq0UcfjZUrV2LDhg2KE8emTZswa9YszJs3TzHLBADuvfdenHrqqZg/f35KxJVq9OjRQ/X4A/yEVFBQgKamJgSDQYn3gDxYAOFc33LLLTjssMMUv0crxPCSayWIQaqHXr16YcGCBbjrrrtQWVmJTz75BM8//zwKCgpw1113wWQyRXj35OeX0NTUJMlqIVqToqIi+vuXLVumaPDEOqd6r93x48djyZIl8Pl8WLt2LV5//XU8++yzGD16NF2VxToX+fn5Eeee4zj6MIqXHj16KNbcEV9TsX7DSSedFPPcxQtZRSdr3tGK1WrFrFmz8Pbbb2PevHl49913UVZWlpIMwjvuuAOrVq3CggULMGXKFPqQOv/88zFkyJCINPRevXrhvvvuw2effYZt27YlvDBTwufz4YMPPsDMmTMjvC379u3D/Pnz8c477+Diiy+WPBvE9454zomH7OxsmEwmXHzxxYqGIjEuzGYzLrjgAlxwwQVoaGjA119/jWeffRbXXXcdVq1apSvqkE7uu+8+fPrpp3j88cdx5JFHUqPmiCOOoNvk5uaiubkZHMdJFr2///47OI5T1dxqvc9j0W1E1ePHj4fNZsPKlSslry9duhQ33XQTRowYgZKSEnz44YeS9/fu3YuKigrqPtVKXl4epk+fji+++AKffvopTjvtNN3p7EceeSQmT56Mhx56CLt27VLcZuvWrZK/TzvtNJSUlGDRokVUlEcIBoN4+OGHYbPZcNJJJ6l+b58+fXDrrbfip59+0q3ST4RDDz0UK1eulAh6g8Egli9fjtLSUtjtdhxxxBEIBAJYsWIF3cbn89FsHYA3GIuKirBv3z6UlpbSf7169cIjjzwSseqOBlkFiUWq27dv1z0Z/vrrrzjyyCOxfv16mEwmjBkzBjfeeCNGjhyJ/fv3A+AnyKamJkn2ijzDjiD+/QDwySefoF+/fhg4cCAmT54MgDeaxL+/sbER//znP2OOXc+1++KLL2L69Onw+Xz0/Nxzzz0A+MWG1nNxxBFH4JtvvpEUi/v222+pKz1eDj30UPz666+oqqqSvP7++++jpKQEgwYNivkbtJy7eBkyZEhS5x09nHXWWWhoaMB3332Hr776CmeffXZKvicnJwfz5s1Da2srHnnkEfp6v3798Mknn2Dv3r0RnyEZcCNHjkzJmL788ks0Nzfj/PPPx5QpUyT/zjrrLAwePJgKlIkX5pNPPpHsQ/4siYU8/JuTk4OxY8dix44dkntjxIgRNCsR4A1HUhupqKgIZ555Ji644AK0trbSuTKWR8UIrF27FlOmTMFxxx1HjaGNGzeisbGRLjgnT54Mv98vKbLJcRzmzZuH5557TnXfWu5zLXQbD1FhYSFmz56NF198EXa7HYcddhjWrVuH//3vf7jllltgNptx0003Yd68efjb3/6G0047DU1NTViyZAl69OiBSy65RPd3nnbaabj++usRDAYjMnQaGxuxZ88eDB8+XLXmhdlsxqOPPoq5c+fijDPOwDnnnIPDDz8cOTk52LVrFz788EOsXr0aEyZMoFljubm5eOCBB3DttdfinHPOwYUXXojBgwejpqYGr776KtavX49HHnkkZgGuc889F5988glWrVol0Qm0t7dj27ZtGDhwoGr4MV6uvfZafPPNN5g9ezauuOIK2Gw2vPLKK9i7dy+ts3TEEUdg6tSpuOOOO9DQ0IB+/frhpZdeQmNjIw0bWSwW3HjjjbjzzjthsVgwffp0tLa24umnn0ZtbS1dZfh8Pvz+++/o3bs3evfurTimKVOmwOl04oEHHsBf//pXdHR04IknntBds2Ps2LFwOp245ZZbcN1116G4uBjff/89Nm3aRLVa06dPx8svv4zbb78dZ599NrZs2YL//Oc/ijqa//znP3A4HCgrK8Nnn32GlStX0ofNqFGjcNppp+Ef//gHqqqqcMghh2Dnzp147LHH0L9//4gMQyWiXbtiDj/8cDz88MOYO3curRnz2muvwW63Y/r06ZrPxdy5c7FixQpcdtlluPzyy2kBP7GmCOAzEX0+H8aOHavpuF9yySV4//33cfHFF+Paa69Ffn4+3n33Xfz444+4//77YTabY/6Gfv36xTx38ZKKeUcrQ4YMwcSJE2k4NFq9pE2bNil6sQDesIkVPjr55JPx3//+F++88w7+9Kc/Yfz48bjxxhuxevVqnH322Zg9ezbKy8thNpuxYcMGLF26FMcccwyOOeYYyX62bdtGQ0lySkpKIjQkarz11lsoKipSDTmddtppeOKJJ7B69WpMmTIF5513Hh577DEEAgGMGTMG7733HjZv3qzpuwi5ubkAgB9++AHDhg3DhAkTcNNNN+GKK66g5z4YDGLp0qVYt24drrnmGgD8w37p0qUoLi5GeXk5amtr8Z///AeHHXYYnYPz8vLwyy+/4Oeff8bkyZMNWUtu/Pjx+Pjjj/G///0Pw4YNQ2VlJZ555hmYTCa6EDr22GNRXl6O2267DTfccAMGDBiA9957D9u3b6eLFCW03Oda6DYGEcCnThYVFeG1117Dv//9b/Tv3x//+Mc/cP755wMAzjzzTGRnZ+O5557D3LlzkZOTg6OPPho33XRTXPHiadOmITc3FwMGDMCQIUMk73311VeYN28eFUOr0atXL/zvf//Du+++iw8++AAffvghWltbUVhYiLKyMjz99NOYMWOG5AaYOnUq3njjDSxduhTPPfcc6uvrkZ+fj0MOOQSvv/66RPgWDRI6E/Pbb79h9uzZWLRoUUTxtkQZMWIE/vvf/9LUY5PJhPHjx+Oll16iXg+ATyF9+OGH8cQTT8Dr9eLkk0/GueeeK/FmnXPOOcjOzsa///1vvP7668jKysLEiRPx8MMP01jzgQMHcN555+Haa6/FddddpzimvLw8PPnkk3jkkUcwd+5c9OvXD9deey3effddXb/N4XBg6dKleOSRR3DfffehtbUVgwcPxt13302P41FHHYVbb70VL7/8Mj799FOMGzcOS5YsodenGOLSf+655zB06FA88cQTOOGEE+j7ixYtwnPPPYfXXnsNNTU1KCoqwsknn4wbbrhBk1A52rUrZvTo0Xj22Wfx1FNP4aabbkIwGMQhhxyCpUuX0tCulnMxePBgvPLKK3jggQdw4403oqioiJZVELNw4UJUVVXhyy+/jH3QwT8k//e//+GRRx7BvffeC7/fj9GjR+Ppp5+mdWG0/IZY5y4Rkj3v6OHss8/G/PnzcdZZZymGVwnRqiBHC7+LueOOO3DmmWfi7rvvxhtvvIH+/fvTa/iDDz7A888/D47jMGjQIFx22WWYPXt2xIP97rvvVt3/7NmzaU2aaNTW1mLVqlU4//zzVe+F008/HU8++SRee+01TJkyBXfddReKi4vxyiuvoKWlBUcffTSuuuoqWnVbCzk5Objkkkvw+uuv4+uvv8aqVaswdepUvPDCC1iyZAmuv/562Gw2jBs3Dv/5z39oksZf//pX2O12vPXWW3jqqaeQm5uLGTNmSIT4V111FZ5++mn85S9/wUcffdSlUget3HbbbfD7/Xj88cfh8/nQv39/XH311di2bRu+/PJLKoN4/vnn8fDDD+Of//wn3G43Ro0ahaVLl6qWkgG03edaMHFqqUwMhgr//Oc/MXz48Kj1kRipYfXq1Zg9e3ZMQ/pgxefz4cwzz4wIMTEY6ebGG2/Eli1bYhbGZBiXbuUhYiRObW0tPv3006QVM2Qw9PDvf/+7WxqCDG0Eg8GYXd9NJlPC5RzE1NbW4scff8TPP/+ctAw4RnpgBhFDF/n5+XjyyScN6ZJlHPz84Q9/iLuJJ+Pg5+KLL46o3SSnX79+mkOuWli7di3uuusuDBgwAH/961+Ttl9G18NCZgwGg8E4KNixY0fMkhh2u1215xeje8MMIgaDwWAwGN0e4xcvYDAYDAaDwUgxzCBiMBgMBoPR7WGiavBtGQKBAMxmsyELWjEYDAaDwYiE4ziEQiFYrdaEK3YzgwhAIBDAhg0b0j0MBoPBYDAYcUDaOyUCM4gg9IEpLS1Nan0KgK+LQRqtJnvfDCnsWHcd7Fh3HexYdx3sWHcdyTrWZD/J6OfGDCIIHc0tFkvKboJU7pshhR3rroMd666DHeuugx3rriNZxzoZchcmqmYwGAwGg9HtYQYRg8FgMBiMbg8ziBgMBoPBYHR7mEHEYDAYDAaj28MMIgaDwWAwGN0eZhAxGAwGg8Ho9jCDiMFgMBgMRreHGUQMBoPBYDC6PcwgYjAYDAaD0e1hBhGDwWAwGIxuDzOIGAwGg8FgdHuYQcRgMBgMBqPbwwwiBoNxUOD2BdM9BAaDkcEwg4jBYGQ8KysPYNxdn+CF73ameygMBiNDYQYRg8HIeDZUtSDEAW+s2ZvuoTAYjAyFGUQMBiPj8QdDAIDKmjbUtnrSPBoGg5GJMIOIwWBkPL6wQQQAX2+pS+NIGAxGpsIMIgaDkfH4AswgYjAYicEMIgaDkfH4RR6ib7fUISD6m8FgMLTADCIGg5Hx+AMc/X+rJ4B1+5rTNxgGg5GRMIOIwWBkPD6ZR+jrzSxsxmAw9MEMIgaDkfEQg6i0Xw8ATEfEYDD0wwwiBoOR8RBR9R/G9AQArK9qQUO7N51DYjAYGUZaDSKv14v58+dj8uTJmDp1KpYuXaq67dVXX41Ro0ZJ/q1cuZK+/+KLL+Loo49GeXk55s+fD7fb3RU/gcFgGAAiqu6X78LYPnngOODbrfVpHhWDwcgkrOn88gcffBAbN27EsmXLsH//ftx6663o27cvTjzxxIhtt2/fjoceeghHHHEEfa1HD949/umnn2LJkiV46KGHUFRUhHnz5uGhhx7CnXfe2WW/hcFgpA9iENmtZkwbVYLfq1vx9ZY6zCrvl+aRMRiMTCFtHqLOzk688cYbuP322zFu3Dgcf/zxuPzyy/Hqq69GbOvz+bBv3z6UlpaipKSE/rPb7QCAl156CXPmzMH06dMxfvx4LFy4EG+99RbzEjEY3QQSMrNbzJg2sgQA8M2WOoRCXLSPMRgMBiVtBlFlZSUCgQDKy8vpa5MmTcK6desQCkkzRnbs2AGTyYQBAwZE7CcYDGLDhg2YPHkyfa2srAx+vx+VlZWp+wEMBsMw+IK84WOzmDFxYAFyHFY0dPjw2/7WNI+MwWBkCmkLmdXV1aGgoIB6eQCguLgYXq8Xzc3NKCwspK/v2LEDOTk5uOWWW/DTTz+hd+/euO666zBt2jS0trbC6/WiZ8+edHur1Yr8/HzU1NToGlMwGEz8h6nsMxX7Zkhhx7rrMNqx9gf4cVjNgMXE4Yihhfh80wF8WVmLsX1y0jy6xDDasT6YYce660jWsU7muUqbQeR2uyXGEAD6t8/nk7y+Y8cOeDweTJ06FVdccQU+//xzXH311Xj99ddRXFws+ax4X/L9xGLDhg16f4Yh9s2Qwo5112GUY93a3gkA2L1zO3I79mFoFt/g9eNfd2FqQVs6h5Y0jHKsuwPsWHcdRjrWaTOIHA5HhMFC/nY6nZLXr7nmGlx00UVURD169Gj89ttv+L//+z/ceOONks+K9+VyuXSNqbS0FBaLRddnYkFCeqnYN0MKO9Zdh9GOtfmLbwB0YuzokSgbWICSQW48t/ZrbGn0Y+iocchz2dI9xLgx2rE+mGHHuutI1rEm+0kGaTOIevXqhaamJgQCAVit/DDq6urgdDqRl5cn2dZsNlNjiDB06FBs27YN+fn5cDgcqK+vx7BhwwAAgUAAzc3NKCkp0TUmi8WSspsglftmSGHHuuswyrEmWWZOmw0WiwUDi3NQnGNHfbsP1a0+FOQ4Y+zB+BjlWHcH2LHuOox0rNMmqh4zZgysVisqKiroa2vXrkVpaSnMZumwbrvtNsybN0/yWmVlJYYOHQqz2YzS0lKsXbuWvldRUQGr1YrRo0en9DcwGAxjQAwim9VEX3Pa+EnWG2B6EAaDEZu0GUQulwuzZs3CggULsH79eqxYsQJLly7F7NmzAfDeIo+H1wHMmDEDH3zwAd59913s3r0bS5Yswdq1a3HhhRcCAP785z/jhRdewIoVK7B+/XosWLAA5557ru6QGYPByEzEafcEh5X/vzcQUvwMg8FgiElrYcZ58+ZhwYIFmDNnDnJycnDddddh5syZAICpU6di0aJFOPPMMzFz5kzcddddeOaZZ7B//36MGDEC//73v9G/f38AwCmnnIKqqirceeed8Pl8mDlzJm6++eZ0/jQGg9GFkF5mNolBRDxEzCBiMBixSatB5HK5sHjxYixevDjivc2bN0v+Puecc3DOOeeo7uuKK67AFVdckfQxMhgM4+MP1yGyWwWDyGkLe4j8LGTGYDBiw5q7MhiMjCYY4hAMV6S2K3iIPMxDxGAwNMAMIgaDkdEQQTUA2EQeIgfzEDEYDB0wg4jBYGQ0PrFBZBGyzJiomsFg6IEZRAwGI6PxiQwepZAZM4gYDIYWmEHEYDAyGlqDyGKCySSuQ8RPbx4WMmMwGBpgBhGDwcho/IFIQTXAPEQMBkMfzCBiMBgZjS/c7VosqAbEGiLmIWIwGLFhBhGDwchofGEPkU3uIaJZZsxDxGAwYsMMIgaDkdEQDZE8ZOZkITMGg6EDZhAxGIyMhqTd2+UhM1aHiMFg6IAZRAwGI6PxB4QsMzFMVM1gMPTADCIGg5HReNU8RExUzWAwdMAMIgaDkdEIHiKZhsjGPEQMBkM7zCBiMBgZDe10H1GHiBVmZDAY2mEGEYPByGhIHSJVUTXzEDEYDA0wg4jBYGQ0frU6RERUzeoQMRgMDTCDiMFgZDRelTpETFTNYDD0wAwiBoOR0VBRtZWJqhkMRvwwg4jBYGQ04m73YpiomsFg6IEZRAwGI6PxhT1Ajog6RMxDxGAwtMMMIgaDkdEIHiKWZcZgMOKHGUQMBiOj8anUISLNXYMhDoEgM4oYDEZ0mEHEYDAyGp+KqJp4iADAw7xEDAYjBswgYjC6ET/tbMTmmrZ0DyOpqIXMxB4j1vGewWDEghlEDEY3oanDhz8//yMu+c9P6R5KUlETVZvNJmoUMR0Rg8GIBTOIGIxuQkOHF4EQh7p2b9TtNuxrwTdb6hAMcV00ssRQS7sHmLCawWBox5ruATAYjK7B7eONAn+QQyjEwWyONCCCIQ5/ev5HtHsD6Jfvwp+nDMR5hw5AcY6jq4erGZ9KyAzgU+/bEGC1iBgMRkyYh4jB6CZ4RC0s/CFlj4kvEEK7NwAAqGp246FPN+PIRV/ihtd+RXWLu0vGqRcSMpM3dwXE7TuYh4jBYESHGUQMRjfB7RMZREHlcJhPZDgsPqsUEwbkwxcM4d2K/Vjy5baUjzEe1ETVgChkxjxEDAYjBswgYjC6CeKwkV/FY0LCTyYTcO7kAXhv7lG46fiRAIBmtz/1g4wDYtzJRdX8a6xaNYPB0AYziBiMboK4Fo9PpVCh2NtiMvEao155vH7I4zOml4XWIVLwEDmZqJrBYGiEGUQMRgbyy54mPLVyG7wB7UaK2KDxqXmIiB5HZFy47HzuhdugYafoomrW4JXBYGiDZZkxGBnIoo824eddTQiFOFz3hxGaPiMRVcfwEIkFyi4bH3bqNLiHSFlUzUJmDAZDG2n1EHm9XsyfPx+TJ0/G1KlTsXTp0pif2bdvH8rLy7F69Wr6WktLC0aNGiX5N2XKlFQOncFIK82dvJ7nuW92oCFGXSGCREOkJqpWqOlDDCKjelmi1iGiWWbGHDuDwTAOafUQPfjgg9i4cSOWLVuG/fv349Zbb0Xfvn1x4oknqn5mwYIF6OzslLy2bds25Ofn48MPP6Svmc0sGsg4eCHennZvAE9+uQ0LThsX8zOkDhEQzUPEG0o2SciM/79RQ2bUq6WoIQp7iPzMQ8RgMKKTNoOos7MTb7zxBp5//nmMGzcO48aNw9atW/Hqq6+qGkTvv/8+Ojo6Il7fsWMHhgwZgpKSklQPm8EwBGLj5tXVu3HJUYMxqCg76mfEITO1EJJS+IkYFe6MDJmFNUTMQ8RgMGKQNjdKZWUlAoEAysvL6WuTJk3CunXrEFIoGtfU1ISHHnoId999d8R727Ztw+DBg1M5XAYjKbz7axX+u3pPwvshdXWGlmTDH+Tw0KebY35GWocohoZI5G3JMryoOtKrRRDqEDEPEYPBiE7aPER1dXUoKCiA3W6nrxUXF8Pr9aK5uRmFhYWS7R944AGcccYZGDEiUkC6fft2BAIBnH322aitrcXkyZMxb9489OzZU9eYgsHkT/hkn6nYN0OK0Y+1xx/E399YhyDH4eRDeiLXaYt/X2GPx/wTR+Evr/yCD9dX47KjGjG+fw/Vz7h9Afp/rz+geJw84W2sZhN9Pxwxg8cfjDjGRjjWxIizmriI8djDuiKPyu/NBIx0rA922LHuOpJ1rJN5rtJmELndbokxBID+7fP5JK9///33WLt2rUQjJGbHjh0oLCzEvHnzwHEcHnvsMVx11VV44403YLFYNI9pw4YNOn+FdlK5b4YUox7rfa0BBMINU3/6dT2KXNqvTTHBEEe1PtaWfThmoBNf7/bgH2+uxYJpBbR+kJzqA830/5u3bkNO+76IbTZXeQAAfq8bFRUVAIB2UQ+0Nb/8CquoB5oRjjUx4rZuqURrlXRKa25oAwDsq65FRYUxW49oxQjHurvAjnXXYaRjnTaDyOFwRBg+5G+n00lf83g8uPPOO3HXXXdJXhezfPlymEwm+v4TTzyBqVOnYt26dZg4caLmMZWWluoyoLQQDAaxYcOGlOybIcXox7plSx2AegDA8JFjMKgoK679tHsDwFu1AIDJ5RMwdKQPxz32DTbW+dCS1R/HjlLW0rl+/xUAb/D0HzgYZeN6R2xTZakGvm9Gfl4uysrKAIT1Ru99BgAYNfYQ5DpthjrWwbc+BQBMOOQQ9O4hnSO+bdwGVG5Dbn4hysoOScfwEsZIx/pghx3rriNZx5rsJxmkzSDq1asXmpqaEAgEYLXyw6irq4PT6UReXh7dbv369di7dy+uv/56yef/8pe/YNasWbj77rvhcrkk7xUVFSE/Px+1tbW6xmSxWFJ2E6Ry3wwpRj3W+1uE9PgAh7jH6A8Joa8shw05LjvmHDkYz3+7E899sxN/GBtp6ABSIXWAMyl+P8nGt1vN9H2X2QyzCQhxgC8oHXe6j3UoxFGvm8thixgLKSrpC3KGvCb0kO5j3Z1gx7rrMNKxTpuoesyYMbBardQtDwBr165FaWmpJGV+/Pjx+Oyzz/Duu+/SfwBw77334q9//Sva29tx6KGH4scff6Sfqa2tRVNTE4YOHdpVP4fBiMm+JiFkk4jIl9QDcljNMIfDVyeX9gHAd6iP9TkgSi8zhUrVJpOJ1iIymrBa3IIkeh0iJqpmMBjRSZtB5HK5MGvWLCxYsADr16/HihUrsHTpUsyePRsA7y3yeDxwOp0YNGiQ5B/Ae5iKioqQk5ODSZMmYdGiRVi/fj1+++033HjjjTj66KMxatSodP08BiOCfU1C/SxfAkJAT9iYIunwgJAJ1ikSTstx+2PXISIZW/IUdqO27/BLDCKlLDNWh4jBYGgjrdUL582bh3HjxmHOnDlYuHAhrrvuOsycORMAMHXqVHz00Uea9rN48WKMHTsWV1xxBS666CL069cPDz/8cCqHzmDoJtkeItK4FACy7LE9OF7Re6rNXVUapZLijEZr3yHuyaZcmJFVqmZ0P77eUocznl6FrbVt6R5KRpHWStUulwuLFy/G4sWLI97bvFm9ror8vR49emDRokVJHx+DkUwkBlECIRzBIBI8RC47aa8RQijE0VCaGLGxpNrcVaVRKm3fYTCDiGbbmU2Kv5n2MmMeIkY34r1fq/DrnmZ8vqkWI3rlpns4GQPrb8FgdAEefxD1op5jiXgsaMjMKg6ZCf9X8xJp6WXmV6n6bFQNkVIzWjGslxmjO0LuU39A+T5nKMMMIgajCxB7h4AkeYhERpDYOFILa3k0aIiEStVSb4vToAaRVyXER2Dd7hndETJHJKJV7I4wg4jB6ALEgmogsQc0MUqcIq+I2Wyiehm1nmNaQmZelZAZ1SgZLmQW3SASNETMIGJ0H8jiR80TzFCGGUQMRhewNxUeIpu0dke0nmOhECcxglQ9RAG1LDNjeojIb3KohsyItspY42YwUglp7aO28GEowwwiBqMLiPAQJfCA9gRI2r2yzkcp9V5ugKlmmal4XIza8V4Yr3K7EgfzEDG6IV7qIWLXvR6YQcRgdAFyDZGaQaIFYky5IjxE6kaL3LMTU0OUIaJqtaw4AhVVG2zcDEYqYR6i+GAGEYPRBRCDqCTXASCxNHBi8MhDZiSspSSqloeMVNPuFSpVAwY2iFSy4gjkGDEPEaM7wTxE8cEMIgajC6gKh8yGlWQDSFBDFFAxiKIYLZEeImWxpU8lBEW8T0atQxTLQxQIcQiwhwOjm0AWQExUrQ9mEDEYKcbtC6K+3QcAGN4zB0By6hA5bNozwSI8RLE0RDKPi9OgomqhTEB0UTXAvESM7gO539k1rw9mEDEYKaaqmfcO5TqtKMlxAkhOllmkhki9n5lHFqKL1dxVrVK1UVt3qIXMxK+zhwOju0ASL1jITB/MIGIwUgxJue9fkEW9OomIHd0qafdUQ6TgxdHuIeJd7PI0dtq6w2AeIrUQH8FiNtH3WLVqRncgEAwhGOLvY2YQ6YMZRAxGitlHDSIXDe0k4q3w0tYdKsJnDSEz9W73as1djRkyi+UhAoQq3qyfGaM74NFQb4yhDDOIGIwUQ2oQ9S9wCXVxEqlDpFqYMZpBJA+ZqYiqY4TMjFuHSH0qI8fcwzxEjG6AR0NFeoYyzCBiMFLMvkZRyCwJvbXIg91l1x4yk3t2Yomq1StVG2uCjSWqBljHe0b3QmIQsSwzXTCDiMFIMRIPkTUJGqKwl0acQQVoyzIjnh6171er/Cx4iCIF2+lES8hM6HjPDCLGwY+WJs4MZZhBxGCkGImGiD6cE0+719O6gxhEuU4+E01VQ6RSmNGo3e59MeoQAYCDFmc01tgZjFTAQmbxwwwiBiOFdPoCaOjgaxDxIbPEvRWqhRlpc9fIfZNJMs9lAxCtdUeM5q6ZqCEK/xa5jorBOBjxMlF13DCDiMFIIVVh71Cu04oeLltSNEREC6Pey0y9DlEe9RDFqlStlnZvrAlWX8jMWMYcg5EKxAkbzCDSBzOIGIwUsk9UgwhA19QhitLcNdfJe4jUDDK1LDNibPmCIUO1wBBE1cp1iABRyMxgxhyDkQrE2ZRMN6cPZhAxGCmECKoHFLgAQFSHKBlp9zKjRUMdotghs3BbEHnrDpHxZSQdERNVMxhSmKg6fphBxGCkELmHiBgx8T6cOY5TrUMUvdu9PGQWK8tMOjU4rGaYwk4YQxlEGjREToNW2WYwUoFHEjJjafd6YAYRg5FCxBlmQOI1cfxBDuGq/OqFGaO07ojmIQqFOFH3eGkIymQyCToin3FWnbG63QPMQ8ToXog9RMEQR9t4MGLDDCIGI4WIaxABiQt8xcZORNo9yTKLEjLLFYmqQ7KJ0h8SJlJ5t3tAVIvIQJ4WX/g4MlE1g8Ejv85Z2Ew7zCBiMFLIXlnIjDy4QxziEieTDBKTKbJWENEQKQmf5aJqQGoAAVL3ulLlZyP2M6NlArRUqmYeIkY3QJ4JqlaVnhEJM4gYjBTR4Q2gMVyDqJ8sZAbE94CmRRmtFphMsmrSolYe8vYdNGQW9hABkfoCv2g8SiEoI/Yzo5onq3qWGdVtsSwzRjcgopEzWwhohhlEDEaKqGrmvUN54RpEgDS0E5dBpNLHDJAKnz0+uUEUFlW7RB6igPJK0mI2wWKONDAED5Fx2nd4aWXtyONBIEYoa+7K6A7Ir3PmIdIOM4gYjBQh6Iey6GsWs4kKluPRtBDvjFNBM2MymWjYTJ5pRlaNWTYLNXbkE6Va2w4Cbd9hKFG1cu81MQ7mIWJ0I+TXuT/ARNVaYQYRg5Ei5BlmBOKxiKc4o1rKPYEIq9UMIpfdQo0H+ffHMi6MKapmlaoZDDHykBnzEGmHGUQMRoogbTv6yQwiewJp4J7wZxwqBlGWSliLfM5ps1B9kDz7hEycasZFtLT+dCFUqo5dh4iJqhndAfl1zrLMtMMMIgYjRXSEe4rliTK7AJHHIo4QjlqVaoJLJWRGQm0um4V+f6SoOnrGllCHyEgGUbgOkQYPESvMyOgORHiI2EJAM8wgYjBSBDUwZA/rREI4NPSlGjKLzATjOI4KLR02M/UQySdKWvVZxbhwRqmEnS5i6Z4AlnbP6F5EZJkxD5FmmEHEYKQINU1OKjVESmEtbyAETlTdmhpEKqJqtarPhtQQaWjd0R0qVb/z6z6c8sS32NvYme6hMNIMq0MUP8wgYjBShFdF35KQhojUIVIJmWUpeHHEoTmXTRBVy1eOsfQ4LgP2BBNE1VqyzIwz7mTz9i9V+G1/K1ZuPpDuoTDSTETa/UG8EEg2zCBiMFIEqfMjD0ElI2TmtGrPMiMTJJ/yb4Y9/Fk1g0gtZKYUjks3ghGnXoeoO4iqyTk50OpN80jU+b81e3HCY98wL1aKkXuIWINX7aTVIPJ6vZg/fz4mT56MqVOnYunSpTE/s2/fPpSXl2P16tWS11988UUcffTRKC8vx/z58+F2u1M1bAZDEz4Vj4sjgY73JFzlVCjMCAAuW6SAWF67yK6Sdi/ocTIn7V5LpWpBxG6ccScbck5qWz1pHok6H6zbj821bVi1rT7dQzmoEbf3AZiGSA9pNYgefPBBbNy4EcuWLcNdd92FJUuW4JNPPon6mQULFqCzU7rC+PTTT7FkyRLcfffdWLZsGdatW4eHHnoolUNnMGLiV0ljT0TkK27doUQW9RAJaffy6tbxpt27DCaqDoU41sssDDGIDrQZ10NErrc2j3EqnR+MkOs8x8HPBSxkpp20GUSdnZ144403cPvtt2PcuHE4/vjjcfnll+PVV19V/cz777+Pjo6OiNdfeuklzJkzB9OnT8f48eOxcOFCvPXWW8xLxEgrJMtMLvglD+/4DKIYafcKRgsxoohhIIiqZWn3QeXx0n0bTEMkbk6rJe3+YDaISCkEI3uIAuHrq83LDKJUIvQt5Mt9MFG1dtJmEFVWViIQCKC8vJy+NmnSJKxbtw6hUOQJbGpqwkMPPYS7775b8nowGMSGDRswefJk+lpZWRn8fj8qKytT9wMYjBioiaoTEfkS3ZFqlplCA1ZagyhsLBEPUEQvsxhZZk6DhczE2ghthRmNMe5UkBEeolDYIPL40zySgxtiEOWGGzmzkJl2rLE3SQ11dXUoKCiA3W6nrxUXF8Pr9aK5uRmFhYWS7R944AGcccYZGDFihOT11tZWeL1e9OzZk75mtVqRn5+PmpoaXWMKBpM/YZJ9pmLfDClGO9Z+KmbmJGMiGh2PP6B7rMS4cVhNip8lnqMOr7DvTq8//BkzgsEgbGbl7/eGq1vbzMr7Dnvg4fYFDHGs3V7hwWoGpzoWq5l/EPuDHHz+gGLjWiOj5VgTg6ixwwe31x+1lUm6CIQN7ja33zD3qBwjXNeJ4pGFzLz+oCF/T7KOdTJ/W9oMIrfbLTGGANC/fT6f5PXvv/8ea9euxYcffhixH4/HI/mseF/y/cRiw4YNurY3yr4ZUoxyrFs7+JDt7p07UNFRRV9va27lX9+3HxUVbbr2WV3XBACor6lGRUVLxPv1Nby+rqa+ERUVFQCATfv4eyTodaOiogId7fzndu7egwpbA/3srr18OLq9tZl+VkxVPX8/Nbd10mOczmPd6OYnQrMJ2LB+nep2HpEn7OdfflVsjJsJqB3rEMdJMou+/ulXlGSpZ92li7YO/trcW1uveH0ZCaPMIXoJhDgEw544zscf71179qHC1ZTOYUXFSMc6bQaRw+GIMFjI306nk77m8Xhw55134q677pK8Lt6P+LPifblcrojto1FaWgpLlPTdeCAhvVTsmyHFaMfa/MU3AAIYO2okygYV0Nf77a8Etu9CYXFPlJWN0rVP57o1ALwYPmQgysr6R7y/C/uBX9bD7spBWVmZ8BqaUVyQh7KyMpRsWQfsq0avPv1QVjaYfvbHlh0A2tCrpAhlZaUR+7ZWtQArf0DIYkNpaWnaj/Xexk7gwzrYrWb6W5UIhjjgnU8BAKPGHoKCLLvqtkYk1nXt9gWBNz+nf5cMGIayAfldOEJtWFd+CyAAqzMn6vlKJ0abQ/TS5gkAb9UCAPr3LMTa6mqU9OqNsrJhaR5ZJMk61mQ/ySBtBlGvXr3Q1NSEQCAAq5UfRl1dHZxOJ/Ly8uh269evx969e3H99ddLPv+Xv/wFs2bNwoIFC+BwOFBfX49hw/iTHggE0NzcjJKSEl1jslgsKbsJUrlvhhSjHOtAOHbvtFsl4yGNWX1BTvc4iTDY5bApfjbbwQsp3f4gfZ+Ip502fhxEXB0IQbIPovGwW5WPX7aTNyTcPmHf6TzWQfChL7vFHHUMFgtfLdwf5BAImQxxbcSD2rH2haQhg7p2vyF/YyB8fbV7A4YcnxijzCF6CXCCYD3Xxc8F8vvcaBjpWKfNIBozZgysVisqKiqoIHrt2rUoLS2F2Sy4tMePH4/PPvtM8tmZM2fi3nvvxVFHHQWz2YzS0lKsXbsWU6ZMAQBUVFTAarVi9OjRXfeDGAwZamnsyUi7V+tlplSpmtYhCuuLSEaWPB1XrUwAwWWwbvexxivGYbXAHwwYJkMumcjPx4E2Y2aakQUCyzJLHeT6dljNtFgpyzLTTtoMIpfLRT08999/Pw4cOIClS5di0aJFAHhvUW5uLpxOJwYNGhTx+V69eqGoqAgA8Oc//xl33nknRo4ciZ49e2LBggU499xzdYfMGIxkopa1JWSZpS7tXvzgp3WIwkaUXaUOUayaPuTzvkCI6hTSiZbGrgSH1Yx278GZei+vHG7UatVClhkziFKFUGLDrJpNylAnbQYRAMybNw8LFizAnDlzkJOTg+uuuw4zZ84EAEydOhWLFi3CmWeeGXM/p5xyCqqqqnDnnXfC5/Nh5syZuPnmm1M9fAYjKmoGBqmLE8/KLVZzV2K0KNUhIp9R62UWK+0+S1Qd2wiellitRsQk0i7F6MjPhVFrEREjup0ZRClDPD/YVe5zhjppNYhcLhcWL16MxYsXR7y3efNm1c8pvXfFFVfgiiuuSOr4GIxEUAuZ2RNoJRG7UnVkHSIyScrrEEV0u48RgnKIXjdC2MynUvhSCcdB3M8sMmRmUA9R+Ppy+4PwB0OazhtDH+I6ZWoFWBnqsCuSwUgBQVH6a0TILBENEW3DoebFCbfu8AfBcfz3Cw1hzZLxRITMYniITCaT0M/MAO071HrFKUGMOSN4tpKN/FwY1UMUED2YO5iOKCUI3mCzqlaQoQ4ziBiMFCA2NmyyZqmJhG+Ewoxq3e7514MhjhoM9DM0ZKY8UZLt5eNV2r8RPETUgNMSMiMeojh0W0aHnAviHTSqhygg6kDAdETqkIVMPIg9RGpaQYY6zCBiMFKAOBwVmWUW38qN4zjqVYqlIQIAj4/flhQmjBRVy3uZCYJMNYR+ZumfZAUPUezK0wdzPzPi9RpUlA2Ar1ZtNK8Ax3GS640ZRMrc/cHvmLp4JZo69BUVJohD6mShwAwi7TCDiMFIAeLMDptZRUOk86El3l4ty8xuNcMabk3RGW7FIRdiEw9QhIZIgybHUB4iXWn3B6+omngA+/Zw0nNb124sL5E8K5H1M1Pm443VqGp2Y0NVZBV6LdC0e5uZLhSMZhwbGWYQMRgpQOgcb4LZLA+ZxachEutf1DxEQGTHe3mqvj38/RHNXYPRNUQAdGmIftvfgpd+2JWyFP1YWXFinN1AVO2yW9Azl6/mf8BgOqKA7BpoZxqiCDiOQ0PYM9Qap8EopN1bVJMnGOowg4jBSAHRHta0DpFObwV58FnNpqhGgDzTjGaZxfAQadHkCCGz2GP/x7sbced7v2HNrsaY28YDE1XzuEXnt2ce38qo1mC1iORhGxYyi6TdG6DzRrzHR7z4UUueYKjDDCIGIwVE87bEqyGS1xNSg2aaUYNI+jm7irbAr8HAcBLvkwbDYn8z76VocacmPKJLVJ1AZp/R8fjEHiLeIDJateqATK/GqlVH0ijSDbXGec94lNLuD8JrPlUwg4jBSAG0irLCwzrRkJmafohADB/iOXBHaIhIBVvpQ0qoQxQlyyz83Z4YITOO4+gELxdvJ4tYlbXFJFId3OiIPUS98kjIzGAeopDcQ8Q0RHIaRAZRvB4iryjtXi15gqFOWgszMhgHK9G8LVTgq/PhHKtKNUEImclF1WbJmCJF1bE1OcT75PYHAYf6GNq9Abr/VLns9YTMnNQIPXhDZk6bBXnhhp5Gq0Uk9xCxatWRNLSLPETxaoiIh0ikIWIhM+0wDxGDkQL8UWr6iDOe9NQckXt61JA3eI3IMovV3DVayIx6n6JPsmL3v94J2RcIaTou1ICL4tEiEA9RvOUCjGxIucPlFVx2C0poyMxYHqIIg4iFzCJo7BDOWbwhM68oPG5TWfgw1GEGEYORArSEzEJcZPZNNMTu8GjI+5kRI0AuqlZr7poMUXWDxCDSYfT5gjjmwZU4718/xtxWS1YcIZG0+ye/2IrxCz7D+n3Nuj/bFXgUQmZG8xBFhsyYQSQnGSEzcbd7G0u71w0ziBiMFBBVVC0yaPRMVkILjugeInnHe7mHSK2CrZbu8aRlSGcMDVFje3weoj2Nnahp9eCnnY2oanZH3dYfxeiUk4io+rtt9fAGQli3L77aMKlGkmWWIR4iZhBFkpSQmbi5KwuZ6YYZRAxGChDqEEXeYmKDQ88DWuhjpj1k5g+GqBdKqEMUvVJ1NAPDJRNsqxFvyKzdKzwIVu9oiLqtlhAfIZFK1U2d/G+JJSRPF6S8gtMueIiMVq06Mu2eiarlNCbFQ8RE1YnADCIGIwVEC5mZzSbqztYTwiFaEbU+ZgSXTUi7VyrmSIw0uXGgJQTl1BgyqxfpIfRoGFpFD4LVO6LXL9Ilqqa9zPQbNY0d/MPbCNW5laC9zGwWFGTZDFmtmhVmjE1DEtLuyXziYGn3ccEMIgYjBcTyXtAQjg6Rr9a0e3GWGVkxmkyCl0StYJuQZaYuUqZZZnpCZgHtK1Rx9tHqndE9RLTViI7WHR6dDweO46iHyKgGEdUQ2S0wmUyGrFYdYIUZY9IgMmAT9xCxStXxwAwiBiMFRPMQAaLijDomK3HRtWiIW3eIdUcmE2/oqGmINIXM7NoqPscfMhMeBLsaOqOKg/16RNW0DpE+o6bVHaCtR7S0K0kHRM9FrgsjVqtmHqLYSEJm3kBcLW+EtHtppWo92azdGWYQMRgpwBcl7R4QNXjV5SHSl2Xm9gcVvUpKYstgiAOZf6OKqkkGm64sM+2/Ua4t+TGKjiiW0SkmXlF1Y6fwO4za9kMsqgZgyGrVRFSd5+Q9jG0eP3tIixD3MSPEU6uJ9jKzWeh9zHGRzXUZyjCDiMFIAbG8F/Gkgct7kqkh7mWmVLtISLvnEApPlGKdgSYNkU97HSI9XjD5Q+DHKDoiISwZuw6Rk/aP02kQiX6HYUNmotYdAAxZrZqk3Rdk2/m/g9xB2UYlXsR9zCzhZtDxZJp5/SIPkag+FwubaYMZRAxGCogdMtPvsdBaqVoaMpPWIAKkmhvyoBJPmOnMMiOi6pG9cgBE1xHpq0MUn6i6SWwQGTRkJvcQGbEWEfEQ9XDZEI7cMh2RCHK/uGwWFIaNxngMIknavei+0KPj684wg4jBSAExRdU2/Rkg2lt3hLPMRCEzh+gzkoky/KASGy1WswZRdcyQmeCd0CWqDmtLpo/uCZMJ2FHXoRr60RcyOzg9ROKyCsQgMmK16oDofsgJX0NMRyRAwmVFOXbk0rCi/uNDrm+nzQKL2USNT+Yh0gYziBiMFOCLUocIiDdkRtLutWmIPJKQmfAZm2TlGPYQiYoyEvG14r41iKo7RdltQHwaov4FWRjVKxcA8NNO5bBZXKJqnZWqtWqIOrwBfL2lLqpWwx8M4aMN1WiJM6VaCbGR5gyfGyN6iPzh42K1mJAj0hExeEhRxqJsO/KcfD+6eFLvxZpBk8nE2nfohBlEDEYKiOW9sMfhsXD7pVoRNWjIzB9Q1B1ZzCaqU5A3YI2Wcg+Ie5mpGwfiirvi79AC8RrkOa04fGgRAPV6RHE1d9XZy0wcMotWnftf3+zAnKU/4d7lv6tuc++Hv+OaV3/Bki+36hpDNIh+yGwSjoMRq1UHRMYr8YCwBq8CpI9ZYXZiHiKPyEMEAA6Sacb0WppgBhGDkQJii6oTqEMUozCjWFStFmaT9znSknIPiHuZhRBSyRJqlGXL6PMQ8Q+BHIcVhw8tBKCuIyKhOE0hM9LcVaeHqEFjyGxvUycA4KUfdmNrbVvE+5tr2vDK6j0AgN+rW3WNIRpi/RDx7BmxWjXREFnNJuQ4+Ad+KzOIKPXEQ5TjQJ4r7CHS6UHzB0PUQ0nmCFua2ndwHIdOX+adX2YQMRgpQGsdIj0hHHEn62hkxRBVA5HFGb0BbeEnsXfKp9ISINIg0l+YMddpw2FDeA/Rltr2iH3y+9UvqvYHOV0pyGIPUbTWHURwHQxxuPvD3yUp5RzH4Z4Pf6ffu7uhU/P3x0LJa2jEatVEvG+1mJEbDgkxDZEAub6lITN9x0cc0iULAKEiftcaRPd/tAnjF3yG3/Ybs/+fGswgYjBSQKyU8HhEvkJhRm1Gi9svaIgcss84ZP3MovVeEyP2TnlV7AN5PRVdHiKv4CEqzLbTbLOfFLxE3jhE1YA+IbtYQxTNQyQOp327tR5fVh6gf6/YdADfbaunYcr9ze6keW7cvkgPoBGrVQfo9cU0REo0ikTVeXEeH7Fuj1zv6WrwunZ3EwIhDt9ure/S700UZhAxGCkgVkp4XBoiX6QeSAnyPscBzZ38pBoZMpNmuZEJM5Zg22w2iWr6KHtaSAsCexy9lMhDgOgopoS9REr1iLTqngDp79LjlWvSGDIj52Z4T96Au+fD3+ELhOANBHFfWFf0l6OHwmkzI8QBVc1uzWOIhjzlnmC0atXkXFnNZvrAZxoigfp2oiGKP2RG+5hZhcQIwRPctWn3ZIGwpSYyfGxkmEHEYKSAlNQhEjVujAZJjQeA5k6hvokYefaJX2PITLyvWCEz8lDWujr1B0N0lUsNIqojijSI9IiqrRYzLSeg55iLvV0ef4gWspTT6ecf7jccNwIluQ7saujEi9/vxLLvd2FXQydKch24dsZwDCzMAgDsbujQPIZoeFSE9karVh0QZ5mFNURtLGRGEYfM4hVVexRC6mptelINCYdWMoOIwWCkplK1ttYdFrOJGmLkgS7/jFCtOqwhIuO1xva2UGG1moco/J19ejjD36FtdSr2GGSHH5qHDeENosqaVmrcEfw6QmaAqMGrxnpC/mAo4qGkZkx1huOHJTkO3HLCKADAE19sw5NfbAMA3HzCKOQ4rBhYmA0A2NOYHB2R26esKzNatWqaZWYWNESsMKOANGQWn4dIqU1PujreEw/Rtrr2iMa+RoYZRAxGCiBGQDoKMwKCsJqEfOSZaXYqMpZ6iDSlsIf37Y3hISIPZa2rU7KqdNksdCLvmevE0JJscFxkPSKtuicC8axp9RCRLvfiskxqYTPyAMiyW3HWxP4Y378H2r0BtHkDKO3XA2dP7A8AGFTEe4j2JElYrRYyM1otInKuJB4ipiECEO5jFs4ySyTt3qvQ/DldHe/JvewLhLAriUkEqYYZRAxGCohZh8gSf+uOWBoiAMgKb0NEwfKQij0i7V67cUGMLbWQGfEQ9dZpEJEVMRHdEg4bzHuJ1u8TMlY4jtPVugMQeeU0ljpo6uDHU5Blp+dR3SAKG3N2C8xmE+764zj63p1/HAtzOFxHDKLdyfIQqVwTRqtWHQgp1CHK0JBZMMRhR1170prTtnsD9FouEmuIdBZmVCrcKvcEdwX+YEiy0NuiUIbCqDCDiMFIAbEe1rRyssaHczDEUaNFi4fIKfMQyXVH8rR7X5B/sGoJP7mop0XNQ8Q/hHvHGTLLlRlEA8NGRHWL4O0Q71NryMxJx60tZEbajxRk2YQebiq1VYhhQozFSYMK8OSfyvHP88twaNigA0A1RMnyEMkbuxKM5iES1yFKpPCgEVjy5TbMeORr3P7uxqQYRcSjmmW3wGW3iEJm8aXdSxs5d33IrFOWfro5g3RE1tibMBgMvSS7DpFY9xJLQwQID+bm8CpTXVQdTrsPRA/xiaGGhVrIrD2+kBl5QOY6pNMS0SLVtAqZWeJ9ahkzINYQ6fMQFWU70OENosXtp5odMf5giBpo2SJB+x8n9I3YdlCRoCHiOC5qmxQtuFXCqERUXWcQD5EQMhPVIcpQg4h4PP67eg9sZhMWnDYuofNYLwqXARAZjH5d1wjtYyYKjzuipN17/EGs2laPI4YVSRIxEqVDtmjIJIOIeYgYjBQQKyWcZJlpXblJDKIYlaoBIMvGT3BkASs3omh9EtLLTEf4KZqHyOMPoiPstRA8RPo0ROSBSeid5wIg9RCJj5teUbVWI5SEGwuybUL1b4WQmbgGUay2Kv3yXTCb+P0kw1hRC5mRsItRMrmCIeF+yHQNkVjsvOyH3bh3+aaEPEXiDDNAOHf+IKfZeAcgauSsIKpWWLy8unoPLlu2Bs9/szO+gavQIbvmWMhMI16vF/Pnz8fkyZMxdepULF26VHXb999/HyeccALGjx+P888/H+vXr5e8P3nyZIwaNUryr6MjOamtDIZeYnW711uHiDz47FYz1aNEQ/5glhtR8rR7YmDYtITMooiqyeRus5joiler0ScuyiiGeohaPPTBQ46v2QRa8DAWeksdNIpW7tF6uBH9kFWU3aeG3WpGnx68gZcMHRGtTWWXfi/RkPkCIUNk+dDmrmZBQ2QUY00vxJN5wrheAIAXvtuJxZ9sjtsoIiHmohzeq5dtt4Bc0nqMRqW0+2ghs/3hWlhiz2sy6JDVS9vV0KE5szPdpNUgevDBB7Fx40YsW7YMd911F5YsWYJPPvkkYrs1a9bg9ttvxzXXXIPly5ejvLwcf/nLX6jBU1tbi7a2NqxYsQLfffcd/ZeVldXVP4nBAJCKkBlxh2u7ZeUegwhRtVUqttRT5NAVJWRGDKKCLLuoBoq2B0WbiqiaeJo6fUHazkBrqxExejvekyyzgiy7UP1boX1Hp4qORw0qrE6CjkhNaJ/lEP7uNMDDiBhl4m737d6Aal0nI0Ou0zlHDsa9sw4BADz79XY8ES6xoBd5yMxkMlEvqZ7U+2gaIiUvLblula7pROgMG7r9C1wozLYjxAHbDrQn9TtSRdoMos7OTrzxxhu4/fbbMW7cOBx//PG4/PLL8eqrr0ZsW1dXh2uuuQann346BgwYgLlz56K5uRnbt28HAGzfvh0lJSUYMGAASkpK6L9E4/MMRrzEytrS27pDT8o9IGiICJF1iOKrVA2IPEQKITOSYVaYbdfdNkBNVO20WVCQxT8gqsOrWa3NaMUQD5HWMESj6LcITW0jHx5un1RQHQsh9T5xD7aahsguKkQpF7mmA3HrDiIa5jhjGGt6IR6iPKcNFx4+CHf9cSwA4Mkvt8ZlXMhDZoBwD+gRVntElaoJ8tC4GJIgEK0CezyQ0He2w0pb72RKgca0GUSVlZUIBAIoLy+nr02aNAnr1q1DKCQ9eSeddBKuvvpqAIDH48GLL76IoqIiDBs2DACwbds2DBkypOsGz2DEIHaWmT4NkVKNkWhEhMwUHpiAYLj5klSpmrTtKMqx0wdyIMRp8gSoiaoBoHcPqY4oVp0nJYTMPn0eotghM6EGkRZIccZkhszk320ymeg1YISu4+KQmcMqGGuZqCNqkxnulxw1BLkOKwIhDlXN+s+puCgjQWjwGk/ITGQQRUm7px4iHTolLZD9ZjssGN07D0Dm6IjSlmVWV1eHgoIC2O3CRVBcXAyv14vm5mYUFhZGfOaHH37ApZdeCo7j8PDDDyM7m59Ytm/fDrfbjYsuugg7d+7EmDFjMH/+fN1GUjCY/NUK2Wcq9s2QYqRjTQwMq5lTHA+Zs7z+oKbxEqGi02bWtH2EiNosPS60jYU/gGAwSA0uqzn28aPerWDkb6sPt4ooyLLBYhKMII8/ENP7RB6O2Q5LxH575zmwqRrY39SJYDAIt4/f1mYxaT7f5OHg1njMiXHXw2mF08Z/tsPrj/hsu4e0R9F2bgYU8CHA3Q0dmraPdl2TVb7DGnkcsu0WtHkCaHP70n5P+MPXl9nEIRQKIddpRVOnHy2dPvQUGQLpJtYc4g+GhBILovPdr8CFypo27GnowJAifVINcs/ku2x0f8TYau7Ufu7otWARxkXuc4/CNU8MZbcvkNTro80dLiNgs2B4Cf+M3lTdGvEdyZqvkzn2tBlEbrdbYgwBoH/7fD6lj2DEiBF4++23sXLlStx2223o378/ysrKsGPHDrS0tOCmm25CTk4Onn/+eVx88cVYvnw5cnJyNI9pw4YN8f+gNO6bIcUIx9obnmy2bq5EW1Xkbba7gb/GWzs9qKioiLm/3/fzk2bI59W0fWujdEW2fetmtFYJXqKWplYAwN791aioaEdVNf93U0N9zP031vGhHm+AizjWm3by3xvqbMXvv22kr//yawVcMcoF7Ktt4sdwoBoVFS2S92x+XoNQsWUXRtsasDl8/LhgQNPxAID2Fn6fu/dWRexfidpm/nfWV+1CZyu/8t+5ex8qspol2/2+jz83nF/buXQ38cbcjtpWzWMHlK/r+mb+vNXs24MKHJC8Z+b4a3Dd75sRqEuv0dHQ1AwAqN5fhYqKJthM/ILhlw2/o6PIOAYRQW0OafMK3pQdm3/DnrDBkWPir8cfN2xFj84qXd+1r56/Fptr96Giog4AEPLy196mrTsxIFSraT/kHm5urENFBX9NNjXw9+P+mlpUVEjF03XhOaCxpU3XdRiLrbvC80NHK8xt/DX4275G1e8wwnxNSJtB5HA4Igwf8rfT6VT8THFxMYqLizFmzBisW7cOr732GsrKyvDCCy/A7/dTj9HDDz+MadOmYeXKlfjjH/+oeUylpaWwWLSFJLQSDAaxYcOGlOybIcVIxzr49qcAgLLSQ6goWIx9fyvw5feA2YqysrKY+6uyVANoRmGPHE3br27dAfy+hf49aUIpFW0CQJ/qSmDbLhQW90RZ2Sjk7/kdwB7079MbZWUjou77d+8eYN3v8Aa5iGP9+o6NADowanA/TC4fCoSPw+hxh6AgK/qDz7JmNQAvxo4YgrLSPpL3Dmnajs92bAVc+SgrK4VnRwOARuRkOTUdDwDoV7UJ2LEbBcU9UVY2Muq2HMeh/Z3PAQCHl4/Dxo5dwK49yC/uFXF8dnBVAJpRXNBD01iGeQLAihVo9XEYNvqQCM2UnGjXtXnV9wD8GDNyGMpGlkjeK1j1Pfa3taLfwCEoGyV9r6vJWrcGgBdDBw1EWVl/FH+3Cgc62tBn4BCUjUjv2MTEmkP4HnQH4LSZMXmiIPcYs/d3rKneA3NOEcrKRun6TvenKwEEcGjpaIzv3wMAMGDbevy8fz96lPRGWdlQTfvJ2bkRQCcG9euLsjJeTvJ1w1agcjvyC4tRVjZWsr3521UA/DBZHZrvIS18Vb8VQBsG9C7ByUeNwvwvV6DRHcKQUePQwyWU1EjWfE32kwzSZhD16tULTU1NCAQCsFr5YdTV1cHpdCIvL0+y7fr162GxWDBunFAOf9iwYVRUbbfbJd4mh8OB/v37o7ZWm2VNsFgsKXuQpnLfDCnpPtYhcVVpu1VxLC4HPzF4AyFNYyVaTbX9ycl2SGv5ZDttks8RTUwgxMFisdBu5A5b7GOX7SRj5yKOdWMn7/0oznXAbrPCbAJCHBDiTDH32+bhf2Seyx6xbd8CPgxR0+qFxWJBkONX5nar9nPtDNdm8gW5mJ/p9AWo4L0414WssK7Jo3C+iHYjW+O5yc+2oDDbjsYOH6paPBiX3UPT+JWuayLyznbYIt7LpmOO/XtTDZGw2MPXV074Gurwabv+uxq1OaQjXJgzV3Y/EV3Y/havrt/DcRwawwVAS/Kc9LN5Lv551u4Nat4fCdNnOYTr0BG+5v0K1zwJ/Sld04lANEk5Thvysx3ol+9CVbMb2+o6abNmMemer8WkTVQ9ZswYWK1WiRtt7dq1KC0thdksHdabb76JRx99VPLab7/9hqFDh4LjOBx33HF4++236XudnZ3YvXs3hg7VZlkzGMnEL0oKUKvrQ/Q0egszxgo7ETTXIZIVZtTVukMx7T4sqg57o+T1jqKhVpgRkNYiAsR1nrRnkuopdUCabdqtZmTZLbTQZXRRtfZJPVktPIgxppTynx1+TV45OB2Q82UNz+15JPU+w6pVywXVhH4FvOh/X5O+8ynvY0ag/cziqEMkbtNj15B2n+waQeR6Iwb5qN65AIDNGSCsTptB5HK5MGvWLCxYsADr16/HihUrsHTpUsyePRsA7y3yePjJ77zzzsOPP/6IZcuWYdeuXXjiiSewfv16XHzxxTCZTDj22GPx5JNPYvXq1di6dStuueUW9O7dG9OmTUvXz2N0YyRVlGOm3Qc1FXRLJO1eqZijvD6JnuauzijNXYVUdX5y11OLSDCIlLLMeIOIZJnpyYoj6OkfRzLMirLt4YytcNuPJNQhApLX5FWtUjUgZJ4lu85MPBAPJKlzJVSrjm4QcRyHa15di2v/+0vSmqkmAhH+y432/mGDqKpZX5FDYniTPmaEvDj6vSml3ZPjrbQgcaeoDlGHV7pAoAZRTWtSvycVpLUw47x58zBu3DjMmTMHCxcuxHXXXYeZM2cCAKZOnYqPPvoIADBu3DgsWbIEb775Jk477TR8/fXXeOGFF9CrF18p9Oabb8YJJ5yAv/3tbzjnnHMQCATwr3/9yzBuOEb3QvzwV69DxF+bIU54WESDGkQa2nYAUoNIqZhjZNp9MOp4xdCaPDHqEAGChyxWLSKO44TCjEpp9+G+aO3eANo8fl0eLYJTR6VqcYFJQPjNSh4ieWNXLRAPUaLFGcnDTMlQzjKQhygg8xARgyJWter9LR58tKEGH66vRl17+vuyCTWIZB6ifN4gqm31ai78CUTeL4T40u4VCjOq3H8cx9EaUG6/tkWZVjpkFedH9eINoi01xi/OmNbmri6XC4sXL8bixYsj3tu8ebPk7+nTp2P69OmK+3E4HLjttttw2223pWScDIYeyORjMZtU20qI+w15A6GYhohSjZFoiCdFJc8FMSR8Mg9RIiEzXyBEHxhCyMxE34uGNyA0SFXyEGU7rMhzWtHqCaCmxaPLo0Ugx1xLiEBcgwiAptYdehpk0pBZY/zFGTmOEzxESiGz8APJCIUZheauYQ+RqIFpNHbVC8dnT0MneuYqJ9x0FYKHSHqu+VpVZnj8IVQ3ezC4OFvT/oQaRA7J63ku/YUZheauCr3MZPefLxhCMLwQC3H83w6Ni61YEAOc6O5Ghg2iyprWpDQ0TiWsuSuDkWRo244oD2vxe1p0RPpDZsKErfQZtUrVWgodEs+DT+YhIkaExWyi2STRWgeIIYaUySTtGC+mb75QnDGukBmpVK3heDfI2iload2hx0NEut4n4iESe7qUQmZCYcb0G0SBkPR85WrUEO0SVfNORquTRBGKh0pDZiaTCf3Dwn89YTNayFTmIaIetAR7mQnd7qX3qvw69viSV5yRhMxywu1jhvXMhsVsQqsngNrW9Hv5opE0g6ixsdEQMV4GI934NPQFM5tN9H0tLna1Fg1qSENmSgaRtIKtnt5gTuohkr5OjIiCLBvVLGnVEBH9UI7dqtq8trdIWK2n1Ygwbu2VquUeomS27gAEDdH+ZrdmYb0csaGjdF1kG6hSNWndQQoF5mrUEEk8REmo7J0obVF0biRspkdYHTtkpsNDFKWXmVxDJDeSk9m+o0PmMXVYLRgS9phVGlxHFJdBVFtbixtvvBGbNm2C1+vFhRdeiKOOOgozZsxAZWVlssfIYGQUQp+t6A9I2n1dg8hXafUXDbHHwBklZCZv7qopZCbqdi9eBDUqTO7aPUTKjV3F9BEJqwUPkXb3u9OqbtTIIanQWjREtLu3jpBZz1wHnDYzQpx+IS6BjMVuNSuGZskDqcMAHiKSeWm1SDVE7TE0RDvrBePCEAaRiqgaEAmrm7SfT6W2Hfz+tYUUxQhe5NghM7lBlMxMM7mGCBCE1UZv4RGXQbRgwQI0NjYiPz8fb7/9NrZs2YLXXnsNM2bMwD333JPsMTIYGYUQMov+sNbT4NUTiJzsouHSKqoOh73i6XYPSBulNoRT7iUGkVU9y0WMWmNXMb3z+AdOTas7LlE1OSZamrs20t/CP/iIUakoqqYrYu0eIpPJJBJWx6cjIp4ppXCZeDxuA3mIIrPMoj/wd0tCZok3w02U1ijXqZB6n3jIjKTdd/iCVJAeCxIKFmuB1Bosy0NmyfQQdXojPaZEWL3Z4MLquETVP/74I95++2306dMHK1aswB/+8AdMmDABhYWFOPXUU5M9RgYjo6DGRYyHtZ5aREru8GhIQmZRNETe8Fi16J6U9uf2B5HDPwdoyEwsECXfE4gRMiMPGqUMMwLxEO1v9qBXOOtMj4aIGJMeDSHKprCHiJQPoB4iBa1FPGn3AF/Mb0tte9yeD0+UlHtAELV2GElUHc4yo6LqKB6iUIiTlCUwgoeIZH3luSI9RDRkpkdDJCtTQRAbXO3eAPJjVHkH1DxEys1d5WHUZBlEHMfRkJmSh2hz7UEYMnM4HPB6vWhpacHq1atx7LHHAgD27duHHj20VV1lMA5WvBqNC1JATY+GSO3hJ0esG1L6DE3HpaJqTvJ6NCxmEzXmxK526v6PI2RGNUQKoQiCWEOUiKhaS92VxrCGqCDsIYrmbaEaIo3nhkBrEcUpFo6WYQYYS0MUDEk9kFpE1dWt/Hkm4cD6dl/MEFuqUSvMCEAQVSchZGazmOl9q1VHRLPMFAozRoTMZAaQUn2tePD4QyBVRLJEBtHEgQXItltitu9JN3F5iI477jjccMMNcDqd6NGjB4499lh89NFHuP/++3HGGWcke4wMRkahNSWcTFaaQmY60+7NZhNcNgvc/qDiZ+QrRz0eIoA3sryBEJo7/RhQxL+mJBCNVilXTLtKOrMYQUPkjktULYTMtHiIlEXVpGaLOHWYeIiyo3i3lCAGUbyej2g1iACDZZnRtPuwhshBsqjUH/ZEUD2oKAuNHT40d/qxt7ETY/rkqX4m1ail3QOChqim1YNAMER/azSoVzU70lDIc1nh9gc1Vav2i9LoxYshm0pSg7wUQ7I8RGKDVbxAKMl14Pt5f9B1v6aDuDVE559/Pg499FAsW7aMNmq96qqrcNNNNyV7jAxGRkG8LjFDZiTrSYOHiDzEHTq8EMSroeRBcMi0BUJmnLYpobQf/1B6ZfUe+pq8bQe/P211iIR05igaorBB1OoJoDncM01fyExb2n0oxEXWIbILhTQjM3b4sesPmSXWvkPwGiofA1K+wAgGERVVm6UeIrdfXSOzM2wQDSnKxqAkFbJMFKEwY6QnsyTHAbvFjGCIQ02rJ+a++D5myllmgCDc1mIQiY18cY0zeb0xQqpCZp0iPZ08W7SHy6Y55J8u4vIQWa1WXHzxxfRvr9eLoUOHYsiQIYYuusRgdAVk8nHECpnp0BDprVQNCAaAUsE11TpEVm3377UzhuPbbQ1485cqXH3scAwuzo5o2yH+Hq1p99E8RLlOG3IdVrR5A9SrossgEh3vYIhTLZrZ4vZTt788ywzga7aIj2k8laoBcXHGzrgK1nlihcwcxgmZBWRe0xwNGhkioh5UlI0shxXr9rUkVMgyGUQLmZnNJvTNd2JXQyf2NblpCE0NtT5mBFINW0vIjHiQTSZ56w4VUbU8ZKYh0UAL5D7W6y01CnF5iLZt24Zzzz0Xv/zyC1pbWzFr1iyce+65OOaYY/Djjz8me4wZzX9W7cJXu+NLq2VkJoKoOlaWmfZWEtGaeKpBHtBRCzOGH1R+GjLTtv/JgwpQ3tuOYIjDE19sBaAcMtPaukMQVatriADBS7Q3bBDFk2UGRPfKEf1QrtNKj5PNYqbeDfHDxCeqsE0awGqlf0EWzCZ+f3Vt+gvWxcoycxkk7Z7jONqehlSqtlnMNJSrFjYjKfdDirMM4SHyB0P03Cul3QNCppkWHZFaHzOCnuKM1INsNUsMa1UNUYqyzGj4WOfiwCjEZRAtXLgQAwYMwODBg/Hmm2+ira0N3333Ha666irFNhzdlRa3H/d+VIln17SwopXdCK16HPIw11aHSF/aPSAKmUUxiCJCZho9RABw/jg+c+SdiipsO9CmKBDVrCHS4CECRE1ewyGJeOoQAdFXxHL9EEGpFpFYoK03ZGa3mqk3LZ4+XbGKdZKHki8Q0py6nQrEvfpsZuH6zYmhIyJVqgcXZ2NggnqrZCAWgKtdp/3z+XFqSb1vUBFUE4SO97E9RF7a2FV6Lail3UfUIUqS0dwtPUTr16/HDTfcgMLCQqxYsQLHH388iouLceqpp2LHjh3JHmPGQlzy/lDyXJIM46NVjyPueB+LeEJmLuohitbcNQSO4+LqDTa80Ibjx/QExwEPf7qF6noKlTRESSjMCAjCarK+0CPSNJtN9AERbUWsVj2Y1iISPTw6/fwDwCratx7IgzWe1PhYmYdiA02eVdSViEsuWEQGLAkJKWWOBUMc1VYNNoiGiBhuTptZ9T6hHqLm2OMkNYjkKfcEPcUZ1ZIuhOQJaRFVebZk0jxEXuIh6kYGUW5uLurr61FdXY2Kigqadr9p0yYUFRUlc3wZjXiiSueExOhaNIuqNRZm5DiOCoH1iBJJpWKlz4hXjmJ9j96H+o3HjYDJBHzyWw0AXsMgTq2lnqhADA2RBlE1APTu4ZL8rceAAwQdUbRMM+ohyortIYq3BhGB1Gpp92qvSEzwxPhuuyjMl84Gr0RQDQiiaiB6g9fqFr74pt1iRt98F+39VtXsTpu3qzVKlWpCfx3FGQ+0KRdlJOhp3+ENKHsLxXOQeFGSqpBZB/UQdaOQ2Zlnnomrr74a5513Hvr374+pU6fif//7H26++WbMnj072WPMWMT1WoxQLZbRNWgXVWvTEPmDHE2p1VqHCABmjO6J4hwHDhtSGPGeeOUo9lBpTbsnjOqdi1NK+9C/8102iVhZb3PXaA8bQPAQyfevFdq1PkqIQKhBpGwQeRRCZvGuiMmDoz0FHiKTyUTDph1pnH/EHiLx+cqN4iHaFdYPDSh0wWI2oWeuA3Yrn8G1vzl2BlcqiCaoJpDijFrasWyq5osUjuiZo/i+0PFeh4dIHjITHW/xwodct2Qe0FKbSwvyTveZRlyjvummm1BaWoqqqiqceuqpsFgs6Nu3Lx599FFMnz492WPMaLLsfL0WNwuZdRs01yHS6CESV1Z26NAQXXj4IFwwZaBi9pJ45SheLeo1MADghuNG4qMN1QhxkWEmtUq5coTCjNo0RAS9Hi3ahy2aqLpdRUOkFDKLo7GrGKKjidX1XYlYhRn5cVnR6gkk7YEXD8SjYzJBYiwT75iSRobqh8KeIbOZb3Wy7UA7djd2UE1RVxKtjxmBhMz2N7sRCnGqjYoBYON+3iA6pJ9yMeN4RNWRITORQRQIAeHoHLluC7LsONDmTVovM7LfnO4UMgOA448/HsceeyzWrVuHzz//HP369WPGkAJaVqSMgwtaRTlmlpk2DRGZrOQptVpQS+UWrxyJm9tiNqmmokdjeM8cnFHeH4C0bQeg3m1bTrSCd2IS9hDRBq/q42nsjC6q7pSEzOKrQUTICXuIOuKowEzaiETzGmYlsP9k4Q97N8WCakDU4FXJIKoXBNWEdOuIhBpE0frtOWExm+APcjQkpoQ/GKIeolIVg0gt7f4/q3ZixsNf0UxLQLie5XXKxPe0eFFCrmFyjSfLICILm6wMDZnFZca1trZi3rx5+PLLL5GXl4dgMIiOjg4ceuiheOqpp5Cbm5vscWYsWUkqnx8KcfAFQ4YvbMUQHv6xUthpYcYY3kPyvjylNhHEhkSnzH0eD7eeOAod3gDOntRf8XuieYg4jhOyzGK42vvINERa6yYRyAo62gJFVUNEKl0n00OkoaeXGrHqEAHGKM5IPERW2fUVrcGr4CESPEHpzjTTYrRbLWb0znOiqtmNqubOCI8mYWttO3yBEHKdVlqxXA7RELWJ9GUcx+G5r3egptWDjzZU48ppwwBI0+7l2CwmBEOcxBNNJBwkwy15ourYPQmNTFweonvvvRc1NTVYvnw5Vq9ejTVr1uCDDz5AZ2cnFi1alOwxZjSuJHmIrn51LQ67bwXNTGAYF79mD1E4LTqG90RvHzMtiFeOxBiJJ1xG6JnnxLMXTcJxY3tJXqfi7Sii6k5fkBZCjKUhynNaJcaH1rpJBKFadTQNEf8AUtMQKYuq49UQkSyz+ENm0RZJRmjfITR2ld4P0bLMdpEMMwUPUbyVvRNFqKYe/RrVIqzeWNUCABjXN091kUM1RCIP0fa6dloF+/dqoVGqUh8zglLpC3I9kAy3ZEk62mmn+25kEH355ZdYsGABhg4dSl8bPnw47rzzTnzxxRdJG9zBAPUQJWiBf7+9Aa2eANaHbySGcfFrFlVr8xB5NDz44oF4hMjDWK+gWs93RPMQkQeNxWyKWWfJZDJJVt16vVrUIIoWMusg6dCytHvFOkThEEGc54Z4xOLSEMUozAgItYjSKqqmjV2l51bIMpOOTZ5yTyCZZrvT5SHSWCurnxaDaD8/j6uFy/jvidQQfbOlnv7/t/2CQRRtjhAySiNF1STDLVl1iDppp/vMjGTE3e3ebI78qMlkQjDItDJilISYevH4g3TS0JLOyUgvWusQ2TVriPSn3GuBjI9UMo6njo7W74jmBSMp57lOq6aQoFhHpFtUrWDUyGnqiKynBAAue2S4LdGQGfEQtcdhsGjxHJJsn840aoiExq7Scys88KVjk6fcEwZQD1FHWgrdahFVA0B/DZlmG8ILWzVBNSBKu/cE6O/9bptgEO2oa6fXIvF4OhVDZpHVqgUPUXJDZlRD1J08RDNmzMDChQuxZ4/Q2HHXrl245557MG3atKQN7mAgKwkua3FZ/31N6W1uyIiNLxweil2HSFvafTR9QCKQ/XUkIWSmhhYNkdC2Q9sk2jtPeEjqT7snXjnl+9EbCNJJXa0OkUchZBaviDQnAQ+RFg1RloIQvKsh594qW0SraYjkKfeEAYUumEy8AU+KZ2qludOHRz/bjOv/92vcITdynZJQlhqkh5na4jUgElRHNYjC3xMMcej0BeELhPDjjgYAfPgxxAGVNfx+oi2alBq8Ek9OQZINItq6I0M1RHGN+uabb8bcuXMxc+ZM9OjBn9CWlhYcc8wx+Mc//pHUAWY6WlaksRCX9WceIuNDG6UmqbmrlvTqeKAeImoQJb8xs6BfUF/Rt+s0iBLxEMXK+iTVti1mU0RoRLF1B23sGt8DQCjMmBoNUTb1EKVRVE2yzCI8RMq/fWdYUD1EpB8C+AVEnzwn9rd4sLuhE8U5yhWexbR6/Hjh251Y+t1OGvL6svIAFpw2DmdN7KcrSUFrrSyhn5my4bW9rgMefwg5DiuGFGUrbgPw15vFzAui2zwB7GroQKcviKJsO8b2zcO3W+vx2/5WlA8soAa+UshZaVFCrp1iYhAlqw5Rhhdm1HwX79+/X/L34sWL0dbWhm+++QZOpxNTp06Fw+FAZ2cn8vPzkz3OjCUrCVkeB1ozwyAKhTMZkv3gzjR8WitV27SFzGhqd6pCZl4SMkv+eSPCci0aorwYDxqCWEOkV/cUS1RNGm4WZNkjasgotu5I8NzkOBMQVWvQEBmpMKNVdq5yVTREu+uFLvdyBhZlYX+LB3sbOzFpUEGU7wzhX9/uwHNf70CLmzdyR/fORbbDirW7m/D3N9bhy8pa3H9GKfKzlCtFy2l1aysN0b9ACJlxHBdhdJFw2di+eVHrFJlMJuQ5rWjq9KPV48d3W/lw2dQRxejTw4Vvt9ZTYbXgRY7SyDk8L4mr05OQmZb2QVog19lB7yGaMWOGojVNYpsmk4me/E2bNiVvhBlOMjREYg+R2qrDCPzlpTX4aVcjvrl5ekSGTndC8BBFX32Sh3mskBnp+j2gILnF6Kio2kdE1cn3ECnpF+QQDVGsoowEsYcoltEpJ5aoujlcgyg/K9I4y1LKMqNZNYmFzNQanEZDW2HG9NdBI6JqeZYZMURqWj3Y3dBBDSBxU1c5gwqz8eOOxpi1iO5dvgkvfr8LAF8n68bjRuKkQ3qDA/Ds19vx2Odb8NGGGvyyuxnPXjQJZQPyY/4O7bWy+NCexx9CQ4cvwpNFMsyiCaoJuU4bmjr9aPP48W1YPzR1eDG9jomwWsgyU+pbKF2UiBfnNO0+aR6izO5lpnnULHssPmgMP0kaovp2H9y+oOG8MBzH4fvtDXD7g9hS24YpQ7tvTztahyimhyisIYqRZba9rh0AMKynuns9HohHqCs0ROKO53K0tEQQI65FpD/LLHpzVyIwVwrf0TpEShqiBA2ieDw4Hi2iajvZf/qbu8qvr6HF2ThscCF+2tWI61+rwJtXHQGbxYydYQ+RUjiJ1CLa3dih+n3vVVRRY+i+Mw7B+YcOlGiR5k4fjqNHFOOG1yqwo74DC97/De/OPSrm79DqybRbzeiZ60Btqxf7mtyqBtEh/fJififREe1tdGP9vmYAwNEjSqhnsrK6FYFgSGOWGT/PEOPHYjbR3+L2BxW9WXrJ9JCZ5hmwX79+mv8xBKiHKBENkaziqZZOyl1NqztAf6NSKf7uBA2ZadUQxahDtP0AbxANV+l5FC92edp9CrLMlGqgyGlLQEPk0FmHSEkYLYY8aJQMHKfC4qaTemni1BARHY0ok0gL4rBH1LR7B/EQpbFStUphRpPJhMfOL0Oe04p1e5vx2OdbEAxx2NvIywKUChaS19SE0Vtq23DbWxsAANdOH44LpgxSrL4+vn8+nr5wIgBQAywWegx3IqyukkkcgiGOenU0eYjCNY8+2VgDjuP7nvXu4cTgomzaFmpnfYdqpWpAnOnJXy+dolIRJAwc4mLPQ7EIBEPUU5WpHqLkz4AMCcnOMgOAvQbUEVW3CmMiMfvuil5RdbT4fTDEYUd4wh5WklyDiEyUpJhaKj1E0UNm2sSqhPwsG84o74dTSvvEzPiR44zhlXNH8fgoiqqJZiLBtPuArJJwLMQGndOuft6IodZhBFG1QqmWfvkuPHDWeADAM19vx1u/7FNMuScMJO07FGoRtXsDuOqVtXD7gzhqeBFuPH5k1HGRRqwtbn9MUbs/GKLnXct1KjR5lY5zR1073P4gsuwWDCmOfT+T63vl5gMAeP0QwPd2G9OH9zD9Xt2qK+1eKCZqkRjTHl9iBpHYC5mpGiJmEKUYQUMU/wqtro2vTEoesEYUVleLOlB3d4OI1iGK4XGxayjMWNXkhi/APyD6J11DxH8/WTGmxiDSIqrWps0gmEwmPHZeGZ66YKJuF7/WkJlS1li05q7xhrDFK2k9mWZk/GZTdMM7my7IjOchIpxc2gfnTR4AjgNuf4f37shT7gmDCvkwWl2bV/KbOI7DrW+ux466DvTp4cQT55fH7MuX67TRatnVMbrTi8siaLlOieH2w/YGyeukIOPYPnma+gaSkBYxlo8OG0RkHwCvI9IVMvMLRr/NYqbarkRT78XZqqnwNncFmTnqDCIZdUCIh2hcOOZsxFpE1S2CQdTazQ0i0qYitocodh0ioh8aUpwdV+PVaJBJixgBya5zBAhGYdS0+y7sf+SMETJzRwmZKYXb3FEMKC1YzCYhE0yHQeQRNXaNZhQmI8s1UdSyzMTcddpYDC3OpteJPOWe0CPLhh4u3kggoTVfIIR/frEVyzdUw2Yx4akLJkY0GVajr4YiioAQLnPazJoWDrPK+8FiNmHl5jp8LyqmuGFf7PpDYsTeKJvFhClDBG3muL7EIGqJXodIFraWt5tJRmkYfr+ZnWEGMIMo5QgNIeNzR3IcR7PMygfwaaZG9BDVtLCQGcGvVVStIWS2LUX6IaCr6xDF1hBp9RAlQiyDKJqHSKl1R6KiaiC+TDOttamSEbJPFNq6I4pBn2W34ok/ldNrcHCU+jxER/R7dQue/2YHpj20Eo+v2AoAuOOUsZg4UD0dX04/jQZRq8Yq1YThPXNw4ZSBAIB7lm9CMBw21JNhBkiLQE4cWCAxNsb15ffxu8hDpNbcFRBCZnKj36mQLBAP7RmeYQYwgyjluKiHKD6XdYvbT1dNZQPzARjTINov9hApdK/uTni1iqptQmxfTVBLM8xKkpthBgid4tNdqVqvqDoRhNVwHBoihZAZyQ5LJOszJ44Gr1qKMgKCqDqddYjI/BXLw3lIvx64d9Yh6NvDiZNK+6huR8JRN76+Dvd9tAnVLR6U5Dpw56ljMfuIQbrGRjxE+zV6iPQY7TccNxJ5Tis2VbfizbV7EQpx+I30MOuv30MkDpcBwIheObCYTWjq9GNvWFOlpVK13IhPmofIq+5dzRQy15TLEBKtQ0TCZflZNgwNu5GNWIuohoXMKOThH8vjQjKkQhwvPFXaXki5T72HKDW9zKSrUyW09ohKBoKoWsVDRCZ1hbRhl0INo2gGlFZyonR9V0NLUUZ+XImHzDiOC1+f8V0fAY29/QDgvEMH4rxDB0bdRpxcMLQkG1ceMxSzyvspFiWMhWAQeaJuF881WpBtx/V/GIF7l2/CQ59uwZg+eejwBeG0melcHos8kQF29IgSyXtOmwUjeuagsqaNejajVqoOkCwz6bVDr+sEvYjt3swPmWXuyDOERF3WxCAqyXHQwnxGrEW0n4XMKGQlFkuT4xBNXt5ASPGBsb0uNRlmgBDOIpNpaj1EsTVEXRMyiy6qJlo/pe715F72BUMIBEPUkOW3j3/s8bTvcPu1eabomAMh+IPK11gsLn3xZ1TWtGHFTdPietiRY6QmqtbLJUcNhjcQwqRBBfjD6J5Rqz3Hol+BPg1Rns5rdPYRg/HKj7uxq6ETf39jHQBeDB1NTyUmL6yX6uGyKeqOxvbJQ2VNG/1byUMk99LKjfhY94RWhD5mxnku6SWtITOv14v58+dj8uTJmDp1KpYuXaq67fvvv48TTjgB48ePx/nnn4/169dL3v/www9x3HHHYcKECZg7dy4aGxtTPXxNJOqOPEAMolwH8lxW5IYnJCPVIuI4TuYh6t51iPwaQ2Zi0bWSx6Kxw4fGcBPLoSkImRHBM9E3pKQOkTV2yKy9CzVEMesQUQ+RuoYIADyBkMTrm8jiJDseg8inLqIVI9ZCxbMo4zgO322rR3WLB1vDeja9EGNY3tw1XvKz7LjtpNE4fmyvhIwhAOiXz9e0ih0y05cJSbBbzZh38hgAwJZa/vhp1Q8BwKGDC3FIvzxcfewwxZDj2L7S4o5OBS+ZWsiMiKqVtHHxQD1ETEMUHw8++CA2btyIZcuW4a677sKSJUvwySefRGy3Zs0a3H777bjmmmuwfPlylJeX4y9/+Qs6OvjV8/r163H77bfj2muvxeuvv47W1lbMmzevq3+OIsQK9we5qA8FNepEBpHJZKIrGiPVImr1BCSTbXf3EPlVKvPKMZtN1ChSKopGwmX98l1xZzFFQ54FlwpRtbhSdUihWnUwxEWtDp1sYrXuiCaSdljNIAldbl+Q6gITTTPOjaPjPRVVxzCI7FZRWnUcBlGHL0iv59rW6GElNQIaQ8jpgITMalo8dGGgBNUQOfSHdWeO7YXDhxbSv8fpMIgKs+348LqjcdW0YYrvE2E1Qbl1h6wOkV+q9UlGeymAZZklRGdnJ9544w3cfvvtGDduHI4//nhcfvnlePXVVyO2raurwzXXXIPTTz8dAwYMwNy5c9Hc3Izt27cDAF555RWcdNJJmDVrFkaPHo0HH3wQX3/9Nfbu3dvVPysCV4IrNJJhVhJOIyW1aIwkrK5ukY6lOxtEHMdpbt0BiDLNFB7QpEJ1KrxDQOQDyq6z6rPe7/CHIn+j2CuitZdZIjhE4QElITt1+ysYoCaTSfD4+oIRWox4yU5AVK3luxNp8Ep6uwHAgTgNIn+SQ2bJpGeuExazCYEQF1EAV0xbAmFdk8mEf5w6lhrT4zUKqrVAahERojV3VQuZxfKaaoVmmbGQmX4qKysRCARQXl5OX5s0aRLWrVuHkGziPOmkk3D11VcDADweD1588UUUFRVh2DDeal63bh0mT55Mt+/Tpw/69u2LdevWdcEviY7dYoJZtKrUC7lJe+YRg4hf0RipFhGpQURSWN3+YFQR7cGMWCujRa9BizMqHK9UptyLv5tAOtMnE/ExUNIRkVCE3WqOSxSrF7EBoXTMO2NkjYlD4InWICIQQ7BNVx0i7QUhicHVGUe16uZOYXFT26puMESDeIiSFTJLJhazCb3z+LBZNB0RuU6Jpkcv4/r2wMNnT8C8k0ZjdO/YPcy00iPLRp8JgFSXSCD3NZmTSdVyV4RBlNic3XkQhMzSNvK6ujoUFBTAbhe6ohcXF8Pr9aK5uRmFhYURn/nhhx9w6aWXguM4PPzww8jO5lfOBw4cQM+ePSXbFhUVoaamJrU/QgMmkwlOiwmdAS6uarHikBkgNoiM4yEi+qERvXLopNLq8Uc0NewOiMOiWgodRqtFJKTcp8YgkhtssQpJJvod/kAIkF0SVFDdRW52sebG6w9FaHDcUTxE4s+7/UGq+0o0zTiVafeA8OCLZ/6RGkRxhsxI6w4DeogAfiFX1ezG/mY3yvorGyutSdC5nTWpf9yfjca4vnnY1+SGyaQ858hrgRFBPkkcIHWIEq5UfRCEzNI2crfbLTGGANC/fT6f0kcwYsQIvP3221i5ciVuu+029O/fH2VlZfB4PIr7UtuPGsFg8ouXBYNBOKy8QdTu8ev+jgPhth1FWTYEg0H0DTe23NfYmZLxxgMpA9C3hxM5DivavQE0d3hRoLPPVKKQ46HnuPiDISz7YTeOHl6MUb1zEx6D2yc8QMzgYo6FeGncvkDEtrRKdZErJedaPndazdqPnZ5jbTbxpQU8Pj+CTukDvCUsGs9xWrvkejYDsIZDJO0eH3Ic0oMgVO1W/m2u8Aq8w+OjK2qXzZLQ2LPC+2xTmR+UjnWn1x/+blPM7yYPPrX9R6OhXTCCalrccf1OX9jYt5hSM8cmSp8evJW+r6lT9bompUSy7Ymd61QwpncuPv2tFg6rOSK6Agj3uS8QQjAYpIa302pGMBiEM+xB6vTqvz7EEA2cy2bWtJ945uto+0kGaTOIHA5HhMFC/nY6nUofQXFxMYqLizFmzBisW7cOr732GsrKylT35XJFNgeMxoYNG3RtrxVH+IJb/3sl/AfsMbaWUt3EC8cbqnaion0fOpr4G3NXXRsqKiqSOs54+X0nX2wMnU1wWkJoB/Dzut/QUqTvtyYLPefxo60deKGiDR+U7MTCYyO9knppcod7TAHYsD52yDYU4K/b3yu3wNokuE+8QaHrt+fALlS0Jl8PV1cj7fJds78KFRVNuvah5VhbTYCPAyo2/Iae2VKDaF017wG1BH1ddj3bzEAgBPy6YSP65EinwI6wobFz62a0VUV6X7gAP97fNm+j3cNDfndCY2+o5c9zdV1T1P2Ij/WecMf0lsb6mN/N+fn9/75lGwrcVbrGtnG7EJrffaAlrt9ZU8uPtb7uACoqjOPZJli8fNr6uq17sSGXn8vk13VtA/96ffVeVFTUde0AY+D08Ear1cQpnp+a/fw5rGvkr6+6Rv63HKjei4qKejQ38L9/z/7ahM5PdR0/dzTW7kdFRbPmz6XquRsPaTOIevXqhaamJgQCAVit/DDq6urgdDqRlyd1W65fvx4WiwXjxo2jrw0bNoyKqnv16oX6+nrJZ+rr61FSIi1kFYvS0lJYkiwsDQaDcH62EgDQb9AQlI3QPiZfIIS2Nz4DAEydPAGF2XYMcfuBFV+gxRvCqLGlhqhF5P3lZwBulI8egl/rd6G+sw29BgxB2Uh9xz9RgsEgNmzYoOs83vnd9wCAGjdQVlaW8Bj2NXUCH9bBbjNr2l+P778HWloxYNAQlI0Wwr6VNW3gUIs8pxXTpuhvYqqF9e7dwPpN9O+hgwehrKyfps/qOdb291fA5w1gxKjRET2q9pj2A2hCz8K8pBx/LWR99CXcAR+GDh8l8Qr6gyEE3uDD7IeWj6c9s8QU/rwa25ua0HfAoLCouhklBT0SGnutrRb4+VeYHFmK+1E61jk7NwLoxOD+fVFWppyBRChZtxaoq0OvvgNQVqYvbPNd03YAvEHT6jfF9Tvzd20Etneif98+KCsbrvvzqeZ33x68Xfk7/LZslJaWKl7Xwa++BeDH+DEjUDa0SH1naWDIKD/+ve5blPXPVzw/20NVwNoNcGXnoqysDOZV3wPwY8yIYSgb3ROrmrYDlVuRk1+IsrJD4h6HZc1PALwYNXwIysarVxonxDNfR9tPMkibQTRmzBhYrVZUVFRQQfTatWtRWloKs0x89+abb6KqqgovvPACfe23337D2LFjAQATJkzA2rVrceaZZwIAqqurUV1djQkTJugak8ViSbpBBAgeIm+A07X/5nbee2A1m1CU44TZbEJBthm5DivavAHUtHkxvGfiYZ5EqWklouos9MjiHyLtvlBKjqUWtJ7H3/e34rfq8Oq13YdOfyjhaslBjj/XNotZ0xiIBsQfgmT7nQ38qm5Yzxy6YEg2DlkxQafdqvucaTnWdqsZ8AIhmCK27QyHnXKdti67Xlx2C9DBe+HE39ku6jeY47TDoqCpIgJqb4Cjouxsh/7jJibPxXtSO73BqPsRH2vy3VmO2MctO6x7cfv135OtolIAzW4//CFtuiUxRFZnt6Vmfk2U/oW8kb6/xUvHJ7+uSdp9fpbDcL+hMMeCH+b9ARaTSbEukzN8zQZC/PVOtELZ4XuO1NzyBhKbs8l+81z67uVUPXfjIW0GkcvlwqxZs7BgwQLcf//9OHDgAJYuXYpFixYB4L1Fubm5cDqdOO+883Duuedi2bJlmDZtGt5//32sX78eDz74IADgT3/6Ey666CKUlZWhtLQU9913H4499lgMGDAgXT9PAo3R6swyEwuqyYVOahFV1rRhb5M77QYRx3E0y6xPvgt5YYMiE1Lv31y7T/L37oZOzV2o1SCZVFoFymod77cf4MNZw1MkqAaU0u5TI3qN1r6DFmXsQiGmWi0iIjqOVldInGXWqSPTKxqpbN0B8LoXQKjCrYemTqkUoa7NiwHhXmJaoaJqA2aZAUJ2bLTijF3ZgDgeomW0kvs6Mu0+3O0+Sh0ijz+I137ag6ZOP8wmEyxm/hk0qCgLp47vK9m2nfYyM+Yx0kJaRz5v3jwsWLAAc+bMQU5ODq677jrMnDkTADB16lQsWrQIZ555JsaNG4clS5bg0UcfxSOPPIIRI0bghRdeQK9evQAA5eXluPvuu/HEE0+gpaUFRx11FO655550/jQJDkviBpGY/gVZqKxpM0SmmbgoY+88Jw0zGL2fmS8QwrsVvJ7CaTPD4w9hZ31HwgYReehrLdRHskLkxsK2FPYwI0Sk3acgy0y8X6XCpOl40JDidfK6K1rqCpGHh8cfpALsZGWZ6WvdQYyx2OeM9jOLI+2+pVN6H9e0enQbROS8G7EOEQD0CSeqtLj9iufAHwzR490V/faSjS2iMKNKHSKFBcvHG6ux4IPfFfc7sDAL4/vn07/J9dUVBVZTRVpH7nK5sHjxYixevDjivc2bN0v+nj59OqZPn666rzPPPJOGzIwG8RDpLXx1oE1alJFgpFpEJOU+P8sGl92SMQbRys0H0NjhQ89cB44aXox3fq3CrvqO2B+MgU9HI0tAXIdIlmF2ILUp90CkFysVrTvE3xNQqARMHkBdUZSRoFaIrpMWllMfi1NUmNHtS86KWGwQcRynSS/m6aLCjHIPUTyp9wHSuiNFBnei5DptyHNa0eoJUG+3GHEFcaN6iKIhtO7Q39yVNL0d0TMHkwcXguM4fLu1HlXNbvy2v1ViEHUcBN3ujXmFHmTYk+4hMk4tIlKluk8PfkykcJnRQ2ZvrOHDZWdM7Idh4UrQOxsSN4j8OqpUA+I6RMLqLBTisKOeGESpqVINRBptKfcQKaxAW7uw0z2BhswCcg9R7Iap5OHR6U9epWpiDAZDnObieHrqEBEDL57CsM3h+5jMQfEUZwyEU8FtCfYdSyV9o4TNiBfTaTOn7B5JJWIPbTDEUU+R0NxVvQ5RU7gsxozRPbHozFI8cNZ4zBzHR2a2i3rbcRxHDe5M9hBl3tnNQJKhIRJjpPYdVD8UdjtTD5HHuAZRXZsXKzcfAACcPbE/Boczn5LiIdLY2JWgpCGqanbD4w/BZjFhoM7whB5sXRUyI5VyFUJmZPXdlZMoOeZun1xDFL0oIyCEqHgPUXJCZlkio0Zr2EyPhohs0xGPQRQOmY0OZ+PF077Db3APESDWEUX+vnQY7clEHDITF+fM0tDctSl8/vOzhBIqpHI+CesDvB6POICVGiNnCsa9Qg8iSJaZW6fLOpaHqMoAITNiEPWWGURG9hC9V1GFYIjDhAH5GNErF4OLwgZRQ+LHk3qINOolSKl9sUFECjIOLspO6UMkUlSdag1RZMiMZrx0Yf8jsQ5IjBaRtDjcRhvBJvgAMJtNunVEtCikptYdYa+WDo0SwHsqSS+zUb14gyiukBnxEBlUQwSIPEQt6h6iTAyXAYIX2h8MUUPaZBK0dNFE1S1u/vwXZAnGIAnjbxN5iMTh2KwEPabphBlEXYAz3pBZuLFrT5lBNCDsIapv9yXcoThRasITCKmgnReuTm1Ug4jjOJpddk64lD7xEDV2+BIed/whM+E8bq/jPVWp1A+Jv5uQKg1RNFF1ssJOenCGf6c8ZEZbD0QxMsSraSpOTcLYidGitX2HvuauYVG1zrmizRugq/6RvYlBpD9kRj1EBs0yA8Qhs0iDr+0g8RD5gyHJ/Ua0atGauwoeIuG3Ew9RVbObPn/E+iGl1P9MwbhX6EEE8RDpTXtV8xDluaw0TbmqOb1eIsFDxE8ogqhav4CzK/htfysqa9pgt5rxx3DaaI7DSo9xomEzr86QmV2h232qm7oSIjVEqZnI5L2UxAhemS4UVduVRaRamrWKV9OCqDpxg4h4iNo8+kJmWjREWXH2MiPeoSy7hS7C4hNVGzvLDAD6FcTWEOVlqIdIXPaiU+Ead0UNmfHXgDhkVpRtR36WDRwHqnXs0JCQkAkwg6gLEEJm2g0ijuNoH7OSHGkrE1KLCAD2pllHpKYhMqqH6I01fAuMmWN70SKSADCEhs0SM4jIalivhmjt7iY8+vkWPPr5Fny/na+6Pqxn6gTVQFeKqtXrEOnJlkoWTpU0Yy0hsyxRI0x51/BE0NPgleM4Udq9dg+RXg0R0Q/lu2zolUdE1fGEzIiHyMAGUT4/f+1XyDITPESZ+bCnGqJgSGjsKrpunHahDAXHScPapOxCgcggMplM1HtNvNlavKuZQGae4QxDCJlpX6G1ewNUJ1CcG9kTzAi1iDiOQ3UzyTILh8zCbuU2jx+hEGc49+mKTbyY+qyJ0hYGg4uz8NOuRuxM0EOktw4RMSA3VLVgQ1WL5L2RvVJbdFNuACl1yk7m9yhpiDqT6GXRCg2ZRWiIYk/q4vCC2x/bo6QVPcUZxXozTYUZHeoakWiIvQO98vj7u8MXRLs3oEsEnwmiahIyq2nxIMhJW0cJHqLMDJkJGiJO5CESrhtyDYU43mgiizSO42iWoThkBvAFY9fubqLebGLIZ7qHKLNHnyHE4yEi4bIch1VxwjVCLaI2b4CuOntTDRF/44Q4oN0XMNwkUh/WZcnDUURHtDtBYbUgqtY2+c8q74e6Nm+ER21YSTbG9slT+VRykBtAqcsy0xIy60KDSEVEqiV8J9EQpSBkpsUgEo9bT8hMbx2iFtHDMNthpS2Dals9yNGhbyMhMyOn3ffMdcJiNiEQ4tDskV6nbd7MFlWT+zoY4qjhIr7fxNeQxycYRK2eAIJh757cICLea5IAQkNmGVylGmAGUZcQT9o9MYjkgmqCEWoRkaKMPVw2SQqn3WqGLxBCS6ffUAaRxx+kq+seshuchMwS9RDpFVX3cNnw9xNGJfSd8RIRMktxYUYlgygtITOrWshMu4fI7QsqrrbjJVuPQRQ+ZnarGRYNRka8lapJDRoSLumZ50BbHW8Q6RH805CZgT1EFrMJvfOcqGp2o75TepwyXlQtuq+JkSu+Zm0WM6xhY9DtD6IHwrKHTmFbYiQRyIKS1CKiIbMuzBZNBca9Qg8i4mndQTLMilUMIuLirVWIeXcV+2XhMoJRaxGRycBiNkX0zhqUJA2RIKo27mqY0HVp98p1iPzBEA2ndGnIzBbLQxS7dYe0DlHi68pcHRoiPRlmgLBq9wVDikapGiRcQhYPJGymV0dk9NYdBFKLSG4QtWZ42r34via6MJessbOSsJqGTF2RhuDwEj6cv6O+Q+J5yuQaRAAziLoE4iFSUvGroZZhRqAizDSm3dfIBNUEowqryWSQ57RGtEcYXJxFt2mWtSvQg19n6450ElmYMVXNXUmlaqmGSHw/dGXIjBRXlLdL0ZIpQx4crZ4A9XwkY+zZOrLM9BRlBKTj07Moa6aCWrlBpC/1nrTuMGpzV0LfsLC6rlMWMqMGUYZ6iET3tZKHCFAOIytlmBH6FbhoJGBfUye9rnIyPGRm7Cv0IIGm3euI4av1MSPEm0qbTOQp9wSSnmq0fmaCJiLyBs+yW2kmTSJhM70hs3QiXjnaLCZNPbTiQa0OEZl8zabUeaeUoCEz2QJFKQMn4rNhI0Qc2kqKhkiHqNqjI8MM4K9FWxyJHc3UQyCEzAD9HiJSmNHoHqK+Kh6iTM8yM5lM9PyrGURKHiKybUF2pCFoMZswNKy73HagXeh0z0JmjFiQLDOPP4SQQoNLJWJ5iOIttpZMhD5mKiEzg9UiIhN8DwUXMABRxer4DSKaZZYJHiLRGFM5XruKqFpcEyVVxpgSTnvk5A8IHiItdYgINospKd5APWn3HTpqEBHimS/kRfl6hz1EB/R6iEKkFEVmGER1HXKDKLNDZoBwr5MwqPw6JgaRVxwy65AaxHKGER1RXTutgp7JfcwAZhB1CcRDBGgPm8U2iOIrx59M5DWICIYNmRFNhIpBNKSYCKvjzzTTW4conVjMJirKTZWgGlDXELnTkGEGiD1EyuOJ5vGRh6mSJQbXk2VGjCa5Di4awnyhI2Qm86jGqyEKZEClakAozhihIXKTUHtmhswAYVHSGitkJtEQKafcE4aLWni0a1hMZALGvkIPEsR9rfQaRGpZZnSCUyim1VUIBpEsZGZQUXWrSk0NQjKavHp11iFKN8RYSaUBRx6EESGzcIiqKzPMAKGHkzxk1qEhjV4+1mQ9APRkmZFtcnR4LOIJsROPqqAh4ueimm4mqj6YPERCyEz6W0htLsWQmYLEABB7iDrodZXDQmaMWJhNJjoJa61FRLLMVD1E4QmU46SF2rqSGlljV4JhPUSiyrtKJCNklkmiakAIlXVJyEwmqk5m2roe1Jq7askaM5tNkvpNydJMEG9PuwZRNdlGTxG8eEJmzTIPQc9cIWSmZxEmhMyMfU8QT3e7n6NGpz8YokZCpoqqAeH+JnNyhKczqqhai4eILCYy12gEmEHUZZAGkFompGCIQ0MMg0h8QWttCJlM2jx+ehNkTsgsuoZICJl1xO11yyRRNSCMM5XjJV4oNVG1Hi1MMlALmWk10MQhvmQZc9l6NERe/atxvcUZgyGOenjzs6Sial8wRI2lWHAcR4v7Gbl1B8AbPCQhhHi/xQZqJnuIyP3d3BldVO1RDJkpe4iGlmTDZOLn+T2NvMyAVapmaMJltwCdfk0u64YOL0Icn31TlK1sEFnCK1VvuGFfUbIHHAMyYeQ5rRE3AYm1Gy/LjD/2PVRu8EFFfOp9myeAxg4filQy/KIhiKqNPfkTyKo9lYJXcS8lMULri64OmUXqJUIhTvN4XDYLmhF+sNiSM4WS8FebnpCZjocPuUe1eoha3X6QNQFZQDisFhRm29HY4UNtmwcF2cr3kRhxuxYjF2Yk9M13obWmDVe8vBZZdiv1bjltZsN7uKJB7m9i5KqJqiUhM1nIVI7TZkH/Ahf2NrpphX9WmJGhCeJK1BIyI/qhwmxH1Eq0ZJLTU98oWajphwBBQ2Q4D1GMLDOnzYK+YW9XvGGzTAuZCQZRKj1E0dPuuzxkFp78gyGOjkl8D8Vy+4u9s8kShIsLM8byTrbH0TfKpTMJg4RLch1WybVBNI1aaxGRlHvA+FlmAFDaj2+Xs6fRjcqaNtqra0TP1PYVTDXkHJJLK0JDRENmwvmKJaoGhLAZgXmIGJpw6QiZxRJUy/eZjpDZpupWAECffGfEe3ku/rIymkFE6xCpGEQAL6ze3+LBzvpOTBpUqPs7fOEVMQuZib4jPBkHgsoaoq4OmTlswm/1+IOwWcw0lGQyCaJrNcTjTXbILMTxxlk0o6wjHg8RDZlpWzzJq1QTeuU5UVnTpjnTTOIhMniWGQAsPG0cSnPdGDxkKMxm4dyOH9AjjaNKHPn9rRoyCyhpiNQ9gcNKcrBycx39m/UyY2jCJcoKi0WslHtCvF2sE+XrLXV45LPNAIApQyKDdULrDmPVIWqJkWUG8AbR99sb4s4084UnFOYhEn2HVSXtPk0hM4fVDJOJXy27/UHkOm2Ct8pmiVkTSewVSpaHKMtuoWNq9waiGkTxhMz0eKgBcYaZ9GFIMs20tgwKBDPLQ+SwmjGuxI6y4cWwWDI7/CNGfn/Lr1t50k8gGKLZdWpZZkBkk2wWMmNoIou6JGMbCWT1FdNDZO/69h1rdzfiqpfXwh/kcMr4PrjimKER2xhWVN0ZvQ4RIGryGnfILDMyaghE65TKLLPYIbOuXZeZTCYqrPaGhdW0KKMGI8OVAg+RyWSibQ9iZZrFEzLTK6qWZ5gRaC2iNqlBxHGcYqiPaHAs5tRVQmfERn5/xxJVi+fuvChi8giDKMM9RJkxax8EUA+RBuOlqpmfbEjlVDWEzLWu8cRsqm7FJf/5GW5/ENNGluCxc8sUNU5EQ+QLhCJSm9NFSJQ1Iw8DiEm0FhERVTsyJGRGjJXUZpkRg8gYITP+O6W1iLS07RA+K2yTzAcAEVZ3xCieGE8dIiqq1liYUS3DSK2f2W1vbcCh931Bs2MJtAaRwTPMDnbk3jl5MoA80aBJ1Pcxmhh+2EGmIcqMWfsgQE/aPeki3y+GQdSVIbNd9R246IWf0OoJYPKgAjx74STVh2iO3Qoy/xkl06zNE4jImlFiSLjJ6+6GzrhS7zNXVJ26B5ZdzUOkwwhJNvKsGi1tOwhZKQiZAaIGr97o9wwZq76QmfaQPSBkGMn1dr1o+w7BQ7SxqgWvr9mL+nYvNlS1SLYPZJjH9GBFPldHZJnJ6hDRkGmMTMKCbDuKwtvYLKaM0U6qkdmjzyCUCl+pQQyiWB6irgqZdXgDmPOfn1Df7sWYPnl44eJDoz4IzGaT4TLNSA0il80Ch1V97AMKs2A28avw+nb9Xe99GVqHqCuyzHwBldYdafEQSWsR6SkSmYqQGSBq36ExZBaXQaQ5y0za6Z5ANUQiD9HTX22j/5d7hEmWWbRsWUbqkd/fsZq7NseoQSSGeIky3TsEMIOoy8jSGDLjOE5kEEVmcInJ1qFLSoSHPt2M3Q2d6JfvwkuXHhbVw0KgtYgM0r5Di6Aa4GutEEN0e1277u8hD/1MEJACXRUyUy7MSO6Fru5lBgAOmWaiU0PbDoJUVJ3EkBlJvY9xPxODKR5RtWYNEc0yUw6Z1bV7EQxx2HagHR9vrKHvy+c3QVOXGffDwYpcQ6TWk89DQ2bKHkIlSAuPTNcPAcwg6jIECzz6hNTqDlCPT2wPkb5U2nhYs6sRy37YBQBYdGZpzMw3gtGE1VoE1YTygQUAgDfW7NP9PZkWMrNbu0BUbVXWEKUrywwAXCSrhhpE2sciSbtPondLi4coKCogqWdFrje8Lu9jRijKtsNsEqrpP/PVdogjy/KaaJnS2PVgR7zgcdrMMMs8dqQOEfGYNqt4CJUgwup03MfJhl2lXYRWD1FV2DtUlG2PKTbN0hGGiwePP4hb31oPjgPOntQfx4ws0fxZwxlEMTrdi7ls6hAAwHsVVdRbpxXy0M80UXUqDThVDZEhQmZSD5GWVW7KQmZO0uBV/X4WN3/Vk+LssukLr6tlmVktZrooWru7Ce9WVAEAhpXwyQjyucgfyozGrgc74vtbSSdHsi5pyMwduwYRoWxAPgBebpDpZMasfRCgNctMq34IEDdsTE3I7Mkvt2J7XQdKch34xyljdX2WFGdsdRujFpHWkBnA3+CHDy1EIMThhe926voeIWSWGbeWvUuzzIwTMos0iLSPxWU3i/6fAg9RFFE1Kcpot5ijauHkEONJb6VqpQciCZst/qQSwRCHo0cU47AhfBFTuUHERNXGQHz8lRYgco2rlirVhEmDCvB/Vx6Bh8+ZkIyhphV2lXYRSs3zlNjfok0/BIhriyTfQ7SxqgXPfr0DAHDP6eOipqorYTQPkZA1E3vFAwBXTRsGAPjfT3to+EALRFRtyxQPUZeIqsOFGWWiag8NmXW99sAlE1WTB4GWMJT4gZJMISnVEEXxEHXEkXIPiBZPmrPM1Ku6k673u8L9q645djg1MOX7D7C0e0NAiqMCyl5N+fNJrTCnGocNKUShht52RiczZu2DAK0hs/0aaxABgns/2SEzfzCEW95cj2CIw8mlvXHiIX1078NoDV6phkijYTdtZAnG9MlDpy+Il37YrekzHMeJmrtmxq3VO7za752nv5GtVmLVIUpHyMwhq0NExMZaxiIOZSdz7DTtPoqGqI0WZdT3vUKWWey5wh8M0e9ReiD2El0rEwfy3lS18D0pzJgJjV0PZhySkJm6QRSZZaZvIZzpsKu0i9AbMotVg0i8z2T3Mnvtpz34vboVPVw2LDztkLj2YbS0+xYdGiKArxx81TS+CveL3+/SZHSSyR/IHIPoL0cPxYuXHIo/TRmYsu+wW9VCZmEjxAB1iHSl3Yu2SYWGKNr9TN7Tm9FDtvcFQxHnQQ65V0wm4T4WQ0JmAHDtjOEwmUzC8YwwiDIr6/JgRRIyU7hmnXYhyYDjONXCnAc7mTFrHwSQyqCxUuSJQaTURT5in3bppJ4sftjRAAC44pihmrPK5BgtZNasQ0NEOKW0DwYUutDY4cMba/fG3F78oMmUOkQuuwXHjuqpS4+iFzIZB0IcQiKjkYSr0qshCtch0tG6I0tiECUzZMbvtz2KQUQy0HJ1hszExzjWooyES/KcNsX6QYOKePHs6N65mD6qZ3j/4flNNhf5aZYZM4jSiTiEr2RME4OW4wBvIKSaZXiwkxmz9kGAflG1Fg0REVUn1yCqrG4DAIzvH3+H5zyXweoQ6Ui7J1gtZvzlaN5L9K9vdkgaVSoh1siwFbGA+FiQrKNAMET1VslMXdeKvHUH0b5oGYskZJZUUTV/bUY1iOLoYwbwBjo5D7GSMGIJak8u7YO7/jgWz8+eTPuTkQeqfC6iafcZ4jE9WLHH8hCJrmmvPyRKu2ceoi7D6/Vi/vz5mDx5MqZOnYqlS5eqbvvVV1/h9NNPR3l5Of74xz/iiy++kLw/efJkjBo1SvKvoyO+flSpQEuKfCAYQk24JL6WkJne6rNacPuCtLHp6N55ce9H8BAZLMtMo6iacM6kASjMtmNfkxvLN1RH3ZY84E0mVplXjNhdTzwGYvFtOkNm1CDSoc1JVdp9tgYPUUccVaoJWhdQsaoU2yxmXHLUEEmaNTkOapWq2QIhvYg9RErXrM1ipl68ZrePevr0JtNkOmktLfnggw9i48aNWLZsGfbv349bb70Vffv2xYknnijZrrKyEtdeey1uueUWTJs2Dd999x3++te/4s0338To0aNRW1uLtrY2rFixAk6n4FnJyjJOXQSXKAuD4zjFzs+1bV6EOH7yKM6JHaqiqbRJDJltrm0DxwHFOfa4w2WAYBAZRlRN62rou8FddgsuPnIwHv18C/75xVacMK63an0o8rC3W8yss7cIiUEUCAEOwBN+KJtM6anZpJ52ryHLLPxAsVvMSc3OyyUeoiii6njadhCy7Ra0uP0xhdV6qhQTaJaZzPvkZ4UZDYHdIs4yU752XDYL2rwBmthjNZuQexC049BD2q7Szs5OvPHGG7j99tsxbtw4HH/88bj88svx6quvRmz74Ycf4vDDD8fs2bMxaNAgXHDBBZgyZQo+/vhjAMD27dtRUlKCAQMGoKSkhP4z0kOJWOXBEEc9CXLE+iF5JVElyOSttYO1FiqrWwEk5h0C+C7JgHEMIr2iajFzjhiM4hwHdtR14L7lm1S3y7QMs67CYjbRZr9EZ0VFzDZLWu5Th1xDRAszxvb49Mx1wmYxoX9BbC+uHsgCJ5qomhRtjCfdX6hsH91r26KjSjFB0DNK57ZAkHmIjIBY06jmkSXVqmta+edQfpbNUM/QriBtM3dlZSUCgQDKy8vpa5MmTcK6desQCklvqjPOOAN///vfI/bR1sZrXbZt24YhQ4akdsAJIr4I1cJmevRDgKB38AVDMfUtWqms4Y/p6N65Ce2HGB5t3gCCIf1d45OJxx+kD754XMA9smx45Fy+6NjLP+7Git9rFbfzZ1gNoq6ENniVGUTJ7AWmB7UsMy3hu8JsO96dexRevnxKUsdEK1X7AuA45XuGFG2My0Pk0FamI1pRRjWEwn4yD1GIeYiMgKRStYqHm9wTxEMUz+Ix00mbP6yurg4FBQWw24Wbrri4GF6vF83NzSgsLKSvDxs2TPLZrVu34ocffsD5558PgPcQud1uXHTRRdi5cyfGjBmD+fPn6zaSgsHkFzgk+zSDg81igj/Ioc3tQ66CVmFfI1/orE8Pp6axOETFtto9PuQ6E7+AN1W3AABG9spJ6Hhki6r5Nnd4uiR9k4xXPu7Gdv4GN5sAl8UU1++aOqwQlx01GC+s2oVb3lyH5dcdhZ55UsPV4yNVhOP7jkxC7VirYbOY4Q2E4PEFEAwG0eHlH7oumzktx4rYPR4/Px7iIXJatZ270b34/k3JHHtW2JDmOKDN7aMGjPhYk3Ball3/cSP929o8vqifbergz00Pp1XzdzjCHiC3Lyj5jC/cu9FiTs38mmz0XteZgthB51S550iiwf4m/jmUn2VL6XFI1rFO5hjTZhC53W6JMQSA/u3zqVcGbmxsxHXXXYeJEyfiD3/4AwBgx44daGlpwU033YScnBw8//zzuPjii7F8+XLk5ORoHtOGDRvi+CXa9203A/4g8Mv633AgL/LQr9/OGyMWTwsqKipi7pPjOJhNQIgDfvp1PYpciQk8OY7Db/uaAQCmlv2oqKhLaH9OiwmeIIcff1mP3jldd6nJz+OeFn5VnW0zYf36dXHv9/heHL7Mt2Jnsx9Xvfg97ji6AGaRS3lLA3/dhoIBTefvYEDrPWPm+Elr4++b0JJnxYZaLwDAFPSn5Vjt388byQ3N7fj1119p2Hnnlko0J3gfxQvHcTADCAFY/cs6FMrGsWHDBlQdaAIANB2oRkVFi679Bzz8g65y2070Cyp7OQFgVzX/He2NtaioaNe076o23vBp8/gk53PPXj5Bo62lOaPuiVQ+C9LB3mov/X997X5UVDRHbMP5+W027z0AADD73V1yzox0rNNmEDkcjgjDh/wtFkaLqa+vxyWXXAKO4/DEE0/AHHbDvvDCC/D7/cjO5hsMPvzww5g2bRpWrlyJP/7xj5rHVFpaCosluZNhMBjEhg0bUFpaitxPm9Dh92LQsBEo7ReZ0u5bvxaAG+WjBqOsbICm/Wd9sALt3gCGjhiNIcXZCY21usWDdn8tLGYTTpk6keos4iX/s69Q0+JB38EjEkrh14r4WIvPo39XI4AGFOW6UFZWltB3PDugHac//T3W1frwa0c+bQQLAL6djcCXPyE3y5nw9xgdtWOthuuTlWj1eTFs+EiM7ZuH+k0HADShsEd2Wo5VR24DsOpnmO0OjD1kPEJvfg4AOHTihLjCUcki58MVaPUEMHj4KAwtEbxQ9FivXQvAi9HDh6BsvL4K8r0rK4DqGhT37oeyskHqG679CYAXh4wcgrIJfTXtu1eLB/jkK/hDkJzPH1t2AOvb0LO4CGVlpbrGmw70XteZQkduA/DdzwCAUUMHo6ws8rwWrlkNNDbBDQcALwb2Lk7pOUvWsSb7SQZpu/N79eqFpqYmBAIBWK38MOrq6uB0OpGXFynora2txezZswEAL730kiSkZrfbJd4mh8OB/v37o7ZWfRWkhMViSdlNYLFYwup+L7wBTvF7qlv4VWv/wmzN48h2WNDuDcCjsk89bD3Ar+aGFmcjy5l4iCvfZUNNiwcdvlCXTi7y89jqISmk9oTHMapPD/zj1LG4/Z2NeOizLZg+uhdG9OL1VoGw7MNmMR9Uk2k0tN4zRFcVhAkWiwWesADdZbOm5ViRcJQ3EIJH5HHPcdrTWjIhx2FFqyeATn/k/WyxWKjWKc9l033cSJ2j5k5/1M82h0tlFGQ7NH9HTjhc7w9yCMFENSukW4vNmrq5NRWk8lmQDpw24VGf7VS+doierzpc+qUwO/H5UgtGOtZpU7qNGTMGVqtV4pJbu3YtSktLqeeH0NnZicsvvxxmsxmvvPIKevXqRd/jOA7HHXcc3n77bcn2u3fvxtChQ1P+O/RAizOqpMkLbTu0iaqB5BZn3FQTzjDrk1iGGYH0M0t3tWqhBlFyRIJ/PmwgjhxWBH+Qw4pNB+jrRFSdKVWquxK7rOO9W0erjFTgFLWaoPohmznt9aNite8gGiJi3OihbGA+AGD5hmpV0TYgNELWU5RPrRI2yzIzBjZJ2n10UXVjh35R/cFC2mZul8uFWbNmYcGCBVi/fj1WrFiBpUuXUi9QXV0dPB7eUn3uueewZ88eLF68mL5XV1eHtrY2mEwmHHvssXjyySexevVqbN26Fbfccgt69+6NadOmpevnKRKtOGObx4/W8GSnpW2HfJ+xqs9qgVSoTjTDjGCUatUtcbTtiIbJZMLkQQUAgD2NQvFPX0CoQ8SQQhu8hj1DJLvLmWaDyOMPivqYpb/mCm3wqmYQxdncFQBOHd8HLpsF2+s68MueJtXtYlWqVsJuMdPSCuLijCTLLN2GZnfHHqMwIxDZqLi7NXYF0lypet68eRg3bhzmzJmDhQsX4rrrrsPMmTMBAFOnTsVHH30EAPj000/h8XhwzjnnYOrUqfTffffdBwC4+eabccIJJ+Bvf/sbzjnnHAQCAfzrX/8yjBuO4FQpbw8I4bIeLpuuGiNZGluCaKEy7CEamywPkYv/Hen2EDXH0bYjFgOLeL3WnnBmICCklCezWN/Bgi2cESlPu09H2w5AZBAFQkLKfZrGIobol1Q9ROHXc+PwEOU6bTi5lNcdvf6zcm8+jz9IjVU9HgKTyaTorQ6we8IQSFp32JSfL/LFSXdr2wGkuVK1y+XC4sWLqedHzObNm+n/P/nkk6j7cTgcuO2223DbbbclfYzJJFoz1ipag0hfsTdXkkJm3kAQ2+vCLTv6JMdDZJQGr8kOmQFCg8vdDYJBRLwfrA5RJNRDFBaVpDtkRowfXyBEw1DxeF2SDTGIlNp3hEIcvc/jHev5hw3AW7/sw4frq3HnH8dFCMjJvWI2QXeVYped1zOKPeCsuasxkNQhYh4iVdjM3YWQFZRSx/t49EOAUFk30ZDZtgPtCIY49HDZ0DtP3xjUMEr7DtLpvkcSVzwDw32c9je7aYVqqiFiq+EIbHINUdpDZsI5agxrZtJVJFIMMVDaFNp3dIgMjXgqVQPA5EEFGFqSjU5fEB+u2x/xvriPmZZq+WKEYpfC2EkvM9bcNb3EFTLT2ffxYIBdpV1ItI73++P2ECUnZCbWDyWrXLtRRNXN4QdeMkNmPXMdcNrMCHGCd89HRdVsNSxHLqoWQmbpMUKcVmHyb2zn669oaduRaqKJqonXyGYxxd3/zWQy4dzJfEmP19dEhs3i6WNGEDSSQtV8UqXexjxEacUWo9s9IF0kAEBBNvMQMVJIliizRQ4pl67XIMpOUsiM6IfGJEk/BHR9yOxAqwcHOiKPQ2sKQmYmk4l6iYiOiPUyU4dkuZBjRLyk6QqZmc0mumomWTXpGouYaCGzDiqotia0aDlzYj9YzCb8uqcZW2rbJO81xyGoJig1eKUhM3ZPpJVcpxUumwU9XDbV5AF50+ruqCFiV2kXEk0AHa+GiO4zSkNILSSrh5mYwhz+hmpoV688nixCIQ6znv4Bf/usPuJh0pzkLDPCwMKwsLqB114xUbU6ERqiNIfMAMAZNogaqEFknJCZkkGUSKd7MT1znZgxuieASHF1cxx9zAhKGkmWdm8MnDYL/u/KI/D6lYerZvyJPUdOmznCQOoOsJm7C4kmgI5XQxSrtpFWNpGQWRI9RESLVBMu9JVKats8qG3zojPAYWOVtKVBIp3uo0E8RERY7Q+n3TNRdSTkmCh1u08X5N4xkoeIaIPalTRESTKIAOD8Q/mw2Tu/VlGv3d7GTrxXweuK4lk8uBQ84EJzV2YQpZvS/j0wurf6/C7WEHVH/RCQ5iyz7oawgpJOdsEQh5qWxEJmsTpYR6OuzYv6di9MJr6pa7Lo04M3iBo7fPD4gyldcextdNP/b9zfiqNG8CvgUIgTDKIke4hoplk4ZMZE1erINUSkVo2W7vKpwmmTG0Tpnw6JIUJCV2LavSTDLPFxThtZgp65Dhxo8+Ldiirsqu/Av7/bCV8gBLMJOHZUT937dEXxELGQmfGRGETdMMMMYAZRl6ImgK5r8yIQ4mAxm9AzNz4PkVrdEi1sDofLBhdlJ/Wh0MNlg8PKdzk/0OrFwLABkQr2iuoBbaxqpf9v8wRAivIm3UMU/j3ku32sUrUqVEMk8xCl1SCyGs9DVJLjAADUt3sj3ktWyAzgDZSzJ/XH019txy1vrqevHzmsCP84dWxcWkKXQp21QDhEykJmxkccvu6O+iGAhcy6FDUNEdEP9c5z6q7oSuqRKNU20goRVCdTPwTwwmPiJUp12Gxvk2AQbRCFzIh3yGWzwGFN7gNvkEhUzXEcDT2wyT8SoVK1rA5RGkNmTnnIzAB1iEpyeYPoQFukQZTMkBkAmm0GAIOLsvD87Ml49fIpcSdWkPlNqVK11cweNUZHnHnJPESMlKPWukNIuddf/4dUHU3EQ0T1Q1Hiy/HSK8+JXQ2dqG5xx944AcQhs10NnWj1+JHntKHZTUSiyb/B+xW4YDLxBm5du1cUMkv/g9VoqNUhSq+HiB8TSTVPp3FGIAZRuzeATl9A4rFNpocIAAYXZ+O5iyahpdOPWeX9EvZsOhUWfELIjC0SjI74XuyOfcwA5iHqUojxIi+iSIwFvfohIDmtO6iHKEkVqsUQD1Ftqj1EopAZAPwWDpulom0HwWG1oG+479zexk7BQ8TqEEVgVxNVG0BDFHZiICtJhkYi5DistB5MfZs0O1Ocdp8sThjXG+ceOiApYV5SU0qqISIhM/aoMTpiDVFBN/UQsau0C1H3EMUnqAYSD5kFgiFsrW0HAIxJhYcobBCRXm2pgoTMCl38JU0yzVKVYUYQZ5oxUbU6cg2Rm2qI0meEyCvzGkFDZDKZqJeorl16z3SERdWkeKPRcNn5616aZRb2ELEsM8PDRNXMIOpSslRS5OOtQQSIQ2bxGUS7GjrhC4aQZbegf4H+749Fn7zUe4i8gSDVKB3ej/8+oiNKVQ0igrinGRNVqyMOmQWCIXqs0tlQVV6Z1wgGEQCaWHGgVaojaqMhM2OMU45LIeOVeYgyB6ddOEcsZMZIOWpZZvHWIAJEHqI4e5ntrOeLCg4pztbdu0gLvbvAQ7S/2QOO4x+uE/vwq2vqIaKtCFJzgw8QCat9ATb5qyEWVYu9mUYImRGMkHYPCJlmdbJMs1SEzJIJzTITi6qZhihjkIbMmEHESDHiDtukxw/HcYl5iEReJ47kl+tgRx0fLhtakrz6Q2J6hzU2tSk0iIh+qH+BC8MKeE/QjvoOtHn8KatBRCAeoj2N/9/enYc3Vad7AP9ma5JuULpRoBYQqyylLa2KQ1UEVHAZEXRcZgScx1Gv4DKOyOLIMowPA7hdRB1BURSvIIrMoDN6p4PLOChqlUJh2lsLsrXUFOiaJmmSc/9IzmmStnQxyTkn+X6ex+exSXpy+iM5efP+3t/745TZ2YhTZm1ut5RB0GjQ5z25gqFjQKSMzIs0ZRaw0izYRdXBJq0y880QcZWZapg4ZcaAKJx8v4GK35JLjzeg3toGo14r1aP05ZiCANja3N08uqNDFk+GaHhKXK9/tyfEbtW1TXYpCAw2sX5oSJIZiUattFrvQHVjSIuqASDLu33HkVO+RdV8WwXy3bpDWmFm0AVtI+G+UGyGqIuASKohUmhA1J4h8tntnlt3qIZBp5VqvVhUTSFnMmghXv/FlWZve3ecviYno08XZN80Z+DqtZ44VCdmiEITEKUmGKHTauByCzjVSbO5YBCX3Is1UGMG9QPgmTarD3VRtTdDVNdsl54rhhf/DtqnzNyKWGEGKLOoGui6F1GLQ9kZInMni0a4uau6XD16IEZlJEr7NEYbvkrDSKPR+O330+pwYad376CbC4f06Zg6rUYqDu3L0nsxQ3RuiKbMdFqNVBMRqjoiMUOUKQVEntVy+443SFNmoUoB9zMbpGDrsDe4ZFF1R75bd0gbu8rc9yewqDpOIRmitK6mzGzqqCHyK6rmKjNVef6X4/DBA0VRew2Lzr9aRr59gz48UIMmuxNDkswYPyz5Jxyz601jz6bB2ibt9D00RFNmQHthdai6VYs1RGKB85jBnoCo7EQDGrxTZqHcrFCsIxKnLFlU3ZHYm8nhaq8hkjsjExiQydkk0leXU2YKzxB1vtu9mCFiQKQWck5jy41X7jDzXWm27ZvjAICbCzJ/0gov8ULU0sspsypvRiM90RjSi6y0632oMkSnAzJEgz1TZofqWlDtbXoZqikzAB1qvxgQdeS77N6qgB5EgP+UmUGnUcy3YjEgqmu2w+2tu3MLgrS5q1L7EJk628uMRdWkInyVhpnYzfX/apuwu+oUNBpgZsHgn3bMLho+duewVFAdmukyUSgzRM12J854s0BDkjyBSXJcDAZ5n7PJO80QylUTgQGRUj5YlaTzomp5x8no8/xy9kMKlBznCYicbkGqS7M72xckKD1DZHe6pUCORdWkJrxyh5mYIXr9iyMAgAnnpkgf5H3V1ymzUBdUi6SAKAQZIjE71D/WgASfb85ilkgUqmX3QPuUmYjL7jvyqyHyZjLlXtXlO2WmpLqcGL1WWuXzY5PnPdPqFDMtGllbFZyN75SjGPRKm7vyPUEqwFdpmInfov5T49lrq6/F1J0ds7erzKQl9yEqqBZlhCEgygwIKnN8AiKtBogP4Ydv4IoMZog6EjNEDqfvlJlyVpnJfS6BxG7VYh2Rtc0TWMQZ9Yqt8fDdLV0MiKQMEYuqSQV45Q4z30LSRJMeV48eGLRj9jpDJAVEoc0QpSeGbsrs2BlPjVDmAP+mlmOGtAdE/cyGkHThFgVmiFhD1JHUmNFnlZnc01R+GSKFrDATBRZW27wZIqVOlwGA1mfFa6vDBbdbkDbOZYaI1ICv0jDzLST9ed6goCw9FqcexNb+PeFyCzh8yrvkPsQ1RL4Zor500z6bnmSIQr0vT3qiyW+ajPUSHRn0PjVEClllpuQMUWBAZPWuYFRyQAS0X4ta21zSxq4AV5mROjAgCrNYn4vwLwozg3PMPhRVV9e3wuF0I0anxeAQbOrqS8wQtba50Njatz3XunJc7FIdUNicEm+UArHEEK4wAzy9lob4ZKg4ZdZRTGerzGTPELX/O8kdnAUKbM4o1hDFKXRjV5HZZ6WZuOQeAAxcZUYqwFdpmInfRM9PT/DLYvwUUlF1W88DokPeTV2zkmOhC/H8vsmgk4pEgz1tdtSbIeps2xOxsLp/iAMiAMjyeX4WVXdk6KQxo9xZGUVPmcX7Z4jEgCjepOwtFXy7VfsGRMwQkRrwyh1mE0akwGTQ4v7JI4JWHCnVEPViyqx9U9fwtGgXs0Q13r5AwSAIgrRtR2YnWa68zP4APNmiUMtKbh9H1hB1JE4jOpzKbMwod3AWKC0xICCSpsyUdZ6BpG7VbU7/KTMWVZMKKOtrURS4clQ6Di6fGtQiX3MfiqrDtcJMlNHPhPKTTagNYoboVIsDrW0uaDTodNrvlxefgyabEzcV/PSVfN3J9M0QccqsA78+RAqcMotTWEAkZYiaA6bMFJbJCtSeIXK3d6nWahS7Mo7Il7LfXREq2Cue4voSEIk9iEK4ZYcvsRdRT/Yza2htQ/HBWpyxOtDY2oZGmxONrW0YPzwZv7iwve5KLKhOTzDBqNfB5fL/+/vHxmDhtAuC+Fd0zXfKjN+GO4rR+9QQtSmjU7V/hkhZl0Kphsj7BaK1TZwyU9Z5BmqvIXKizbvkntNlpBbKfndRj7Q3ZuzNlFl4M0QDEz0ZnJ70Ipq/rRT/e7C2w+3v7T2BwqFJ0jl3teReDkNTPAGRyaDlt+FOiBkip1uQpnblnjIz6LTQazVwugXlZYi8AVGjzQl7m6u9hkjxq8za9zMTt+1gQTWphbLfXdQjscbeZYisDqeUqQlfhshzge+uqPr/apvwvwdrodEA140dhP5mAxLNevz7+1PYe6wef/60CqtvygXQ9ZJ7OZybGo9Zl2Qho5/8wZkS+bYiaLR5tqOQe8oM8GSJmu1OxdUQ9TMbEKPTwuFyo67Z4VNDpOxLtu+O905miEhllP3uoh7pbWPGw94VZkmxBiTFhbZHj2hgv55liF769BAA4OpRA/HcbfnS7ZNHnsGMF3bjve9O4KEp2RjU39zlkns5aDQa/OGGMXKfhmL5Fpo3ePfnUkIQYjJo0WxX1tYdgOf1lJpgxIn6Vlia7T7L7pV1noF86xnbXNy2g9SFr9QIYDb0bsos3NNlgM+O92fJEFXXt+Ive08AAO6deK7ffePOScIlw5PR5hKw4V+eoOlsK8xIWXwDIrEXlVIyRID803edSfFpzijVECk9IPKOp63NBaeb23aQusgaENntdixevBiFhYUoKirCxo0bu3zsJ598ghtuuAH5+fm4/vrr8c9//tPv/vfffx9TpkxBbm4u5s6di9OnT4f69BVDbNbW08aMUkAUpukyoL2out7aBlsX/ZJe/tdhON0CLhmeLC2Z93XfFZ4g6a2vjuJUs/2sPYhIWXRajdTvSuxDpIQgpD0gUl6g4duLSG01RMwQkRrJ+kpdvXo1ysrKsGnTJixduhTr1q3Dhx9+2OFx5eXlmDdvHmbOnIkdO3bg1ltvxYMPPojy8nIAwL59+/DYY49h3rx52Lp1KxobG7Fo0aJw/zmyES9CLT0NiKRd7sOXIUo06aVvj51Nm9VbHdjy9VEAHbNDoqIRKRg7pB9sbW688vlhVNeLRdUMiNQgcEsTJUyZnevtwzUsjF8OekravqPZLtUQKX3KzORbVM0aIlIZ2d5dVqsV27Ztw4YNGzB69GiMHj0alZWVePPNNzF16lS/x77//vsYP348Zs2aBQDIysrCrl278Pe//x0XXHABNm/ejGnTpmH69OkAPIHWFVdcgWPHjiEzMzjbYyiZtH9QbzNEYWrKCHhqIjL6mXCorgU1DTYMDfgAev2LI7A6XBiVkYjLzkvp8hj3TRyBezeX4OXPPdkkg04jNX0kZTPotLC1tTfrU8KU2X/fmg9Lk12RQXX7fmYOWL0ZogSFL7uP9S2q5iozUhnZXqnl5eVwOp3Iz28vnC0oKEBpaSncPh1OAeDGG2/EI4880uEYTU1NAIDS0lIUFhZKt2dkZGDQoEEoLS0N0dkri5ghcrjcUu+PrgiCIHWpPjeMARHQ3q06sDljq8OF13b/AMCTHTrbsvWrRqVjRFo8HE7P3zm4vznkW49QcAR28FbCNJXJoFNkMAQAaT4ZIlubuoqqfZfd8/1JaiHbu8tisSApKQkxMe2rnFJSUmC321FfX48BAwZIt597rv8USmVlJb744gvceuutAIAff/wRaWlpfo9JTk7GyZMne3VOgY39gkE8ZiiOLYrxSUk3tzrOuplpbaMNLQ4XtBpgUD9TSM8rULp3O4Lqeqvf82756ghOtziQmWTG1SNTuz2ney4bhvnv7AcADEkydxjjcP5N0aovYx1YXGvQCvy3OovkOM/7uLbRJtUQmfUaRY+Z0duAs8XuhKPNUzyv1yr7nH3xGhI+wRrrYP5byRYQtba2+gVDAKSfHQ5Hl793+vRp3H///Rg3bhwmT54MALDZbJ0e62zH6cz+/ft79XilHFsQBOg0gEsAvt67D8nmrqciyn70bAWQFqvDf8r2heycOqOxeTJ6ZVXHsTexEYCnUd+Lu+oAAFOHGVC2v/tzOkcQkBqrhcXqhtltxd69e/3uD+VYk7/ejLXgal8FadRpoiaD21f1pzzXr8OWJojbpB6qOIgTeuVmXE5We7K/pxuaUFnlWQ1qt3V8jyodryHho6Sxli0gMhqNHQIW8WeTqfOakLq6Otx5550QBAFr166F1js33dWxzObeLcfOycmBThfcugaXy4X9+/eH5Ni+Yt8vRpPNiWEjzj9rsfTBr44COIMLBg9AXl5eyM6nM/ttR/Be+X/gjEmQnnv1RxX40epCclwMHvr5xX7bKZzNcmMtlvz1AH51+WjkjfDUHIVrrKlvYx338WeA1bMyMM5kCPvrT21SzliBXZ+h2eEJh7Qa4KKCPEV3Qm9JOAX8+2tAb8SQc7KA3fXonxivmn9rXkPCJ1hjLR4nGGQLiNLT03HmzBk4nU7o9Z7TsFgsMJlMSExM7PD42tpaqaj69ddf95tSS09PR11dnd/j6+rqkJqa2qtz0ul0IXsThPLYgGfTxyabE3YXzvo8P5zyrMw6Ny0+7G/4jP6eWo3aJjt0Oh3+cbAWL312GADwhxvGIM7U8yaR14wdhGvGDur0vlCPNbXrzVjH+DzObOC/UXfS+/nXNsUb9dK1UqnijJ5pPpvTBbfgCdwMKnw/8hoSPkoaa9mKqkeOHAm9Xu+XSi0pKUFOTo6U+RFZrVbcdddd0Gq12Lx5M9LT0/3uz83NRUlJifRzTU0NampqkJubG9K/QUmkpff2szdnFHv3DE0OfyFphrcX0cmGVhw7bcXv3t4LALhzwlBcOzYj7OdD4WXwmepRQg8ipTMZdEj0WVWm9IJqwGcvM4eLm7uS6sgWEJnNZkyfPh3Lli3Dvn37UFxcjI0bN0pZIIvFApvNMx/90ksv4ejRo1i1apV0n8VikVaZ3XbbbfjLX/6Cbdu2oby8HI8++igmTpwYFUvuRVLL/C6aHorEFV4DZdhzS+xWbWmy47/eLEGjzYn8c/pj0bSRYT8XCj/fVWYMiHpGXHoPKL8pIxCwl5l3lZmey+5JJWR9hy1atAjLli3D7NmzER8fj/vvvx9XXXUVAKCoqAgrV67EjBkz8NFHH8Fms+Hmm2/2+/0bb7wRf/rTn5Cfn48//OEPWLt2LRoaGjBhwgSsWLFCjj9JNnE97EUkNkUcKEPvnuR4o7S7eNmJRiTFGrDu9nGI0fOCGQ18A6Ke1opFu9QEI6q8fcPijcofs1ifL2ZiY8bAhpxESiVrQGQ2m7Fq1Sop8+OroqJC+v/OulcHmjFjBmbMmBHU81MTcw+mzJwuN+qaPavM0vsZu3xcqOi0GqQlGFHdYINGAzxzSx4G9+c+ZNEihhmiXktNaP/iooYpM7FTtSAAzXbPlzNu3UFqwVdqhIj1aYjWFUuzHW7BE5ikxIU/IAI8xdwAcP8VIzDx/LRuHk2RxDdToISmjGqQptIpMwBosrUB4OaupB7Kf4dRj4gfMC32rgOi2kZvD6IEI7QyXaRWzshB2YkGXDVqoCzPT/LhlFnv+dYQqSFDZNBpYdBp0OYS0OgNiFhUTWqh/HcY9Uj76o6up8zE+iE59/4akhSLIUnK3CqBQsug55RZb4k73gNAnApqiABPlqjN5USTzdupmlNmpBJ8pUaIWO/F0nqWompphRk3QyUZsIao99S2ygxor2dsbOWUGakLA6IIEWvwTpmdJSA6KS25Z0BE4edbQ8Qps55RY0AkTt8zQ0Rqw1dqhOjJlJmYIUpLlKegmqIb+xD1ntqKqoH2YJc1RKQ2DIgihDhldrYMEafMSE6+AZGZAVGPJMXGQOedclJDUTXQHuyKGSIDGzOSSvCVGiF8W+Z3Rc6mjES+DTjNnDLrEa1Wg5Q4zx5/askQxQbUEDFDRGrBgChCiPP21rNOmYlNGRkQUfixD1HfXJCRAECe/Qf7QpwyE7PVBtYQkUrwqhQhpJb5XWSImu1ONHu7WMu57J6il/+UGT8ke2rtrXn4ZM9ejPA2NVW6wPowPVeZkUrwqhQhuguIxPqheKNeNal3iix+AZGBr8GeijfqMSRRPeMVOB2qY0BEKsGAKEJ0N2VWKzVl5Aozkgf7EEWHwIJ5TpmRWvCVGiG6yxCxBxHJzbeGiKvMIldghohF1aQWDIgihJgham1zwe0WOtwvFVQnMCAieeh1XGUWDQKzf1x2T2rBV2qEEC9CggDYnB2zRGINEVeYkVxi2IcoKgR2IWeGiNSCAVGE8P3G3dm0GXsQkdwMet9l9wyIIlVgSwVu3UFqwVdqhNBqNVJQZLV3EhA1yr/TPUU33+Jak54BUaQKbKnAzV1JLRgQRRCpsLqt40qzHxu5yozkJQZEJoMWWn5IRqzAlgrMEJFa8JUaQcT9zAKnzNxuAT82eYqqucqM5CLWELFLdWQLrA9jDRGpBQOiCBLr/WYWOGVW12KH0y1AqwFS45khInmIGSKuMItsXGVGasVXagQRM0SNtja/22sbPNmhlHgj09ckG3G6dlB/ZikjGfsQkVrx0zGCZKd5NoEsPV7vd3stC6pJAc5LT8D/3HUx/vvWfLlPhUKoY6dqBkSkDgyIIsiFwwYAAL4+fNrvdq4wI6X42YgUDOpvlvs0KIQ6ZIg4ZUYqwVdqBLlwaBIAYP+JBtja2uuIaqVtO1g/RESh1WG3e2aISCUYEEWQcwbEIi3BiDaXgO+O1ku3sykjEYVLYKdqbu5KasFXagTRaDTt02Y/tE+b1XqX3KcxICKiEDPqtfBtM6VnzylSCQZEEeaioZ0ERMwQEVGYaDQavzoiZohILfhKjTAXegOib4+cgdPlBtBeVM2mjEQUDmaf5pusISK1YEAUYc4fmIAEkx4tDhf+U9MEW5sLDa2evkRcZUZE4eC7nxlXmZFa8JUaYXRaDQqzPKvNvvrhtLTCzGTQItHELROIKPRiffYzYx8iUgsGRBHItx+R7wozjYYXJiIKPZPP0nsdi6pJJRgQRSDfwmo2ZSSicItlUTWpEF+pEShnSD/E6LU41eLAl4dOAWBBNRGFj+/2HVx2T2rBgCgCGfU65GX2BwD8vewkAGaIiCh8zJwyIxWSNSCy2+1YvHgxCgsLUVRUhI0bN3b7O9988w0mT57c4fbCwkKcf/75fv+1tLSE4rRVQZw2q7dyhRkRhZfYh8ig07B2kVRD1mVHq1evRllZGTZt2oTq6mosWLAAgwYNwtSpUzt9fEVFBR588EEYjf57ctXW1qKpqQnFxcUwmdo/+GNjY0N6/kpW6N3XTMSmjEQULuJ+ZlxyT2oiW0BktVqxbds2bNiwAaNHj8bo0aNRWVmJN998s9OAaMuWLVi1ahUyMzPR3Nzsd19VVRVSU1ORmZkZrtNXvIKsJGg1gFvw/MyNXYkoXMQMEZsykprIFr6Xl5fD6XQiPz9fuq2goAClpaVwu90dHv/ZZ59h1apVmDNnTof7vv/+ewwbNiyUp6s6CSYDRmYkSj+nJTBDREThIdYQcYUZqYlsGSKLxYKkpCTExMRIt6WkpMBut6O+vh4DBgzwe/wLL7wAANi+fXuHY1VVVaG1tRV33HEHDh8+jJEjR2Lx4sW9DpJcLlcf/pKeHTMUx+5OYVYSDlQ3AgBS4gyynEM4yTnW0YZjHT5qHGuj3hMI6bUaVZ23GsdarYI11sH8t5ItIGptbfULhgBIPzscjl4d69ChQ2hoaMDDDz+M+Ph4bNiwAXPmzMEHH3yA+Pj4Hh9n//79vXre3gjlsbuSCk8PokSjFgfL9oX9+eUix1hHK451+KhprE/XWgEAblcb9u7dK+/J9IGaxlrtlDTWsgVERqOxQ+Aj/uxbGN0Tr7zyCtra2hAXFwcAePLJJ3H55Zfj448/xvXXX9/j4+Tk5ECn03X/wF5wuVzYv39/SI7dnfNGOvF57bcYP2wA8vJGhPW55SDnWEcbjnX4qHGsv3cfB74rQ6zJhLy8PLlPp8fUONZqFayxFo8TDLIFROnp6Thz5gycTif0es9pWCwWmEwmJCYmdvPb/mJiYvyyTUajEUOGDEFtbW2vjqPT6UL2JgjlsbuSGKvDlrsvCetzKoEcYx2tONbho6axjjd6rscGnUY15+xLTWOtdkoaa9kq3kaOHAm9Xu+XTi0pKUFOTg60vViqKQgCpkyZ4ldbZLVaceTIEQwfPjyYp0xERD0g7nbPompSE9lerWazGdOnT8eyZcuwb98+FBcXY+PGjZg1axYAT7bIZrN1exyNRoOJEyfiueeew549e1BZWYlHH30UAwcOxOWXXx7qP4OIiALkZybhvLR4XDc2Q+5TIeoxWRszLlq0CMuWLcPs2bMRHx+P+++/H1dddRUAoKioCCtXrsSMGTO6Pc78+fOh1+vxu9/9Ds3NzRg/fjzWr1+vmDQcEVE0SYqLwT8e5hdSUhdZAyKz2YxVq1Zh1apVHe6rqKjo9HdmzJjRIUgyGo1YuHAhFi5cGJLzJCIiosjGCV4iIiKKegyIiIiIKOoxICIiIqKox4CIiIiIoh4DIiIiIop6DIiIiIgo6jEgIiIioqjHgIiIiIiiHgMiIiIiinoMiIiIiCjqMSAiIiKiqMeAiIiIiKIeAyIiIiKKerLudq8UgiAAAFwuV9CPLR4zFMcmfxzr8OFYhw/HOnw41uETrLEWf1/8HP8pNEIwjqJyDocD+/fvl/s0iIiIqA9ycnIQExPzk47BgAiA2+2G0+mEVquFRqOR+3SIiIioBwRBgNvthl6vh1b706qAGBARERFR1GNRNREREUU9BkREREQU9RgQERERUdRjQERERERRjwERERERRT0GRERERBT1GBARERFR1GNAFEJ2ux2LFy9GYWEhioqKsHHjRrlPKWLU1tbigQcewEUXXYRLL70UK1euhN1uBwAcO3YMc+bMQV5eHq655hp8/vnnMp9t5Lj77ruxcOFC6eeDBw/i5ptvRm5uLmbOnImysjIZz079HA4Hli9fjgsvvBA/+9nP8PTTT0tbEnCsg6umpgb33HMPxo0bh0mTJuG1116T7uNYB4fD4cB1112HPXv2SLd1d33evXs3rrvuOuTm5mLWrFk4duxY2M6XAVEIrV69GmVlZdi0aROWLl2KdevW4cMPP5T7tFRPEAQ88MADaG1txZtvvolnnnkGH3/8MZ599lkIgoC5c+ciJSUF7777Lm644QbMmzcP1dXVcp+26n3wwQf49NNPpZ+tVivuvvtuFBYWYvv27cjPz8c999wDq9Uq41mq2x//+Efs3r0br7zyCp566im8/fbb2Lp1K8c6BB566CHExsZi+/btWLx4MZ599ln84x//4FgHid1ux8MPP4zKykrptu6uz9XV1Zg7dy5mzJiBd955BwMGDMB9990XlH3KekSgkGhpaRFycnKEL7/8Urrt+eefF371q1/JeFaR4fvvvxeys7MFi8Ui3bZz506hqKhI2L17t5CXlye0tLRI982ePVtYu3atHKcaMc6cOSNcdtllwsyZM4UFCxYIgiAI27ZtEyZNmiS43W5BEATB7XYLV155pfDuu+/KeaqqdebMGWHUqFHCnj17pNteeuklYeHChRzrIKuvrxeys7OFiooK6bZ58+YJy5cv51gHQWVlpfDzn/9cuP7664Xs7Gzpc7C76/Ozzz7r9xlptVqF/Px8v8/RUGKGKETKy8vhdDqRn58v3VZQUIDS0lK43W4Zz0z9UlNT8fLLLyMlJcXv9ubmZpSWlmLUqFGIjY2Vbi8oKMDevXvDfJaRZdWqVbjhhhswYsQI6bbS0lIUFBRI+/9pNBqMGzeOY91HJSUliI+Px0UXXSTddvfdd2PlypUc6yAzmUwwm83Yvn072tracOjQIXz77bcYOXIkxzoIvvrqK1x88cXYunWr3+3dXZ9LS0tRWFgo3Wc2mzF69OiwjT0DohCxWCxISkry2303JSUFdrsd9fX18p1YBEhMTMSll14q/ex2u7F582aMHz8eFosFaWlpfo9PTk7GyZMnw32aEeOLL77AN998g/vuu8/vdo51cB07dgyDBw/Gjh07MHXqVEyePBnPP/883G43xzrIjEYjlixZgq1btyI3NxfTpk3DZZddhptvvpljHQS33347Fi9eDLPZ7Hd7d2Mr99jrw/IsUai1tdUvGAIg/exwOOQ4pYi1Zs0aHDx4EO+88w5ee+21TsedY943drsdS5cuxZIlS2Aymfzu6+o1zrHuG6vViiNHjmDLli1YuXIlLBYLlixZArPZzLEOgaqqKlxxxRW48847UVlZiRUrVuCSSy7hWIdQd2Mr99gzIAoRo9HY4R9R/Dnwg4X6bs2aNdi0aROeeeYZZGdnw2g0dsjAORwOjnkfrVu3DmPGjPHLyIm6eo1zrPtGr9ejubkZTz31FAYPHgzAU2T61ltvISsri2MdRF988QXeeecdfPrppzCZTMjJyUFtbS1efPFFZGZmcqxDpLvrc1fXlMTExLCcH6fMQiQ9PR1nzpyB0+mUbrNYLDCZTGH7x410K1aswKuvvoo1a9bg6quvBuAZ97q6Or/H1dXVdUjDUs988MEHKC4uRn5+PvLz87Fz507s3LkT+fn5HOsgS01NhdFolIIhABg2bBhqamo41kFWVlaGrKwsvyBn1KhRqK6u5liHUHdj29X9qampYTk/BkQhMnLkSOj1er9isJKSEuTk5ECr5bD/VOvWrcOWLVvw9NNP49prr5Vuz83NxYEDB2Cz2aTbSkpKkJubK8dpqt4bb7yBnTt3YseOHdixYwcmTZqESZMmYceOHcjNzcV3330nLYkVBAHffvstx7qPcnNzYbfbcfjwYem2Q4cOYfDgwRzrIEtLS8ORI0f8shGHDh3CkCFDONYh1N31OTc3FyUlJdJ9ra2tOHjwYNjGnp/MIWI2mzF9+nQsW7YM+/btQ3FxMTZu3IhZs2bJfWqqV1VVhRdeeAG/+c1vUFBQAIvFIv130UUXISMjA4sWLUJlZSXWr1+Pffv24aabbpL7tFVp8ODByMrKkv6Li4tDXFwcsrKyMHXqVDQ2NuKJJ57A999/jyeeeAKtra2YNm2a3KetSsOHD8fEiROxaNEilJeX41//+hfWr1+P2267jWMdZJMmTYLBYMDvf/97HD58GLt27cKf//xn3HHHHRzrEOru+jxz5kx8++23WL9+PSorK7Fo0SIMGTIEF198cXhOMCyL+6OU1WoVHn30USEvL08oKioSXn31VblPKSK89NJLQnZ2dqf/CYIg/PDDD8Ivf/lLYcyYMcK1114r/Pvf/5b5jCPHggULpD5EgiAIpaWlwvTp04WcnBzhpptuEg4cOCDj2alfY2OjMH/+fCEvL0+45JJLhOeee07qh8OxDq7Kykphzpw5wrhx44QpU6YIr776Ksc6BHz7EAlC99fnTz75RLjqqquEsWPHCrNnzxaOHj0atnPVCEK4WkASERERKROnzIiIiCjqMSAiIiKiqMeAiIiIiKIeAyIiIiKKegyIiIiIKOoxICIiIqKox4CIiIiIoh4DIiIiH8ePH8f555+P48ePy30qRBRGDIiIiIgo6jEgIiIioqjHgIiIFK2mpgb33nsvcnNzMWnSJKxbtw4ulwvbt2/HbbfdhieffBL5+fmYOHEitm3bJv2e2+3Gyy+/jMmTJ2Ps2LG44447UFFRId1/6tQpPPTQQxg3bhwmTJiAp59+Gr47GRUXF2PKlCnIzc3Fvffei4aGhrD+3UQUXnq5T4CIqCuCIGDevHm44IIL8N5778FisWDJkiXQaDTIyMjA/v37ERsbi61bt2Lfvn1YtmwZMjIyUFRUhOeffx5vvfUWVqxYgaFDh2LDhg2466678NFHHyE2NhZz586FTqfD5s2b0dLSgt/+9rdIS0vDxIkTAQDvvfeeFCTNmzcPGzZswCOPPCLvgBBRyDAgIiLF+vLLL1FdXY1t27ZBq9Vi+PDhWLBgARYtWoQFCxZAo9Fg9erVSE5ORnZ2Nr7++mu8/fbbmDBhAjZv3oyHH34YkydPBgCsWLECV155Jf76178iLy8P3333HYqLi5GZmQkAWLZsGaxWq/Tc8+fPx9ixYwEA06ZNQ3l5efgHgIjChgERESlWVVUV6uvrUVBQIN3mdrths9lQX1+PrKwsJCcnS/eNGTMGW7ZswalTp1BfX4/c3FzpPoPBgDFjxqCqqgr9+vVD//79pWAIAKZMmQIA0uqyc845R7ovISEBdrs9ZH8nEcmPARERKZbT6cTw4cPxwgsvdLjvq6++gl7vfwlzuVzQarUwGo2dHs/lcsHtdsNgMHT73FotSyyJognf8USkWMOGDUN1dTUGDBiArKwsZGVl4fjx41i7di0A4MiRI2hpaZEeX1ZWhuzsbCQkJCAlJQV79+6V7mtra8OBAwcwbNgwZGVlob6+HjU1NdL9r7/+Ou67776w/W1EpCwMiIhIsYqKijB48GDMnz8fFRUV+Oabb/D444/DbDZDp9PBarVi6dKlqKqqwttvv40PP/wQt99+OwBgzpw5WLt2LXbt2oWqqio8/vjjsNvtuOaaa3Deeedh/PjxeOyxx1BRUYE9e/Zg/fr1mDBhgsx/MRHJhVNmRKRYOp0OL774IlasWIFf/OIXiI2NxdSpU7FgwQL87W9/Q0ZGBlJTU3HTTTchNTUVa9askeqNfv3rX6O5uRmPP/44mpubkZ+fjzfeeAMDBgwAAKxZswbLly/HLbfcgvj4eNxyyy24/fbbceLECTn/ZCKSiUbwbbxBRKQS27dvx7p167Br1y65T4WIIgCnzIiIiCjqMSAiIiKiqMcpMyIiIop6zBARERFR1GNARERERFGPARERERFFPQZEREREFPUYEBEREVHUY0BEREREUY8BEREREUU9BkREREQU9RgQERERUdT7f0F8E40GXWCbAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-09 14:52:39,295]\u001B[0m A new study created in memory with name: VERSE_Adj loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:40,281]\u001B[0m Trial 0 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008444624308806515, 'num_negative_samples': 11, 'lmbda': 0.3633455085004771}. Best is trial 0 with value: 0.0.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:41,560]\u001B[0m Trial 1 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007643110595521042, 'num_negative_samples': 11, 'lmbda': 0.7752498210671216}. Best is trial 1 with value: 0.3404414533245951.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:42,836]\u001B[0m Trial 2 finished with value: 0.3404414533245951 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00557609502916944, 'num_negative_samples': 16, 'lmbda': 0.16234026577185656}. Best is trial 1 with value: 0.3404414533245951.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:44,070]\u001B[0m Trial 3 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00969967235157516, 'num_negative_samples': 11, 'lmbda': 0.37646501261367704}. Best is trial 3 with value: 0.41746836453909475.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:45,340]\u001B[0m Trial 4 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008732175067372658, 'num_negative_samples': 11, 'lmbda': 0.05822838535666164}. Best is trial 4 with value: 0.5724289450397678.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:45,964]\u001B[0m Trial 5 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.008209055045013285, 'num_negative_samples': 11, 'lmbda': 0.9216066815326035}. Best is trial 4 with value: 0.5724289450397678.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:47,316]\u001B[0m Trial 6 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005540910915556067, 'num_negative_samples': 21, 'lmbda': 0.29355239955170254}. Best is trial 4 with value: 0.5724289450397678.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:47,921]\u001B[0m Trial 7 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005541024594076663, 'num_negative_samples': 11, 'lmbda': 0.864438039875259}. Best is trial 4 with value: 0.5724289450397678.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:49,188]\u001B[0m Trial 8 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007420214115797201, 'num_negative_samples': 21, 'lmbda': 0.133082368731812}. Best is trial 8 with value: 0.6459935698655926.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:50,603]\u001B[0m Trial 9 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006165559762325938, 'num_negative_samples': 1, 'lmbda': 0.06031329046468903}. Best is trial 8 with value: 0.6459935698655926.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:51,137]\u001B[0m Trial 10 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00677015569528368, 'num_negative_samples': 6, 'lmbda': 0.5971402187839316}. Best is trial 8 with value: 0.6459935698655926.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:52,403]\u001B[0m Trial 11 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.009327774980753269, 'num_negative_samples': 21, 'lmbda': 0.002559506025324114}. Best is trial 8 with value: 0.6459935698655926.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:53,681]\u001B[0m Trial 12 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.008792468845481495, 'num_negative_samples': 21, 'lmbda': 0.18704655188400335}. Best is trial 8 with value: 0.6459935698655926.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:54,942]\u001B[0m Trial 13 finished with value: 0.6805446536716203 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007097083398809987, 'num_negative_samples': 21, 'lmbda': 0.2574876767091216}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:55,489]\u001B[0m Trial 14 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007072207837908918, 'num_negative_samples': 21, 'lmbda': 0.47868937959528607}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:56,744]\u001B[0m Trial 15 finished with value: 0.5007710104811096 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007803771413764284, 'num_negative_samples': 21, 'lmbda': 0.23997879357254395}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:58,027]\u001B[0m Trial 16 finished with value: 0.5089773777040515 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.006909207812631225, 'num_negative_samples': 16, 'lmbda': 0.53808645256744}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:59,273]\u001B[0m Trial 17 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006241994034233579, 'num_negative_samples': 1, 'lmbda': 0.1355398015324464}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:52:59,832]\u001B[0m Trial 18 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007298389254795809, 'num_negative_samples': 6, 'lmbda': 0.6422934848472737}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:00,484]\u001B[0m Trial 19 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0063242695328839275, 'num_negative_samples': 21, 'lmbda': 0.4036601476319204}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:01,821]\u001B[0m Trial 20 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007993097552857775, 'num_negative_samples': 21, 'lmbda': 0.2602279468481492}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:03,137]\u001B[0m Trial 21 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00873195260897112, 'num_negative_samples': 21, 'lmbda': 0.19633578925303471}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:04,374]\u001B[0m Trial 22 finished with value: 0.3464674335917916 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.009110338855185637, 'num_negative_samples': 21, 'lmbda': 0.11848773087533868}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:05,638]\u001B[0m Trial 23 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007478340377948278, 'num_negative_samples': 21, 'lmbda': 0.32325819714343706}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:06,934]\u001B[0m Trial 24 finished with value: 0.5912676411833029 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0066063491658762035, 'num_negative_samples': 21, 'lmbda': 0.20704202657130172}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:08,182]\u001B[0m Trial 25 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009997165326278225, 'num_negative_samples': 16, 'lmbda': 0.4480771679692285}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:09,428]\u001B[0m Trial 26 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007252525344481208, 'num_negative_samples': 6, 'lmbda': 0.006648101251830241}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:10,686]\u001B[0m Trial 27 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008195115274115717, 'num_negative_samples': 1, 'lmbda': 0.2885346321470569}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:12,150]\u001B[0m Trial 28 finished with value: 0.5451809077932042 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008608744366619445, 'num_negative_samples': 21, 'lmbda': 0.0963386511672426}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:12,696]\u001B[0m Trial 29 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005001958486397876, 'num_negative_samples': 21, 'lmbda': 0.33248510701279593}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:13,268]\u001B[0m Trial 30 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.009177881835456973, 'num_negative_samples': 21, 'lmbda': 0.19224886216915066}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:14,560]\u001B[0m Trial 31 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006494452082864481, 'num_negative_samples': 21, 'lmbda': 0.22021083348351386}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:15,881]\u001B[0m Trial 32 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006650900754615854, 'num_negative_samples': 21, 'lmbda': 0.1655282888866273}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:17,216]\u001B[0m Trial 33 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.00768573949646435, 'num_negative_samples': 21, 'lmbda': 0.07874425405301674}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:18,497]\u001B[0m Trial 34 finished with value: 0.6308430573153381 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005917954639033293, 'num_negative_samples': 16, 'lmbda': 0.39490405719286786}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:19,788]\u001B[0m Trial 35 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006002800630930831, 'num_negative_samples': 16, 'lmbda': 0.4048370379792181}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:21,103]\u001B[0m Trial 36 finished with value: 0.6805446536716203 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005952524842179946, 'num_negative_samples': 16, 'lmbda': 0.7198258516777378}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:22,389]\u001B[0m Trial 37 finished with value: 0.5509731650193398 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005905561028199483, 'num_negative_samples': 16, 'lmbda': 0.7816309263586655}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:23,688]\u001B[0m Trial 38 finished with value: 0.4818944098266987 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0051705749019937885, 'num_negative_samples': 16, 'lmbda': 0.676620862640052}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:24,339]\u001B[0m Trial 39 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005766926310945403, 'num_negative_samples': 16, 'lmbda': 0.5289564622973382}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:25,594]\u001B[0m Trial 40 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005219336667909247, 'num_negative_samples': 16, 'lmbda': 0.7383766185592027}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:26,912]\u001B[0m Trial 41 finished with value: 0.416110740246089 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.008367876645964317, 'num_negative_samples': 16, 'lmbda': 0.3593551073089973}. Best is trial 13 with value: 0.6805446536716203.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:28,209]\u001B[0m Trial 42 finished with value: 0.7187952884282609 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007039073475270541, 'num_negative_samples': 11, 'lmbda': 0.9923629513466374}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:29,516]\u001B[0m Trial 43 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006935538876322714, 'num_negative_samples': 11, 'lmbda': 0.9809096064882378}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:30,800]\u001B[0m Trial 44 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007407801299977778, 'num_negative_samples': 11, 'lmbda': 0.8561506201404763}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:32,195]\u001B[0m Trial 45 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0057055360277412865, 'num_negative_samples': 11, 'lmbda': 0.9996825703303825}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:33,525]\u001B[0m Trial 46 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007125410832693105, 'num_negative_samples': 11, 'lmbda': 0.896247946271927}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:34,191]\u001B[0m Trial 47 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006432964407686458, 'num_negative_samples': 16, 'lmbda': 0.7956312634312454}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:34,752]\u001B[0m Trial 48 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00788107719782972, 'num_negative_samples': 1, 'lmbda': 0.9423782098005535}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:36,062]\u001B[0m Trial 49 finished with value: 0.5406843298205133 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005431867561242145, 'num_negative_samples': 11, 'lmbda': 0.6945472478725395}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:37,497]\u001B[0m Trial 50 finished with value: 0.416110740246089 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00681077437804988, 'num_negative_samples': 16, 'lmbda': 0.6001762905792871}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:38,822]\u001B[0m Trial 51 finished with value: 0.314970394174356 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006094437345501728, 'num_negative_samples': 6, 'lmbda': 0.2687519171597005}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:40,142]\u001B[0m Trial 52 finished with value: 0.4069376986693302 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007599880834556294, 'num_negative_samples': 11, 'lmbda': 0.15075098011126167}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:41,416]\u001B[0m Trial 53 finished with value: 0.6754232607754794 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007182982312065553, 'num_negative_samples': 16, 'lmbda': 0.46178205551236684}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:42,676]\u001B[0m Trial 54 finished with value: 0.6372747936651046 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007153326959898284, 'num_negative_samples': 16, 'lmbda': 0.4637054387985298}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:43,965]\u001B[0m Trial 55 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006955617188340098, 'num_negative_samples': 16, 'lmbda': 0.46926933359833534}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:45,235]\u001B[0m Trial 56 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0071720700270328985, 'num_negative_samples': 16, 'lmbda': 0.5049727142840509}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:46,491]\u001B[0m Trial 57 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007982963712314738, 'num_negative_samples': 16, 'lmbda': 0.5707027267922901}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:47,119]\u001B[0m Trial 58 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00739459611907653, 'num_negative_samples': 1, 'lmbda': 0.039098919497367324}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:47,667]\u001B[0m Trial 59 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007646477129529988, 'num_negative_samples': 6, 'lmbda': 0.44491188382123825}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:49,102]\u001B[0m Trial 60 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00674836482458157, 'num_negative_samples': 16, 'lmbda': 0.7449277657046446}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:50,412]\u001B[0m Trial 61 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0070114762659827115, 'num_negative_samples': 16, 'lmbda': 0.41332679457263993}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:51,736]\u001B[0m Trial 62 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007067219729660842, 'num_negative_samples': 16, 'lmbda': 0.42630887792003147}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:53,016]\u001B[0m Trial 63 finished with value: 0.5406843298205133 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007286744050277399, 'num_negative_samples': 16, 'lmbda': 0.36033115837658025}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:54,296]\u001B[0m Trial 64 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006348330172432011, 'num_negative_samples': 16, 'lmbda': 0.564763802743008}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:55,583]\u001B[0m Trial 65 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006591682955498119, 'num_negative_samples': 11, 'lmbda': 0.6159603687186093}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:56,864]\u001B[0m Trial 66 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007023390084775032, 'num_negative_samples': 16, 'lmbda': 0.4950428121379442}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:58,149]\u001B[0m Trial 67 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007497442266591906, 'num_negative_samples': 21, 'lmbda': 0.5170622040831181}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:59,383]\u001B[0m Trial 68 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006794121103338688, 'num_negative_samples': 1, 'lmbda': 0.4635886212226661}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:53:59,934]\u001B[0m Trial 69 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007276167300274796, 'num_negative_samples': 21, 'lmbda': 0.8146462067213158}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:01,216]\u001B[0m Trial 70 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007777540456635759, 'num_negative_samples': 6, 'lmbda': 0.3189746488911923}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:02,487]\u001B[0m Trial 71 finished with value: 0.45573271518764996 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006150606478355866, 'num_negative_samples': 16, 'lmbda': 0.3892919408503779}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:03,744]\u001B[0m Trial 72 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.008161497693883708, 'num_negative_samples': 16, 'lmbda': 0.4290095252579076}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:05,010]\u001B[0m Trial 73 finished with value: 0.314970394174356 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0071684638927121775, 'num_negative_samples': 16, 'lmbda': 0.2989252274708719}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:06,306]\u001B[0m Trial 74 finished with value: 0.46027367060462177 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006491347196604172, 'num_negative_samples': 16, 'lmbda': 0.24993246318396928}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:07,595]\u001B[0m Trial 75 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006930721408113987, 'num_negative_samples': 16, 'lmbda': 0.3573195245404929}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:08,250]\u001B[0m Trial 76 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007558148267160749, 'num_negative_samples': 21, 'lmbda': 0.12008630875972848}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:09,551]\u001B[0m Trial 77 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00738135430976225, 'num_negative_samples': 16, 'lmbda': 0.3856952545164912}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:10,958]\u001B[0m Trial 78 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005884201847429638, 'num_negative_samples': 16, 'lmbda': 0.49193250889685536}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:12,379]\u001B[0m Trial 79 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006637452387777905, 'num_negative_samples': 21, 'lmbda': 0.5685229599985682}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:13,806]\u001B[0m Trial 80 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.00665480281509323, 'num_negative_samples': 21, 'lmbda': 0.5484568839877613}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:15,219]\u001B[0m Trial 81 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006294791126540454, 'num_negative_samples': 21, 'lmbda': 0.6363306924899995}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:16,630]\u001B[0m Trial 82 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0056887874130267255, 'num_negative_samples': 21, 'lmbda': 0.5003990962983892}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:18,044]\u001B[0m Trial 83 finished with value: 0.4818944098266987 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006841075675603757, 'num_negative_samples': 21, 'lmbda': 0.422536946497214}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:19,454]\u001B[0m Trial 84 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0054386253333791835, 'num_negative_samples': 11, 'lmbda': 0.691082262563566}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:20,869]\u001B[0m Trial 85 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005387497262507472, 'num_negative_samples': 11, 'lmbda': 0.7264458306375067}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:22,266]\u001B[0m Trial 86 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005562005583691573, 'num_negative_samples': 11, 'lmbda': 0.7016907223601389}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:23,702]\u001B[0m Trial 87 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005932904556677333, 'num_negative_samples': 11, 'lmbda': 0.6652706587165047}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:25,132]\u001B[0m Trial 88 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005850233492479333, 'num_negative_samples': 11, 'lmbda': 0.6641745962735983}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:25,705]\u001B[0m Trial 89 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006690884632900557, 'num_negative_samples': 21, 'lmbda': 0.5753526422025607}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:26,343]\u001B[0m Trial 90 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006023252665810718, 'num_negative_samples': 11, 'lmbda': 0.6383979416226541}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:27,781]\u001B[0m Trial 91 finished with value: 0.5114083119567587 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005413121217411784, 'num_negative_samples': 11, 'lmbda': 0.8290760940407693}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:29,216]\u001B[0m Trial 92 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00620902214863535, 'num_negative_samples': 11, 'lmbda': 0.6663090140906109}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:30,625]\u001B[0m Trial 93 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0051592059273487464, 'num_negative_samples': 11, 'lmbda': 0.6155255916151464}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:32,042]\u001B[0m Trial 94 finished with value: 0.4760466052503372 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005823387899198089, 'num_negative_samples': 11, 'lmbda': 0.2191082912921923}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:33,467]\u001B[0m Trial 95 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.005679918767346993, 'num_negative_samples': 11, 'lmbda': 0.5398041633676468}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:34,899]\u001B[0m Trial 96 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006038725551937406, 'num_negative_samples': 21, 'lmbda': 0.5899976363093123}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:36,214]\u001B[0m Trial 97 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005288476394616535, 'num_negative_samples': 1, 'lmbda': 0.7566267648644784}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:37,632]\u001B[0m Trial 98 finished with value: 0.29417420270727607 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0063874436662388345, 'num_negative_samples': 6, 'lmbda': 0.6912994862417563}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:39,049]\u001B[0m Trial 99 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006533127534284855, 'num_negative_samples': 11, 'lmbda': 0.1818552974785548}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:40,338]\u001B[0m Trial 100 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005916792862008494, 'num_negative_samples': 21, 'lmbda': 0.721451487198287}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:41,783]\u001B[0m Trial 101 finished with value: 0.39965262694272663 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007023468382788674, 'num_negative_samples': 16, 'lmbda': 0.476262562554595}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:43,088]\u001B[0m Trial 102 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007231542737079379, 'num_negative_samples': 16, 'lmbda': 0.9382125508379625}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:44,409]\u001B[0m Trial 103 finished with value: 0.6157651067303722 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007392382171120964, 'num_negative_samples': 16, 'lmbda': 0.4495015852564133}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:45,744]\u001B[0m Trial 104 finished with value: 0.5981366814633041 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005008664002335326, 'num_negative_samples': 16, 'lmbda': 0.5463162316700994}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:47,079]\u001B[0m Trial 105 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007113459720213159, 'num_negative_samples': 16, 'lmbda': 0.4852828246151632}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:48,529]\u001B[0m Trial 106 finished with value: 0.6687467549246293 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0068694957862289975, 'num_negative_samples': 21, 'lmbda': 0.5151043262328806}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:49,940]\u001B[0m Trial 107 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0069772914589421135, 'num_negative_samples': 21, 'lmbda': 0.5221353727352954}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:50,513]\u001B[0m Trial 108 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006890731547738437, 'num_negative_samples': 21, 'lmbda': 0.599862350164525}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:51,961]\u001B[0m Trial 109 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0067448371259783745, 'num_negative_samples': 21, 'lmbda': 0.07955540164737701}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:53,425]\u001B[0m Trial 110 finished with value: 0.5509731650193398 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007529861842228529, 'num_negative_samples': 21, 'lmbda': 0.8823678368834815}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:54,805]\u001B[0m Trial 111 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007230924429116329, 'num_negative_samples': 16, 'lmbda': 0.4183023101046857}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:56,139]\u001B[0m Trial 112 finished with value: 0.4166666666666667 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00770715023105766, 'num_negative_samples': 21, 'lmbda': 0.47033607262699995}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:57,588]\u001B[0m Trial 113 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007098848052513884, 'num_negative_samples': 11, 'lmbda': 0.5193619964580111}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:58,251]\u001B[0m Trial 114 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0071782264412306234, 'num_negative_samples': 16, 'lmbda': 0.4566231864678943}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:54:59,740]\u001B[0m Trial 115 finished with value: 0.5430209893473684 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0073546073751046106, 'num_negative_samples': 1, 'lmbda': 0.7746448425759871}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:01,171]\u001B[0m Trial 116 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006901328454274542, 'num_negative_samples': 21, 'lmbda': 0.5654757064792783}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:02,481]\u001B[0m Trial 117 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005634652067414933, 'num_negative_samples': 16, 'lmbda': 0.5037186534854246}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:03,782]\u001B[0m Trial 118 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005512692144236829, 'num_negative_samples': 6, 'lmbda': 0.3327860987316485}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:05,215]\u001B[0m Trial 119 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006819882121926988, 'num_negative_samples': 11, 'lmbda': 0.6271834755210454}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:06,547]\u001B[0m Trial 120 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007479339308082446, 'num_negative_samples': 16, 'lmbda': 0.43648428742373024}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:07,867]\u001B[0m Trial 121 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0059544389927834954, 'num_negative_samples': 16, 'lmbda': 0.40432860213277044}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:09,221]\u001B[0m Trial 122 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005809996795539844, 'num_negative_samples': 16, 'lmbda': 0.3704651175223722}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:10,552]\u001B[0m Trial 123 finished with value: 0.4281744192888377 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005801088535542306, 'num_negative_samples': 16, 'lmbda': 0.27394915303688117}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:11,937]\u001B[0m Trial 124 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0070384778317446875, 'num_negative_samples': 16, 'lmbda': 0.37424438886060973}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:13,554]\u001B[0m Trial 125 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006098927791744943, 'num_negative_samples': 21, 'lmbda': 0.030777856306132542}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:18,426]\u001B[0m Trial 126 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0060869266047398176, 'num_negative_samples': 21, 'lmbda': 0.0029266726402270224}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:20,612]\u001B[0m Trial 127 finished with value: 0.6009252125773316 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.00561798535168923, 'num_negative_samples': 21, 'lmbda': 0.03420038833495272}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:21,951]\u001B[0m Trial 128 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006105468428078879, 'num_negative_samples': 21, 'lmbda': 0.14264951283374938}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:22,529]\u001B[0m Trial 129 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006258660680284791, 'num_negative_samples': 21, 'lmbda': 0.05759973533444016}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:23,328]\u001B[0m Trial 130 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.0061789923724337, 'num_negative_samples': 21, 'lmbda': 0.2295985730500893}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:24,639]\u001B[0m Trial 131 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005868917081876261, 'num_negative_samples': 16, 'lmbda': 0.34626921333890404}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:25,970]\u001B[0m Trial 132 finished with value: 0.6060395619242064 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006586675165972357, 'num_negative_samples': 11, 'lmbda': 0.09131407294051772}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:27,318]\u001B[0m Trial 133 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005731952527405228, 'num_negative_samples': 16, 'lmbda': 0.11836202003818785}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:28,734]\u001B[0m Trial 134 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0055060022432521834, 'num_negative_samples': 21, 'lmbda': 0.3034264882857652}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:30,053]\u001B[0m Trial 135 finished with value: 0.29417420270727607 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007313566497435508, 'num_negative_samples': 11, 'lmbda': 0.4925314471318043}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:31,396]\u001B[0m Trial 136 finished with value: 0.41746836453909475 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006489301311691514, 'num_negative_samples': 16, 'lmbda': 0.41332584577760045}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:32,052]\u001B[0m Trial 137 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006698093110829881, 'num_negative_samples': 21, 'lmbda': 0.713458694361029}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:33,393]\u001B[0m Trial 138 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005973481083197475, 'num_negative_samples': 16, 'lmbda': 0.6757010315126423}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:34,700]\u001B[0m Trial 139 finished with value: 0.314970394174356 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006981472989383993, 'num_negative_samples': 11, 'lmbda': 0.5353366163070311}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:36,247]\u001B[0m Trial 140 finished with value: 0.6687467549246293 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0053405670845845365, 'num_negative_samples': 21, 'lmbda': 0.4495283663121164}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:37,823]\u001B[0m Trial 141 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005314083901835099, 'num_negative_samples': 21, 'lmbda': 0.45359606810703784}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:39,273]\u001B[0m Trial 142 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005098645946068378, 'num_negative_samples': 21, 'lmbda': 0.4818473472561531}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:40,771]\u001B[0m Trial 143 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005785806464118222, 'num_negative_samples': 21, 'lmbda': 0.1665155847127374}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:42,262]\u001B[0m Trial 144 finished with value: 0.33477947172129646 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005438651716271761, 'num_negative_samples': 21, 'lmbda': 0.4385041228809049}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:43,749]\u001B[0m Trial 145 finished with value: 0.5828481227184134 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007165581421507258, 'num_negative_samples': 16, 'lmbda': 0.38842410766389573}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:45,030]\u001B[0m Trial 146 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007075253987039348, 'num_negative_samples': 1, 'lmbda': 0.5100288500629171}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:46,465]\u001B[0m Trial 147 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007244733146622038, 'num_negative_samples': 21, 'lmbda': 0.661832248467677}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:48,059]\u001B[0m Trial 148 finished with value: 0.38949891105034135 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00944776723225851, 'num_negative_samples': 6, 'lmbda': 0.4627926356288454}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:49,558]\u001B[0m Trial 149 finished with value: 0.5958964613022909 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0052625302785554995, 'num_negative_samples': 11, 'lmbda': 0.9666423418768753}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:51,026]\u001B[0m Trial 150 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006351723000887391, 'num_negative_samples': 16, 'lmbda': 0.031410419427692}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:52,442]\u001B[0m Trial 151 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005941496464741533, 'num_negative_samples': 16, 'lmbda': 0.3729687926429051}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:53,881]\u001B[0m Trial 152 finished with value: 0.4370036867375632 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.0057217714214954744, 'num_negative_samples': 16, 'lmbda': 0.3994413830010115}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:55,351]\u001B[0m Trial 153 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005594960867893747, 'num_negative_samples': 16, 'lmbda': 0.3455389315969077}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:56,613]\u001B[0m Trial 154 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006023099614931951, 'num_negative_samples': 16, 'lmbda': 0.8359681755640206}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:57,913]\u001B[0m Trial 155 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005875249622495945, 'num_negative_samples': 21, 'lmbda': 0.41400746881364714}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:58,469]\u001B[0m Trial 156 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.006868823407451831, 'num_negative_samples': 16, 'lmbda': 0.4419757389279737}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:55:59,748]\u001B[0m Trial 157 finished with value: 0.5828481227184134 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007455008699443426, 'num_negative_samples': 21, 'lmbda': 0.48277429812690875}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:00,990]\u001B[0m Trial 158 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006179348331464996, 'num_negative_samples': 11, 'lmbda': 0.5796430616357263}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:02,236]\u001B[0m Trial 159 finished with value: 0.44809041961928775 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006265246592366857, 'num_negative_samples': 11, 'lmbda': 0.5751452331951098}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:02,846]\u001B[0m Trial 160 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006140524018501488, 'num_negative_samples': 11, 'lmbda': 0.5981911001696965}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:04,064]\u001B[0m Trial 161 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0059999301525615716, 'num_negative_samples': 11, 'lmbda': 0.5556831834374922}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:05,283]\u001B[0m Trial 162 finished with value: 0.6754232607754794 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00581612071491062, 'num_negative_samples': 11, 'lmbda': 0.6530374700929621}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:06,541]\u001B[0m Trial 163 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0071186429672698065, 'num_negative_samples': 11, 'lmbda': 0.6513827460088792}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:07,811]\u001B[0m Trial 164 finished with value: 0.48959479688217644 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005737632642726079, 'num_negative_samples': 11, 'lmbda': 0.6174746413961091}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:09,061]\u001B[0m Trial 165 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006983414410617568, 'num_negative_samples': 11, 'lmbda': 0.6837939965978082}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:10,296]\u001B[0m Trial 166 finished with value: 0.4353821461299537 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005351737257717421, 'num_negative_samples': 11, 'lmbda': 0.5230063706373363}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:11,546]\u001B[0m Trial 167 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005475008642103997, 'num_negative_samples': 11, 'lmbda': 0.7362260281439443}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:12,796]\u001B[0m Trial 168 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005889027305035892, 'num_negative_samples': 11, 'lmbda': 0.7045356012308889}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:14,155]\u001B[0m Trial 169 finished with value: 0.46027367060462177 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006133040561867413, 'num_negative_samples': 21, 'lmbda': 0.5899119056166611}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:15,421]\u001B[0m Trial 170 finished with value: 0.4891995904702285 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006754129264340029, 'num_negative_samples': 11, 'lmbda': 0.6421519136962583}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:16,702]\u001B[0m Trial 171 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005826372091799026, 'num_negative_samples': 16, 'lmbda': 0.7560006479450674}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:17,952]\u001B[0m Trial 172 finished with value: 0.32075014954979214 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006019282339028336, 'num_negative_samples': 16, 'lmbda': 0.4292452998686693}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:19,358]\u001B[0m Trial 173 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005628189330585367, 'num_negative_samples': 21, 'lmbda': 0.4627410033431788}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:20,624]\u001B[0m Trial 174 finished with value: 0.4818944098266987 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007248537827680262, 'num_negative_samples': 16, 'lmbda': 0.49979596273772914}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:21,874]\u001B[0m Trial 175 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0062431156186265584, 'num_negative_samples': 16, 'lmbda': 0.3904085490654531}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:23,273]\u001B[0m Trial 176 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006421530660888709, 'num_negative_samples': 21, 'lmbda': 0.5495565867554104}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:24,593]\u001B[0m Trial 177 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005917777954485875, 'num_negative_samples': 1, 'lmbda': 0.1942232367168087}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:26,002]\u001B[0m Trial 178 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006919410541878087, 'num_negative_samples': 11, 'lmbda': 0.12186928850603589}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:27,305]\u001B[0m Trial 179 finished with value: 0.5163977794943222 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.0057664404998894955, 'num_negative_samples': 16, 'lmbda': 0.46750903665588645}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:28,554]\u001B[0m Trial 180 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0073466373765178755, 'num_negative_samples': 6, 'lmbda': 0.529205337664425}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:29,822]\u001B[0m Trial 181 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0073750989360453585, 'num_negative_samples': 16, 'lmbda': 0.44579940301676046}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:31,127]\u001B[0m Trial 182 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0072052462228890096, 'num_negative_samples': 16, 'lmbda': 0.47839368911996183}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:32,466]\u001B[0m Trial 183 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007037405486390343, 'num_negative_samples': 16, 'lmbda': 0.42800654974216357}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:33,758]\u001B[0m Trial 184 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00606975405686048, 'num_negative_samples': 16, 'lmbda': 0.4076175734184714}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:35,042]\u001B[0m Trial 185 finished with value: 0.6308430573153381 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007618958747034406, 'num_negative_samples': 21, 'lmbda': 0.5042246462804661}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:36,455]\u001B[0m Trial 186 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007496855527290646, 'num_negative_samples': 21, 'lmbda': 0.9188753355584782}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:37,028]\u001B[0m Trial 187 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007871985591868368, 'num_negative_samples': 21, 'lmbda': 0.5125323360547014}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:38,333]\u001B[0m Trial 188 finished with value: 0.4493160587325148 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.007582274928729533, 'num_negative_samples': 21, 'lmbda': 0.4956001039429985}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:39,724]\u001B[0m Trial 189 finished with value: 0.4426670377159262 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.005537148769055573, 'num_negative_samples': 21, 'lmbda': 0.2428516781081111}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:41,026]\u001B[0m Trial 190 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007111251430998304, 'num_negative_samples': 21, 'lmbda': 0.624155227209127}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:42,316]\u001B[0m Trial 191 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007641307515539293, 'num_negative_samples': 16, 'lmbda': 0.4515002035101575}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:43,612]\u001B[0m Trial 192 finished with value: 0.47366546671567095 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007279647276279641, 'num_negative_samples': 21, 'lmbda': 0.47387534964526723}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:44,894]\u001B[0m Trial 193 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0077566197573897475, 'num_negative_samples': 11, 'lmbda': 0.4409579131816128}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:46,216]\u001B[0m Trial 194 finished with value: 0.6608722544880642 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00583379772837017, 'num_negative_samples': 16, 'lmbda': 0.05968021960272836}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:46,860]\u001B[0m Trial 195 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005864151033447418, 'num_negative_samples': 16, 'lmbda': 0.68949288507088}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:48,123]\u001B[0m Trial 196 finished with value: 0.416110740246089 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005964600232689169, 'num_negative_samples': 21, 'lmbda': 0.06299551003893054}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:49,525]\u001B[0m Trial 197 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005776274875954158, 'num_negative_samples': 11, 'lmbda': 0.059525979248267503}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:50,826]\u001B[0m Trial 198 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005646364199347622, 'num_negative_samples': 16, 'lmbda': 0.09021566243273486}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:52,142]\u001B[0m Trial 199 finished with value: 0.4226493565977341 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006185095804014073, 'num_negative_samples': 21, 'lmbda': 0.6602769920784107}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:53,532]\u001B[0m Trial 200 finished with value: 0.4493160587325148 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005911870106878313, 'num_negative_samples': 16, 'lmbda': 0.032545452045938644}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:54,860]\u001B[0m Trial 201 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007434418043570109, 'num_negative_samples': 16, 'lmbda': 0.48720231235617467}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:56,157]\u001B[0m Trial 202 finished with value: 0.3268602252303067 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006850172403607649, 'num_negative_samples': 16, 'lmbda': 0.015620264481242811}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:57,490]\u001B[0m Trial 203 finished with value: 0.5274515410965525 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006093457476226365, 'num_negative_samples': 16, 'lmbda': 0.5383348963926193}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:56:58,802]\u001B[0m Trial 204 finished with value: 0.314970394174356 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007116293135268592, 'num_negative_samples': 16, 'lmbda': 0.2818146749761611}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:00,083]\u001B[0m Trial 205 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005701124463342282, 'num_negative_samples': 11, 'lmbda': 0.3624278507083506}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:01,399]\u001B[0m Trial 206 finished with value: 0.47809144373375745 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005181646713852886, 'num_negative_samples': 16, 'lmbda': 0.4222803296644875}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:02,719]\u001B[0m Trial 207 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007003890897018056, 'num_negative_samples': 21, 'lmbda': 0.5757568010624255}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:04,105]\u001B[0m Trial 208 finished with value: 0.3713906763541037 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0073264618434687265, 'num_negative_samples': 11, 'lmbda': 0.51022474889305}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:05,438]\u001B[0m Trial 209 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005831013166895948, 'num_negative_samples': 16, 'lmbda': 0.7985494822022832}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:06,770]\u001B[0m Trial 210 finished with value: 0.4764285119345052 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007189197331378694, 'num_negative_samples': 21, 'lmbda': 0.3114403076869843}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:08,068]\u001B[0m Trial 211 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006623499260769394, 'num_negative_samples': 11, 'lmbda': 0.059010988795989726}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:09,369]\u001B[0m Trial 212 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0066669425449116465, 'num_negative_samples': 11, 'lmbda': 0.01896729140921697}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:10,642]\u001B[0m Trial 213 finished with value: 0.705468061066683 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0066232657537747515, 'num_negative_samples': 11, 'lmbda': 0.06147748600816779}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:11,929]\u001B[0m Trial 214 finished with value: 0.3779644730092272 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006520622912029929, 'num_negative_samples': 11, 'lmbda': 0.118469210396243}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:13,227]\u001B[0m Trial 215 finished with value: 0.4069376986693302 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006586584715022369, 'num_negative_samples': 11, 'lmbda': 0.05267732428848289}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:14,521]\u001B[0m Trial 216 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006966593679858783, 'num_negative_samples': 11, 'lmbda': 0.01746792840256471}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:19,541]\u001B[0m Trial 217 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006714563407171825, 'num_negative_samples': 11, 'lmbda': 0.044268841283657004}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:21,467]\u001B[0m Trial 218 finished with value: 0.49199948380409103 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006794259483255499, 'num_negative_samples': 11, 'lmbda': 0.07796795750665983}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:22,795]\u001B[0m Trial 219 finished with value: 0.5730576425878946 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006438356164002543, 'num_negative_samples': 11, 'lmbda': 0.04482153410789824}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:24,264]\u001B[0m Trial 220 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005961874213754415, 'num_negative_samples': 11, 'lmbda': 0.07335921543939705}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:25,811]\u001B[0m Trial 221 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00605043172586067, 'num_negative_samples': 1, 'lmbda': 0.46231663003370876}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:28,139]\u001B[0m Trial 222 finished with value: 0.49501483062599505 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006351607324306574, 'num_negative_samples': 16, 'lmbda': 0.44940626634318837}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:31,074]\u001B[0m Trial 223 finished with value: 0.6459935698655926 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007535545155613948, 'num_negative_samples': 11, 'lmbda': 0.1104070228171194}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:32,798]\u001B[0m Trial 224 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006871954663785859, 'num_negative_samples': 11, 'lmbda': 0.09386785426846088}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:33,376]\u001B[0m Trial 225 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007651585355041983, 'num_negative_samples': 11, 'lmbda': 0.1370141150127747}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:34,763]\u001B[0m Trial 226 finished with value: 0.5399664674850008 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006640586829076248, 'num_negative_samples': 11, 'lmbda': 0.10565991517233062}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:36,378]\u001B[0m Trial 227 finished with value: 0.4499657051403686 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00758203264614159, 'num_negative_samples': 11, 'lmbda': 0.07829999499239573}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:39,095]\u001B[0m Trial 228 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005847301121421326, 'num_negative_samples': 6, 'lmbda': 0.10348007110919143}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:40,641]\u001B[0m Trial 229 finished with value: 0.3713906763541037 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005378485295665747, 'num_negative_samples': 21, 'lmbda': 0.052169922588199406}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:41,360]\u001B[0m Trial 230 finished with value: 0.0 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00599734368916063, 'num_negative_samples': 11, 'lmbda': 0.0037420594004855673}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:42,876]\u001B[0m Trial 231 finished with value: 0.4944132324730442 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007418442907527426, 'num_negative_samples': 16, 'lmbda': 0.6779849319941199}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:45,687]\u001B[0m Trial 232 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007505256458174332, 'num_negative_samples': 21, 'lmbda': 0.3947919532272372}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:47,231]\u001B[0m Trial 233 finished with value: 0.38248698840130013 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007088873757528606, 'num_negative_samples': 11, 'lmbda': 0.2149080762423068}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:50,340]\u001B[0m Trial 234 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007289998764812725, 'num_negative_samples': 16, 'lmbda': 0.16852835430575405}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:52,543]\u001B[0m Trial 235 finished with value: 0.6687467549246293 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005734582577237222, 'num_negative_samples': 21, 'lmbda': 0.7053478643843202}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:54,043]\u001B[0m Trial 236 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0056833458987924955, 'num_negative_samples': 21, 'lmbda': 0.7094908223032467}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:55,731]\u001B[0m Trial 237 finished with value: 0.5724289450397678 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.005769205759797925, 'num_negative_samples': 21, 'lmbda': 0.7210064188960706}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:57:58,047]\u001B[0m Trial 238 finished with value: 0.4629100498862757 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005934369847099965, 'num_negative_samples': 21, 'lmbda': 0.6524139923900835}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:00,516]\u001B[0m Trial 239 finished with value: 0.5614960175974338 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0056176628147813195, 'num_negative_samples': 21, 'lmbda': 0.6826338996905656}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:02,329]\u001B[0m Trial 240 finished with value: 0.46811943184313104 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.005836495325185978, 'num_negative_samples': 21, 'lmbda': 0.06387541835438301}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:04,387]\u001B[0m Trial 241 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0055333767757462776, 'num_negative_samples': 16, 'lmbda': 0.4851557681143015}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:06,995]\u001B[0m Trial 242 finished with value: 0.5455447255899809 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0076911433083808375, 'num_negative_samples': 11, 'lmbda': 0.42857315937253443}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:10,791]\u001B[0m Trial 243 finished with value: 0.5194185766091661 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007176614778772422, 'num_negative_samples': 16, 'lmbda': 0.7344508802255099}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:12,229]\u001B[0m Trial 244 finished with value: 0.48959479688217644 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006127640926774211, 'num_negative_samples': 21, 'lmbda': 0.9961466589514155}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:13,568]\u001B[0m Trial 245 finished with value: 0.4104233100681459 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007022285940047221, 'num_negative_samples': 11, 'lmbda': 0.46850074633086314}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:14,879]\u001B[0m Trial 246 finished with value: 0.0 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.0057785646596206965, 'num_negative_samples': 16, 'lmbda': 0.6062388049881468}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:16,207]\u001B[0m Trial 247 finished with value: 0.37374127372092536 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.00987663994027828, 'num_negative_samples': 21, 'lmbda': 0.6377161959741982}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:17,516]\u001B[0m Trial 248 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007450457462727803, 'num_negative_samples': 16, 'lmbda': 0.7033488650043201}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:18,938]\u001B[0m Trial 249 finished with value: 0.522635770061855 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006929175795255078, 'num_negative_samples': 11, 'lmbda': 0.5208511902105561}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:20,855]\u001B[0m Trial 250 finished with value: 0.0 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007822973755805257, 'num_negative_samples': 21, 'lmbda': 0.49495499698957307}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[32m[I 2022-11-09 14:58:22,219]\u001B[0m Trial 251 finished with value: 0.0 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006029502767448999, 'num_negative_samples': 16, 'lmbda': 0.40641281422764364}. Best is trial 42 with value: 0.7187952884282609.\u001B[0m\n",
      "\u001B[33m[W 2022-11-09 14:58:22,340]\u001B[0m Trial 252 failed because of the following error: KeyboardInterrupt()\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1420\\2232532568.py\", line 48, in objective\n",
      "    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,loss_to_train)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1420\\1223343394.py\", line 70, in train\n",
      "    optimizer.step()\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 113, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\adam.py\", line 171, in step\n",
      "    capturable=group['capturable'])\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\adam.py\", line 226, in adam\n",
      "    capturable=capturable)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\adam.py\", line 259, in _single_tensor_adam\n",
      "    grad = grad.add(param, alpha=weight_decay)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\3979139515.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m                 \u001B[0mMO\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMainOptuna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'unsupervised'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m                 \u001B[0mbest_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMO\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m500\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m                 \u001B[0mloss_trgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\2232532568.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, number_of_trials)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m         \u001B[0mstudy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"maximize\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstudy_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Name\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" loss,\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_trials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m         \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    426\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m             \u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    429\u001B[0m         )\n\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0mprogress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             )\n\u001B[0;32m     78\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m             \u001B[0mfrozen_trial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     ):\n\u001B[1;32m--> 234\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\2232532568.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mLossSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss_to_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\1223343394.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, model, data, optimizer, Sampler, train_loader, dropout, epoch, loss)\u001B[0m\n\u001B[0;32m     68\u001B[0m                     \u001B[0mtotal_loss\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[0mtotal_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mtotal_loss\u001B[0m \u001B[1;33m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m==\u001B[0m \u001B[1;34m'supervised'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m                     \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    169\u001B[0m                  \u001B[0mmaximize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'maximize'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m                  \u001B[0mforeach\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'foreach'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 171\u001B[1;33m                  capturable=group['capturable'])\n\u001B[0m\u001B[0;32m    172\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    173\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    224\u001B[0m          \u001B[0meps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0meps\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m          \u001B[0mmaximize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmaximize\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 226\u001B[1;33m          capturable=capturable)\n\u001B[0m\u001B[0;32m    227\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    258\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mweight_decay\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 259\u001B[1;33m             \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrad\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    260\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;31m# Decay the first and second moment running average coefficient\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "loss = VERSE_Adj\n",
    "loss_name = 'VERSE_Adj'\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "for name in datasets_names[:2]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#on real graphs\n",
    "loss = Force2Vec\n",
    "loss_name = 'Force2Vec'\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "for name in ['Cornell']:\n",
    "    for conv in ['GCN']:\n",
    "         if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                MO = MainOptuna(name = name, conv = conv, device = device, loss_function = loss, mode = 'unsupervised')\n",
    "                best_values = MO.run(number_of_trials =500)\n",
    "\n",
    "                loss_trgt = dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name, conv=conv, device=device, loss_function=loss_trgt, mode='unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = VERSE_SR\n",
    "loss_name = 'VERSE_SR'\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "for name in ['Cornell']:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "loss = VERSE_Adj\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis = analysis.drop(columns=['Unnamed: 0'])\n",
    "for name in ['Cornell']:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modkdjfjf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "number_of_trials = 100\n",
    "import os\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "        if len(analysis[(analysis['la'] == l)&(analysis['fa']==f)&(analysis['cl']==cl)&(analysis['asp']==asp)&(analysis['ad']==ad)] ) == 0:\n",
    "            data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask = data_load(name)\n",
    "            x = data.x.detach()\n",
    "            y = data.y.detach()\n",
    "            def objective(trial):\n",
    "            # Integer parameter\n",
    "                c = trial.suggest_categorical(\"c\",  [0.001, 0.01, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,10,20,30,100])\n",
    "                clf = LogisticRegression(max_iter = 3000, C=c).fit(x[train_mask].numpy(), y[train_mask].numpy())\n",
    "\n",
    "                accs_micro = []\n",
    "                accs_macro = []\n",
    "                for mask in [train_mask,test_mask,val_mask]:\n",
    "                    accs_micro += [accuracy_score(data.y.detach()[mask].numpy(),clf.predict(x[mask].numpy()))]\n",
    "                    accs_macro += [accuracy_score(data.y.detach()[mask].numpy(),clf.predict(x[mask].numpy()))]\n",
    "\n",
    "                return np.sqrt(accs_micro[2]*accs_macro[2])\n",
    "\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(objective, n_trials = number_of_trials)\n",
    "            trial = study.best_trial\n",
    "            c=trial.params['c']\n",
    "            clf = LogisticRegression(max_iter = 3000, C=c).fit(x[train_mask].numpy(), y[train_mask].numpy())\n",
    "            accs_micro = []\n",
    "            accs_macro = []\n",
    "            for mask in [train_mask,test_mask,val_mask]:\n",
    "                accs_micro += [f1_score(y[mask].numpy(),clf.predict(x[mask].numpy()), average='micro')]\n",
    "                accs_macro += [f1_score(y[mask].numpy(),clf.predict(x[mask].numpy()), average='macro')]\n",
    "\n",
    "            to_append = pd.Series([l,f,cl,asp,ad, accs_micro[0],accs_micro[1], accs_macro[0] , accs_macro[1]],index = analysis.columns)\n",
    "            analysis = analysis.append(to_append, ignore_index=True)\n",
    "            analysis.to_csv('classification_on_features.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = Force2Vec\n",
    "loss_name = 'Force2Vec'\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "        print('hey')\n",
    "        for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name = name, conv = conv, device = device, loss_function = loss, mode = 'unsupervised')\n",
    "                best_values = MO.run(number_of_trials = 500)\n",
    "\n",
    "                loss_trgt = dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_force2vec.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = VERSE_Adj\n",
    "loss_name = 'VERSE_Adj'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = VERSE_SR\n",
    "loss_name = 'VERSE_SR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = VERSE_PPR\n",
    "loss_name = 'VERSE_PPR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = LapEigen\n",
    "loss_name = 'LapEigen'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = LINE\n",
    "loss_name = 'LINE'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = GraphFactorization\n",
    "loss_name = 'GraphFactorization'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi, train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_CN\n",
    "loss_name = 'HOPE_CN'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_AA\n",
    "loss_name = 'HOPE_AA'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_RPR\n",
    "loss_name = 'HOPE_RPR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_Katz\n",
    "loss_name = 'HOPE_Katz'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"betta\"] = best_values['betta']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = Node2Vec\n",
    "loss_name = 'Node2Vec'\n",
    "device = 'cpu'\n",
    "for name in ['chameleon']:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"walks_per_node\"] = best_values['walk_length']\n",
    "                loss_trgt[\"walk_length\"] = best_values['walk_length']\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"context_size\"] = best_values['context_size']\n",
    "                loss_trgt[\"p\"] = best_values['p']\n",
    "                loss_trgt[\"q\"] = best_values['q']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = DeepWalk\n",
    "loss_name = 'DeepWalk'\n",
    "device='cpu'\n",
    "for name in ['Citeseer']:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"walks_per_node\"] = best_values['walk_length']\n",
    "                loss_trgt[\"walk_length\"] = best_values['walk_length']\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"context_size\"] = best_values['context_size']\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = APP\n",
    "loss_name = 'APP'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My__RW_Neighbour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}