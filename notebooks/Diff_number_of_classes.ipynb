{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch_geometric.datasets import Planetoid, WikipediaNetwork, Actor, WebKB\n",
    "\n",
    "from modules.model import Net\n",
    "from modules.sampling import SamplerContextMatrix, SamplerRandomWalk, SamplerFactorization, SamplerAPP\n",
    "\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = pd.read_csv('../results/data_analysis_realdata.csv') #pd.read_csv('../classification_on_features.csv')\n",
    "analysis = analysis.drop(columns='Unnamed: 0') \n",
    "analysis\n",
    "\n",
    "synthetic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "benchmark_data_dir = \"../data_benchmark/\"\n",
    "help_data = \"../data_help/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "if synthetic:\n",
    "    datasets_names=[]\n",
    "    for l_a_trgt in [0.1,0.5,0.9]:\n",
    "                for f_a_trgt in [0.1,0.5,0.9]:\n",
    "                    for cl_trgt in [0.01,0.1,0.2,0.3,0.5]:\n",
    "                        for asp_trgt in [2,3,4,5,6,7]:\n",
    "                            for a_deg_trgt in [2,5,10,15,20,25,30,35,40]:\n",
    "                                datasets_names.append((l_a_trgt,f_a_trgt,cl_trgt,asp_trgt,a_deg_trgt))\n",
    "    def data_load(name):\n",
    "        x = torch.tensor(np.load(f'{benchmark_data_dir}/graph_'+str(name)+'_attr.npy'),dtype=torch.float)\n",
    "        edge_list = torch.tensor(np.load(f'{benchmark_data_dir}/graph_'+str(name)+'_edgelist.npy')).t()\n",
    "        y =  torch.tensor(np.load(f'{benchmark_data_dir}/graph_'+str(name)+'_labels.npy'))\n",
    "        data=Data(x=x,edge_index=edge_list,y=y)\n",
    "        indices=list(range(len(data.x)))\n",
    "\n",
    "        train_indices = torch.tensor(indices[:int(0.7*len(indices)+1)])\n",
    "        val_indices = torch.tensor(indices[int(0.7*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        test_indices = torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        train_mask = torch.tensor([False]*len(indices))\n",
    "        test_mask = torch.tensor([False]*len(indices))\n",
    "        val_mask = torch.tensor([False]*len(indices))\n",
    "        train_mask[train_indices] =True\n",
    "        test_mask[test_indices]=True\n",
    "        val_mask[val_indices]=True\n",
    "        return data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask\n",
    "else:\n",
    "    datasets_names = ['Cornell','Texas','Wisconsin','Actor','Pubmed','squirrel']\n",
    "\n",
    "    def data_load(name):\n",
    "        if name == 'Cora' or name == 'Citeseer' or name == 'Pubmed':\n",
    "            data = Planetoid(root='/tmp/'+str(name), name=name,transform=T.NormalizeFeatures())[0]\n",
    "        elif name == 'Actor':\n",
    "            data = Actor(root='/tmp/actor',transform=T.NormalizeFeatures())[0]\n",
    "        elif name == \"Cornell\" or name==\"Texas\" or name==\"Wisconsin\":\n",
    "            data = WebKB(root='/tmp/'+str(name),name=name,transform=T.NormalizeFeatures())[0]\n",
    "        elif name == 'squirrel' or name=='chameleon':\n",
    "            data = WikipediaNetwork(root='/tmp/'+str(name), name=name,transform=T.NormalizeFeatures())[0]\n",
    "\n",
    "        indices=list(range(len(data.x)))\n",
    "\n",
    "        train_indices = torch.tensor(indices[:int(0.7*len(indices)+1)])\n",
    "        val_indices = torch.tensor(indices[int(0.7*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        test_indices = torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        train_mask = torch.tensor([False]*len(indices))\n",
    "        test_mask = torch.tensor([False]*len(indices))\n",
    "        val_mask = torch.tensor([False]*len(indices))\n",
    "        train_mask[train_indices] =True\n",
    "        test_mask[test_indices]=True\n",
    "        val_mask[val_indices]=True\n",
    "        return data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "class Main:\n",
    "    def __init__(self,name, conv, device, loss_function, mode):\n",
    "        data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask = data_load(name)\n",
    "        self.Conv = conv\n",
    "        self.device = device\n",
    "        self.x = data.x\n",
    "        self.y = data.y.squeeze()\n",
    "        self.data=data.to(device)\n",
    "        self.loss = loss_function\n",
    "        self.mode = mode\n",
    "        self.datasetname=name\n",
    "        self.train_indices =train_indices# torch.tensor(indices[:int(0.7*len(indices)+1)])\n",
    "        self.val_indices =val_indices# torch.tensor(indices[int(0.7*len(indices)+1):int(0.8*len(indices)+1)])\n",
    "        self.test_indices = test_indices#torch.tensor(indices[int(0.8*len(indices)+1):])\n",
    "        self.train_mask = train_mask#torch.tensor([False]*len(indices))\n",
    "        self.test_mask = test_mask#torch.tensor([False]*len(indices))\n",
    "        self.val_mask =val_mask# torch.tensor([False]*len(indices))\n",
    "        self.flag = self.loss[\"flag_tosave\"]\n",
    "        super(Main, self).__init__()\n",
    "    def sampling(self,Sampler, epoch, nodes, loss):\n",
    "        if (epoch == 0): \n",
    "            if self.flag:  \n",
    "                if \"alpha\" in self.loss: \n",
    "                    name_of_file = self.datasetname+\"_samples_\"+loss[\"Name\"]+\"_alpha_\"+str(loss[\"alpha\"])+\".pickle\"\n",
    "                elif \"betta\" in self.loss: \n",
    "                    name_of_file = self.datasetname+\"_samples_\"+loss[\"Name\"]+\"_betta_\"+str(loss[\"betta\"])+\".pickle\"\n",
    "                else:\n",
    "                    name_of_file = self.datasetname+\"_samples_\"+loss[\"Name\"]+\".pickle\"             \n",
    "                \n",
    "                if os.path.exists(f'{help_data}/'+str(name_of_file)):\n",
    "                    with open(f'{help_data}/'+str(name_of_file),'rb') as f:\n",
    "                        self.samples = pickle.load(f)\n",
    "                else:\n",
    "                    self.samples = Sampler.sample(nodes) \n",
    "                    with open(f'{help_data}/'+str(name_of_file),'wb') as f:\n",
    "                        pickle.dump(self.samples,f)\n",
    "            else:\n",
    "                self.samples = Sampler.sample(nodes)\n",
    " \n",
    "    def train(self, model,data,optimizer,Sampler,train_loader,dropout,epoch,loss):\n",
    "        model.train()   \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "       # print('train loader',len(train_loader))\n",
    "        \n",
    "        if model.mode == 'unsupervised':\n",
    "            if model.conv=='GCN':\n",
    "                arr = torch.nonzero(self.train_mask == True)\n",
    "                indices_of_train_data = ([item for sublist in arr for item in sublist])\n",
    "                #print('before',data.x)\n",
    "                out = model.inference(data.to(self.device),dp=dropout)\n",
    "                #print('after',out, sum(sum(out)))\n",
    "                samples = self.sampling(Sampler,epoch, indices_of_train_data,loss)\n",
    "                loss = model.loss(out[self.train_mask], self.samples)\n",
    "                #print('loss',loss)\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    adjs = [adj.to(self.device) for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id.to(self.device)].to(self.device), adjs)\n",
    "                    self.sampling(Sampler,epoch,n_id[:batch_size],loss)                 \n",
    "                    loss = model.loss(out, self.samples)#pos_batch.to(device), neg_batch.to(device))\n",
    "                    total_loss+=loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)\n",
    "        elif model.mode== 'supervised':\n",
    "            if model.conv=='GCN':\n",
    "                out = model.inference(data.to(self.device),dp=dropout)\n",
    "                y=self.y.to(self.device)\n",
    "                loss = model.loss_sup(out[self.train_mask],y[self.train_mask])\n",
    "                total_loss+=loss\n",
    "            else:\n",
    "                for batch_size, n_id, adjs in train_loader:\n",
    "                    if len(train_loader.sizes) == 1:\n",
    "                        adjs = [adjs]\n",
    "                    adjs = [adj.to(self.device) for adj in adjs]\n",
    "                    out = model.forward(data.x[n_id].to(self.device), adjs)\n",
    "                    y = self.y.to(self.device)\n",
    "                    loss = model.loss_sup(out,y[n_id[:batch_size]])\n",
    "                    total_loss += loss\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizer.step()      \n",
    "            return total_loss /len(train_loader)       \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, model, data):\n",
    "        model.eval()\n",
    "        out = model.inference(data.to(self.device))\n",
    "\n",
    "        y_true = self.y.cpu().detach().numpy()\n",
    "        self.y=self.y.cpu()\n",
    "        if model.mode == 'supervised':\n",
    "            y_true = self.y.unsqueeze(-1)\n",
    "            y_pred = out.cpu().argmax(dim=-1, keepdim=True)\n",
    "\n",
    "            accs_micro = []\n",
    "            accs_macro = []\n",
    "            for mask in [self.train_mask,self.test_mask,self.val_mask]:\n",
    "                accs_micro += [f1_score(self.y.detach()[mask].cpu().numpy(),y_pred[mask], average='micro')]\n",
    "                accs_macro += [f1_score(self.y.detach()[mask].cpu().numpy(),y_pred[mask], average='macro')]\n",
    "                \n",
    "            return out,accs_micro,accs_macro\n",
    "            \n",
    "        elif model.mode == 'unsupervised': \n",
    "                #clf = LogisticRegression(max_iter = 3000,C=c).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\n",
    "                clf = CatBoostClassifier(logging_level='Silent',allow_const_label=True).fit(out.cpu().detach()[self.train_mask].numpy(),self.y.detach()[self.train_mask].cpu().numpy(),\n",
    "                        eval_set = (out.cpu().detach()[self.val_mask].numpy(), self.y.detach()[self.val_mask].cpu().numpy())\n",
    "                     )\n",
    "                accs_micro = []\n",
    "                accs_macro = []\n",
    "                for mask in [self.train_mask,self.test_mask,self.val_mask]:\n",
    "                    accs_micro += [f1_score(self.y.detach()[mask].cpu().numpy(),clf.predict(out.cpu().detach()[mask].numpy()), average='micro')]\n",
    "                    accs_macro += [f1_score(self.y.detach()[mask].cpu().numpy(),clf.predict(out.cpu().detach()[mask].numpy()), average='macro')]\n",
    "                return out, accs_micro,accs_macro\n",
    "        \n",
    "                \n",
    "\n",
    "    def run(self,params):\n",
    "        \n",
    "        hidden_layer=params['hidden_layer']\n",
    "        out_layer=params['out_layer']\n",
    "        dropout=params['dropout']\n",
    "        size=params['size of network, number of convs']\n",
    "        learning_rate=params['lr']\n",
    "        #c=params['c']\n",
    "\n",
    "        #hidden_layer=64,out_layer=128,dropout=0.0,size=1,learning_rate=0.001,c=100\n",
    "        classifier = \"logistic regression\"\n",
    "        train_loader = NeighborSampler(self.data.edge_index, node_idx=self.train_mask, batch_size = int(sum(self.train_mask)), sizes=[-1]*size)\n",
    "        \n",
    "        Sampler = self.loss[\"Sampler\"]\n",
    "        LossSampler = Sampler(self.datasetname, self.data, device=device, mask=self.train_mask, loss_info=self.loss, help_dir=help_data)\n",
    "        model = Net(dataset = self.data,mode=self.mode,conv=self.Conv,loss_function=self.loss,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = (size),dropout = dropout)\n",
    "        model.to(self.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)\n",
    "                #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "        scheduler=lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "        losses=[]\n",
    "        train_accs_mi=[]\n",
    "        test_accs_mi=[]\n",
    "        val_accs=[]\n",
    "        name_of_plot='conv: '+model.conv+', mode: '+model.mode+', loss from '+self.loss[\"Name\"]\n",
    "        train_accs_ma = []\n",
    "        test_accs_ma = []\n",
    "        print(name_of_plot)\n",
    "        log = 'Loss: {:.4f}, Epoch: {:03d}, Train acc micro: {:.4f}, Test acc micro: {:.4f},Train acc macro: {:.4f}, Test acc macro: {:.4f}'\n",
    "         \n",
    "        for epoch in range(100):\n",
    "                    print(epoch)\n",
    "                    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,self.loss)\n",
    "                    losses.append(loss.detach().cpu())\n",
    "                    out, [train_acc_mi, test_acc_mi,val_acc_mi],[train_acc_ma, test_acc_ma,val_acc_ma] = self.test(model,self.data)\n",
    "                    train_accs_mi.append(train_acc_mi)\n",
    "                    test_accs_mi.append(test_acc_mi)\n",
    "                    train_accs_ma.append(train_acc_ma)\n",
    "                    test_accs_ma.append(test_acc_ma)\n",
    "                    print(log.format(loss, epoch, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma))\n",
    "        np.save('../data_help/embedings_'+str(self.datasetname)+str(self.loss['name'])+'.npy', out.cpu().numpy())\n",
    "                    \n",
    "                     #scheduler.step()\n",
    "        print(log.format(loss, epoch, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma))\n",
    "        plt.plot(losses)\n",
    "        plt.title(name_of_plot+' loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        plt.plot(test_accs_mi)\n",
    "        plt.title(name_of_plot+' test f1 micro')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "                  \n",
    "        plt.plot(test_accs_ma)\n",
    "        plt.title(name_of_plot+' test f1 macro')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()\n",
    "        return train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MainOptuna(Main):\n",
    "    def objective(self,trial):\n",
    "        # Integer parameter\n",
    "        hidden_layer = trial.suggest_categorical(\"hidden_layer\", [32,64,128,256])\n",
    "        out_layer = trial.suggest_categorical(\"out_layer\", [32,64,128])\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5,step = 0.1)\n",
    "        size = trial.suggest_categorical(\"size of network, number of convs\", [1,2,3])\n",
    "        Conv = self.Conv\n",
    "        learning_rate= trial.suggest_float(\"lr\",5e-3,1e-2)\n",
    "\n",
    "        #c =trial.suggest_categorical(\"c\",  [0.001, 0.01, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,10,20,30,100])\n",
    "        # варьируем параметры\n",
    "        loss_to_train={}\n",
    "        for name in self.loss:\n",
    "            \n",
    "            if type(self.loss[name]) == list :\n",
    "                if len(self.loss[name]) == 3:\n",
    "                    var = trial.suggest_int(name,self.loss[name][0],self.loss[name][1],step=self.loss[name][2])\n",
    "                    loss_to_train[name] = var\n",
    "                elif len(self.loss[name]) == 2:\n",
    "                    var_2 = trial.suggest_float(name,self.loss[name][0],self.loss[name][1])\n",
    "                    loss_to_train[name] = var_2\n",
    "                else:\n",
    "                    var_3 = trial.suggest_categorical(name, self.loss[name])\n",
    "                    loss_to_train[name] = var_3\n",
    "            else:\n",
    "                loss_to_train[name] = self.loss[name]\n",
    "        if name =='q' and type(self.loss[name]) == list:\n",
    "            var_5 = trial.suggest_categorical('p', self.loss['p'])\n",
    "            var_4 = trial.suggest_categorical('q', self.loss[name]) \n",
    "            if var_4 > 1:\n",
    "                var_4=1\n",
    "            if var_5 < var_4:     \n",
    "                var_5=var_4\n",
    "            loss_to_train['q'] = var_4\n",
    "            loss_to_train['p'] = var_5\n",
    "                \n",
    "        Sampler =loss_to_train[\"Sampler\"]\n",
    "        model = Net(dataset = self.data,mode=self.mode,conv=Conv,loss_function=loss_to_train,device=device,hidden_layer=hidden_layer,out_layer =out_layer,num_layers = size,dropout = dropout)\n",
    "        train_loader = NeighborSampler(self.data.edge_index, batch_size = int(sum(self.train_mask)),node_idx=self.train_mask, sizes=[-1]*size)\n",
    "       \n",
    "        LossSampler = Sampler(self.datasetname,self.data,device=self.device,mask=self.train_mask,loss_info=loss_to_train, help_dir=help_data)\n",
    "        model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay = 1e-5)  \n",
    "\n",
    "        for epoch in range(50):\n",
    "            loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,loss_to_train)\n",
    "        _, [train_acc_mi, test_acc_mi,val_acc_mi], [train_acc_ma, test_acc_ma,val_acc_ma] = self.test(model=model, data=self.data)\n",
    "        trial.report(np.sqrt(val_acc_mi*val_acc_ma), epoch)\n",
    "        return np.sqrt(val_acc_mi*val_acc_ma)\n",
    "\n",
    "    \n",
    "    def run(self,number_of_trials):\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\",study_name=self.loss[\"Name\"]+\" loss,\"+str(self.Conv)+\" conv\")\n",
    "        study.optimize(self.objective,n_trials = number_of_trials)\n",
    "        trial = study.best_trial\n",
    "        return trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#loss functions\n",
    "\n",
    "VERSE_PPR =  {\"Name\": \"VERSE_PPR\",\"C\": \"PPR\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]}\n",
    "VERSE_Adj =  {\"Name\": \"VERSE_Adj\",\"C\": \"Adj\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n",
    "\n",
    "VERSE_SR =  {\"Name\": \"VERSE_SimRank\",\"C\": \"SR\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"Sampler\":SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n",
    "DeepWalk = {\"Name\": \"DeepWalk\",\"walk_length\":[5, 10, 15, 20],\"walks_per_node\":[5, 10, 15, 20],\"num_negative_samples\":[1,6, 11, 16, 21],\"context_size\" : [5, 10, 15, 20],\"p\":1,\"q\":1,\"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\" : SamplerRandomWalk } #Проблемы с памятью после того, как увеличила количество тренировочных данных\n",
    "Node2Vec = {\"Name\": \"Node2Vec\",\"walk_length\":[5, 10, 15, 20],\"walks_per_node\":[5, 10, 15, 20],\"num_negative_samples\":[1,6, 11, 16, 21],\"context_size\" : [5, 10, 15, 20],\"p\": [0.25, 0.50, 1, 2, 4] ,\"q\":[0.25, 0.50, 1, 2, 4], \"loss var\": \"Random Walks\",\"flag_tosave\":False,\"Sampler\": SamplerRandomWalk}#то же самое \n",
    "APP ={\"Name\": \"APP\",\"C\": \"PPR\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":True,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerAPP}\n",
    "HOPE_Katz = {\"Name\": \"HOPE_Katz\",\"C\":\"Katz\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"betta\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} #проверить\n",
    "\n",
    "HOPE_RPR = {\"Name\": \"HOPE_RPR\",\"C\":\"RPR\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"alpha\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} #проверить\n",
    "HOPE_CN = {\"Name\": \"HOPE_CommonNeighbors\",\"C\":\"CN\",\"loss var\": \"Factorization\",\"flag_tosave\":False,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} \n",
    "HOPE_AA = {\"Name\": \"HOPE_AdamicAdar\",\"C\":\"AA\",\"loss var\": \"Factorization\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} \n",
    "\n",
    "LapEigen = {\"Name\": \"LaplacianEigenMaps\", \"C\":\"Adj\",\"loss var\": \"Laplacian EigenMaps\",\"flag_tosave\":True,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]}\n",
    "LINE = {\"Name\": \"LINE\",\"C\": \"Adj\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Context Matrix\",\"flag_tosave\":False,\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n",
    "GraphFactorization = {\"Name\": \"Graph Factorization\",\"C\":\"Adj\",\"loss var\": \"Factorization\",\"flag_tosave\":False,\"Sampler\" :SamplerFactorization,\"lmbda\": [0.0,1.0]} \n",
    "\n",
    "Force2Vec = {\"Name\": \"Force2Vec\",\"C\": \"Adj\",\"num_negative_samples\":[1, 6, 11, 16, 21],\"loss var\": \"Force2Vec\",\"flag_tosave\":False,\"Sampler\" :SamplerContextMatrix,\"lmbda\": [0.0,1.0]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "analysis = pd.DataFrame(columns=['loss','conv','dataset','train acc micro','test acc micro','train acc macro','test acc macro'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-08 13:02:05,492]\u001B[0m A new study created in memory with name: LINE loss,GCN conv\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "loss = LINE\n",
    "loss_name = 'LINE'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "\n",
    "for name in datasets_names[:2]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-08 02:22:44,782]\u001B[0m A new study created in memory with name: LaplacianEigenMaps loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:23:04,136]\u001B[0m Trial 0 finished with value: 0.44497831183743997 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0071760648037464785, 'lmbda': 0.3136929181197623}. Best is trial 0 with value: 0.44497831183743997.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:23:13,653]\u001B[0m Trial 1 finished with value: 0.472502088099326 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.008659963621377154, 'lmbda': 0.22238524048410957}. Best is trial 1 with value: 0.472502088099326.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:23:16,206]\u001B[0m Trial 2 finished with value: 0.38148888458666896 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.009963816287653596, 'lmbda': 0.9030118051680475}. Best is trial 1 with value: 0.472502088099326.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:23:40,818]\u001B[0m Trial 3 finished with value: 0.4140393356054125 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005599611588732642, 'lmbda': 0.11591865833205084}. Best is trial 1 with value: 0.472502088099326.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:23:48,379]\u001B[0m Trial 4 finished with value: 0.6546132587402416 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0054084685084059905, 'lmbda': 0.7878272809618022}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:23:56,143]\u001B[0m Trial 5 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0064761005283688906, 'lmbda': 0.9881344941761986}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:24:30,268]\u001B[0m Trial 6 finished with value: 0.3855959161172688 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007268438329161458, 'lmbda': 0.06404454168800833}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:24:34,998]\u001B[0m Trial 7 finished with value: 0.3804331015163438 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009123998397968082, 'lmbda': 0.6004159941049392}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:25:20,520]\u001B[0m Trial 8 finished with value: 0.4654746681256314 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006988231705458089, 'lmbda': 0.18815528455233643}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:01,269]\u001B[0m Trial 9 finished with value: 0.4449193369300429 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0053274659532293695, 'lmbda': 0.9642749177796504}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:25,049]\u001B[0m Trial 10 finished with value: 0.35486043161491804 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 1, 'lr': 0.006156614831763626, 'lmbda': 0.6911599275004747}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:32,360]\u001B[0m Trial 11 finished with value: 0.6136024254416996 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006123271677950461, 'lmbda': 0.7718909864889596}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:39,568]\u001B[0m Trial 12 finished with value: 0.49914456738033236 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005068589249383302, 'lmbda': 0.7379657194365253}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:46,858]\u001B[0m Trial 13 finished with value: 0.5804909103247844 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006023475912410051, 'lmbda': 0.400976774863279}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:53,084]\u001B[0m Trial 14 finished with value: 0.5268956705260043 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.0065368423060583125, 'lmbda': 0.8094152783066322}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:26:58,931]\u001B[0m Trial 15 finished with value: 0.58309518948453 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008189286711891602, 'lmbda': 0.5265713379339116}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:06,191]\u001B[0m Trial 16 finished with value: 0.5881917195189638 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005645400582940487, 'lmbda': 0.836434684951989}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:19,416]\u001B[0m Trial 17 finished with value: 0.38544964466377263 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.007858923405810302, 'lmbda': 0.6347345777756157}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:23,237]\u001B[0m Trial 18 finished with value: 0.5617686762218463 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 2, 'lr': 0.005944378965927705, 'lmbda': 0.5159775546337477}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:30,855]\u001B[0m Trial 19 finished with value: 0.551848744709125 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005025580502470457, 'lmbda': 0.764826390736526}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:44,001]\u001B[0m Trial 20 finished with value: 0.3855959161172688 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006695108547738903, 'lmbda': 0.41077221744331754}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:51,240]\u001B[0m Trial 21 finished with value: 0.6262649536799838 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006436974462399541, 'lmbda': 0.9918149075232332}. Best is trial 4 with value: 0.6546132587402416.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:27:58,562]\u001B[0m Trial 22 finished with value: 0.788262662246131 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005747739740961673, 'lmbda': 0.8665226382116956}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:06,066]\u001B[0m Trial 23 finished with value: 0.6531599602878279 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005579255446827411, 'lmbda': 0.8815060757965248}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:13,332]\u001B[0m Trial 24 finished with value: 0.44646007584844505 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005629847755283986, 'lmbda': 0.874422766866934}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:20,543]\u001B[0m Trial 25 finished with value: 0.5993262210114948 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005480824902733809, 'lmbda': 0.8986666417953028}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:27,688]\u001B[0m Trial 26 finished with value: 0.4538085564885329 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005193989857061734, 'lmbda': 0.6258644288836346}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:34,921]\u001B[0m Trial 27 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005801245357984338, 'lmbda': 0.6715767611852927}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:39,105]\u001B[0m Trial 28 finished with value: 0.5268956705260043 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0069465975253214735, 'lmbda': 0.9314023774876363}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:28:52,168]\u001B[0m Trial 29 finished with value: 0.4068201635890796 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007563496228865945, 'lmbda': 0.8406208395520995}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:29:16,963]\u001B[0m Trial 30 finished with value: 0.6687845148272553 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006271950847036484, 'lmbda': 0.694489393252215}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:29:40,446]\u001B[0m Trial 31 finished with value: 0.45993310550389993 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006239980000325295, 'lmbda': 0.7278393611411589}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:30:05,276]\u001B[0m Trial 32 finished with value: 0.3530939318018998 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.0053698239939634195, 'lmbda': 0.8006520104912613}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:30:29,451]\u001B[0m Trial 33 finished with value: 0.31101772641409176 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005880489610166375, 'lmbda': 0.5637414147415915}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:30:53,927]\u001B[0m Trial 34 finished with value: 0.4053217416888888 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006791755355245423, 'lmbda': 0.8745705686723478}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:31:18,683]\u001B[0m Trial 35 finished with value: 0.46598589800857404 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00547089389377653, 'lmbda': 0.43920300936362683}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:31:25,966]\u001B[0m Trial 36 finished with value: 0.5340273262532407 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.00626513444004295, 'lmbda': 0.7019719962986718}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:31:50,743]\u001B[0m Trial 37 finished with value: 0.31622776601683794 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.009716990133253917, 'lmbda': 0.9284752775495867}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:31:57,830]\u001B[0m Trial 38 finished with value: 0.291976304591905 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007322759679594388, 'lmbda': 0.85075705177038}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:11,078]\u001B[0m Trial 39 finished with value: 0.44225358709016444 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005716405903194247, 'lmbda': 0.7754245371986532}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:14,747]\u001B[0m Trial 40 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.008864930770384197, 'lmbda': 0.31739388912857625}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:21,715]\u001B[0m Trial 41 finished with value: 0.3993049516903647 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006437977256547097, 'lmbda': 0.9825274591978589}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:29,051]\u001B[0m Trial 42 finished with value: 0.412310562561766 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006451257566107236, 'lmbda': 0.9911119519084421}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:36,286]\u001B[0m Trial 43 finished with value: 0.34307921721126833 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005270860003698604, 'lmbda': 0.9283724322563374}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:40,248]\u001B[0m Trial 44 finished with value: 0.3086066999241838 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0059599283539597155, 'lmbda': 0.9473935189475895}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:47,198]\u001B[0m Trial 45 finished with value: 0.291976304591905 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.00708859879762156, 'lmbda': 0.8919494047250168}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:32:54,429]\u001B[0m Trial 46 finished with value: 0.404189292234739 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006232504962900997, 'lmbda': 0.6700614183543238}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:33:00,206]\u001B[0m Trial 47 finished with value: 0.573488351136175 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00671697838937101, 'lmbda': 0.9995183700396562}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:33:25,062]\u001B[0m Trial 48 finished with value: 0.34307921721126833 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005567507231520457, 'lmbda': 0.8102722745962214}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:33:32,178]\u001B[0m Trial 49 finished with value: 0.5296749527356902 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0052021590449496235, 'lmbda': 0.7447377803381698}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:33:45,489]\u001B[0m Trial 50 finished with value: 0.48608076469237244 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005804321645859853, 'lmbda': 0.8160388703179108}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:33:52,824]\u001B[0m Trial 51 finished with value: 0.6351686023719635 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006109500649769599, 'lmbda': 0.7629593303423617}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:33:59,993]\u001B[0m Trial 52 finished with value: 0.43779751788545657 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006079096866015148, 'lmbda': 0.7195362155299381}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:07,112]\u001B[0m Trial 53 finished with value: 0.5913317196078518 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.006402895199652933, 'lmbda': 0.8646460902892388}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:14,264]\u001B[0m Trial 54 finished with value: 0.5502567094655532 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005003884764913221, 'lmbda': 0.7842729142037776}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:21,388]\u001B[0m Trial 55 finished with value: 0.6614078299055111 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006032570080914239, 'lmbda': 0.018161273089893737}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:28,522]\u001B[0m Trial 56 finished with value: 0.5543478937468667 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005468484954159697, 'lmbda': 0.035242281038954146}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:35,714]\u001B[0m Trial 57 finished with value: 0.4447383588045985 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0060486279180994255, 'lmbda': 0.09024946437061636}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:42,873]\u001B[0m Trial 58 finished with value: 0.5569664623760037 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.008334507212451901, 'lmbda': 0.3009916043361909}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:34:50,098]\u001B[0m Trial 59 finished with value: 0.5521562670203758 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005621697950235539, 'lmbda': 0.5684000062367152}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:35:14,567]\u001B[0m Trial 60 finished with value: 0.38490017945975047 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.005805294546235909, 'lmbda': 0.1325621568226941}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:35:21,916]\u001B[0m Trial 61 finished with value: 0.3079201435678004 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0065649632365777965, 'lmbda': 0.9481286033916185}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:35:29,095]\u001B[0m Trial 62 finished with value: 0.5795911713664433 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006247613114388341, 'lmbda': 0.9044864757131483}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:35:36,270]\u001B[0m Trial 63 finished with value: 0.6098724821177329 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006900992728495986, 'lmbda': 0.8333019455802315}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:35:43,475]\u001B[0m Trial 64 finished with value: 0.4774845054988204 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00607472915381216, 'lmbda': 0.22974680194542746}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:35:50,723]\u001B[0m Trial 65 finished with value: 0.513099995067503 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0053527005679590315, 'lmbda': 0.46202918187058534}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:36:04,051]\u001B[0m Trial 66 finished with value: 0.47919685895217384 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006608124585056924, 'lmbda': 0.6440967149716361}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:36:11,025]\u001B[0m Trial 67 finished with value: 0.42745297914825214 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0051598912969538935, 'lmbda': 0.7684884732124924}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:36:35,270]\u001B[0m Trial 68 finished with value: 0.44909721852658097 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005911187085029855, 'lmbda': 0.5913254157717861}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:36:42,558]\u001B[0m Trial 69 finished with value: 0.3530939318018998 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005716132341811496, 'lmbda': 0.7438533127889975}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:36:50,055]\u001B[0m Trial 70 finished with value: 0.48608076469237244 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005466363736064424, 'lmbda': 0.8996707284772455}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:36:57,197]\u001B[0m Trial 71 finished with value: 0.577991413495109 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006321799794245518, 'lmbda': 0.8452504530127494}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:37:04,451]\u001B[0m Trial 72 finished with value: 0.49938233453876074 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0060877665395213335, 'lmbda': 0.6900033032252375}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:37:11,647]\u001B[0m Trial 73 finished with value: 0.5141106537602235 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 2, 'lr': 0.005902928742224283, 'lmbda': 0.7902459019684851}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:37:18,798]\u001B[0m Trial 74 finished with value: 0.5378282804569311 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005632445012914042, 'lmbda': 0.8663573681762302}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:37:43,343]\u001B[0m Trial 75 finished with value: 0.4981447060324421 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.007660269450272962, 'lmbda': 0.964256633199218}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:37:50,584]\u001B[0m Trial 76 finished with value: 0.4822486211112817 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006802861467445858, 'lmbda': 0.823016373876478}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:38:03,801]\u001B[0m Trial 77 finished with value: 0.6521009816245412 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006127181224647442, 'lmbda': 0.7107097256250502}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:38:17,118]\u001B[0m Trial 78 finished with value: 0.40871194568479957 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006338063908287313, 'lmbda': 0.6644417892158277}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:38:30,773]\u001B[0m Trial 79 finished with value: 0.28344643293200983 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006187475440154537, 'lmbda': 0.3592571233220405}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:38:43,925]\u001B[0m Trial 80 finished with value: 0.6263819221164612 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005831992166048333, 'lmbda': 0.7180371875728382}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:38:57,118]\u001B[0m Trial 81 finished with value: 0.538496252083174 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005827915377430141, 'lmbda': 0.7095297698534374}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:39:10,311]\u001B[0m Trial 82 finished with value: 0.39699161097092034 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005960079206275823, 'lmbda': 0.7387286776964814}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:39:23,637]\u001B[0m Trial 83 finished with value: 0.5747199581561704 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005428745156715714, 'lmbda': 0.6315434675924612}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:39:36,875]\u001B[0m Trial 84 finished with value: 0.5887638742179041 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005711890370087025, 'lmbda': 0.9184561260203685}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:39:50,258]\u001B[0m Trial 85 finished with value: 0.5868938953886336 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005532331703096854, 'lmbda': 0.6952353973445072}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:40:03,618]\u001B[0m Trial 86 finished with value: 0.46004370622823615 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006487100904881955, 'lmbda': 0.6079260964171123}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:40:16,865]\u001B[0m Trial 87 finished with value: 0.44365008376579496 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005305003737759478, 'lmbda': 0.7609824605573863}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:40:41,603]\u001B[0m Trial 88 finished with value: 0.5887638742179041 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005765740108203168, 'lmbda': 0.7958393637121304}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:40:54,836]\u001B[0m Trial 89 finished with value: 0.5925462944877059 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005982507141704235, 'lmbda': 0.0027913513224275266}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:41:19,325]\u001B[0m Trial 90 finished with value: 0.43761086363784 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006132588818139825, 'lmbda': 0.8826776272345945}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:41:26,490]\u001B[0m Trial 91 finished with value: 0.5543478937468667 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006383163415704003, 'lmbda': 0.7614431465824163}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:41:33,916]\u001B[0m Trial 92 finished with value: 0.5470719781598663 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00622159860055087, 'lmbda': 0.6590767893101157}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:41:40,994]\u001B[0m Trial 93 finished with value: 0.313370480742935 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006629117053517275, 'lmbda': 0.7204450375297599}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:41:48,158]\u001B[0m Trial 94 finished with value: 0.51279914485397 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.005132381864231986, 'lmbda': 0.5342615749357518}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:41:55,297]\u001B[0m Trial 95 finished with value: 0.4452126297784978 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00560658369619729, 'lmbda': 0.8541439081207955}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:42:02,440]\u001B[0m Trial 96 finished with value: 0.3333333333333333 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006123738196001408, 'lmbda': 0.8080352908830104}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:42:09,565]\u001B[0m Trial 97 finished with value: 0.5072129308928917 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009394737002473192, 'lmbda': 0.6787898704751344}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:42:16,668]\u001B[0m Trial 98 finished with value: 0.37045989963899906 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005877332125054154, 'lmbda': 0.779207479246167}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:42:29,776]\u001B[0m Trial 99 finished with value: 0.34318767136623335 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.006013411015333056, 'lmbda': 0.8270559403375236}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:42:52,965]\u001B[0m Trial 100 finished with value: 0.5458840701004363 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006514063614290596, 'lmbda': 0.9465345662526429}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:00,086]\u001B[0m Trial 101 finished with value: 0.39852669849304284 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0068927852757913, 'lmbda': 0.8365453576213583}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:07,465]\u001B[0m Trial 102 finished with value: 0.46352392238063883 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006319840593027178, 'lmbda': 0.7390682786362885}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:14,591]\u001B[0m Trial 103 finished with value: 0.6409318612720472 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007113439364021142, 'lmbda': 0.7582638160593801}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:21,798]\u001B[0m Trial 104 finished with value: 0.5401025443167483 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007165474923976769, 'lmbda': 0.7097014694757311}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:28,959]\u001B[0m Trial 105 finished with value: 0.4844379575137921 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0057392053376347524, 'lmbda': 0.7563319331010897}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:36,301]\u001B[0m Trial 106 finished with value: 0.337099931231621 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007853296238788691, 'lmbda': 0.7919291243676676}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:43,483]\u001B[0m Trial 107 finished with value: 0.5303820459239246 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006674995281160406, 'lmbda': 0.6472201962677235}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:50,736]\u001B[0m Trial 108 finished with value: 0.5925462944877059 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006005440535228145, 'lmbda': 0.24439880554471677}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:43:57,953]\u001B[0m Trial 109 finished with value: 0.443471156521669 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005546362000850054, 'lmbda': 0.9679225215324817}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:44:05,221]\u001B[0m Trial 110 finished with value: 0.404189292234739 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.006161916875612961, 'lmbda': 0.7275508572349625}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:44:12,351]\u001B[0m Trial 111 finished with value: 0.40081686672863537 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007326896038635205, 'lmbda': 0.8814562865423232}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:44:19,015]\u001B[0m Trial 112 finished with value: 0.48468611999997996 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007072929344870892, 'lmbda': 0.8144566363168464}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:44:26,200]\u001B[0m Trial 113 finished with value: 0.4355255901580752 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006789132115181816, 'lmbda': 0.8353833097776711}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:44:33,408]\u001B[0m Trial 114 finished with value: 0.4031128874149275 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00740575942547049, 'lmbda': 0.15341338632015597}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:44:40,774]\u001B[0m Trial 115 finished with value: 0.551848744709125 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006917736447975548, 'lmbda': 0.7660660077468566}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:45:05,299]\u001B[0m Trial 116 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005863626719370355, 'lmbda': 0.9168945641153395}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:45:18,464]\u001B[0m Trial 117 finished with value: 0.420883424647321 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005692219082883015, 'lmbda': 0.696714886863503}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:45:25,951]\u001B[0m Trial 118 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006491015637881872, 'lmbda': 0.8595788280188927}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:45:33,079]\u001B[0m Trial 119 finished with value: 0.48996667240470554 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006271019975379079, 'lmbda': 0.7804197418111088}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:45:46,176]\u001B[0m Trial 120 finished with value: 0.2924988129130707 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.007226443095241658, 'lmbda': 0.8035146692057504}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:45:53,446]\u001B[0m Trial 121 finished with value: 0.5354126134736337 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006352912218771581, 'lmbda': 0.9464400927351738}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:46:00,662]\u001B[0m Trial 122 finished with value: 0.49320077697110454 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006427400556968238, 'lmbda': 0.9676154188269396}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:46:02,689]\u001B[0m Trial 123 finished with value: 0.3651483716701107 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006572646675533983, 'lmbda': 0.7532515964546679}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:46:10,065]\u001B[0m Trial 124 finished with value: 0.499876527964533 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0067400083847316316, 'lmbda': 0.4823752984719044}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:46:17,257]\u001B[0m Trial 125 finished with value: 0.337099931231621 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005386016988251295, 'lmbda': 0.9903521141368501}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:46:41,505]\u001B[0m Trial 126 finished with value: 0.4583677673015524 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006085742182153776, 'lmbda': 0.894564013829599}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:46:48,588]\u001B[0m Trial 127 finished with value: 0.5333333333333333 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0061866732648622625, 'lmbda': 0.7303998699656877}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:01,749]\u001B[0m Trial 128 finished with value: 0.5436301767407516 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005932424165697551, 'lmbda': 0.915845711539399}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:08,860]\u001B[0m Trial 129 finished with value: 0.36313651960128146 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006844666202060243, 'lmbda': 0.40669608941624075}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:16,116]\u001B[0m Trial 130 finished with value: 0.5497276013898588 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005784617299411302, 'lmbda': 0.8697345052875609}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:23,388]\u001B[0m Trial 131 finished with value: 0.31954383440814826 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007045997857763706, 'lmbda': 0.8528089922706994}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:30,617]\u001B[0m Trial 132 finished with value: 0.5758289219624358 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005258816972876101, 'lmbda': 0.9776607096737382}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:37,939]\u001B[0m Trial 133 finished with value: 0.5747199581561704 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005602057768953101, 'lmbda': 0.9407365371523613}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:45,409]\u001B[0m Trial 134 finished with value: 0.5228688295026747 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005503474174766328, 'lmbda': 0.8963853248493324}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:47:52,586]\u001B[0m Trial 135 finished with value: 0.5887638742179041 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0062564321963828285, 'lmbda': 0.8208189074078532}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:48:17,185]\u001B[0m Trial 136 finished with value: 0.5082650227325636 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005380958557532941, 'lmbda': 0.7849503499150664}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:48:24,458]\u001B[0m Trial 137 finished with value: 0.4840033669916556 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.005828543129022227, 'lmbda': 0.9258640114129658}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:48:37,649]\u001B[0m Trial 138 finished with value: 0.48879975420361393 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006028642315979634, 'lmbda': 0.8350224212430725}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:48:44,932]\u001B[0m Trial 139 finished with value: 0.6152739970966333 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00508152172862613, 'lmbda': 0.6746161966432518}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:48:52,189]\u001B[0m Trial 140 finished with value: 0.5747199581561704 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0064124155691360485, 'lmbda': 0.6025492055199437}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:48:59,531]\u001B[0m Trial 141 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005079303628925923, 'lmbda': 0.6709700665297059}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:06,830]\u001B[0m Trial 142 finished with value: 0.5155004759849798 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005192224642985706, 'lmbda': 0.9983207694202662}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:14,165]\u001B[0m Trial 143 finished with value: 0.562813698535545 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00528270967706312, 'lmbda': 0.7095161228461704}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:21,526]\u001B[0m Trial 144 finished with value: 0.5800432884278693 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005457385872055017, 'lmbda': 0.747693158637512}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:24,921]\u001B[0m Trial 145 finished with value: 0.41573970964154905 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.007600291390831228, 'lmbda': 0.7224052470883541}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:31,912]\u001B[0m Trial 146 finished with value: 0.3855959161172688 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0056780393376799874, 'lmbda': 0.6935861789579306}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:39,899]\u001B[0m Trial 147 finished with value: 0.420883424647321 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006109831263114124, 'lmbda': 0.8032639246881867}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:49:46,922]\u001B[0m Trial 148 finished with value: 0.5390893098092535 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005025090634725783, 'lmbda': 0.6809273654644511}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:11,499]\u001B[0m Trial 149 finished with value: 0.5470719781598663 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005922549164598795, 'lmbda': 0.773263025031338}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:18,670]\u001B[0m Trial 150 finished with value: 0.6622073078111707 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006172185053626746, 'lmbda': 0.6295977998230283}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:26,016]\u001B[0m Trial 151 finished with value: 0.38873012632302 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006290971552910278, 'lmbda': 0.6600381094630469}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:33,129]\u001B[0m Trial 152 finished with value: 0.4772987414590597 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0061795532805252375, 'lmbda': 0.6211339996344233}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:40,216]\u001B[0m Trial 153 finished with value: 0.5600925849390471 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005977847947298241, 'lmbda': 0.7237732921183105}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:47,310]\u001B[0m Trial 154 finished with value: 0.5018484351393873 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006547845873688699, 'lmbda': 0.5579418327274399}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:50:54,692]\u001B[0m Trial 155 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006069532548272606, 'lmbda': 0.7420722413903342}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:01,951]\u001B[0m Trial 156 finished with value: 0.33166247903554 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0055671942474978505, 'lmbda': 0.631683373794555}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:09,129]\u001B[0m Trial 157 finished with value: 0.562813698535545 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005782565280732445, 'lmbda': 0.6854251164395209}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:22,312]\u001B[0m Trial 158 finished with value: 0.3107751543820654 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006641909779114481, 'lmbda': 0.6494537816393272}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:29,409]\u001B[0m Trial 159 finished with value: 0.4973631059243991 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006363592236464055, 'lmbda': 0.8703072426330253}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:36,692]\u001B[0m Trial 160 finished with value: 0.5064111390119689 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.0058803926379058565, 'lmbda': 0.7603324714392686}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:43,893]\u001B[0m Trial 161 finished with value: 0.5458840701004363 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0060392900855533544, 'lmbda': 0.742436579952256}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:51,215]\u001B[0m Trial 162 finished with value: 0.4714045207910316 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005133056037313911, 'lmbda': 0.7094588673038738}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:51:58,616]\u001B[0m Trial 163 finished with value: 0.7244109619753591 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005100636646603712, 'lmbda': 0.678114333409897}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:52:05,914]\u001B[0m Trial 164 finished with value: 0.58309518948453 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0053535600787639765, 'lmbda': 0.6758613596118579}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:52:13,203]\u001B[0m Trial 165 finished with value: 0.5409182864283593 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00523514660082321, 'lmbda': 0.7866814891914725}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:52:20,483]\u001B[0m Trial 166 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006199817005106442, 'lmbda': 0.8237952036494216}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:52:34,780]\u001B[0m Trial 167 finished with value: 0.22871947814084556 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 3, 'lr': 0.005668791147609981, 'lmbda': 0.850555183015489}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:52:41,917]\u001B[0m Trial 168 finished with value: 0.5805489101161392 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005020642198215365, 'lmbda': 0.9597692697762359}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:52:55,203]\u001B[0m Trial 169 finished with value: 0.538496252083174 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006456508493313981, 'lmbda': 0.6985767757386628}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:53:02,228]\u001B[0m Trial 170 finished with value: 0.3724032901658037 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.0054969153098828666, 'lmbda': 0.909531415547714}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:53:09,425]\u001B[0m Trial 171 finished with value: 0.45877684169560096 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006112521933781792, 'lmbda': 0.7490431782924158}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:53:16,707]\u001B[0m Trial 172 finished with value: 0.4902758105091158 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006205761412651704, 'lmbda': 0.806079052890067}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:53:23,728]\u001B[0m Trial 173 finished with value: 0.49894625804895326 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00598454968849529, 'lmbda': 0.730044375174266}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:53:48,159]\u001B[0m Trial 174 finished with value: 0.530498417932204 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005884389835280184, 'lmbda': 0.8894675025869346}. Best is trial 22 with value: 0.788262662246131.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:53:55,427]\u001B[0m Trial 175 finished with value: 0.8122794961083161 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006089141708792908, 'lmbda': 0.7734639049956569}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:02,642]\u001B[0m Trial 176 finished with value: 0.6327900761099848 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006296503532525699, 'lmbda': 0.26739711355483065}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:09,969]\u001B[0m Trial 177 finished with value: 0.6633249580710799 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006317253258072287, 'lmbda': 0.18404532669570695}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:17,183]\u001B[0m Trial 178 finished with value: 0.47466687473986285 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0063076609516214705, 'lmbda': 0.27769608427162207}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:24,347]\u001B[0m Trial 179 finished with value: 0.5747199581561704 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006253985992088482, 'lmbda': 0.09753056889653497}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:31,523]\u001B[0m Trial 180 finished with value: 0.4824065188020536 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006146847149984672, 'lmbda': 0.3738609193452914}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:38,615]\u001B[0m Trial 181 finished with value: 0.4874075682282104 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006400888445881015, 'lmbda': 0.1961201742552447}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:45,743]\u001B[0m Trial 182 finished with value: 0.5635275972181937 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006498854413682972, 'lmbda': 0.06518228014356048}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:54:52,850]\u001B[0m Trial 183 finished with value: 0.45682541379553165 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006338130038424572, 'lmbda': 0.4307275820298416}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:00,092]\u001B[0m Trial 184 finished with value: 0.508844336632097 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006068508443999192, 'lmbda': 0.05581531091039344}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:07,324]\u001B[0m Trial 185 finished with value: 0.5548606765399494 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006991116952856818, 'lmbda': 0.15751124739844818}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:14,505]\u001B[0m Trial 186 finished with value: 0.5462837412242157 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006234643348408512, 'lmbda': 0.2647801979965627}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:27,768]\u001B[0m Trial 187 finished with value: 0.4549841557797173 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006708007446008688, 'lmbda': 0.0021319453795388965}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:34,909]\u001B[0m Trial 188 finished with value: 0.6018490028422595 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.00596910821630919, 'lmbda': 0.7748813792055632}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:42,334]\u001B[0m Trial 189 finished with value: 0.47561625940544355 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007455573309662353, 'lmbda': 0.3312501349959329}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:49,423]\u001B[0m Trial 190 finished with value: 0.4991834824832941 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006131949535571216, 'lmbda': 0.7041485188546832}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:55:56,687]\u001B[0m Trial 191 finished with value: 0.5244044240850758 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.005965842324074112, 'lmbda': 0.7700844995530783}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:03,857]\u001B[0m Trial 192 finished with value: 0.491082086989147 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0063192508003522135, 'lmbda': 0.7849701720432901}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:11,041]\u001B[0m Trial 193 finished with value: 0.48879975420361393 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006015998047538132, 'lmbda': 0.13570557684830123}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:18,155]\u001B[0m Trial 194 finished with value: 0.4772607021092118 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.0057865706851233205, 'lmbda': 0.7634425380571863}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:25,316]\u001B[0m Trial 195 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.008606241372313904, 'lmbda': 0.8021918627156889}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:32,379]\u001B[0m Trial 196 finished with value: 0.554109228435186 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.006437671289913656, 'lmbda': 0.7301995172238746}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:39,646]\u001B[0m Trial 197 finished with value: 0.47531665858238753 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006189788222354739, 'lmbda': 0.6631043334852199}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:56:52,827]\u001B[0m Trial 198 finished with value: 0.49867549436206376 and parameters: {'hidden_layer': 64, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.0071398232820447365, 'lmbda': 0.2151390206828629}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:00,111]\u001B[0m Trial 199 finished with value: 0.43782223754431626 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.005900390888403022, 'lmbda': 0.5826914854168428}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:04,305]\u001B[0m Trial 200 finished with value: 0.6110100926607787 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009971289392262356, 'lmbda': 0.5087334293222204}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:06,912]\u001B[0m Trial 201 finished with value: 0.5113685182896591 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009419884352102014, 'lmbda': 0.7116631946036943}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:13,879]\u001B[0m Trial 202 finished with value: 0.6276648476870316 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009758739964927116, 'lmbda': 0.7609835712956875}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:18,182]\u001B[0m Trial 203 finished with value: 0.5747199581561704 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009994398612231208, 'lmbda': 0.6891920615572935}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:21,426]\u001B[0m Trial 204 finished with value: 0.4221434924348926 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009878397455537802, 'lmbda': 0.48847384639266556}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:28,590]\u001B[0m Trial 205 finished with value: 0.6820129120481779 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007317424823547027, 'lmbda': 0.7515113506884183}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:35,664]\u001B[0m Trial 206 finished with value: 0.6209312003399052 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007251581700195654, 'lmbda': 0.7667360291421456}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:42,744]\u001B[0m Trial 207 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007272205087808686, 'lmbda': 0.7385040733341393}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:57:49,766]\u001B[0m Trial 208 finished with value: 0.39581140290126393 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007866532555037503, 'lmbda': 0.5398194167312054}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:14,347]\u001B[0m Trial 209 finished with value: 0.44095855184409843 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009638084825864314, 'lmbda': 0.7640518032747364}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:21,554]\u001B[0m Trial 210 finished with value: 0.485912657903775 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007342074407827548, 'lmbda': 0.7200682577470907}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:25,643]\u001B[0m Trial 211 finished with value: 0.5055642069607709 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009824480882683282, 'lmbda': 0.7505388055865204}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:32,863]\u001B[0m Trial 212 finished with value: 0.6903658003345798 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007128058049525462, 'lmbda': 0.45748636809722654}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:39,916]\u001B[0m Trial 213 finished with value: 0.6981456921068893 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007236462997797683, 'lmbda': 0.44474445993156175}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:46,971]\u001B[0m Trial 214 finished with value: 0.5458840701004363 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007500479285998259, 'lmbda': 0.45127190150409235}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:58:54,432]\u001B[0m Trial 215 finished with value: 0.3913539251583432 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007136800375862522, 'lmbda': 0.35893637937824885}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:01,659]\u001B[0m Trial 216 finished with value: 0.5570484990582331 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007242300932297429, 'lmbda': 0.47438186224754986}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:07,766]\u001B[0m Trial 217 finished with value: 0.5481450200110942 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007336579219676483, 'lmbda': 0.4326579932538799}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:14,810]\u001B[0m Trial 218 finished with value: 0.30281331944409007 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006971419779062593, 'lmbda': 0.7943112923617948}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:21,867]\u001B[0m Trial 219 finished with value: 0.6416125518306719 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007699637908087296, 'lmbda': 0.7560119557275897}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:25,644]\u001B[0m Trial 220 finished with value: 0.6080075678923569 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008550711088001957, 'lmbda': 0.1796079596165937}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:32,751]\u001B[0m Trial 221 finished with value: 0.5266407004309744 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008820566308060678, 'lmbda': 0.752312137544591}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:39,999]\u001B[0m Trial 222 finished with value: 0.47299628983331193 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007247603552544604, 'lmbda': 0.3906738033436029}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:47,235]\u001B[0m Trial 223 finished with value: 0.5928347083740892 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007729833855030794, 'lmbda': 0.7771898540792993}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 02:59:54,525]\u001B[0m Trial 224 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00813537874269496, 'lmbda': 0.7273600063039819}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:00,824]\u001B[0m Trial 225 finished with value: 0.5708992257184501 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007396095920751957, 'lmbda': 0.7464838178894102}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:08,036]\u001B[0m Trial 226 finished with value: 0.5403473962572368 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007075870971349666, 'lmbda': 0.7103975135249424}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:15,117]\u001B[0m Trial 227 finished with value: 0.40739909913256556 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009009860206363818, 'lmbda': 0.30135139344551887}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:22,462]\u001B[0m Trial 228 finished with value: 0.33333333333333337 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.00721782700818221, 'lmbda': 0.6882357051401625}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:32,000]\u001B[0m Trial 229 finished with value: 0.4120977570959453 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 2, 'lr': 0.00717517846669256, 'lmbda': 0.6434142056467024}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:40,461]\u001B[0m Trial 230 finished with value: 0.46900252660659514 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007529197548955556, 'lmbda': 0.7672741608728217}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:44,464]\u001B[0m Trial 231 finished with value: 0.3194476226640778 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009887124038614841, 'lmbda': 0.4931046760113146}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:51,600]\u001B[0m Trial 232 finished with value: 0.5244044240850758 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005146066707715411, 'lmbda': 0.4644101236077426}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:00:58,795]\u001B[0m Trial 233 finished with value: 0.5321166677977192 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.008055037692420927, 'lmbda': 0.5231118031172657}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:06,094]\u001B[0m Trial 234 finished with value: 0.5569664623760037 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.00835825401355163, 'lmbda': 0.41304426930143817}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:09,876]\u001B[0m Trial 235 finished with value: 0.611911832068611 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009559310410799226, 'lmbda': 0.5109027544699879}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:17,052]\u001B[0m Trial 236 finished with value: 0.5106277908033803 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009675094252457963, 'lmbda': 0.03546302725299773}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:21,700]\u001B[0m Trial 237 finished with value: 0.30971910810591896 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009516780949562934, 'lmbda': 0.337803863761688}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:28,836]\u001B[0m Trial 238 finished with value: 0.34167540363327853 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.009243118298140632, 'lmbda': 0.7874392777012044}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:32,306]\u001B[0m Trial 239 finished with value: 0.5055642069607709 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009773028864011001, 'lmbda': 0.7400545799898696}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:39,346]\u001B[0m Trial 240 finished with value: 0.41690469391639595 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0061102302682469025, 'lmbda': 0.6138284751600867}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:43,585]\u001B[0m Trial 241 finished with value: 0.521749194749951 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009958507738395227, 'lmbda': 0.5119399658151018}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:50,733]\u001B[0m Trial 242 finished with value: 0.5548606765399494 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.006269195812972344, 'lmbda': 0.5035958076483558}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:01:57,408]\u001B[0m Trial 243 finished with value: 0.5987641593469991 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007409693071579748, 'lmbda': 0.5331317935619992}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:04,585]\u001B[0m Trial 244 finished with value: 0.4823391671062556 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.0057081871643078, 'lmbda': 0.671712570001961}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:08,739]\u001B[0m Trial 245 finished with value: 0.39247981354510963 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009550692858312095, 'lmbda': 0.7609001943149485}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:15,966]\u001B[0m Trial 246 finished with value: 0.462481230850387 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006182196064645513, 'lmbda': 0.5570149032878668}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:23,144]\u001B[0m Trial 247 finished with value: 0.5673198849430997 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.007061818936967515, 'lmbda': 0.4484489199479421}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:36,326]\u001B[0m Trial 248 finished with value: 0.5453507196359123 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00972969363837534, 'lmbda': 0.7130149628090205}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:43,646]\u001B[0m Trial 249 finished with value: 0.5758289219624358 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006061990453025439, 'lmbda': 0.10324303442232234}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:50,882]\u001B[0m Trial 250 finished with value: 0.4240572619393621 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009882294808727099, 'lmbda': 0.7257826927697919}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:02:58,089]\u001B[0m Trial 251 finished with value: 0.6068631050598053 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005089482620148463, 'lmbda': 0.8037100786863182}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:03:22,565]\u001B[0m Trial 252 finished with value: 0.40073461953531997 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005581352603772459, 'lmbda': 0.7779444870778285}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:03:29,981]\u001B[0m Trial 253 finished with value: 0.3054721308482779 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006297312565243965, 'lmbda': 0.7534265908357557}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:03:37,134]\u001B[0m Trial 254 finished with value: 0.492392264815505 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005285901830658409, 'lmbda': 0.7018378369416552}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:03:44,381]\u001B[0m Trial 255 finished with value: 0.49065338146265813 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007286857057206233, 'lmbda': 0.7323083906379819}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:03:51,584]\u001B[0m Trial 256 finished with value: 0.4448356863818233 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.005860452943235137, 'lmbda': 0.6551398729400627}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:04,899]\u001B[0m Trial 257 finished with value: 0.4608098078517271 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005418547784502224, 'lmbda': 0.7664172225620898}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:12,217]\u001B[0m Trial 258 finished with value: 0.4469956020210052 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.006141597541920747, 'lmbda': 0.26152845549600534}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:19,470]\u001B[0m Trial 259 finished with value: 0.6416125518306719 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005003967596970488, 'lmbda': 0.6822530114886682}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:26,666]\u001B[0m Trial 260 finished with value: 0.5311515523799737 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005022624012820451, 'lmbda': 0.6787501065866498}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:33,962]\u001B[0m Trial 261 finished with value: 0.5340273262532407 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005138601227784778, 'lmbda': 0.6791248964457122}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:41,225]\u001B[0m Trial 262 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005238359584546673, 'lmbda': 0.7178846518383043}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:04:48,400]\u001B[0m Trial 263 finished with value: 0.4844379575137921 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.00518405886620767, 'lmbda': 0.6347125360355006}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:05:13,109]\u001B[0m Trial 264 finished with value: 0.29814239699997197 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.005081265111298306, 'lmbda': 0.7924106155168384}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:05:26,613]\u001B[0m Trial 265 finished with value: 0.5969420987675821 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005007375969603414, 'lmbda': 0.6939603927546919}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:05:31,594]\u001B[0m Trial 266 finished with value: 0.5527707983925666 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.006009096280227242, 'lmbda': 0.74249972605772}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:05:38,903]\u001B[0m Trial 267 finished with value: 0.6638830776128736 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007132303430979777, 'lmbda': 0.8208510875507471}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:05:46,190]\u001B[0m Trial 268 finished with value: 0.6110100926607787 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.00715014964405416, 'lmbda': 0.8167927986151678}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:05:53,411]\u001B[0m Trial 269 finished with value: 0.6531599602878279 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007321786323126197, 'lmbda': 0.8360948220178973}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:00,750]\u001B[0m Trial 270 finished with value: 0.45133546692422 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.006991083892020666, 'lmbda': 0.8326323925433741}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:08,010]\u001B[0m Trial 271 finished with value: 0.38315459141851343 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007344119865277704, 'lmbda': 0.8101986171485229}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:15,350]\u001B[0m Trial 272 finished with value: 0.6200358412579424 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007207927010614411, 'lmbda': 0.8518201865567914}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:22,626]\u001B[0m Trial 273 finished with value: 0.5323821928091443 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007152386624354734, 'lmbda': 0.8465728588188427}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:29,822]\u001B[0m Trial 274 finished with value: 0.42860670048857574 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 3, 'lr': 0.007344048892593306, 'lmbda': 0.8736372033494747}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:43,355]\u001B[0m Trial 275 finished with value: 0.538496252083174 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.0068905615496081905, 'lmbda': 0.8373428859133876}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:50,584]\u001B[0m Trial 276 finished with value: 0.6655546280831972 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007600317952828338, 'lmbda': 0.847976749866562}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 03:06:57,848]\u001B[0m Trial 277 finished with value: 0.4714045207910317 and parameters: {'hidden_layer': 128, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 3, 'lr': 0.007496769753982161, 'lmbda': 0.869956769504134}. Best is trial 175 with value: 0.8122794961083161.\u001B[0m\n",
      "\u001B[33m[W 2022-11-08 03:06:58,689]\u001B[0m Trial 278 failed because of the following error: CatBoostError('C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored.')\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\", line 48, in objective\n",
      "    _, [train_acc_mi, test_acc_mi,val_acc_mi], [train_acc_ma, test_acc_ma,val_acc_ma] = self.test(model=model, data=self.data)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\", line 113, in test\n",
      "    eval_set = (out.cpu().detach()[self.val_mask].numpy(), self.y.detach()[self.val_mask].cpu().numpy())\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\", line 5130, in fit\n",
      "    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\", line 2360, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored.\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\582067259.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m                 \u001B[0mMO\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMainOptuna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'unsupervised'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m                 \u001B[0mbest_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMO\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m500\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m                 \u001B[0mloss_trgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, number_of_trials)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mstudy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"maximize\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstudy_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Name\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" loss,\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_trials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m         \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    426\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m             \u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    429\u001B[0m         )\n\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0mprogress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             )\n\u001B[0;32m     78\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m             \u001B[0mfrozen_trial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     ):\n\u001B[1;32m--> 234\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mLossSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss_to_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m         \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\u001B[0m in \u001B[0;36mtest\u001B[1;34m(self, model, data)\u001B[0m\n\u001B[0;32m    111\u001B[0m                 \u001B[1;31m#clf = LogisticRegression(max_iter = 3000,C=c).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m                 clf = CatBoostClassifier(logging_level='Silent').fit(out.cpu().detach()[self.train_mask].numpy(),self.y.detach()[self.train_mask].cpu().numpy(),\n\u001B[1;32m--> 113\u001B[1;33m                         \u001B[0meval_set\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m                      )\n\u001B[0;32m    115\u001B[0m                 \u001B[0maccs_micro\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   5128\u001B[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001B[0;32m   5129\u001B[0m                   \u001B[0meval_set\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogging_level\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumn_description\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose_eval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric_period\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5130\u001B[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001B[0m\u001B[0;32m   5131\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5132\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   2358\u001B[0m                 \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2359\u001B[0m                 \u001B[0mallow_clear_pool\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2360\u001B[1;33m                 \u001B[0mtrain_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"init_model\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2361\u001B[0m             )\n\u001B[0;32m   2362\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_train\u001B[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1758\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_clear_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minit_model\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1759\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_object\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_clear_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minit_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_object\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0minit_model\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1760\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_trained_model_attributes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1761\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_catboost.pyx\u001B[0m in \u001B[0;36m_catboost._CatBoost._train\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_catboost.pyx\u001B[0m in \u001B[0;36m_catboost._CatBoost._train\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mCatBoostError\u001B[0m: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored."
     ]
    }
   ],
   "source": [
    "loss = LapEigen\n",
    "loss_name = 'LapEigen'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "\n",
    "for name in datasets_names[:2]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-08 12:10:33,131]\u001B[0m A new study created in memory with name: HOPE_CommonNeighbors loss,GCN conv\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:11:04,790]\u001B[0m Trial 0 finished with value: 0.2193425501870036 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.009241288423042414, 'lmbda': 0.2331214395594492}. Best is trial 0 with value: 0.2193425501870036.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:11:33,534]\u001B[0m Trial 1 finished with value: 0.2435382709999983 and parameters: {'hidden_layer': 256, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009177299100031424, 'lmbda': 0.1941686293388779}. Best is trial 1 with value: 0.2435382709999983.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:12:02,407]\u001B[0m Trial 2 finished with value: 0.2303402065528819 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.005738030285534562, 'lmbda': 0.3895938411447514}. Best is trial 1 with value: 0.2435382709999983.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:12:31,132]\u001B[0m Trial 3 finished with value: 0.26533918818524177 and parameters: {'hidden_layer': 32, 'out_layer': 32, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.009093254871893875, 'lmbda': 0.8975029954572447}. Best is trial 3 with value: 0.26533918818524177.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:13:11,923]\u001B[0m Trial 4 finished with value: 0.2476007089820391 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.007984683308184503, 'lmbda': 0.20893732075857607}. Best is trial 3 with value: 0.26533918818524177.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:13:52,548]\u001B[0m Trial 5 finished with value: 0.25068604858111865 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009497258411672867, 'lmbda': 0.36594040469979827}. Best is trial 3 with value: 0.26533918818524177.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:14:53,914]\u001B[0m Trial 6 finished with value: 0.19510522098034397 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 2, 'lr': 0.009412826730660608, 'lmbda': 0.45554861961666915}. Best is trial 3 with value: 0.26533918818524177.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:15:57,359]\u001B[0m Trial 7 finished with value: 0.2768245520819261 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.009789344695156663, 'lmbda': 0.19703906737047228}. Best is trial 7 with value: 0.2768245520819261.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:16:37,978]\u001B[0m Trial 8 finished with value: 0.2684551552459711 and parameters: {'hidden_layer': 256, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006811291280165638, 'lmbda': 0.6725971229746023}. Best is trial 7 with value: 0.2768245520819261.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:17:18,660]\u001B[0m Trial 9 finished with value: 0.24641864503856808 and parameters: {'hidden_layer': 128, 'out_layer': 64, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.009162767323044583, 'lmbda': 0.32310451777450666}. Best is trial 7 with value: 0.2768245520819261.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:18:21,072]\u001B[0m Trial 10 finished with value: 0.21681503172116415 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.007874000940863603, 'lmbda': 0.035791902779026386}. Best is trial 7 with value: 0.2768245520819261.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:19:23,547]\u001B[0m Trial 11 finished with value: 0.2859843481570387 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006328956407552254, 'lmbda': 0.6947617835664271}. Best is trial 11 with value: 0.2859843481570387.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:20:26,282]\u001B[0m Trial 12 finished with value: 0.28625950416995627 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005193091252952718, 'lmbda': 0.6631470377067136}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:21:28,858]\u001B[0m Trial 13 finished with value: 0.2725267599166097 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005250178427025695, 'lmbda': 0.6616714555497534}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:22:31,351]\u001B[0m Trial 14 finished with value: 0.2800678788459704 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006234416144608209, 'lmbda': 0.6943289508520776}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:23:33,908]\u001B[0m Trial 15 finished with value: 0.27210964964566015 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005040664028478086, 'lmbda': 0.8899107711330482}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:24:35,902]\u001B[0m Trial 16 finished with value: 0.20233104977126423 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 3, 'lr': 0.006804685168771188, 'lmbda': 0.5838139702780465}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:25:38,670]\u001B[0m Trial 17 finished with value: 0.25589133290207294 and parameters: {'hidden_layer': 64, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.005980191017318652, 'lmbda': 0.7833676627043424}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:26:40,909]\u001B[0m Trial 18 finished with value: 0.26136016828213443 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.4, 'size of network, number of convs': 1, 'lr': 0.006835510751780502, 'lmbda': 0.9763128810290029}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:27:43,059]\u001B[0m Trial 19 finished with value: 0.18756279009556495 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 3, 'lr': 0.005613159660918943, 'lmbda': 0.5571001322165865}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:28:45,436]\u001B[0m Trial 20 finished with value: 0.27978267751106006 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006352749618596484, 'lmbda': 0.7825169909343787}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:29:48,122]\u001B[0m Trial 21 finished with value: 0.2672489371342051 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.006263679884267093, 'lmbda': 0.7236701461818937}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:30:53,857]\u001B[0m Trial 22 finished with value: 0.27937168534463425 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.007354012797783874, 'lmbda': 0.5560806817326296}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:31:56,538]\u001B[0m Trial 23 finished with value: 0.2752521675593982 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.2, 'size of network, number of convs': 1, 'lr': 0.005394161926538001, 'lmbda': 0.8115829767536841}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:33:04,272]\u001B[0m Trial 24 finished with value: 0.2528995715907073 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.30000000000000004, 'size of network, number of convs': 1, 'lr': 0.006208366512022451, 'lmbda': 0.7091443391633783}. Best is trial 12 with value: 0.28625950416995627.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:34:07,699]\u001B[0m Trial 25 finished with value: 0.28992250777439643 and parameters: {'hidden_layer': 256, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.007148271734365268, 'lmbda': 0.6178867009055727}. Best is trial 25 with value: 0.28992250777439643.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:35:32,897]\u001B[0m Trial 26 finished with value: 0.2741260304924157 and parameters: {'hidden_layer': 32, 'out_layer': 128, 'dropout': 0.0, 'size of network, number of convs': 1, 'lr': 0.0073816763535617955, 'lmbda': 0.46505170618098113}. Best is trial 25 with value: 0.28992250777439643.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:36:35,982]\u001B[0m Trial 27 finished with value: 0.26280320616372593 and parameters: {'hidden_layer': 128, 'out_layer': 128, 'dropout': 0.1, 'size of network, number of convs': 1, 'lr': 0.008353214206341645, 'lmbda': 0.5737410357232573}. Best is trial 25 with value: 0.28992250777439643.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:37:04,765]\u001B[0m Trial 28 finished with value: 0.25301770884594693 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.0, 'size of network, number of convs': 2, 'lr': 0.007069135554721826, 'lmbda': 0.6278785190815985}. Best is trial 25 with value: 0.28992250777439643.\u001B[0m\n",
      "\u001B[32m[I 2022-11-08 12:37:56,272]\u001B[0m Trial 29 finished with value: 0.2114819613453127 and parameters: {'hidden_layer': 32, 'out_layer': 64, 'dropout': 0.5, 'size of network, number of convs': 3, 'lr': 0.00859876545438895, 'lmbda': 0.5139158789721502}. Best is trial 25 with value: 0.28992250777439643.\u001B[0m\n",
      "\u001B[33m[W 2022-11-08 12:38:07,102]\u001B[0m Trial 30 failed because of the following error: KeyboardInterrupt()\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\", line 47, in objective\n",
      "    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,loss_to_train)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\", line 57, in train\n",
      "    loss = model.loss(out[self.train_mask], self.samples)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\modules\\model.py\", line 171, in lossFactorization\n",
      "    sum(out * out)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\4249768457.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m                 \u001B[0mMO\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMainOptuna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'unsupervised'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m                 \u001B[0mbest_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMO\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m500\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m                 \u001B[0mloss_trgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, number_of_trials)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mstudy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"maximize\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstudy_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Name\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" loss,\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_trials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m         \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    426\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m             \u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    429\u001B[0m         )\n\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0mprogress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             )\n\u001B[0;32m     78\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m             \u001B[0mfrozen_trial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     ):\n\u001B[1;32m--> 234\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mLossSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss_to_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m         \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, model, data, optimizer, Sampler, train_loader, dropout, epoch, loss)\u001B[0m\n\u001B[0;32m     55\u001B[0m                 \u001B[1;31m#print('after',out, sum(sum(out)))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m                 \u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msampling\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices_of_train_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m                 \u001B[1;31m#print('loss',loss)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m                 \u001B[0mtotal_loss\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\modules\\model.py\u001B[0m in \u001B[0;36mlossFactorization\u001B[1;34m(self, out, S, **kwargs)\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[0mlmbda\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_function\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"lmbda\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m         loss = 0.5 * sum(sum((S - torch.matmul(out, out.t())) * (S - torch.matmul(out, out.t())))) + 0.5 * lmbda * sum(\n\u001B[1;32m--> 171\u001B[1;33m             \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    172\u001B[0m         )\n\u001B[0;32m    173\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "loss = HOPE_CN\n",
    "loss_name = 'HOPE_CN'\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "analysis=analysis.drop(columns=['Unnamed: 0'])\n",
    "for name in datasets_names[3:4]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-08 12:50:26,646]\u001B[0m A new study created in memory with name: Node2Vec loss,GCN conv\u001B[0m\n",
      "\u001B[33m[W 2022-11-08 12:50:26,673]\u001B[0m Trial 0 failed because of the following error: TypeError(\"'NoneType' object is not callable\")\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\", line 47, in objective\n",
      "    loss = self.train(model,self.data,optimizer,LossSampler,train_loader,dropout,epoch,loss_to_train)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\", line 56, in train\n",
      "    samples = self.sampling(Sampler,epoch, indices_of_train_data,loss)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\", line 41, in sampling\n",
      "    self.samples = Sampler.sample(nodes)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\", line 84, in sample\n",
      "    return (self.pos_sample(batch), self.neg_sample(batch))\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\", line 148, in pos_sample\n",
      "    rw = RW(rowptr, col, start, self.walk_length, self.p, self.q)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2300966455.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m                 \u001B[0mMO\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMainOptuna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'unsupervised'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m                 \u001B[0mbest_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMO\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m500\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m                 \u001B[0mloss_trgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, number_of_trials)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mstudy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"maximize\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstudy_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Name\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" loss,\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_trials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m         \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    426\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m             \u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    429\u001B[0m         )\n\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0mprogress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             )\n\u001B[0;32m     78\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m             \u001B[0mfrozen_trial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     ):\n\u001B[1;32m--> 234\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mLossSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss_to_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m         \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, model, data, optimizer, Sampler, train_loader, dropout, epoch, loss)\u001B[0m\n\u001B[0;32m     54\u001B[0m                 \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minference\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m                 \u001B[1;31m#print('after',out, sum(sum(out)))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m                 \u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msampling\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices_of_train_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m                 \u001B[1;31m#print('loss',loss)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\u001B[0m in \u001B[0;36msampling\u001B[1;34m(self, Sampler, epoch, nodes, loss)\u001B[0m\n\u001B[0;32m     39\u001B[0m                         \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSampler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnodes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\u001B[0m in \u001B[0;36msample\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     82\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m             \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos_sample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mneg_sample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mabc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabstractmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\modules\\sampling.py\u001B[0m in \u001B[0;36mpos_sample\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    146\u001B[0m             \u001B[0md2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m             \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwalks_per_node\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 148\u001B[1;33m             \u001B[0mrw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRW\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrowptr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwalk_length\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    149\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "loss = Node2Vec\n",
    "loss_name = 'Node2Vec'\n",
    "device= 'cpu'\n",
    "for name in ['Cornell']:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"walks_per_node\"] = best_values['walk_length']\n",
    "                loss_trgt[\"walk_length\"] = best_values['walk_length']\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"context_size\"] = best_values['context_size']\n",
    "                loss_trgt[\"p\"] = best_values['p']\n",
    "                loss_trgt[\"q\"] = best_values['q']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-08 02:12:33,141]\u001B[0m A new study created in memory with name: VERSE_PPR loss,GCN conv\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-08 02:12:35,478]\u001B[0m Trial 0 finished with value: 0.2086996778999804 and parameters: {'hidden_layer': 64, 'out_layer': 32, 'dropout': 0.2, 'size of network, number of convs': 2, 'lr': 0.009706458885946383, 'num_negative_samples': 1, 'alpha': 0.7, 'lmbda': 0.9156151933970228}. Best is trial 0 with value: 0.2086996778999804.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m[W 2022-11-08 02:12:36,758]\u001B[0m Trial 1 failed because of the following error: CatBoostError('C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored.')\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\", line 48, in objective\n",
      "    _, [train_acc_mi, test_acc_mi,val_acc_mi], [train_acc_ma, test_acc_ma,val_acc_ma] = self.test(model=model, data=self.data)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\", line 113, in test\n",
      "    eval_set = (out.cpu().detach()[self.val_mask].numpy(), self.y.detach()[self.val_mask].cpu().numpy())\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\", line 5130, in fit\n",
      "    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\", line 2360, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "  File \"C:\\Users\\User\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored.\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2128321872.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m                 \u001B[0mMO\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMainOptuna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'unsupervised'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m                 \u001B[0mbest_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mMO\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m500\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m                 \u001B[0mloss_trgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, number_of_trials)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mstudy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"maximize\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mstudy_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Name\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" loss,\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\" conv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_trials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumber_of_trials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m         \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    426\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    427\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 428\u001B[1;33m             \u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    429\u001B[0m         )\n\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0mprogress_bar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m             )\n\u001B[0;32m     78\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m             \u001B[0mfrozen_trial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m     ):\n\u001B[1;32m--> 234\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\2299971027.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mLossSampler\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss_to_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrain_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc_ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m         \u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreport\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc_mi\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mval_acc_ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20236\\3717966241.py\u001B[0m in \u001B[0;36mtest\u001B[1;34m(self, model, data)\u001B[0m\n\u001B[0;32m    111\u001B[0m                 \u001B[1;31m#clf = LogisticRegression(max_iter = 3000,C=c).fit(out.cpu().detach()[self.train_mask].numpy(), self.y.detach()[self.train_mask].numpy())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m                 clf = CatBoostClassifier(logging_level='Silent').fit(out.cpu().detach()[self.train_mask].numpy(),self.y.detach()[self.train_mask].cpu().numpy(),\n\u001B[1;32m--> 113\u001B[1;33m                         \u001B[0meval_set\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mval_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m                      )\n\u001B[0;32m    115\u001B[0m                 \u001B[0maccs_micro\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   5128\u001B[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001B[0;32m   5129\u001B[0m                   \u001B[0meval_set\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogging_level\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumn_description\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose_eval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric_period\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5130\u001B[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001B[0m\u001B[0;32m   5131\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5132\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   2358\u001B[0m                 \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2359\u001B[0m                 \u001B[0mallow_clear_pool\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2360\u001B[1;33m                 \u001B[0mtrain_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"init_model\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2361\u001B[0m             )\n\u001B[0;32m   2362\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Benchmarking-Loss-Functions\\venv\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_train\u001B[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1758\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_clear_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minit_model\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1759\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_object\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_clear_pool\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minit_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_object\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0minit_model\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1760\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_trained_model_attributes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1761\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_catboost.pyx\u001B[0m in \u001B[0;36m_catboost._CatBoost._train\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_catboost.pyx\u001B[0m in \u001B[0;36m_catboost._CatBoost._train\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mCatBoostError\u001B[0m: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/quantization.cpp:2416: All features are either constant or ignored."
     ]
    }
   ],
   "source": [
    "loss = VERSE_PPR\n",
    "loss_name = 'VERSE_PPR'\n",
    "\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "\n",
    "for name in datasets_names[:2]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = VERSE_Adj\n",
    "loss_name = 'VERSE_Adj'\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "analysis = pd.read_csv('../results/classification_catboost.csv')\n",
    "for name in datasets_names[:2]:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#on real graphs\n",
    "loss = Force2Vec\n",
    "loss_name = 'Force2Vec'\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "for name in datasets_names[2:]:\n",
    "    for conv in ['GCN']:\n",
    "         if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                MO = MainOptuna(name = name, conv = conv, device = device, loss_function = loss, mode = 'unsupervised')\n",
    "                best_values = MO.run(number_of_trials =500)\n",
    "\n",
    "                loss_trgt = dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name, conv=conv, device=device, loss_function=loss_trgt, mode='unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = VERSE_SR\n",
    "loss_name = 'VERSE_SR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('../results/classification_catboost.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modkdjfjf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "number_of_trials = 100\n",
    "import os\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "        if len(analysis[(analysis['la'] == l)&(analysis['fa']==f)&(analysis['cl']==cl)&(analysis['asp']==asp)&(analysis['ad']==ad)] ) == 0:\n",
    "            data, train_indices,val_indices,test_indices,train_mask,val_mask,test_mask = data_load(name)\n",
    "            x = data.x.detach()\n",
    "            y = data.y.detach()\n",
    "            def objective(trial):\n",
    "            # Integer parameter\n",
    "                c = trial.suggest_categorical(\"c\",  [0.001, 0.01, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,10,20,30,100])\n",
    "                clf = LogisticRegression(max_iter = 3000, C=c).fit(x[train_mask].numpy(), y[train_mask].numpy())\n",
    "\n",
    "                accs_micro = []\n",
    "                accs_macro = []\n",
    "                for mask in [train_mask,test_mask,val_mask]:\n",
    "                    accs_micro += [f1_score(data.y.detach()[mask].numpy(),clf.predict(x[mask].numpy()), average='micro')]\n",
    "                    accs_macro += [f1_score(data.y.detach()[mask].numpy(),clf.predict(x[mask].numpy()), average='macro')]\n",
    "\n",
    "                return np.sqrt(accs_micro[2]*accs_macro[2])\n",
    "\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(objective, n_trials = number_of_trials)\n",
    "            trial = study.best_trial\n",
    "            c=trial.params['c']\n",
    "            clf = LogisticRegression(max_iter = 3000, C=c).fit(x[train_mask].numpy(), y[train_mask].numpy())\n",
    "            accs_micro = []\n",
    "            accs_macro = []\n",
    "            for mask in [train_mask,test_mask,val_mask]:\n",
    "                accs_micro += [f1_score(y[mask].numpy(),clf.predict(x[mask].numpy()), average='micro')]\n",
    "                accs_macro += [f1_score(y[mask].numpy(),clf.predict(x[mask].numpy()), average='macro')]\n",
    "\n",
    "            to_append = pd.Series([l,f,cl,asp,ad, accs_micro[0],accs_micro[1], accs_macro[0] , accs_macro[1]],index = analysis.columns)\n",
    "            analysis = analysis.append(to_append, ignore_index=True)\n",
    "            analysis.to_csv('classification_on_features.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = Force2Vec\n",
    "loss_name = 'Force2Vec'\n",
    "for (l,f,cl,asp,ad) in datasets_names:\n",
    "    name =  \"\".join(list(map(lambda x:str(x),  [l,f,cl,asp,ad])))\n",
    "    if os.path.exists('../data_benchmark/graph_'+str(name)+'_attr.npy'):\n",
    "        print('hey')\n",
    "        for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "\n",
    "                MO = MainOptuna(name = name, conv = conv, device = device, loss_function = loss, mode = 'unsupervised')\n",
    "                best_values = MO.run(number_of_trials = 500)\n",
    "\n",
    "                loss_trgt = dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_force2vec.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = VERSE_Adj\n",
    "loss_name = 'VERSE_Adj'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    " \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = VERSE_SR\n",
    "loss_name = 'VERSE_SR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = VERSE_PPR\n",
    "loss_name = 'VERSE_PPR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = LapEigen\n",
    "loss_name = 'LapEigen'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = LINE\n",
    "loss_name = 'LINE'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = GraphFactorization\n",
    "loss_name = 'GraphFactorization'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi, train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_CN\n",
    "loss_name = 'HOPE_CN'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_AA\n",
    "loss_name = 'HOPE_AA'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_RPR\n",
    "loss_name = 'HOPE_RPR'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = HOPE_Katz\n",
    "loss_name = 'HOPE_Katz'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"betta\"] = best_values['betta']\n",
    "                loss_trgt[\"lmbda\"] = best_values['lmbda']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = Node2Vec\n",
    "loss_name = 'Node2Vec'\n",
    "device = 'cpu'\n",
    "for name in ['chameleon']:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"walks_per_node\"] = best_values['walk_length']\n",
    "                loss_trgt[\"walk_length\"] = best_values['walk_length']\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"context_size\"] = best_values['context_size']\n",
    "                loss_trgt[\"p\"] = best_values['p']\n",
    "                loss_trgt[\"q\"] = best_values['q']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = DeepWalk\n",
    "loss_name = 'DeepWalk'\n",
    "device='cpu'\n",
    "for name in ['Citeseer']:\n",
    "    for conv in ['GCN','GAT','SAGE']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"walks_per_node\"] = best_values['walk_length']\n",
    "                loss_trgt[\"walk_length\"] = best_values['walk_length']\n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"context_size\"] = best_values['context_size']\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = APP\n",
    "loss_name = 'APP'\n",
    "\n",
    "for name in datasets_names:\n",
    "    for conv in ['GCN']:\n",
    "            if len(analysis[ (analysis['loss'] == loss_name) & (analysis['conv'] == conv) & (analysis['dataset'] == name)] ) == 0:\n",
    "                \n",
    "                MO = MainOptuna(name=name,conv=conv, device=device, loss_function=loss,mode= 'unsupervised')\n",
    "                best_values=MO.run(number_of_trials=500)\n",
    "\n",
    "                loss_trgt=dict()\n",
    "                for par in loss:\n",
    "                    loss_trgt[par]=loss[par]\n",
    "   \n",
    "                \n",
    "                loss_trgt[\"num_negative_samples\"] = best_values['num_negative_samples']\n",
    "                loss_trgt[\"alpha\"] = best_values['alpha']\n",
    "\n",
    "                M = Main(name=name,conv=conv, device=device, loss_function=loss_trgt,mode= 'unsupervised')\n",
    "                train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma = M.run(best_values)\n",
    "\n",
    "                to_append=pd.Series([loss_name, conv,name, train_acc_mi, test_acc_mi,train_acc_ma , test_acc_ma],index = analysis.columns)\n",
    "                analysis = analysis.append(to_append,ignore_index=True)\n",
    "                analysis.to_csv('data_analysis_realdata.csv')\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "My__RW_Neighbour.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}